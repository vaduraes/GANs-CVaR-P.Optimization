{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e879a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Remote\\anaconda3\\envs\\TF_V0\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\Remote\\anaconda3\\envs\\TF_V0\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.8.0 and strictly below 2.11.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.6.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import imageio\n",
    "from pathlib import Path\n",
    "\n",
    "#####--\n",
    "import numpy as np\n",
    "from numpy import expand_dims\n",
    "from numpy import ones\n",
    "from numpy import zeros\n",
    "from numpy.random import rand\n",
    "from numpy.random import randint\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "import numpy.random as random\n",
    "\n",
    "#Keras and tensorflow\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.datasets.cifar10 import load_data\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, TimeDistributed, RepeatVector\n",
    "from keras.layers import Conv2D,BatchNormalization\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout,Cropping2D\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Reshape\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "from keras.constraints import Constraint\n",
    "from keras.layers import Lambda\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras import backend\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.layers import Multiply\n",
    "from tensorflow_addons.image import translate as translate_tf\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "### \n",
    "from scipy.ndimage import affine_transform\n",
    "from scipy.ndimage import rotate\n",
    "\n",
    "### \n",
    "from scipy.ndimage import affine_transform\n",
    "from scipy.ndimage import rotate\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3de2c58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def PlotData_Stage1(Scenario,Tech,EnergyPu):\n",
    "  ShapeFileCoast=\"./GEO_data/ne_10m_coastline.shp\"\n",
    "  ShapeFileStates=\"./GEO_data/ne_10m_admin_1_states_provinces_lines.shp\"\n",
    "  X_LAT=np.zeros((int(len(Lat)*len(Long))),dtype=float)\n",
    "  Y_LONG=np.zeros((int(len(Lat)*len(Long))),dtype=float)\n",
    "\n",
    "  min_latitude=np.min(Lat)\n",
    "  max_latitude=np.max(Lat)\n",
    "\n",
    "  min_longitude=np.min(Long)\n",
    "  max_longitude=np.max(Long)\n",
    "\n",
    "  xlim =[min_longitude,max_longitude]\n",
    "  ylim=[min_latitude, max_latitude]\n",
    "\n",
    "  df = gpd.read_file(ShapeFileCoast)\n",
    "  df1 = gpd.read_file(ShapeFileStates)\n",
    "\n",
    "  fig, ax = plt.subplots(figsize  = None)\n",
    "  df.plot(color='black',linewidth=1,ax=ax)\n",
    "  df1.plot(color='black',linewidth=1,ax=ax)\n",
    "\n",
    "  count=0\n",
    "  for I_lat in range(len(Lat)):\n",
    "    for I_long in range(len(Long)):\n",
    "\n",
    "      Y_LONG[count]=Lat[I_lat]\n",
    "      X_LAT[count]=Long[I_long]\n",
    "      count=count+1\n",
    "\n",
    "  plt.scatter(X_LAT,Y_LONG,c=(EnergyPu[Scenario,:,:,Tech]), s=5, cmap='jet')\n",
    "  plt.colorbar()\n",
    "  ax.set_xlim(xlim)\n",
    "  ax.set_ylim(ylim)\n",
    "\n",
    "  return plt.show()\n",
    "\n",
    "NPZ_Data=np.load(\"./AggregatedData_Daily.npz\", allow_pickle=True) \n",
    "EnergyPu=NPZ_Data[\"EnergyPu\"]\n",
    "Lat=NPZ_Data[\"Lat\"]\n",
    "Long=NPZ_Data[\"Long\"]\n",
    "EnergyPu=NPZ_Data[\"EnergyPu\"]\n",
    "StartYear=NPZ_Data[\"StartYear\"]\n",
    "EndYear=NPZ_Data[\"EndYear\"]\n",
    "WindEnergy_RatedPower=float(NPZ_Data[\"WindEnergy_RatedPower\"])\n",
    "WaveEnergy_RatedPower=float(NPZ_Data[\"WaveEnergy_RatedPower\"])\n",
    "OceanEnergy_RatedPower=float(NPZ_Data[\"OceanEnergy_RatedPower\"])\n",
    "\n",
    "NPZ_Data_Yearly=np.load(\"AggregatedData_Daily.npz\", allow_pickle=True) \n",
    "EnergyPu_Yearly=NPZ_Data_Yearly[\"EnergyPu\"]\n",
    "\n",
    "Idx_Exclude=np.max(EnergyPu_Yearly[:,:,:,1],axis=0)<=0.001\n",
    "EnergyPu[:,Idx_Exclude,:]=0\n",
    "\n",
    "Idx_Exclude_Ocean=np.max(EnergyPu_Yearly[:,:,:,2],axis=0)<=0.05\n",
    "EnergyPu[:,Idx_Exclude_Ocean,2]=0\n",
    "    \n",
    "#EnergyPu=np.round(EnergyPu*255)#Put data in image format for convenience\n",
    "#Extend data 25x25> 26x26 to improve in the padding\n",
    "\n",
    "Idx_Exclude=np.max(EnergyPu_Yearly[:,:,:,1],axis=0)>0.05\n",
    "\n",
    "Idx_Exclude_Ocean=np.max(EnergyPu_Yearly[:,:,:,2],axis=0)>0.05\n",
    "Idx_Exclude_Ocean=np.reshape(Idx_Exclude_Ocean*1,(25,25,1))\n",
    "\n",
    "Idx_Exclude=np.reshape(Idx_Exclude*1,(25,25,1))\n",
    "Idx_Exclude=np.repeat(Idx_Exclude,2,axis=2)\n",
    "\n",
    "Idx_Exclude=np.concatenate((Idx_Exclude,Idx_Exclude_Ocean),axis=2)\n",
    "\n",
    "PlotData_Stage1(1,2,EnergyPu)\n",
    "\n",
    "min=np.mean(EnergyPu,axis=0)\n",
    "MaxMin=1\n",
    "EnergyPu=(EnergyPu-min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11552349",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to smooth zeros points\n",
    "XY=np.zeros((25,25,2),dtype=float)\n",
    "\n",
    "for x in range(25):\n",
    "    for y in range(25):\n",
    "        XY[x,y,0]=x\n",
    "        XY[x,y,1]=y\n",
    "\n",
    "def distance_matrix(x0, y0, x1, y1):\n",
    "    obs = np.vstack((x0, y0)).T\n",
    "    interp = np.vstack((x1, y1)).T\n",
    "\n",
    "    d0 = np.subtract.outer(obs[:,0], interp[:,0])\n",
    "    d1 = np.subtract.outer(obs[:,1], interp[:,1])\n",
    "\n",
    "    return np.hypot(d0, d1)\n",
    "\n",
    "EnergyPu_tmp=np.copy(EnergyPu)\n",
    "for t in range(3):\n",
    "    for x in range(25):\n",
    "        for y in range(25):\n",
    "            if Idx_Exclude[x,y,t]==0:\n",
    "                z=EnergyPu[:,Idx_Exclude[:,:,t]==1,t]\n",
    "                xy=XY[Idx_Exclude[:,:,t]==1,:]\n",
    "                d=distance_matrix(xy[:,0], xy[:,1], x, y)\n",
    "                weights = 1.0 / d**3\n",
    "                weights  /= weights.sum(axis=0)\n",
    "                for i in range(z.shape[0]):\n",
    "                    EnergyPu_tmp[i,x,y,t]=np.dot(weights[:,0], z[i])\n",
    "                    \n",
    "EnergyPu=EnergyPu_tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e36a8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAKE_GIF (GENERATOR, latent_dim_G, TrainData,ImageShape,number=0):\n",
    "  for j in range(1):\n",
    "    X_gan = generate_latent_points(latent_dim_G, 3)\n",
    "    FakeImage=GENERATOR.predict(X_gan)*MaxMin+min\n",
    "\n",
    "    IDX_REAL=random.randint(0, 2000)\n",
    "\n",
    "    RealImage=TrainData[IDX_REAL,:,:,:]\n",
    "\n",
    "    count=0\n",
    "    X_LAT=np.zeros((int(len(Lat)*len(Long))),dtype=float)\n",
    "    Y_LONG=np.zeros((int(len(Lat)*len(Long))),dtype=float)\n",
    "\n",
    "    for I_lat in range(len(Lat)):\n",
    "      for I_long in range(len(Long)):\n",
    "\n",
    "        Y_LONG[count]=Lat[I_lat]\n",
    "        X_LAT[count]=Long[I_long]\n",
    "        count=count+1\n",
    "\n",
    "    min_longitude=-77\n",
    "    max_longitude=-74.5\n",
    "\n",
    "    min_latitude=34\n",
    "    max_latitude=36.5\n",
    "    xlim =[min_longitude,max_longitude]\n",
    "    ylim=[min_latitude, max_latitude]\n",
    "\n",
    "    ShapeFileCoast=\"./GEO_data/ne_10m_coastline.shp\"\n",
    "    ShapeFileStates=\"./GEO_data/ne_10m_admin_1_states_provinces_lines.shp\"\n",
    "\n",
    "    df = gpd.read_file(ShapeFileCoast)\n",
    "    df1 = gpd.read_file(ShapeFileStates)\n",
    "\n",
    "    Real_FLAT=np.zeros((int(RealImage.shape[0]*RealImage.shape[1]),RealImage.shape[2]))\n",
    "    Fake_FLAT=np.zeros((int(RealImage.shape[0]*RealImage.shape[1]),RealImage.shape[2]))\n",
    "\n",
    "    for i in range(RealImage.shape[2]):\n",
    "      Real_FLAT[:,i]=np.reshape(TrainData[random.randint(0, 2000),:,:,2],-1)\n",
    "      Fake_FLAT[:,i]=np.reshape(FakeImage[i,:,:,2],-1)\n",
    "\n",
    "    print(\"Processing Figure \"+str(j))\n",
    "    fig, axs = plt.subplots(RealImage.shape[2], 2)\n",
    "\n",
    "    for i in range(RealImage.shape[2]):\n",
    "\n",
    "      z1_plot=axs[i,0].scatter(X_LAT,Y_LONG,c=Real_FLAT[:,i], s=0.3, cmap='jet')\n",
    "      df.plot(color='black',linewidth=1,ax=axs[i,0])\n",
    "      df1.plot(color='black',linewidth=1,ax=axs[i,0])\n",
    "      axs[i,0].set_xlim(xlim)\n",
    "      axs[i,0].set_ylim(ylim)\n",
    "      axs[0,0].set_title('Real Data', fontsize=10)\n",
    "\n",
    "      axs[i,0].set_xlabel('Longitude', fontsize=10)\n",
    "      axs[i,0].set_ylabel('Latitude', fontsize=10)\n",
    "\n",
    "\n",
    "      if i<=1: \n",
    "        axs[i,0].get_xaxis().set_visible(False)\n",
    "\n",
    "      clb=fig.colorbar(z1_plot, ax=axs[i,0])\n",
    "\n",
    "      z2_plot =axs[i,1].scatter(X_LAT,Y_LONG,c=Fake_FLAT[:,i], s=0.3, cmap='jet')\n",
    "      df.plot(color='black',linewidth=1,ax=axs[i,1])\n",
    "      df1.plot(color='black',linewidth=1,ax=axs[i,1])\n",
    "\n",
    "\n",
    "      if i==0:\n",
    "        clb.ax.set_title('CF', fontsize=8)\n",
    "      axs[i,1].set_xlim(xlim)\n",
    "      axs[i,1].set_ylim(ylim)\n",
    "\n",
    "      axs[i,1].set_xlabel('Longitude', fontsize=10)\n",
    "      axs[i,1].set_ylabel('Latitude', fontsize=10)\n",
    "\n",
    "      if i<=1: \n",
    "        axs[i,1].get_xaxis().set_visible(False)\n",
    "\n",
    "      clb=fig.colorbar(z1_plot, ax=axs[i,1])\n",
    "\n",
    "      if i==0:\n",
    "        clb.ax.set_title('CF', fontsize=8)\n",
    "\n",
    "      if i<=1: \n",
    "        axs[i,1].get_xaxis().set_visible(False)\n",
    "      axs[0,1].set_title('Fake Data', fontsize=10)\n",
    "\n",
    "    \n",
    "\n",
    "    plt.savefig('./Plots_Tmp/Iteration'+str(number)+'.png',dpi=200)\n",
    "    plt.close() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2564bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MMD(x, y, kernel=\"rbf\"):\n",
    "    \"\"\"Emprical maximum mean discrepancy. The lower the result\n",
    "       the more evidence that distributions are the same.\n",
    "\n",
    "    Args:\n",
    "        x: first sample, distribution P\n",
    "        y: second sample, distribution Q\n",
    "        kernel: kernel type such as \"multiscale\" or \"rbf\"\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cpu\")\n",
    "    x.to(device)\n",
    "    y.to(device)\n",
    "\n",
    "    xx, yy, zz = torch.mm(x, x.t()), torch.mm(y, y.t()), torch.mm(x, y.t())\n",
    "    rx = (xx.diag().unsqueeze(0).expand_as(xx))\n",
    "    ry = (yy.diag().unsqueeze(0).expand_as(yy))\n",
    "\n",
    "    dxx = rx.t() + rx - 2. * xx \n",
    "    dyy = ry.t() + ry - 2. * yy \n",
    "    dxy = rx.t() + ry - 2. * zz \n",
    "\n",
    "    dxx=dxx.to(device)\n",
    "    dyy=dyy.to(device)\n",
    "    dxy=dxy.to(device)\n",
    "\n",
    "    XX, YY, XY = (torch.zeros(xx.shape).to(device),\n",
    "                  torch.zeros(xx.shape).to(device),\n",
    "                  torch.zeros(xx.shape).to(device))\n",
    "\n",
    "    if kernel == \"multiscale\":\n",
    "        \n",
    "        bandwidth_range = [0.2, 0.5, 0.9, 1.3]\n",
    "        for a in bandwidth_range:\n",
    "            XX += a**2 * (a**2 + dxx)**-1\n",
    "            YY += a**2 * (a**2 + dyy)**-1\n",
    "            XY += a**2 * (a**2 + dxy)**-1\n",
    "            \n",
    "    if kernel == \"rbf\":\n",
    "      \n",
    "        bandwidth_range = [10, 15, 20, 50]\n",
    "        for a in bandwidth_range:\n",
    "            XX += torch.exp(-0.5*dxx/a)\n",
    "            YY += torch.exp(-0.5*dyy/a)\n",
    "            XY += torch.exp(-0.5*dxy/a)\n",
    "     \n",
    "    return torch.mean(XX + YY - 2. * XY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3255f474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Augmentation_Layer(in_shape=[25,25,3]):\n",
    "    x                = Input(shape=(25,25,3,))\n",
    "\n",
    "    p                = Input(shape=(6,))#Apply Transformation\n",
    "    InvP             = Lambda(lambda p: 1. - p)(p) #Not Apply Transformation\n",
    "\n",
    "    x_shape=x.shape[2]\n",
    "    y_shape=x.shape[1]\n",
    "    \n",
    "    #Reflect Image Reflect image in all directions to assure that minimize the effect of distortions\n",
    "    ImageFlip_x      = tf.image.flip_left_right(x)\n",
    "    x_flat           = tf.keras.layers.Reshape((x.shape[1],x.shape[2],x.shape[3]))(x)\n",
    "    x_temp           = tf.keras.backend.stack([ImageFlip_x, x_flat, ImageFlip_x],axis=2)\n",
    "    x_temp           = tf.keras.layers.Reshape((y_shape,x_shape*3,3))(x_temp)\n",
    "\n",
    "    ImageFlip_y      = tf.image.flip_up_down(x_temp)\n",
    "    x_temp           = tf.keras.backend.stack([ImageFlip_y, x_temp, ImageFlip_y],axis=1)\n",
    "    x_reflected      = tf.keras.layers.Reshape((y_shape*3,x_shape*3,3))(x_temp)\n",
    "    y=x_reflected\n",
    "\n",
    "    #Augmentation 1: Flip-x\n",
    "    y_temp_1         = tf.keras.layers.RandomFlip(mode=\"horizontal\")(y,training=True)\n",
    "    y                = tf.keras.layers.Add()([tf.keras.layers.Multiply()([y_temp_1,p[:,0]]), tf.keras.layers.Multiply()([y,InvP[:,0]])]) #Differentiable equation to define if the change will be propagated or not\n",
    "\n",
    "    #Augmentation 2: 90 Rotations\n",
    "    K                = Lambda(lambda m: tf.keras.backend.round(tf.squeeze(tf.keras.backend.random_uniform([1],minval=1,maxval=4.1))))(x) \n",
    "    K                = tf.cast(K,tf.int32)\n",
    "    y_temp_2         = tf.image.rot90(y, k=K) #90, 180, 270 degrees\n",
    "    y                = tf.keras.layers.Add()([tf.keras.layers.Multiply()([y_temp_2, p[:,1]]), tf.keras.layers.Multiply()([y, InvP[:,1]])]) #Differentiable equation to define if the change will be propagated or not\n",
    "\n",
    "    #Augmentation 3: Translation (will not show outside traning)\n",
    "    y_temp_3         = tf.keras.layers.experimental.preprocessing.RandomTranslation(0.1, 0.1)(y,training=True)\n",
    "    y                = tf.keras.layers.Add()([tf.keras.layers.Multiply()([y_temp_3, p[:,2]]), tf.keras.layers.Multiply()([y, InvP[:,2]])]) #Differentiable equation to define if the change will be propagated or not\n",
    "\n",
    "    #Augmentation 4: Arbitrary Rotation\n",
    "    y_temp_4         = tf.keras.layers.experimental.preprocessing.RandomRotation(0.5)(y,training=True) #https://docs.w3cub.com/tensorflow~2.3/keras/layers/experimental/preprocessing/randomrotation\n",
    "    y                = tf.keras.layers.Add()([tf.keras.layers.Multiply()([y_temp_4,p[:,3]]), tf.keras.layers.Multiply()([y,InvP[:,3]])]) #Differentiable equation to define if the change will be propagated or not\n",
    "\n",
    "    #Augmentation 5: Isotropic Scaling\n",
    "    y_temp_5         = tf.keras.layers.RandomZoom(0.1)(y,training=True)\n",
    "    y                = tf.keras.layers.Add()([tf.keras.layers.Multiply()([y_temp_5,p[:,4]]), tf.keras.layers.Multiply()([y,InvP[:,4]])]) #Differentiable equation to define if the change will be propagated or not\n",
    "\n",
    "    #Augmentation 6: Anisotropic Scaling\n",
    "    y_temp_6         = tf.keras.layers.RandomZoom(0.1,0.1)(y,training=True)\n",
    "    y                = tf.keras.layers.Add()([tf.keras.layers.Multiply()([y_temp_6,p[:,5]]), tf.keras.layers.Multiply()([y,InvP[:,5]])]) #Differentiable equation to define if the change will be propagated or not\n",
    "\n",
    "    #Reduce shape to the Original Size (Last Step)\n",
    "    y=tf.keras.layers.CenterCrop(25, 25)(y)\n",
    "\n",
    "    model=Model(inputs=[x,p], outputs=y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3e2034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original\n",
    "Idx_Exclude1=np.ones((25,25,3))\n",
    "def G_Create_CNN(latent_dim_G,Idx_Exclude=Idx_Exclude1, in_shape=(25,25,3)):\n",
    "  \n",
    "  x = Input(shape=(latent_dim_G,),name=\"Image\")\n",
    "  #Layer1\n",
    "\n",
    "  n_nodes = 512* 4 * 4 # foundation for 4x4 image\n",
    "\n",
    "  y=Dense(n_nodes)(x)\n",
    "  y=BatchNormalization()(y)\n",
    "  y=LeakyReLU(alpha=0.2)(y)\n",
    "  y=Reshape((4, 4, 512))(y)\n",
    "\n",
    "  y=Conv2DTranspose(512, (3,3), strides=(2,2), padding='same')(y)\n",
    "  y=BatchNormalization()(y)\n",
    "  y=LeakyReLU(alpha=0.2)(y)\n",
    "\n",
    "  y=Conv2DTranspose(512, (3,3), strides=(1,1), padding='same')(y)\n",
    "  y=BatchNormalization()(y)\n",
    "  y=LeakyReLU(alpha=0.2)(y)\n",
    "\n",
    "  #Layer2\n",
    "  y=Conv2DTranspose(256, (3,3), strides=(2,2), padding='same')(y)\n",
    "  y=BatchNormalization()(y)\n",
    "  y=LeakyReLU(alpha=0.2)(y)\n",
    "\n",
    "  y=Conv2DTranspose(256, (3,3), strides=(1,1), padding='same')(y)\n",
    "  y=BatchNormalization()(y)\n",
    "  y=LeakyReLU(alpha=0.2)(y)\n",
    "\n",
    "  #Layer3\n",
    "  y=Conv2DTranspose(256, (3,3), strides=(2,2), padding='same')(y)\n",
    "  y=BatchNormalization()(y)\n",
    "  y012=LeakyReLU(alpha=0.2)(y)\n",
    "\n",
    "\n",
    "  # upsample to 40x60\n",
    "  y=Conv2DTranspose(128, (3,3), strides=(1,1), padding='same')(y)\n",
    "  y=BatchNormalization()(y)\n",
    "  y=LeakyReLU(alpha=0.2)(y)\n",
    "\n",
    "\n",
    "  # output layer\n",
    "  y=Conv2D(3, (3,3),  padding='same')(y)\n",
    "  y=Cropping2D(cropping=((4, 3), (4, 3)))(y)\n",
    "\n",
    "  y=Lambda(lambda InputLayer: InputLayer*Idx_Exclude,input_shape=in_shape)(y)\n",
    "  model=Model(x, y)\n",
    "\n",
    "  return model\n",
    "\n",
    "# use the generator to generate n fake examples\n",
    "def generate_fake_samples(GENERATOR, latent_dim_G, n_samples):\n",
    "  x_input = generate_latent_points(latent_dim_G, n_samples)\n",
    "\n",
    "  # predict outputs\n",
    "  X = GENERATOR.predict(x_input)\n",
    "\n",
    "  # create 'fake' class labels (0)\n",
    "  y = zeros((n_samples, 1))\n",
    "  return X, y\n",
    "\n",
    "def generate_latent_points(latent_dim_G, n_samples):\n",
    "  x_input = randn(latent_dim_G * n_samples)\n",
    "  x_input = x_input.reshape(n_samples, latent_dim_G)\n",
    "\n",
    "  return x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3baaa962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the standalone generator model (CNN)\n",
    "# define the standalone discriminator model\n",
    "AugmentModel=Augmentation_Layer(in_shape=[25,25,3])\n",
    "AugmentModel.__name__=\"Augmentation\"\n",
    "def D_Create_CNN(in_shape=(25,25,3),AugmentModel=AugmentModel):\n",
    "\n",
    "  x = Input(shape=(in_shape[0],in_shape[1],in_shape[2],),name=\"Image\")\n",
    "  p = Input(shape=(6,),name=\"Maskp\")\n",
    "  y = Lambda(AugmentModel)((x,p))\n",
    "\n",
    "  y=Conv2D(64, (3,3), padding='same', input_shape=in_shape)(x)\n",
    "  y=LeakyReLU(alpha=0.2)(y)\n",
    "  \n",
    "  y=Conv2D(128, (3,3), padding='same')(y)\n",
    "  y=LeakyReLU(alpha=0.2)(y)\n",
    "  \n",
    "  y=Conv2D(128, (3,3), strides=(2,2), padding='same')(y)\n",
    "  y=LeakyReLU(alpha=0.2)(y)\n",
    "\n",
    "  # # Layer2 \n",
    "  y=Conv2D(256, (3,3), strides=(1,1), padding='same')(y)\n",
    "  y=LeakyReLU(alpha=0.2)(y)\n",
    "\n",
    "  y=Conv2D(256, (3,3), strides=(2,2), padding='same')(y)\n",
    "  y=LeakyReLU(alpha=0.2)(y)\n",
    "\n",
    "  ##Layer3\n",
    "  y=Conv2D(512, (3,3), strides=(1,1), padding='same')(y)\n",
    "  y=LeakyReLU(alpha=0.2)(y)\n",
    "\n",
    "  y=Conv2D(512, (3,3), strides=(2,2), padding='same')(y)\n",
    "  y=LeakyReLU(alpha=0.2)(y)\n",
    "\n",
    "  # #Layer4\n",
    "  y=Flatten()(y)\n",
    "  y=Dense(1)(y)\n",
    "  opt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "\n",
    "  model = Model((x,p), y)\n",
    "\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "890efec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasBatchGenerator(object):\n",
    "\n",
    "    def __init__(self, data, batch_size, ImageShape):\n",
    "        self.data = data\n",
    "        self.ImageShape=ImageShape #[x, y, # of chanels]\n",
    "        self.batch_size = batch_size\n",
    "        # this will track the progress of the batches sequentially through the\n",
    "        # data set - once the data reaches the end of the data set it will reset\n",
    "        # back to zero\n",
    "        self.current_idx = 0\n",
    "\n",
    "    def generate(self):\n",
    "        x = np.zeros((self.batch_size, self.ImageShape[0], self.ImageShape[1], self.ImageShape[2]),dtype=float)\n",
    "        y = np.zeros((self.batch_size, 1),dtype=float)\n",
    "        while True:\n",
    "            for i in range(self.batch_size):\n",
    "                if self.current_idx>= len(self.data):\n",
    "                    # reset the index back to the start of the data set\n",
    "                    self.current_idx = 0\n",
    "                x[i,:,:,:] = self.data[self.current_idx]\n",
    "                # convert all of temp_y into a one hot representation\n",
    "                y[i, 0] = 1\n",
    "                self.current_idx += 1\n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "994da791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(DISCRIMINATOR, batch_size, real_images, fake_images):\n",
    "    \"\"\" Calculates the gradient penalty.\n",
    "\n",
    "    This loss is calculated on an interpolated image\n",
    "    and added to the discriminator loss.\n",
    "    \"\"\"\n",
    "    # Get the interpolated image\n",
    "    alpha = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n",
    "    diff = fake_images - real_images\n",
    "    interpolated = real_images + alpha * diff\n",
    "\n",
    "    with tf.GradientTape() as gp_tape:\n",
    "        gp_tape.watch(interpolated)\n",
    "        # 1. Get the discriminator output for this interpolated image.\n",
    "        p_f=np.zeros((interpolated.shape[0],6))    \n",
    "        pred = DISCRIMINATOR((interpolated,p_f), training=True)\n",
    "\n",
    "    # 2. Calculate the gradients w.r.t to this interpolated image.\n",
    "    grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "    # 3. Calculate the norm of the gradients.\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "    gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "    return gp\n",
    "def discriminator_loss(real_img, fake_img):\n",
    "    real_loss = tf.reduce_mean(real_img)\n",
    "    fake_loss = tf.reduce_mean(fake_img)\n",
    "    return fake_loss - real_loss\n",
    "\n",
    "\n",
    "# Define the loss functions for the generator.\n",
    "def generator_loss(fake_img):\n",
    "    return -tf.reduce_mean(fake_img)\n",
    "\n",
    "generator_optimizer = keras.optimizers.Adam(\n",
    "    learning_rate=0.0002, beta_1=0.5, beta_2=0.9\n",
    ")\n",
    "discriminator_optimizer = keras.optimizers.Adam(\n",
    "    learning_rate=0.0002, beta_1=0.5, beta_2=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b2edc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(GENERATOR, DISCRIMINATOR, latent_dim_G, TrainData, batch_size, NumEpochs,ImageShape):\n",
    "  Prob_Limit=0.0 #% of time the augmentation is applied\n",
    "  count_p_update=0\n",
    "  bat_per_epo = int(TrainData.shape[0] / (batch_size/2))+1\n",
    "  train_data_generator=KerasBatchGenerator (TrainData, batch_size, ImageShape)\n",
    "\n",
    "  KID=[]\n",
    "  KID_A=0\n",
    "\n",
    "  for i in range(NumEpochs):\n",
    "    if i!=0 and i%10==0:\n",
    "      MAKE_GIF (GENERATOR, latent_dim_G, TrainData, ImageShape, number=i)\n",
    "      GENERATOR.save(\"./SaveStep_Tmp/GENERATOR_W_VS\"+str(i)+\".hdf5\")\n",
    "      DISCRIMINATOR.save(\"./SaveStep_Tmp/DISCRIMINATOR_W_VS\"+str(i)+\".hdf5\")\n",
    "      x_torch=torch.from_numpy(np.reshape(TrainData,(TrainData.shape[0],-1))).double()\n",
    "      y_gan, _ = generate_fake_samples(GENERATOR, latent_dim_G, TrainData.shape[0])\n",
    "      y_torch=torch.from_numpy(np.reshape(y_gan,(y_gan.shape[0],-1))).double()\n",
    "      KID_A=MMD(x_torch, y_torch, kernel=\"rbf\")\n",
    "      KID.append(KID_A)\n",
    "      np.savez(\"./SaveStep_Tmp/PerformanceTrack.npz\", KID=KID)\n",
    "\n",
    "    for j in range(bat_per_epo):\n",
    "\n",
    "      X_gan = generate_latent_points(latent_dim_G, batch_size)\n",
    "      X_TD,_=next(train_data_generator.generate()) #Get real examples\n",
    "\n",
    "      with tf.GradientTape() as tape:\n",
    "          # Generate fake images from the latent vector\n",
    "          fake_images = GENERATOR(X_gan, training=True)\n",
    "\n",
    "          # Get the logits for the fake images\n",
    "\n",
    "          p_f=np.random.random((fake_images.shape[0],6))    \n",
    "          p_f=(p_f<=Prob_Limit)*1# If 1 we appy the augmentation, if 0 we do not apply the augmentation\n",
    "          fake_logits = DISCRIMINATOR((fake_images,p_f), training=True)\n",
    "          # Get the logits for the real images\n",
    "\n",
    "          p_r=np.random.random((X_TD.shape[0],6))    \n",
    "          p_r=(p_r<=Prob_Limit)*1# If 1 we appy the augmentation, if 0 we do not apply the augmentation  \n",
    "          real_logits = DISCRIMINATOR((X_TD,p_r), training=True)\n",
    "\n",
    "          # Calculate the discriminator loss using the fake and real image logits\n",
    "\n",
    "          d_cost = discriminator_loss(real_img=real_logits, fake_img=fake_logits)\n",
    "          # Calculate the gradient penalty\n",
    "          gp = gradient_penalty(DISCRIMINATOR,batch_size, X_TD, fake_images)\n",
    "          # Add the gradient penalty to the original discriminator loss\n",
    "          d_loss = d_cost + gp * 10.0\n",
    "\n",
    "      # Get the gradients w.r.t the discriminator loss\n",
    "      d_gradient = tape.gradient(d_loss, DISCRIMINATOR.trainable_variables)\n",
    "      # Update the weights of the discriminator using the discriminator optimizer\n",
    "      discriminator_optimizer.apply_gradients(zip(d_gradient, DISCRIMINATOR.trainable_variables))\n",
    "\n",
    "      # Train the generator\n",
    "      # Get the latent vector\n",
    "      X_gan = generate_latent_points(latent_dim_G, batch_size)\n",
    "      with tf.GradientTape() as tape:\n",
    "          # Generate fake images using the generator\n",
    "          generated_images = GENERATOR(X_gan, training=True)\n",
    "          # Get the discriminator logits for fake images\n",
    "          p_f=np.random.random((generated_images.shape[0],6))    \n",
    "          p_f=(p_f<=Prob_Limit)*1# If 1 we appy the augmentation, if 0 we do not apply the augmentation\n",
    "          gen_img_logits = DISCRIMINATOR((generated_images,p_f), training=True)\n",
    "          # Calculate the generator loss\n",
    "          g_loss = generator_loss(gen_img_logits)\n",
    "\n",
    "      # Get the gradients w.r.t the generator loss\n",
    "      gen_gradient = tape.gradient(g_loss, GENERATOR.trainable_variables)\n",
    "      # Update the weights of the generator using the generator optimizer\n",
    "      generator_optimizer.apply_gradients(zip(gen_gradient, GENERATOR.trainable_variables))\n",
    "      \n",
    "      KID.append(KID_A)\n",
    "\n",
    "      # count_p_update+=1     \t\n",
    "      # if count_p_update==4:\n",
    "      #   count_p_update=0\n",
    "      #   AverageAccuracy_Discriminator=dF_hist_A[-4:] + dR_hist_A[-4:] #concatenate accuracy of the discriminator for fake and real iamges\n",
    "      #   AverageAccuracy_Discriminator=np.mean(AverageAccuracy_Discriminator)\n",
    "\n",
    "      #   if AverageAccuracy_Discriminator>=0.6: #Value suggested by the paper\n",
    "      #     Prob_Limit=np.minimum(0.8,Prob_Limit+0.01) #Too precise need better gradients. More augmentation\n",
    "      #   else:\n",
    "      #     Prob_Limit=np.maximum(0,Prob_Limit-0.01)\n",
    "\n",
    "#-------------------------------------------------------------------------------      \n",
    "      # summarize loss on this batch\n",
    "      print('epoch %d, batch %d, d_loss=%.3f g_loss=%.3f KID= %.5f'% (i,j,d_loss,g_loss,KID[-1]))\t\n",
    "\n",
    "  return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "432c747a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, batch 0, d_loss=9.708 g_loss=0.275 KID= 0.00000\n",
      "epoch 0, batch 1, d_loss=9.522 g_loss=0.785 KID= 0.00000\n",
      "epoch 0, batch 2, d_loss=9.083 g_loss=1.676 KID= 0.00000\n",
      "epoch 0, batch 3, d_loss=8.073 g_loss=3.606 KID= 0.00000\n",
      "epoch 0, batch 4, d_loss=4.835 g_loss=10.344 KID= 0.00000\n",
      "epoch 0, batch 5, d_loss=-2.191 g_loss=24.337 KID= 0.00000\n",
      "epoch 0, batch 6, d_loss=-13.276 g_loss=47.565 KID= 0.00000\n",
      "epoch 0, batch 7, d_loss=-28.774 g_loss=88.679 KID= 0.00000\n",
      "epoch 0, batch 8, d_loss=-5.798 g_loss=34.097 KID= 0.00000\n",
      "epoch 0, batch 9, d_loss=-13.424 g_loss=20.096 KID= 0.00000\n",
      "epoch 0, batch 10, d_loss=-7.066 g_loss=13.010 KID= 0.00000\n",
      "epoch 0, batch 11, d_loss=-3.808 g_loss=11.193 KID= 0.00000\n",
      "epoch 0, batch 12, d_loss=-3.014 g_loss=10.298 KID= 0.00000\n",
      "epoch 0, batch 13, d_loss=-3.126 g_loss=10.883 KID= 0.00000\n",
      "epoch 0, batch 14, d_loss=-5.999 g_loss=15.499 KID= 0.00000\n",
      "epoch 0, batch 15, d_loss=-4.633 g_loss=13.220 KID= 0.00000\n",
      "epoch 0, batch 16, d_loss=-2.256 g_loss=9.056 KID= 0.00000\n",
      "epoch 0, batch 17, d_loss=-3.462 g_loss=9.542 KID= 0.00000\n",
      "epoch 0, batch 18, d_loss=-2.752 g_loss=8.749 KID= 0.00000\n",
      "epoch 0, batch 19, d_loss=-2.393 g_loss=8.247 KID= 0.00000\n",
      "epoch 1, batch 0, d_loss=-2.669 g_loss=8.326 KID= 0.00000\n",
      "epoch 1, batch 1, d_loss=-2.754 g_loss=8.684 KID= 0.00000\n",
      "epoch 1, batch 2, d_loss=-3.656 g_loss=9.468 KID= 0.00000\n",
      "epoch 1, batch 3, d_loss=-3.236 g_loss=8.600 KID= 0.00000\n",
      "epoch 1, batch 4, d_loss=-2.919 g_loss=8.148 KID= 0.00000\n",
      "epoch 1, batch 5, d_loss=-2.944 g_loss=8.254 KID= 0.00000\n",
      "epoch 1, batch 6, d_loss=-3.862 g_loss=10.498 KID= 0.00000\n",
      "epoch 1, batch 7, d_loss=-3.773 g_loss=9.195 KID= 0.00000\n",
      "epoch 1, batch 8, d_loss=-0.632 g_loss=5.331 KID= 0.00000\n",
      "epoch 1, batch 9, d_loss=1.188 g_loss=3.878 KID= 0.00000\n",
      "epoch 1, batch 10, d_loss=0.900 g_loss=6.309 KID= 0.00000\n",
      "epoch 1, batch 11, d_loss=-2.370 g_loss=14.155 KID= 0.00000\n",
      "epoch 1, batch 12, d_loss=-4.765 g_loss=14.287 KID= 0.00000\n",
      "epoch 1, batch 13, d_loss=-3.387 g_loss=10.675 KID= 0.00000\n",
      "epoch 1, batch 14, d_loss=-2.924 g_loss=9.220 KID= 0.00000\n",
      "epoch 1, batch 15, d_loss=1.931 g_loss=4.974 KID= 0.00000\n",
      "epoch 1, batch 16, d_loss=6.115 g_loss=1.860 KID= 0.00000\n",
      "epoch 1, batch 17, d_loss=5.012 g_loss=3.130 KID= 0.00000\n",
      "epoch 1, batch 18, d_loss=3.088 g_loss=5.654 KID= 0.00000\n",
      "epoch 1, batch 19, d_loss=0.353 g_loss=9.597 KID= 0.00000\n",
      "epoch 2, batch 0, d_loss=-1.978 g_loss=12.157 KID= 0.00000\n",
      "epoch 2, batch 1, d_loss=-4.067 g_loss=13.600 KID= 0.00000\n",
      "epoch 2, batch 2, d_loss=-2.837 g_loss=12.225 KID= 0.00000\n",
      "epoch 2, batch 3, d_loss=-2.027 g_loss=9.890 KID= 0.00000\n",
      "epoch 2, batch 4, d_loss=-1.099 g_loss=7.571 KID= 0.00000\n",
      "epoch 2, batch 5, d_loss=0.930 g_loss=4.226 KID= 0.00000\n",
      "epoch 2, batch 6, d_loss=-0.596 g_loss=5.756 KID= 0.00000\n",
      "epoch 2, batch 7, d_loss=-2.478 g_loss=7.036 KID= 0.00000\n",
      "epoch 2, batch 8, d_loss=-1.427 g_loss=5.015 KID= 0.00000\n",
      "epoch 2, batch 9, d_loss=-1.351 g_loss=4.412 KID= 0.00000\n",
      "epoch 2, batch 10, d_loss=-2.044 g_loss=5.999 KID= 0.00000\n",
      "epoch 2, batch 11, d_loss=-2.148 g_loss=7.231 KID= 0.00000\n",
      "epoch 2, batch 12, d_loss=-1.552 g_loss=6.521 KID= 0.00000\n",
      "epoch 2, batch 13, d_loss=-3.151 g_loss=8.976 KID= 0.00000\n",
      "epoch 2, batch 14, d_loss=-1.792 g_loss=7.353 KID= 0.00000\n",
      "epoch 2, batch 15, d_loss=-1.422 g_loss=7.099 KID= 0.00000\n",
      "epoch 2, batch 16, d_loss=-3.432 g_loss=9.695 KID= 0.00000\n",
      "epoch 2, batch 17, d_loss=-1.905 g_loss=6.961 KID= 0.00000\n",
      "epoch 2, batch 18, d_loss=-2.412 g_loss=8.426 KID= 0.00000\n",
      "epoch 2, batch 19, d_loss=-3.915 g_loss=8.522 KID= 0.00000\n",
      "epoch 3, batch 0, d_loss=-1.549 g_loss=7.434 KID= 0.00000\n",
      "epoch 3, batch 1, d_loss=-5.523 g_loss=11.680 KID= 0.00000\n",
      "epoch 3, batch 2, d_loss=-2.416 g_loss=8.071 KID= 0.00000\n",
      "epoch 3, batch 3, d_loss=-4.641 g_loss=10.185 KID= 0.00000\n",
      "epoch 3, batch 4, d_loss=-2.795 g_loss=9.273 KID= 0.00000\n",
      "epoch 3, batch 5, d_loss=-5.911 g_loss=10.811 KID= 0.00000\n",
      "epoch 3, batch 6, d_loss=-2.810 g_loss=12.207 KID= 0.00000\n",
      "epoch 3, batch 7, d_loss=-4.502 g_loss=11.334 KID= 0.00000\n",
      "epoch 3, batch 8, d_loss=-3.032 g_loss=11.710 KID= 0.00000\n",
      "epoch 3, batch 9, d_loss=-4.426 g_loss=17.851 KID= 0.00000\n",
      "epoch 3, batch 10, d_loss=-4.267 g_loss=10.220 KID= 0.00000\n",
      "epoch 3, batch 11, d_loss=-2.397 g_loss=7.729 KID= 0.00000\n",
      "epoch 3, batch 12, d_loss=-0.725 g_loss=7.498 KID= 0.00000\n",
      "epoch 3, batch 13, d_loss=-0.173 g_loss=11.276 KID= 0.00000\n",
      "epoch 3, batch 14, d_loss=-4.223 g_loss=20.830 KID= 0.00000\n",
      "epoch 3, batch 15, d_loss=-6.618 g_loss=16.787 KID= 0.00000\n",
      "epoch 3, batch 16, d_loss=-5.540 g_loss=11.479 KID= 0.00000\n",
      "epoch 3, batch 17, d_loss=0.426 g_loss=3.718 KID= 0.00000\n",
      "epoch 3, batch 18, d_loss=1.592 g_loss=1.794 KID= 0.00000\n",
      "epoch 3, batch 19, d_loss=1.421 g_loss=2.784 KID= 0.00000\n",
      "epoch 4, batch 0, d_loss=0.733 g_loss=4.214 KID= 0.00000\n",
      "epoch 4, batch 1, d_loss=-2.682 g_loss=6.715 KID= 0.00000\n",
      "epoch 4, batch 2, d_loss=-3.953 g_loss=10.133 KID= 0.00000\n",
      "epoch 4, batch 3, d_loss=-4.660 g_loss=10.706 KID= 0.00000\n",
      "epoch 4, batch 4, d_loss=-4.687 g_loss=5.237 KID= 0.00000\n",
      "epoch 4, batch 5, d_loss=1.196 g_loss=2.104 KID= 0.00000\n",
      "epoch 4, batch 6, d_loss=0.197 g_loss=5.840 KID= 0.00000\n",
      "epoch 4, batch 7, d_loss=-1.180 g_loss=8.222 KID= 0.00000\n",
      "epoch 4, batch 8, d_loss=-1.556 g_loss=9.039 KID= 0.00000\n",
      "epoch 4, batch 9, d_loss=-1.341 g_loss=6.187 KID= 0.00000\n",
      "epoch 4, batch 10, d_loss=-3.919 g_loss=10.587 KID= 0.00000\n",
      "epoch 4, batch 11, d_loss=-3.972 g_loss=10.594 KID= 0.00000\n",
      "epoch 4, batch 12, d_loss=-3.759 g_loss=8.906 KID= 0.00000\n",
      "epoch 4, batch 13, d_loss=-3.495 g_loss=9.542 KID= 0.00000\n",
      "epoch 4, batch 14, d_loss=-3.288 g_loss=10.078 KID= 0.00000\n",
      "epoch 4, batch 15, d_loss=-1.878 g_loss=6.221 KID= 0.00000\n",
      "epoch 4, batch 16, d_loss=-0.746 g_loss=6.506 KID= 0.00000\n",
      "epoch 4, batch 17, d_loss=-1.157 g_loss=7.782 KID= 0.00000\n",
      "epoch 4, batch 18, d_loss=-1.878 g_loss=8.517 KID= 0.00000\n",
      "epoch 4, batch 19, d_loss=-2.222 g_loss=8.813 KID= 0.00000\n",
      "epoch 5, batch 0, d_loss=-2.177 g_loss=9.014 KID= 0.00000\n",
      "epoch 5, batch 1, d_loss=0.926 g_loss=3.874 KID= 0.00000\n",
      "epoch 5, batch 2, d_loss=0.579 g_loss=5.373 KID= 0.00000\n",
      "epoch 5, batch 3, d_loss=-0.766 g_loss=7.839 KID= 0.00000\n",
      "epoch 5, batch 4, d_loss=-2.515 g_loss=6.425 KID= 0.00000\n",
      "epoch 5, batch 5, d_loss=-3.612 g_loss=4.782 KID= 0.00000\n",
      "epoch 5, batch 6, d_loss=-4.205 g_loss=3.155 KID= 0.00000\n",
      "epoch 5, batch 7, d_loss=-4.394 g_loss=5.552 KID= 0.00000\n",
      "epoch 5, batch 8, d_loss=-6.144 g_loss=10.567 KID= 0.00000\n",
      "epoch 5, batch 9, d_loss=-4.665 g_loss=6.513 KID= 0.00000\n",
      "epoch 5, batch 10, d_loss=-3.187 g_loss=4.377 KID= 0.00000\n",
      "epoch 5, batch 11, d_loss=-3.222 g_loss=5.772 KID= 0.00000\n",
      "epoch 5, batch 12, d_loss=-2.099 g_loss=11.239 KID= 0.00000\n",
      "epoch 5, batch 13, d_loss=-3.081 g_loss=18.588 KID= 0.00000\n",
      "epoch 5, batch 14, d_loss=-2.039 g_loss=10.963 KID= 0.00000\n",
      "epoch 5, batch 15, d_loss=-1.293 g_loss=14.447 KID= 0.00000\n",
      "epoch 5, batch 16, d_loss=-3.745 g_loss=19.421 KID= 0.00000\n",
      "epoch 5, batch 17, d_loss=-1.444 g_loss=9.631 KID= 0.00000\n",
      "epoch 5, batch 18, d_loss=-0.821 g_loss=8.787 KID= 0.00000\n",
      "epoch 5, batch 19, d_loss=-1.855 g_loss=11.327 KID= 0.00000\n",
      "epoch 6, batch 0, d_loss=-2.664 g_loss=11.399 KID= 0.00000\n",
      "epoch 6, batch 1, d_loss=-0.340 g_loss=5.562 KID= 0.00000\n",
      "epoch 6, batch 2, d_loss=-1.697 g_loss=3.505 KID= 0.00000\n",
      "epoch 6, batch 3, d_loss=-1.183 g_loss=1.922 KID= 0.00000\n",
      "epoch 6, batch 4, d_loss=1.224 g_loss=1.029 KID= 0.00000\n",
      "epoch 6, batch 5, d_loss=0.605 g_loss=3.155 KID= 0.00000\n",
      "epoch 6, batch 6, d_loss=-2.300 g_loss=10.254 KID= 0.00000\n",
      "epoch 6, batch 7, d_loss=-7.064 g_loss=25.240 KID= 0.00000\n",
      "epoch 6, batch 8, d_loss=-11.778 g_loss=26.886 KID= 0.00000\n",
      "epoch 6, batch 9, d_loss=-6.192 g_loss=0.566 KID= 0.00000\n",
      "epoch 6, batch 10, d_loss=-3.520 g_loss=-1.324 KID= 0.00000\n",
      "epoch 6, batch 11, d_loss=-4.204 g_loss=6.029 KID= 0.00000\n",
      "epoch 6, batch 12, d_loss=-2.335 g_loss=12.532 KID= 0.00000\n",
      "epoch 6, batch 13, d_loss=-2.064 g_loss=12.418 KID= 0.00000\n",
      "epoch 6, batch 14, d_loss=-3.596 g_loss=13.665 KID= 0.00000\n",
      "epoch 6, batch 15, d_loss=-1.193 g_loss=8.246 KID= 0.00000\n",
      "epoch 6, batch 16, d_loss=0.849 g_loss=6.631 KID= 0.00000\n",
      "epoch 6, batch 17, d_loss=0.308 g_loss=10.836 KID= 0.00000\n",
      "epoch 6, batch 18, d_loss=-1.062 g_loss=13.214 KID= 0.00000\n",
      "epoch 6, batch 19, d_loss=-1.057 g_loss=9.065 KID= 0.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, batch 0, d_loss=-1.047 g_loss=8.884 KID= 0.00000\n",
      "epoch 7, batch 1, d_loss=-1.105 g_loss=7.334 KID= 0.00000\n",
      "epoch 7, batch 2, d_loss=-2.500 g_loss=5.824 KID= 0.00000\n",
      "epoch 7, batch 3, d_loss=-3.711 g_loss=6.218 KID= 0.00000\n",
      "epoch 7, batch 4, d_loss=-2.434 g_loss=6.445 KID= 0.00000\n",
      "epoch 7, batch 5, d_loss=-1.691 g_loss=8.697 KID= 0.00000\n",
      "epoch 7, batch 6, d_loss=-1.888 g_loss=17.884 KID= 0.00000\n",
      "epoch 7, batch 7, d_loss=-7.006 g_loss=39.505 KID= 0.00000\n",
      "epoch 7, batch 8, d_loss=3.776 g_loss=13.406 KID= 0.00000\n",
      "epoch 7, batch 9, d_loss=-4.526 g_loss=7.920 KID= 0.00000\n",
      "epoch 7, batch 10, d_loss=-3.277 g_loss=7.147 KID= 0.00000\n",
      "epoch 7, batch 11, d_loss=-3.795 g_loss=6.508 KID= 0.00000\n",
      "epoch 7, batch 12, d_loss=-1.100 g_loss=3.953 KID= 0.00000\n",
      "epoch 7, batch 13, d_loss=1.969 g_loss=1.934 KID= 0.00000\n",
      "epoch 7, batch 14, d_loss=0.632 g_loss=1.843 KID= 0.00000\n",
      "epoch 7, batch 15, d_loss=0.270 g_loss=2.940 KID= 0.00000\n",
      "epoch 7, batch 16, d_loss=-1.099 g_loss=4.682 KID= 0.00000\n",
      "epoch 7, batch 17, d_loss=-2.991 g_loss=6.700 KID= 0.00000\n",
      "epoch 7, batch 18, d_loss=-3.523 g_loss=9.768 KID= 0.00000\n",
      "epoch 7, batch 19, d_loss=-5.331 g_loss=13.886 KID= 0.00000\n",
      "epoch 8, batch 0, d_loss=-6.128 g_loss=17.487 KID= 0.00000\n",
      "epoch 8, batch 1, d_loss=-3.499 g_loss=14.439 KID= 0.00000\n",
      "epoch 8, batch 2, d_loss=-2.790 g_loss=10.450 KID= 0.00000\n",
      "epoch 8, batch 3, d_loss=-2.512 g_loss=8.215 KID= 0.00000\n",
      "epoch 8, batch 4, d_loss=-0.932 g_loss=6.177 KID= 0.00000\n",
      "epoch 8, batch 5, d_loss=-1.587 g_loss=5.731 KID= 0.00000\n",
      "epoch 8, batch 6, d_loss=-2.131 g_loss=7.663 KID= 0.00000\n",
      "epoch 8, batch 7, d_loss=-2.914 g_loss=9.250 KID= 0.00000\n",
      "epoch 8, batch 8, d_loss=-4.672 g_loss=8.539 KID= 0.00000\n",
      "epoch 8, batch 9, d_loss=-2.794 g_loss=9.257 KID= 0.00000\n",
      "epoch 8, batch 10, d_loss=-1.022 g_loss=11.847 KID= 0.00000\n",
      "epoch 8, batch 11, d_loss=-2.175 g_loss=17.585 KID= 0.00000\n",
      "epoch 8, batch 12, d_loss=-3.662 g_loss=26.666 KID= 0.00000\n",
      "epoch 8, batch 13, d_loss=-3.803 g_loss=22.885 KID= 0.00000\n",
      "epoch 8, batch 14, d_loss=-3.895 g_loss=19.373 KID= 0.00000\n",
      "epoch 8, batch 15, d_loss=-1.795 g_loss=16.440 KID= 0.00000\n",
      "epoch 8, batch 16, d_loss=-2.178 g_loss=16.047 KID= 0.00000\n",
      "epoch 8, batch 17, d_loss=-3.007 g_loss=18.345 KID= 0.00000\n",
      "epoch 8, batch 18, d_loss=-1.152 g_loss=14.119 KID= 0.00000\n",
      "epoch 8, batch 19, d_loss=-3.110 g_loss=14.793 KID= 0.00000\n",
      "epoch 9, batch 0, d_loss=-2.591 g_loss=13.626 KID= 0.00000\n",
      "epoch 9, batch 1, d_loss=-2.715 g_loss=13.909 KID= 0.00000\n",
      "epoch 9, batch 2, d_loss=-2.752 g_loss=15.300 KID= 0.00000\n",
      "epoch 9, batch 3, d_loss=-4.162 g_loss=22.302 KID= 0.00000\n",
      "epoch 9, batch 4, d_loss=-5.478 g_loss=23.579 KID= 0.00000\n",
      "epoch 9, batch 5, d_loss=-6.937 g_loss=22.921 KID= 0.00000\n",
      "epoch 9, batch 6, d_loss=-2.743 g_loss=7.532 KID= 0.00000\n",
      "epoch 9, batch 7, d_loss=-1.317 g_loss=5.134 KID= 0.00000\n",
      "epoch 9, batch 8, d_loss=-1.214 g_loss=8.859 KID= 0.00000\n",
      "epoch 9, batch 9, d_loss=-0.148 g_loss=7.443 KID= 0.00000\n",
      "epoch 9, batch 10, d_loss=1.161 g_loss=3.468 KID= 0.00000\n",
      "epoch 9, batch 11, d_loss=-0.034 g_loss=1.079 KID= 0.00000\n",
      "epoch 9, batch 12, d_loss=-0.276 g_loss=0.935 KID= 0.00000\n",
      "epoch 9, batch 13, d_loss=-1.373 g_loss=4.023 KID= 0.00000\n",
      "epoch 9, batch 14, d_loss=-2.945 g_loss=6.839 KID= 0.00000\n",
      "epoch 9, batch 15, d_loss=-3.047 g_loss=8.895 KID= 0.00000\n",
      "epoch 9, batch 16, d_loss=-3.260 g_loss=9.534 KID= 0.00000\n",
      "epoch 9, batch 17, d_loss=-2.969 g_loss=11.722 KID= 0.00000\n",
      "epoch 9, batch 18, d_loss=-3.119 g_loss=16.089 KID= 0.00000\n",
      "epoch 9, batch 19, d_loss=-4.165 g_loss=15.657 KID= 0.00000\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 10, batch 0, d_loss=-4.635 g_loss=14.356 KID= 1.87352\n",
      "epoch 10, batch 1, d_loss=-4.751 g_loss=21.622 KID= 1.87352\n",
      "epoch 10, batch 2, d_loss=-5.011 g_loss=15.189 KID= 1.87352\n",
      "epoch 10, batch 3, d_loss=-5.579 g_loss=15.498 KID= 1.87352\n",
      "epoch 10, batch 4, d_loss=-6.922 g_loss=26.827 KID= 1.87352\n",
      "epoch 10, batch 5, d_loss=-6.515 g_loss=18.749 KID= 1.87352\n",
      "epoch 10, batch 6, d_loss=-5.821 g_loss=15.866 KID= 1.87352\n",
      "epoch 10, batch 7, d_loss=-6.202 g_loss=16.944 KID= 1.87352\n",
      "epoch 10, batch 8, d_loss=-3.213 g_loss=13.609 KID= 1.87352\n",
      "epoch 10, batch 9, d_loss=-3.251 g_loss=13.461 KID= 1.87352\n",
      "epoch 10, batch 10, d_loss=-1.137 g_loss=12.158 KID= 1.87352\n",
      "epoch 10, batch 11, d_loss=-1.046 g_loss=17.085 KID= 1.87352\n",
      "epoch 10, batch 12, d_loss=-2.208 g_loss=24.210 KID= 1.87352\n",
      "epoch 10, batch 13, d_loss=-3.399 g_loss=27.995 KID= 1.87352\n",
      "epoch 10, batch 14, d_loss=-4.319 g_loss=29.559 KID= 1.87352\n",
      "epoch 10, batch 15, d_loss=-1.080 g_loss=15.314 KID= 1.87352\n",
      "epoch 10, batch 16, d_loss=-1.049 g_loss=11.004 KID= 1.87352\n",
      "epoch 10, batch 17, d_loss=-1.055 g_loss=10.103 KID= 1.87352\n",
      "epoch 10, batch 18, d_loss=-1.024 g_loss=10.338 KID= 1.87352\n",
      "epoch 10, batch 19, d_loss=-1.970 g_loss=10.415 KID= 1.87352\n",
      "epoch 11, batch 0, d_loss=-2.407 g_loss=11.100 KID= 1.87352\n",
      "epoch 11, batch 1, d_loss=-3.955 g_loss=14.770 KID= 1.87352\n",
      "epoch 11, batch 2, d_loss=-5.473 g_loss=20.132 KID= 1.87352\n",
      "epoch 11, batch 3, d_loss=-5.118 g_loss=15.692 KID= 1.87352\n",
      "epoch 11, batch 4, d_loss=-5.375 g_loss=8.282 KID= 1.87352\n",
      "epoch 11, batch 5, d_loss=-6.511 g_loss=11.771 KID= 1.87352\n",
      "epoch 11, batch 6, d_loss=-2.986 g_loss=-0.264 KID= 1.87352\n",
      "epoch 11, batch 7, d_loss=-2.376 g_loss=-0.449 KID= 1.87352\n",
      "epoch 11, batch 8, d_loss=-1.838 g_loss=14.485 KID= 1.87352\n",
      "epoch 11, batch 9, d_loss=-3.014 g_loss=19.326 KID= 1.87352\n",
      "epoch 11, batch 10, d_loss=-2.508 g_loss=17.032 KID= 1.87352\n",
      "epoch 11, batch 11, d_loss=-3.450 g_loss=17.551 KID= 1.87352\n",
      "epoch 11, batch 12, d_loss=-4.455 g_loss=20.886 KID= 1.87352\n",
      "epoch 11, batch 13, d_loss=-5.422 g_loss=17.453 KID= 1.87352\n",
      "epoch 11, batch 14, d_loss=-4.758 g_loss=16.631 KID= 1.87352\n",
      "epoch 11, batch 15, d_loss=-2.929 g_loss=15.240 KID= 1.87352\n",
      "epoch 11, batch 16, d_loss=-2.456 g_loss=14.566 KID= 1.87352\n",
      "epoch 11, batch 17, d_loss=-2.103 g_loss=16.558 KID= 1.87352\n",
      "epoch 11, batch 18, d_loss=-2.240 g_loss=20.610 KID= 1.87352\n",
      "epoch 11, batch 19, d_loss=-4.699 g_loss=27.271 KID= 1.87352\n",
      "epoch 12, batch 0, d_loss=-3.982 g_loss=26.761 KID= 1.87352\n",
      "epoch 12, batch 1, d_loss=-4.272 g_loss=24.467 KID= 1.87352\n",
      "epoch 12, batch 2, d_loss=-3.051 g_loss=16.429 KID= 1.87352\n",
      "epoch 12, batch 3, d_loss=-1.434 g_loss=14.451 KID= 1.87352\n",
      "epoch 12, batch 4, d_loss=-0.931 g_loss=14.094 KID= 1.87352\n",
      "epoch 12, batch 5, d_loss=-1.170 g_loss=13.269 KID= 1.87352\n",
      "epoch 12, batch 6, d_loss=-3.004 g_loss=18.246 KID= 1.87352\n",
      "epoch 12, batch 7, d_loss=-3.561 g_loss=25.520 KID= 1.87352\n",
      "epoch 12, batch 8, d_loss=2.005 g_loss=12.917 KID= 1.87352\n",
      "epoch 12, batch 9, d_loss=-1.310 g_loss=12.895 KID= 1.87352\n",
      "epoch 12, batch 10, d_loss=-2.235 g_loss=15.178 KID= 1.87352\n",
      "epoch 12, batch 11, d_loss=-0.899 g_loss=9.886 KID= 1.87352\n",
      "epoch 12, batch 12, d_loss=-0.540 g_loss=5.631 KID= 1.87352\n",
      "epoch 12, batch 13, d_loss=-0.281 g_loss=2.658 KID= 1.87352\n",
      "epoch 12, batch 14, d_loss=-1.170 g_loss=2.096 KID= 1.87352\n",
      "epoch 12, batch 15, d_loss=-1.198 g_loss=4.220 KID= 1.87352\n",
      "epoch 12, batch 16, d_loss=-2.188 g_loss=5.651 KID= 1.87352\n",
      "epoch 12, batch 17, d_loss=-2.317 g_loss=6.788 KID= 1.87352\n",
      "epoch 12, batch 18, d_loss=-2.411 g_loss=11.043 KID= 1.87352\n",
      "epoch 12, batch 19, d_loss=-1.862 g_loss=13.193 KID= 1.87352\n",
      "epoch 13, batch 0, d_loss=-0.673 g_loss=11.292 KID= 1.87352\n",
      "epoch 13, batch 1, d_loss=-1.464 g_loss=11.684 KID= 1.87352\n",
      "epoch 13, batch 2, d_loss=-1.888 g_loss=11.476 KID= 1.87352\n",
      "epoch 13, batch 3, d_loss=-1.246 g_loss=8.514 KID= 1.87352\n",
      "epoch 13, batch 4, d_loss=-0.667 g_loss=8.394 KID= 1.87352\n",
      "epoch 13, batch 5, d_loss=-0.576 g_loss=9.886 KID= 1.87352\n",
      "epoch 13, batch 6, d_loss=-1.223 g_loss=11.666 KID= 1.87352\n",
      "epoch 13, batch 7, d_loss=-1.595 g_loss=16.803 KID= 1.87352\n",
      "epoch 13, batch 8, d_loss=-0.606 g_loss=18.598 KID= 1.87352\n",
      "epoch 13, batch 9, d_loss=-2.802 g_loss=24.163 KID= 1.87352\n",
      "epoch 13, batch 10, d_loss=-2.437 g_loss=23.391 KID= 1.87352\n",
      "epoch 13, batch 11, d_loss=-2.752 g_loss=15.406 KID= 1.87352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, batch 12, d_loss=-2.285 g_loss=17.977 KID= 1.87352\n",
      "epoch 13, batch 13, d_loss=0.108 g_loss=9.681 KID= 1.87352\n",
      "epoch 13, batch 14, d_loss=0.094 g_loss=9.120 KID= 1.87352\n",
      "epoch 13, batch 15, d_loss=-0.257 g_loss=9.253 KID= 1.87352\n",
      "epoch 13, batch 16, d_loss=0.729 g_loss=6.994 KID= 1.87352\n",
      "epoch 13, batch 17, d_loss=0.638 g_loss=4.932 KID= 1.87352\n",
      "epoch 13, batch 18, d_loss=-0.381 g_loss=6.471 KID= 1.87352\n",
      "epoch 13, batch 19, d_loss=-1.039 g_loss=11.758 KID= 1.87352\n",
      "epoch 14, batch 0, d_loss=-2.605 g_loss=21.958 KID= 1.87352\n",
      "epoch 14, batch 1, d_loss=-1.647 g_loss=20.481 KID= 1.87352\n",
      "epoch 14, batch 2, d_loss=-1.328 g_loss=17.890 KID= 1.87352\n",
      "epoch 14, batch 3, d_loss=-2.069 g_loss=21.313 KID= 1.87352\n",
      "epoch 14, batch 4, d_loss=-0.536 g_loss=19.395 KID= 1.87352\n",
      "epoch 14, batch 5, d_loss=-0.958 g_loss=20.355 KID= 1.87352\n",
      "epoch 14, batch 6, d_loss=-2.065 g_loss=25.334 KID= 1.87352\n",
      "epoch 14, batch 7, d_loss=-0.499 g_loss=16.165 KID= 1.87352\n",
      "epoch 14, batch 8, d_loss=-1.448 g_loss=16.431 KID= 1.87352\n",
      "epoch 14, batch 9, d_loss=-0.524 g_loss=15.746 KID= 1.87352\n",
      "epoch 14, batch 10, d_loss=0.491 g_loss=11.447 KID= 1.87352\n",
      "epoch 14, batch 11, d_loss=-0.131 g_loss=9.506 KID= 1.87352\n",
      "epoch 14, batch 12, d_loss=-0.250 g_loss=7.603 KID= 1.87352\n",
      "epoch 14, batch 13, d_loss=0.043 g_loss=4.625 KID= 1.87352\n",
      "epoch 14, batch 14, d_loss=-0.324 g_loss=2.507 KID= 1.87352\n",
      "epoch 14, batch 15, d_loss=-0.018 g_loss=0.461 KID= 1.87352\n",
      "epoch 14, batch 16, d_loss=-0.368 g_loss=-0.760 KID= 1.87352\n",
      "epoch 14, batch 17, d_loss=-0.310 g_loss=-0.788 KID= 1.87352\n",
      "epoch 14, batch 18, d_loss=-0.321 g_loss=0.388 KID= 1.87352\n",
      "epoch 14, batch 19, d_loss=-0.926 g_loss=2.899 KID= 1.87352\n",
      "epoch 15, batch 0, d_loss=-1.303 g_loss=5.100 KID= 1.87352\n",
      "epoch 15, batch 1, d_loss=-0.679 g_loss=4.749 KID= 1.87352\n",
      "epoch 15, batch 2, d_loss=-0.795 g_loss=5.975 KID= 1.87352\n",
      "epoch 15, batch 3, d_loss=-1.048 g_loss=10.329 KID= 1.87352\n",
      "epoch 15, batch 4, d_loss=-1.723 g_loss=14.226 KID= 1.87352\n",
      "epoch 15, batch 5, d_loss=-2.046 g_loss=13.601 KID= 1.87352\n",
      "epoch 15, batch 6, d_loss=-1.151 g_loss=9.876 KID= 1.87352\n",
      "epoch 15, batch 7, d_loss=-0.455 g_loss=6.503 KID= 1.87352\n",
      "epoch 15, batch 8, d_loss=-0.864 g_loss=5.336 KID= 1.87352\n",
      "epoch 15, batch 9, d_loss=-1.492 g_loss=5.859 KID= 1.87352\n",
      "epoch 15, batch 10, d_loss=-1.342 g_loss=6.102 KID= 1.87352\n",
      "epoch 15, batch 11, d_loss=-1.055 g_loss=6.214 KID= 1.87352\n",
      "epoch 15, batch 12, d_loss=-0.015 g_loss=4.908 KID= 1.87352\n",
      "epoch 15, batch 13, d_loss=-0.900 g_loss=2.449 KID= 1.87352\n",
      "epoch 15, batch 14, d_loss=-0.110 g_loss=-0.389 KID= 1.87352\n",
      "epoch 15, batch 15, d_loss=-1.343 g_loss=-1.679 KID= 1.87352\n",
      "epoch 15, batch 16, d_loss=-2.345 g_loss=-0.728 KID= 1.87352\n",
      "epoch 15, batch 17, d_loss=-4.515 g_loss=-0.339 KID= 1.87352\n",
      "epoch 15, batch 18, d_loss=-4.655 g_loss=0.317 KID= 1.87352\n",
      "epoch 15, batch 19, d_loss=-1.341 g_loss=2.119 KID= 1.87352\n",
      "epoch 16, batch 0, d_loss=0.323 g_loss=8.119 KID= 1.87352\n",
      "epoch 16, batch 1, d_loss=-0.381 g_loss=16.600 KID= 1.87352\n",
      "epoch 16, batch 2, d_loss=-0.109 g_loss=14.263 KID= 1.87352\n",
      "epoch 16, batch 3, d_loss=-0.620 g_loss=16.877 KID= 1.87352\n",
      "epoch 16, batch 4, d_loss=-1.500 g_loss=21.467 KID= 1.87352\n",
      "epoch 16, batch 5, d_loss=-1.094 g_loss=18.915 KID= 1.87352\n",
      "epoch 16, batch 6, d_loss=-3.026 g_loss=23.914 KID= 1.87352\n",
      "epoch 16, batch 7, d_loss=-2.011 g_loss=18.681 KID= 1.87352\n",
      "epoch 16, batch 8, d_loss=-1.906 g_loss=18.581 KID= 1.87352\n",
      "epoch 16, batch 9, d_loss=-1.214 g_loss=18.655 KID= 1.87352\n",
      "epoch 16, batch 10, d_loss=-0.912 g_loss=17.131 KID= 1.87352\n",
      "epoch 16, batch 11, d_loss=-1.943 g_loss=18.403 KID= 1.87352\n",
      "epoch 16, batch 12, d_loss=-2.457 g_loss=21.213 KID= 1.87352\n",
      "epoch 16, batch 13, d_loss=-2.910 g_loss=24.897 KID= 1.87352\n",
      "epoch 16, batch 14, d_loss=-3.176 g_loss=21.557 KID= 1.87352\n",
      "epoch 16, batch 15, d_loss=-1.371 g_loss=14.204 KID= 1.87352\n",
      "epoch 16, batch 16, d_loss=0.050 g_loss=10.760 KID= 1.87352\n",
      "epoch 16, batch 17, d_loss=0.064 g_loss=8.926 KID= 1.87352\n",
      "epoch 16, batch 18, d_loss=-0.397 g_loss=7.470 KID= 1.87352\n",
      "epoch 16, batch 19, d_loss=-0.544 g_loss=7.841 KID= 1.87352\n",
      "epoch 17, batch 0, d_loss=-0.954 g_loss=10.857 KID= 1.87352\n",
      "epoch 17, batch 1, d_loss=-1.913 g_loss=17.397 KID= 1.87352\n",
      "epoch 17, batch 2, d_loss=-2.171 g_loss=21.263 KID= 1.87352\n",
      "epoch 17, batch 3, d_loss=-2.212 g_loss=21.721 KID= 1.87352\n",
      "epoch 17, batch 4, d_loss=0.062 g_loss=13.796 KID= 1.87352\n",
      "epoch 17, batch 5, d_loss=-0.479 g_loss=12.605 KID= 1.87352\n",
      "epoch 17, batch 6, d_loss=0.250 g_loss=9.522 KID= 1.87352\n",
      "epoch 17, batch 7, d_loss=0.215 g_loss=7.105 KID= 1.87352\n",
      "epoch 17, batch 8, d_loss=-0.469 g_loss=8.784 KID= 1.87352\n",
      "epoch 17, batch 9, d_loss=-1.238 g_loss=14.697 KID= 1.87352\n",
      "epoch 17, batch 10, d_loss=-0.928 g_loss=13.363 KID= 1.87352\n",
      "epoch 17, batch 11, d_loss=-1.134 g_loss=17.405 KID= 1.87352\n",
      "epoch 17, batch 12, d_loss=-0.244 g_loss=12.975 KID= 1.87352\n",
      "epoch 17, batch 13, d_loss=0.260 g_loss=11.609 KID= 1.87352\n",
      "epoch 17, batch 14, d_loss=-0.489 g_loss=11.649 KID= 1.87352\n",
      "epoch 17, batch 15, d_loss=-0.874 g_loss=12.112 KID= 1.87352\n",
      "epoch 17, batch 16, d_loss=-0.770 g_loss=11.619 KID= 1.87352\n",
      "epoch 17, batch 17, d_loss=-1.183 g_loss=14.356 KID= 1.87352\n",
      "epoch 17, batch 18, d_loss=-1.360 g_loss=19.591 KID= 1.87352\n",
      "epoch 17, batch 19, d_loss=-1.675 g_loss=21.033 KID= 1.87352\n",
      "epoch 18, batch 0, d_loss=-1.575 g_loss=18.377 KID= 1.87352\n",
      "epoch 18, batch 1, d_loss=-0.782 g_loss=17.371 KID= 1.87352\n",
      "epoch 18, batch 2, d_loss=-0.027 g_loss=14.255 KID= 1.87352\n",
      "epoch 18, batch 3, d_loss=-0.038 g_loss=12.477 KID= 1.87352\n",
      "epoch 18, batch 4, d_loss=-0.213 g_loss=11.790 KID= 1.87352\n",
      "epoch 18, batch 5, d_loss=-1.473 g_loss=15.580 KID= 1.87352\n",
      "epoch 18, batch 6, d_loss=0.270 g_loss=7.807 KID= 1.87352\n",
      "epoch 18, batch 7, d_loss=-1.228 g_loss=7.391 KID= 1.87352\n",
      "epoch 18, batch 8, d_loss=-1.106 g_loss=10.525 KID= 1.87352\n",
      "epoch 18, batch 9, d_loss=-0.578 g_loss=11.718 KID= 1.87352\n",
      "epoch 18, batch 10, d_loss=-0.858 g_loss=11.354 KID= 1.87352\n",
      "epoch 18, batch 11, d_loss=0.020 g_loss=11.240 KID= 1.87352\n",
      "epoch 18, batch 12, d_loss=0.650 g_loss=10.931 KID= 1.87352\n",
      "epoch 18, batch 13, d_loss=-0.188 g_loss=9.920 KID= 1.87352\n",
      "epoch 18, batch 14, d_loss=-1.263 g_loss=9.638 KID= 1.87352\n",
      "epoch 18, batch 15, d_loss=-2.142 g_loss=12.654 KID= 1.87352\n",
      "epoch 18, batch 16, d_loss=-2.044 g_loss=14.321 KID= 1.87352\n",
      "epoch 18, batch 17, d_loss=-0.145 g_loss=8.401 KID= 1.87352\n",
      "epoch 18, batch 18, d_loss=-0.743 g_loss=6.606 KID= 1.87352\n",
      "epoch 18, batch 19, d_loss=-0.432 g_loss=4.778 KID= 1.87352\n",
      "epoch 19, batch 0, d_loss=0.025 g_loss=1.695 KID= 1.87352\n",
      "epoch 19, batch 1, d_loss=-0.015 g_loss=0.133 KID= 1.87352\n",
      "epoch 19, batch 2, d_loss=0.120 g_loss=1.409 KID= 1.87352\n",
      "epoch 19, batch 3, d_loss=-0.787 g_loss=2.927 KID= 1.87352\n",
      "epoch 19, batch 4, d_loss=-1.124 g_loss=1.298 KID= 1.87352\n",
      "epoch 19, batch 5, d_loss=-1.572 g_loss=-0.747 KID= 1.87352\n",
      "epoch 19, batch 6, d_loss=-1.207 g_loss=-3.096 KID= 1.87352\n",
      "epoch 19, batch 7, d_loss=-1.478 g_loss=-5.417 KID= 1.87352\n",
      "epoch 19, batch 8, d_loss=-1.438 g_loss=-3.997 KID= 1.87352\n",
      "epoch 19, batch 9, d_loss=-1.274 g_loss=1.032 KID= 1.87352\n",
      "epoch 19, batch 10, d_loss=-1.237 g_loss=5.619 KID= 1.87352\n",
      "epoch 19, batch 11, d_loss=-1.399 g_loss=9.773 KID= 1.87352\n",
      "epoch 19, batch 12, d_loss=-0.866 g_loss=15.562 KID= 1.87352\n",
      "epoch 19, batch 13, d_loss=-1.785 g_loss=21.927 KID= 1.87352\n",
      "epoch 19, batch 14, d_loss=-0.652 g_loss=17.673 KID= 1.87352\n",
      "epoch 19, batch 15, d_loss=-1.169 g_loss=16.692 KID= 1.87352\n",
      "epoch 19, batch 16, d_loss=-0.328 g_loss=14.382 KID= 1.87352\n",
      "epoch 19, batch 17, d_loss=0.213 g_loss=11.836 KID= 1.87352\n",
      "epoch 19, batch 18, d_loss=-0.650 g_loss=12.010 KID= 1.87352\n",
      "epoch 19, batch 19, d_loss=-0.453 g_loss=11.118 KID= 1.87352\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 20, batch 0, d_loss=-0.473 g_loss=10.682 KID= 0.36948\n",
      "epoch 20, batch 1, d_loss=-1.105 g_loss=11.700 KID= 0.36948\n",
      "epoch 20, batch 2, d_loss=-0.502 g_loss=12.634 KID= 0.36948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20, batch 3, d_loss=-1.287 g_loss=16.378 KID= 0.36948\n",
      "epoch 20, batch 4, d_loss=-1.530 g_loss=20.115 KID= 0.36948\n",
      "epoch 20, batch 5, d_loss=-0.343 g_loss=17.195 KID= 0.36948\n",
      "epoch 20, batch 6, d_loss=-0.263 g_loss=18.757 KID= 0.36948\n",
      "epoch 20, batch 7, d_loss=-0.161 g_loss=18.377 KID= 0.36948\n",
      "epoch 20, batch 8, d_loss=0.096 g_loss=15.060 KID= 0.36948\n",
      "epoch 20, batch 9, d_loss=-0.404 g_loss=15.546 KID= 0.36948\n",
      "epoch 20, batch 10, d_loss=-0.099 g_loss=12.285 KID= 0.36948\n",
      "epoch 20, batch 11, d_loss=-0.743 g_loss=10.490 KID= 0.36948\n",
      "epoch 20, batch 12, d_loss=-0.758 g_loss=8.016 KID= 0.36948\n",
      "epoch 20, batch 13, d_loss=-0.596 g_loss=3.508 KID= 0.36948\n",
      "epoch 20, batch 14, d_loss=-0.960 g_loss=-0.655 KID= 0.36948\n",
      "epoch 20, batch 15, d_loss=-0.186 g_loss=-0.914 KID= 0.36948\n",
      "epoch 20, batch 16, d_loss=-0.435 g_loss=-2.327 KID= 0.36948\n",
      "epoch 20, batch 17, d_loss=-0.558 g_loss=-2.957 KID= 0.36948\n",
      "epoch 20, batch 18, d_loss=-0.069 g_loss=-0.194 KID= 0.36948\n",
      "epoch 20, batch 19, d_loss=-0.812 g_loss=1.675 KID= 0.36948\n",
      "epoch 21, batch 0, d_loss=-1.130 g_loss=1.343 KID= 0.36948\n",
      "epoch 21, batch 1, d_loss=-0.980 g_loss=0.450 KID= 0.36948\n",
      "epoch 21, batch 2, d_loss=-1.189 g_loss=-0.808 KID= 0.36948\n",
      "epoch 21, batch 3, d_loss=-0.691 g_loss=-1.863 KID= 0.36948\n",
      "epoch 21, batch 4, d_loss=0.646 g_loss=-0.635 KID= 0.36948\n",
      "epoch 21, batch 5, d_loss=0.144 g_loss=1.869 KID= 0.36948\n",
      "epoch 21, batch 6, d_loss=-0.423 g_loss=5.590 KID= 0.36948\n",
      "epoch 21, batch 7, d_loss=-0.573 g_loss=7.853 KID= 0.36948\n",
      "epoch 21, batch 8, d_loss=-0.872 g_loss=9.689 KID= 0.36948\n",
      "epoch 21, batch 9, d_loss=-0.475 g_loss=10.797 KID= 0.36948\n",
      "epoch 21, batch 10, d_loss=0.024 g_loss=10.713 KID= 0.36948\n",
      "epoch 21, batch 11, d_loss=-0.090 g_loss=11.229 KID= 0.36948\n",
      "epoch 21, batch 12, d_loss=0.088 g_loss=10.544 KID= 0.36948\n",
      "epoch 21, batch 13, d_loss=-0.663 g_loss=11.037 KID= 0.36948\n",
      "epoch 21, batch 14, d_loss=-1.156 g_loss=11.961 KID= 0.36948\n",
      "epoch 21, batch 15, d_loss=-1.428 g_loss=13.651 KID= 0.36948\n",
      "epoch 21, batch 16, d_loss=-0.516 g_loss=12.922 KID= 0.36948\n",
      "epoch 21, batch 17, d_loss=0.001 g_loss=9.720 KID= 0.36948\n",
      "epoch 21, batch 18, d_loss=-0.114 g_loss=7.575 KID= 0.36948\n",
      "epoch 21, batch 19, d_loss=-0.702 g_loss=6.204 KID= 0.36948\n",
      "epoch 22, batch 0, d_loss=-0.867 g_loss=4.204 KID= 0.36948\n",
      "epoch 22, batch 1, d_loss=-1.267 g_loss=4.326 KID= 0.36948\n",
      "epoch 22, batch 2, d_loss=-0.978 g_loss=5.342 KID= 0.36948\n",
      "epoch 22, batch 3, d_loss=-0.818 g_loss=7.013 KID= 0.36948\n",
      "epoch 22, batch 4, d_loss=-0.802 g_loss=7.353 KID= 0.36948\n",
      "epoch 22, batch 5, d_loss=-0.639 g_loss=6.930 KID= 0.36948\n",
      "epoch 22, batch 6, d_loss=-0.476 g_loss=6.422 KID= 0.36948\n",
      "epoch 22, batch 7, d_loss=-0.449 g_loss=5.793 KID= 0.36948\n",
      "epoch 22, batch 8, d_loss=-0.446 g_loss=5.933 KID= 0.36948\n",
      "epoch 22, batch 9, d_loss=-0.785 g_loss=7.229 KID= 0.36948\n",
      "epoch 22, batch 10, d_loss=-0.613 g_loss=7.926 KID= 0.36948\n",
      "epoch 22, batch 11, d_loss=-1.138 g_loss=9.857 KID= 0.36948\n",
      "epoch 22, batch 12, d_loss=-0.962 g_loss=10.996 KID= 0.36948\n",
      "epoch 22, batch 13, d_loss=-0.481 g_loss=13.060 KID= 0.36948\n",
      "epoch 22, batch 14, d_loss=-0.975 g_loss=14.215 KID= 0.36948\n",
      "epoch 22, batch 15, d_loss=-0.131 g_loss=9.490 KID= 0.36948\n",
      "epoch 22, batch 16, d_loss=0.362 g_loss=6.850 KID= 0.36948\n",
      "epoch 22, batch 17, d_loss=-0.357 g_loss=7.112 KID= 0.36948\n",
      "epoch 22, batch 18, d_loss=-0.633 g_loss=8.477 KID= 0.36948\n",
      "epoch 22, batch 19, d_loss=-1.326 g_loss=12.551 KID= 0.36948\n",
      "epoch 23, batch 0, d_loss=-0.932 g_loss=12.353 KID= 0.36948\n",
      "epoch 23, batch 1, d_loss=-0.578 g_loss=11.403 KID= 0.36948\n",
      "epoch 23, batch 2, d_loss=-0.037 g_loss=10.039 KID= 0.36948\n",
      "epoch 23, batch 3, d_loss=0.071 g_loss=10.608 KID= 0.36948\n",
      "epoch 23, batch 4, d_loss=-0.095 g_loss=9.100 KID= 0.36948\n",
      "epoch 23, batch 5, d_loss=-0.802 g_loss=6.971 KID= 0.36948\n",
      "epoch 23, batch 6, d_loss=-1.176 g_loss=5.821 KID= 0.36948\n",
      "epoch 23, batch 7, d_loss=-1.374 g_loss=7.412 KID= 0.36948\n",
      "epoch 23, batch 8, d_loss=-1.278 g_loss=6.711 KID= 0.36948\n",
      "epoch 23, batch 9, d_loss=-1.712 g_loss=8.682 KID= 0.36948\n",
      "epoch 23, batch 10, d_loss=-0.692 g_loss=9.306 KID= 0.36948\n",
      "epoch 23, batch 11, d_loss=-1.252 g_loss=14.656 KID= 0.36948\n",
      "epoch 23, batch 12, d_loss=-0.643 g_loss=16.470 KID= 0.36948\n",
      "epoch 23, batch 13, d_loss=-0.558 g_loss=12.297 KID= 0.36948\n",
      "epoch 23, batch 14, d_loss=-0.778 g_loss=11.704 KID= 0.36948\n",
      "epoch 23, batch 15, d_loss=-0.732 g_loss=10.608 KID= 0.36948\n",
      "epoch 23, batch 16, d_loss=-0.611 g_loss=7.598 KID= 0.36948\n",
      "epoch 23, batch 17, d_loss=-0.734 g_loss=4.627 KID= 0.36948\n",
      "epoch 23, batch 18, d_loss=-0.774 g_loss=2.744 KID= 0.36948\n",
      "epoch 23, batch 19, d_loss=-1.065 g_loss=3.167 KID= 0.36948\n",
      "epoch 24, batch 0, d_loss=-0.837 g_loss=1.918 KID= 0.36948\n",
      "epoch 24, batch 1, d_loss=-1.012 g_loss=1.868 KID= 0.36948\n",
      "epoch 24, batch 2, d_loss=-0.681 g_loss=3.105 KID= 0.36948\n",
      "epoch 24, batch 3, d_loss=-0.382 g_loss=4.809 KID= 0.36948\n",
      "epoch 24, batch 4, d_loss=-0.751 g_loss=4.215 KID= 0.36948\n",
      "epoch 24, batch 5, d_loss=-0.621 g_loss=3.913 KID= 0.36948\n",
      "epoch 24, batch 6, d_loss=-0.558 g_loss=4.713 KID= 0.36948\n",
      "epoch 24, batch 7, d_loss=-1.057 g_loss=6.145 KID= 0.36948\n",
      "epoch 24, batch 8, d_loss=-0.712 g_loss=5.533 KID= 0.36948\n",
      "epoch 24, batch 9, d_loss=-0.499 g_loss=4.718 KID= 0.36948\n",
      "epoch 24, batch 10, d_loss=-0.739 g_loss=4.934 KID= 0.36948\n",
      "epoch 24, batch 11, d_loss=-0.648 g_loss=4.432 KID= 0.36948\n",
      "epoch 24, batch 12, d_loss=-0.451 g_loss=3.730 KID= 0.36948\n",
      "epoch 24, batch 13, d_loss=-0.729 g_loss=5.340 KID= 0.36948\n",
      "epoch 24, batch 14, d_loss=-0.731 g_loss=8.456 KID= 0.36948\n",
      "epoch 24, batch 15, d_loss=-1.524 g_loss=13.025 KID= 0.36948\n",
      "epoch 24, batch 16, d_loss=-1.258 g_loss=12.821 KID= 0.36948\n",
      "epoch 24, batch 17, d_loss=-0.725 g_loss=13.189 KID= 0.36948\n",
      "epoch 24, batch 18, d_loss=-0.751 g_loss=14.275 KID= 0.36948\n",
      "epoch 24, batch 19, d_loss=-0.631 g_loss=15.460 KID= 0.36948\n",
      "epoch 25, batch 0, d_loss=0.237 g_loss=14.644 KID= 0.36948\n",
      "epoch 25, batch 1, d_loss=-0.704 g_loss=17.679 KID= 0.36948\n",
      "epoch 25, batch 2, d_loss=-0.015 g_loss=12.131 KID= 0.36948\n",
      "epoch 25, batch 3, d_loss=-0.497 g_loss=10.038 KID= 0.36948\n",
      "epoch 25, batch 4, d_loss=-0.515 g_loss=7.000 KID= 0.36948\n",
      "epoch 25, batch 5, d_loss=-0.167 g_loss=2.820 KID= 0.36948\n",
      "epoch 25, batch 6, d_loss=-0.316 g_loss=0.584 KID= 0.36948\n",
      "epoch 25, batch 7, d_loss=-0.580 g_loss=-0.126 KID= 0.36948\n",
      "epoch 25, batch 8, d_loss=-0.556 g_loss=-0.663 KID= 0.36948\n",
      "epoch 25, batch 9, d_loss=-0.578 g_loss=-1.098 KID= 0.36948\n",
      "epoch 25, batch 10, d_loss=-0.759 g_loss=0.012 KID= 0.36948\n",
      "epoch 25, batch 11, d_loss=-1.078 g_loss=1.589 KID= 0.36948\n",
      "epoch 25, batch 12, d_loss=-1.068 g_loss=2.569 KID= 0.36948\n",
      "epoch 25, batch 13, d_loss=-0.703 g_loss=4.842 KID= 0.36948\n",
      "epoch 25, batch 14, d_loss=0.117 g_loss=7.928 KID= 0.36948\n",
      "epoch 25, batch 15, d_loss=-0.504 g_loss=10.967 KID= 0.36948\n",
      "epoch 25, batch 16, d_loss=0.115 g_loss=9.132 KID= 0.36948\n",
      "epoch 25, batch 17, d_loss=-0.708 g_loss=8.934 KID= 0.36948\n",
      "epoch 25, batch 18, d_loss=-0.763 g_loss=7.395 KID= 0.36948\n",
      "epoch 25, batch 19, d_loss=-0.793 g_loss=3.938 KID= 0.36948\n",
      "epoch 26, batch 0, d_loss=-1.371 g_loss=1.856 KID= 0.36948\n",
      "epoch 26, batch 1, d_loss=-1.622 g_loss=0.689 KID= 0.36948\n",
      "epoch 26, batch 2, d_loss=-1.132 g_loss=-0.855 KID= 0.36948\n",
      "epoch 26, batch 3, d_loss=-0.539 g_loss=-1.614 KID= 0.36948\n",
      "epoch 26, batch 4, d_loss=-0.161 g_loss=0.461 KID= 0.36948\n",
      "epoch 26, batch 5, d_loss=-0.275 g_loss=3.582 KID= 0.36948\n",
      "epoch 26, batch 6, d_loss=-0.450 g_loss=7.258 KID= 0.36948\n",
      "epoch 26, batch 7, d_loss=-0.983 g_loss=11.992 KID= 0.36948\n",
      "epoch 26, batch 8, d_loss=-1.047 g_loss=16.290 KID= 0.36948\n",
      "epoch 26, batch 9, d_loss=-0.441 g_loss=14.688 KID= 0.36948\n",
      "epoch 26, batch 10, d_loss=-0.527 g_loss=13.375 KID= 0.36948\n",
      "epoch 26, batch 11, d_loss=0.341 g_loss=9.675 KID= 0.36948\n",
      "epoch 26, batch 12, d_loss=0.011 g_loss=7.203 KID= 0.36948\n",
      "epoch 26, batch 13, d_loss=-0.796 g_loss=6.447 KID= 0.36948\n",
      "epoch 26, batch 14, d_loss=-0.800 g_loss=4.835 KID= 0.36948\n",
      "epoch 26, batch 15, d_loss=-1.436 g_loss=5.261 KID= 0.36948\n",
      "epoch 26, batch 16, d_loss=-0.832 g_loss=6.384 KID= 0.36948\n",
      "epoch 26, batch 17, d_loss=-0.310 g_loss=6.146 KID= 0.36948\n",
      "epoch 26, batch 18, d_loss=-0.694 g_loss=6.856 KID= 0.36948\n",
      "epoch 26, batch 19, d_loss=-0.514 g_loss=7.467 KID= 0.36948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27, batch 0, d_loss=0.255 g_loss=6.900 KID= 0.36948\n",
      "epoch 27, batch 1, d_loss=-0.293 g_loss=7.653 KID= 0.36948\n",
      "epoch 27, batch 2, d_loss=-0.167 g_loss=7.678 KID= 0.36948\n",
      "epoch 27, batch 3, d_loss=-0.446 g_loss=8.089 KID= 0.36948\n",
      "epoch 27, batch 4, d_loss=-0.632 g_loss=6.565 KID= 0.36948\n",
      "epoch 27, batch 5, d_loss=-1.120 g_loss=3.610 KID= 0.36948\n",
      "epoch 27, batch 6, d_loss=-0.902 g_loss=0.817 KID= 0.36948\n",
      "epoch 27, batch 7, d_loss=-1.061 g_loss=-2.711 KID= 0.36948\n",
      "epoch 27, batch 8, d_loss=-0.310 g_loss=-2.379 KID= 0.36948\n",
      "epoch 27, batch 9, d_loss=-0.028 g_loss=-0.500 KID= 0.36948\n",
      "epoch 27, batch 10, d_loss=-0.675 g_loss=0.874 KID= 0.36948\n",
      "epoch 27, batch 11, d_loss=-0.511 g_loss=1.491 KID= 0.36948\n",
      "epoch 27, batch 12, d_loss=-0.688 g_loss=2.531 KID= 0.36948\n",
      "epoch 27, batch 13, d_loss=-1.259 g_loss=4.195 KID= 0.36948\n",
      "epoch 27, batch 14, d_loss=-0.941 g_loss=4.362 KID= 0.36948\n",
      "epoch 27, batch 15, d_loss=-0.860 g_loss=3.685 KID= 0.36948\n",
      "epoch 27, batch 16, d_loss=-0.421 g_loss=2.756 KID= 0.36948\n",
      "epoch 27, batch 17, d_loss=0.261 g_loss=2.660 KID= 0.36948\n",
      "epoch 27, batch 18, d_loss=-0.374 g_loss=2.568 KID= 0.36948\n",
      "epoch 27, batch 19, d_loss=-0.449 g_loss=2.632 KID= 0.36948\n",
      "epoch 28, batch 0, d_loss=-0.580 g_loss=2.319 KID= 0.36948\n",
      "epoch 28, batch 1, d_loss=-0.722 g_loss=1.487 KID= 0.36948\n",
      "epoch 28, batch 2, d_loss=-0.176 g_loss=1.011 KID= 0.36948\n",
      "epoch 28, batch 3, d_loss=-0.070 g_loss=1.854 KID= 0.36948\n",
      "epoch 28, batch 4, d_loss=-0.740 g_loss=2.352 KID= 0.36948\n",
      "epoch 28, batch 5, d_loss=-0.642 g_loss=3.481 KID= 0.36948\n",
      "epoch 28, batch 6, d_loss=-0.810 g_loss=5.344 KID= 0.36948\n",
      "epoch 28, batch 7, d_loss=-1.002 g_loss=6.548 KID= 0.36948\n",
      "epoch 28, batch 8, d_loss=-0.689 g_loss=7.888 KID= 0.36948\n",
      "epoch 28, batch 9, d_loss=-0.885 g_loss=11.466 KID= 0.36948\n",
      "epoch 28, batch 10, d_loss=-0.783 g_loss=14.423 KID= 0.36948\n",
      "epoch 28, batch 11, d_loss=-0.924 g_loss=16.287 KID= 0.36948\n",
      "epoch 28, batch 12, d_loss=-1.047 g_loss=19.193 KID= 0.36948\n",
      "epoch 28, batch 13, d_loss=-0.835 g_loss=15.468 KID= 0.36948\n",
      "epoch 28, batch 14, d_loss=-1.121 g_loss=14.471 KID= 0.36948\n",
      "epoch 28, batch 15, d_loss=-0.369 g_loss=7.564 KID= 0.36948\n",
      "epoch 28, batch 16, d_loss=-0.414 g_loss=2.798 KID= 0.36948\n",
      "epoch 28, batch 17, d_loss=-0.739 g_loss=1.637 KID= 0.36948\n",
      "epoch 28, batch 18, d_loss=-0.670 g_loss=1.566 KID= 0.36948\n",
      "epoch 28, batch 19, d_loss=-0.256 g_loss=1.983 KID= 0.36948\n",
      "epoch 29, batch 0, d_loss=-0.325 g_loss=3.454 KID= 0.36948\n",
      "epoch 29, batch 1, d_loss=-0.422 g_loss=4.238 KID= 0.36948\n",
      "epoch 29, batch 2, d_loss=-0.215 g_loss=3.327 KID= 0.36948\n",
      "epoch 29, batch 3, d_loss=-0.398 g_loss=2.438 KID= 0.36948\n",
      "epoch 29, batch 4, d_loss=-0.786 g_loss=2.509 KID= 0.36948\n",
      "epoch 29, batch 5, d_loss=-0.661 g_loss=3.589 KID= 0.36948\n",
      "epoch 29, batch 6, d_loss=-0.538 g_loss=4.485 KID= 0.36948\n",
      "epoch 29, batch 7, d_loss=-0.406 g_loss=5.513 KID= 0.36948\n",
      "epoch 29, batch 8, d_loss=-0.516 g_loss=6.627 KID= 0.36948\n",
      "epoch 29, batch 9, d_loss=-0.745 g_loss=8.257 KID= 0.36948\n",
      "epoch 29, batch 10, d_loss=-0.498 g_loss=9.451 KID= 0.36948\n",
      "epoch 29, batch 11, d_loss=-0.927 g_loss=12.108 KID= 0.36948\n",
      "epoch 29, batch 12, d_loss=-0.671 g_loss=13.871 KID= 0.36948\n",
      "epoch 29, batch 13, d_loss=-0.600 g_loss=15.575 KID= 0.36948\n",
      "epoch 29, batch 14, d_loss=-0.699 g_loss=17.413 KID= 0.36948\n",
      "epoch 29, batch 15, d_loss=-0.140 g_loss=11.651 KID= 0.36948\n",
      "epoch 29, batch 16, d_loss=0.093 g_loss=7.060 KID= 0.36948\n",
      "epoch 29, batch 17, d_loss=0.043 g_loss=3.185 KID= 0.36948\n",
      "epoch 29, batch 18, d_loss=-0.077 g_loss=-0.516 KID= 0.36948\n",
      "epoch 29, batch 19, d_loss=-0.322 g_loss=-1.969 KID= 0.36948\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 30, batch 0, d_loss=-0.742 g_loss=-0.909 KID= 0.42490\n",
      "epoch 30, batch 1, d_loss=-1.125 g_loss=-1.000 KID= 0.42490\n",
      "epoch 30, batch 2, d_loss=-1.195 g_loss=-1.657 KID= 0.42490\n",
      "epoch 30, batch 3, d_loss=-0.847 g_loss=-3.038 KID= 0.42490\n",
      "epoch 30, batch 4, d_loss=-0.068 g_loss=-2.032 KID= 0.42490\n",
      "epoch 30, batch 5, d_loss=-0.279 g_loss=0.025 KID= 0.42490\n",
      "epoch 30, batch 6, d_loss=-0.202 g_loss=3.764 KID= 0.42490\n",
      "epoch 30, batch 7, d_loss=-0.235 g_loss=6.876 KID= 0.42490\n",
      "epoch 30, batch 8, d_loss=-0.423 g_loss=10.465 KID= 0.42490\n",
      "epoch 30, batch 9, d_loss=-0.740 g_loss=12.268 KID= 0.42490\n",
      "epoch 30, batch 10, d_loss=-0.818 g_loss=10.482 KID= 0.42490\n",
      "epoch 30, batch 11, d_loss=-0.719 g_loss=10.074 KID= 0.42490\n",
      "epoch 30, batch 12, d_loss=-0.825 g_loss=10.885 KID= 0.42490\n",
      "epoch 30, batch 13, d_loss=-1.027 g_loss=12.941 KID= 0.42490\n",
      "epoch 30, batch 14, d_loss=-0.390 g_loss=9.241 KID= 0.42490\n",
      "epoch 30, batch 15, d_loss=-0.228 g_loss=5.873 KID= 0.42490\n",
      "epoch 30, batch 16, d_loss=-0.180 g_loss=4.210 KID= 0.42490\n",
      "epoch 30, batch 17, d_loss=0.036 g_loss=3.387 KID= 0.42490\n",
      "epoch 30, batch 18, d_loss=-0.452 g_loss=3.942 KID= 0.42490\n",
      "epoch 30, batch 19, d_loss=-0.608 g_loss=5.593 KID= 0.42490\n",
      "epoch 31, batch 0, d_loss=-0.816 g_loss=6.410 KID= 0.42490\n",
      "epoch 31, batch 1, d_loss=-0.665 g_loss=6.097 KID= 0.42490\n",
      "epoch 31, batch 2, d_loss=-0.459 g_loss=5.180 KID= 0.42490\n",
      "epoch 31, batch 3, d_loss=-0.242 g_loss=4.410 KID= 0.42490\n",
      "epoch 31, batch 4, d_loss=-0.559 g_loss=3.157 KID= 0.42490\n",
      "epoch 31, batch 5, d_loss=-0.679 g_loss=2.350 KID= 0.42490\n",
      "epoch 31, batch 6, d_loss=-0.540 g_loss=2.127 KID= 0.42490\n",
      "epoch 31, batch 7, d_loss=-0.285 g_loss=1.884 KID= 0.42490\n",
      "epoch 31, batch 8, d_loss=-0.325 g_loss=2.061 KID= 0.42490\n",
      "epoch 31, batch 9, d_loss=-0.370 g_loss=3.308 KID= 0.42490\n",
      "epoch 31, batch 10, d_loss=-0.802 g_loss=4.519 KID= 0.42490\n",
      "epoch 31, batch 11, d_loss=-0.631 g_loss=3.717 KID= 0.42490\n",
      "epoch 31, batch 12, d_loss=-0.212 g_loss=3.485 KID= 0.42490\n",
      "epoch 31, batch 13, d_loss=-0.201 g_loss=4.754 KID= 0.42490\n",
      "epoch 31, batch 14, d_loss=-0.048 g_loss=6.587 KID= 0.42490\n",
      "epoch 31, batch 15, d_loss=-0.202 g_loss=8.912 KID= 0.42490\n",
      "epoch 31, batch 16, d_loss=-0.601 g_loss=11.755 KID= 0.42490\n",
      "epoch 31, batch 17, d_loss=-0.620 g_loss=12.921 KID= 0.42490\n",
      "epoch 31, batch 18, d_loss=-0.963 g_loss=13.477 KID= 0.42490\n",
      "epoch 31, batch 19, d_loss=-0.018 g_loss=8.841 KID= 0.42490\n",
      "epoch 32, batch 0, d_loss=-0.022 g_loss=5.606 KID= 0.42490\n",
      "epoch 32, batch 1, d_loss=-0.252 g_loss=3.632 KID= 0.42490\n",
      "epoch 32, batch 2, d_loss=-0.453 g_loss=2.752 KID= 0.42490\n",
      "epoch 32, batch 3, d_loss=-0.542 g_loss=2.030 KID= 0.42490\n",
      "epoch 32, batch 4, d_loss=-0.898 g_loss=1.548 KID= 0.42490\n",
      "epoch 32, batch 5, d_loss=-0.188 g_loss=0.698 KID= 0.42490\n",
      "epoch 32, batch 6, d_loss=-0.303 g_loss=-0.662 KID= 0.42490\n",
      "epoch 32, batch 7, d_loss=-0.538 g_loss=-1.712 KID= 0.42490\n",
      "epoch 32, batch 8, d_loss=-0.285 g_loss=-2.087 KID= 0.42490\n",
      "epoch 32, batch 9, d_loss=-0.299 g_loss=-1.816 KID= 0.42490\n",
      "epoch 32, batch 10, d_loss=-0.193 g_loss=-0.397 KID= 0.42490\n",
      "epoch 32, batch 11, d_loss=-0.261 g_loss=1.899 KID= 0.42490\n",
      "epoch 32, batch 12, d_loss=-0.745 g_loss=3.870 KID= 0.42490\n",
      "epoch 32, batch 13, d_loss=-1.017 g_loss=5.452 KID= 0.42490\n",
      "epoch 32, batch 14, d_loss=-0.827 g_loss=7.252 KID= 0.42490\n",
      "epoch 32, batch 15, d_loss=-0.472 g_loss=7.199 KID= 0.42490\n",
      "epoch 32, batch 16, d_loss=-0.553 g_loss=6.646 KID= 0.42490\n",
      "epoch 32, batch 17, d_loss=-0.453 g_loss=6.262 KID= 0.42490\n",
      "epoch 32, batch 18, d_loss=-0.660 g_loss=5.204 KID= 0.42490\n",
      "epoch 32, batch 19, d_loss=-0.697 g_loss=4.780 KID= 0.42490\n",
      "epoch 33, batch 0, d_loss=-0.603 g_loss=4.627 KID= 0.42490\n",
      "epoch 33, batch 1, d_loss=-0.440 g_loss=6.361 KID= 0.42490\n",
      "epoch 33, batch 2, d_loss=-0.195 g_loss=7.091 KID= 0.42490\n",
      "epoch 33, batch 3, d_loss=-0.466 g_loss=7.056 KID= 0.42490\n",
      "epoch 33, batch 4, d_loss=-0.472 g_loss=7.157 KID= 0.42490\n",
      "epoch 33, batch 5, d_loss=0.011 g_loss=5.703 KID= 0.42490\n",
      "epoch 33, batch 6, d_loss=0.088 g_loss=4.384 KID= 0.42490\n",
      "epoch 33, batch 7, d_loss=-0.282 g_loss=3.664 KID= 0.42490\n",
      "epoch 33, batch 8, d_loss=-0.445 g_loss=3.457 KID= 0.42490\n",
      "epoch 33, batch 9, d_loss=-0.480 g_loss=3.898 KID= 0.42490\n",
      "epoch 33, batch 10, d_loss=-0.627 g_loss=4.646 KID= 0.42490\n",
      "epoch 33, batch 11, d_loss=-0.389 g_loss=4.580 KID= 0.42490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33, batch 12, d_loss=-0.594 g_loss=5.128 KID= 0.42490\n",
      "epoch 33, batch 13, d_loss=0.130 g_loss=5.205 KID= 0.42490\n",
      "epoch 33, batch 14, d_loss=0.161 g_loss=4.666 KID= 0.42490\n",
      "epoch 33, batch 15, d_loss=-0.120 g_loss=3.699 KID= 0.42490\n",
      "epoch 33, batch 16, d_loss=-0.146 g_loss=2.900 KID= 0.42490\n",
      "epoch 33, batch 17, d_loss=-0.163 g_loss=2.451 KID= 0.42490\n",
      "epoch 33, batch 18, d_loss=-0.382 g_loss=1.619 KID= 0.42490\n",
      "epoch 33, batch 19, d_loss=-0.266 g_loss=1.151 KID= 0.42490\n",
      "epoch 34, batch 0, d_loss=-0.499 g_loss=0.694 KID= 0.42490\n",
      "epoch 34, batch 1, d_loss=-0.582 g_loss=0.335 KID= 0.42490\n",
      "epoch 34, batch 2, d_loss=-0.147 g_loss=-0.173 KID= 0.42490\n",
      "epoch 34, batch 3, d_loss=-0.457 g_loss=-0.143 KID= 0.42490\n",
      "epoch 34, batch 4, d_loss=-0.625 g_loss=0.710 KID= 0.42490\n",
      "epoch 34, batch 5, d_loss=-0.380 g_loss=1.283 KID= 0.42490\n",
      "epoch 34, batch 6, d_loss=-0.432 g_loss=1.926 KID= 0.42490\n",
      "epoch 34, batch 7, d_loss=-0.166 g_loss=2.607 KID= 0.42490\n",
      "epoch 34, batch 8, d_loss=-0.173 g_loss=2.683 KID= 0.42490\n",
      "epoch 34, batch 9, d_loss=-0.331 g_loss=3.134 KID= 0.42490\n",
      "epoch 34, batch 10, d_loss=-0.062 g_loss=3.536 KID= 0.42490\n",
      "epoch 34, batch 11, d_loss=-0.155 g_loss=4.673 KID= 0.42490\n",
      "epoch 34, batch 12, d_loss=-0.520 g_loss=6.634 KID= 0.42490\n",
      "epoch 34, batch 13, d_loss=-0.367 g_loss=9.254 KID= 0.42490\n",
      "epoch 34, batch 14, d_loss=-0.840 g_loss=15.187 KID= 0.42490\n",
      "epoch 34, batch 15, d_loss=-0.350 g_loss=14.068 KID= 0.42490\n",
      "epoch 34, batch 16, d_loss=0.221 g_loss=10.034 KID= 0.42490\n",
      "epoch 34, batch 17, d_loss=-0.120 g_loss=8.647 KID= 0.42490\n",
      "epoch 34, batch 18, d_loss=-0.221 g_loss=6.398 KID= 0.42490\n",
      "epoch 34, batch 19, d_loss=-0.084 g_loss=4.790 KID= 0.42490\n",
      "epoch 35, batch 0, d_loss=-0.465 g_loss=4.284 KID= 0.42490\n",
      "epoch 35, batch 1, d_loss=-0.397 g_loss=3.915 KID= 0.42490\n",
      "epoch 35, batch 2, d_loss=-0.496 g_loss=3.705 KID= 0.42490\n",
      "epoch 35, batch 3, d_loss=-0.580 g_loss=3.542 KID= 0.42490\n",
      "epoch 35, batch 4, d_loss=-0.330 g_loss=1.936 KID= 0.42490\n",
      "epoch 35, batch 5, d_loss=-0.450 g_loss=0.465 KID= 0.42490\n",
      "epoch 35, batch 6, d_loss=-0.389 g_loss=-0.757 KID= 0.42490\n",
      "epoch 35, batch 7, d_loss=-0.138 g_loss=-2.249 KID= 0.42490\n",
      "epoch 35, batch 8, d_loss=-0.003 g_loss=-2.819 KID= 0.42490\n",
      "epoch 35, batch 9, d_loss=-0.188 g_loss=-2.521 KID= 0.42490\n",
      "epoch 35, batch 10, d_loss=-0.291 g_loss=-0.627 KID= 0.42490\n",
      "epoch 35, batch 11, d_loss=-0.581 g_loss=0.039 KID= 0.42490\n",
      "epoch 35, batch 12, d_loss=-0.149 g_loss=0.969 KID= 0.42490\n",
      "epoch 35, batch 13, d_loss=0.159 g_loss=3.127 KID= 0.42490\n",
      "epoch 35, batch 14, d_loss=-0.122 g_loss=4.209 KID= 0.42490\n",
      "epoch 35, batch 15, d_loss=-0.241 g_loss=4.558 KID= 0.42490\n",
      "epoch 35, batch 16, d_loss=-0.496 g_loss=4.789 KID= 0.42490\n",
      "epoch 35, batch 17, d_loss=-0.426 g_loss=4.739 KID= 0.42490\n",
      "epoch 35, batch 18, d_loss=-0.379 g_loss=4.484 KID= 0.42490\n",
      "epoch 35, batch 19, d_loss=-0.338 g_loss=4.317 KID= 0.42490\n",
      "epoch 36, batch 0, d_loss=-0.320 g_loss=3.907 KID= 0.42490\n",
      "epoch 36, batch 1, d_loss=-0.413 g_loss=3.835 KID= 0.42490\n",
      "epoch 36, batch 2, d_loss=-0.228 g_loss=3.715 KID= 0.42490\n",
      "epoch 36, batch 3, d_loss=-0.119 g_loss=3.638 KID= 0.42490\n",
      "epoch 36, batch 4, d_loss=-0.534 g_loss=3.791 KID= 0.42490\n",
      "epoch 36, batch 5, d_loss=-0.424 g_loss=3.989 KID= 0.42490\n",
      "epoch 36, batch 6, d_loss=-0.188 g_loss=3.612 KID= 0.42490\n",
      "epoch 36, batch 7, d_loss=-0.074 g_loss=3.330 KID= 0.42490\n",
      "epoch 36, batch 8, d_loss=-0.096 g_loss=3.132 KID= 0.42490\n",
      "epoch 36, batch 9, d_loss=0.049 g_loss=2.599 KID= 0.42490\n",
      "epoch 36, batch 10, d_loss=-0.281 g_loss=3.003 KID= 0.42490\n",
      "epoch 36, batch 11, d_loss=-0.351 g_loss=3.514 KID= 0.42490\n",
      "epoch 36, batch 12, d_loss=-0.472 g_loss=4.259 KID= 0.42490\n",
      "epoch 36, batch 13, d_loss=-0.458 g_loss=5.725 KID= 0.42490\n",
      "epoch 36, batch 14, d_loss=-0.464 g_loss=5.854 KID= 0.42490\n",
      "epoch 36, batch 15, d_loss=-0.173 g_loss=4.541 KID= 0.42490\n",
      "epoch 36, batch 16, d_loss=-0.360 g_loss=3.814 KID= 0.42490\n",
      "epoch 36, batch 17, d_loss=-0.262 g_loss=2.786 KID= 0.42490\n",
      "epoch 36, batch 18, d_loss=-0.249 g_loss=2.125 KID= 0.42490\n",
      "epoch 36, batch 19, d_loss=-0.215 g_loss=1.964 KID= 0.42490\n",
      "epoch 37, batch 0, d_loss=-0.447 g_loss=2.944 KID= 0.42490\n",
      "epoch 37, batch 1, d_loss=-0.349 g_loss=3.425 KID= 0.42490\n",
      "epoch 37, batch 2, d_loss=-0.262 g_loss=3.977 KID= 0.42490\n",
      "epoch 37, batch 3, d_loss=-0.177 g_loss=4.905 KID= 0.42490\n",
      "epoch 37, batch 4, d_loss=-0.503 g_loss=6.119 KID= 0.42490\n",
      "epoch 37, batch 5, d_loss=-0.509 g_loss=6.866 KID= 0.42490\n",
      "epoch 37, batch 6, d_loss=-0.367 g_loss=8.307 KID= 0.42490\n",
      "epoch 37, batch 7, d_loss=-0.373 g_loss=9.194 KID= 0.42490\n",
      "epoch 37, batch 8, d_loss=-0.164 g_loss=8.496 KID= 0.42490\n",
      "epoch 37, batch 9, d_loss=-0.442 g_loss=8.698 KID= 0.42490\n",
      "epoch 37, batch 10, d_loss=-0.445 g_loss=8.486 KID= 0.42490\n",
      "epoch 37, batch 11, d_loss=0.166 g_loss=5.377 KID= 0.42490\n",
      "epoch 37, batch 12, d_loss=-0.001 g_loss=2.920 KID= 0.42490\n",
      "epoch 37, batch 13, d_loss=0.156 g_loss=1.701 KID= 0.42490\n",
      "epoch 37, batch 14, d_loss=-0.198 g_loss=1.203 KID= 0.42490\n",
      "epoch 37, batch 15, d_loss=-0.184 g_loss=1.011 KID= 0.42490\n",
      "epoch 37, batch 16, d_loss=-0.348 g_loss=0.806 KID= 0.42490\n",
      "epoch 37, batch 17, d_loss=-0.533 g_loss=0.627 KID= 0.42490\n",
      "epoch 37, batch 18, d_loss=-0.487 g_loss=0.559 KID= 0.42490\n",
      "epoch 37, batch 19, d_loss=-0.272 g_loss=0.356 KID= 0.42490\n",
      "epoch 38, batch 0, d_loss=-0.314 g_loss=0.198 KID= 0.42490\n",
      "epoch 38, batch 1, d_loss=0.225 g_loss=-0.123 KID= 0.42490\n",
      "epoch 38, batch 2, d_loss=-0.036 g_loss=-0.236 KID= 0.42490\n",
      "epoch 38, batch 3, d_loss=-0.289 g_loss=0.377 KID= 0.42490\n",
      "epoch 38, batch 4, d_loss=-0.509 g_loss=0.346 KID= 0.42490\n",
      "epoch 38, batch 5, d_loss=-0.659 g_loss=-0.475 KID= 0.42490\n",
      "epoch 38, batch 6, d_loss=-0.575 g_loss=-1.626 KID= 0.42490\n",
      "epoch 38, batch 7, d_loss=-0.247 g_loss=-2.452 KID= 0.42490\n",
      "epoch 38, batch 8, d_loss=0.373 g_loss=-1.615 KID= 0.42490\n",
      "epoch 38, batch 9, d_loss=-0.117 g_loss=-0.708 KID= 0.42490\n",
      "epoch 38, batch 10, d_loss=-0.023 g_loss=0.539 KID= 0.42490\n",
      "epoch 38, batch 11, d_loss=-0.401 g_loss=1.046 KID= 0.42490\n",
      "epoch 38, batch 12, d_loss=-0.595 g_loss=0.966 KID= 0.42490\n",
      "epoch 38, batch 13, d_loss=-0.227 g_loss=1.409 KID= 0.42490\n",
      "epoch 38, batch 14, d_loss=-0.312 g_loss=2.125 KID= 0.42490\n",
      "epoch 38, batch 15, d_loss=-0.364 g_loss=2.738 KID= 0.42490\n",
      "epoch 38, batch 16, d_loss=-0.293 g_loss=3.828 KID= 0.42490\n",
      "epoch 38, batch 17, d_loss=-0.468 g_loss=5.442 KID= 0.42490\n",
      "epoch 38, batch 18, d_loss=-0.280 g_loss=5.434 KID= 0.42490\n",
      "epoch 38, batch 19, d_loss=-0.108 g_loss=5.516 KID= 0.42490\n",
      "epoch 39, batch 0, d_loss=-0.077 g_loss=4.819 KID= 0.42490\n",
      "epoch 39, batch 1, d_loss=-0.038 g_loss=4.714 KID= 0.42490\n",
      "epoch 39, batch 2, d_loss=-0.158 g_loss=4.823 KID= 0.42490\n",
      "epoch 39, batch 3, d_loss=-0.099 g_loss=5.123 KID= 0.42490\n",
      "epoch 39, batch 4, d_loss=-0.369 g_loss=5.361 KID= 0.42490\n",
      "epoch 39, batch 5, d_loss=-0.269 g_loss=5.124 KID= 0.42490\n",
      "epoch 39, batch 6, d_loss=-0.146 g_loss=5.184 KID= 0.42490\n",
      "epoch 39, batch 7, d_loss=-0.217 g_loss=6.041 KID= 0.42490\n",
      "epoch 39, batch 8, d_loss=-0.397 g_loss=7.911 KID= 0.42490\n",
      "epoch 39, batch 9, d_loss=-0.301 g_loss=9.492 KID= 0.42490\n",
      "epoch 39, batch 10, d_loss=-0.359 g_loss=11.657 KID= 0.42490\n",
      "epoch 39, batch 11, d_loss=0.002 g_loss=10.381 KID= 0.42490\n",
      "epoch 39, batch 12, d_loss=-0.262 g_loss=11.092 KID= 0.42490\n",
      "epoch 39, batch 13, d_loss=-0.627 g_loss=12.924 KID= 0.42490\n",
      "epoch 39, batch 14, d_loss=-0.710 g_loss=11.682 KID= 0.42490\n",
      "epoch 39, batch 15, d_loss=0.143 g_loss=7.216 KID= 0.42490\n",
      "epoch 39, batch 16, d_loss=0.216 g_loss=3.792 KID= 0.42490\n",
      "epoch 39, batch 17, d_loss=-0.266 g_loss=1.321 KID= 0.42490\n",
      "epoch 39, batch 18, d_loss=-0.481 g_loss=-0.114 KID= 0.42490\n",
      "epoch 39, batch 19, d_loss=-0.303 g_loss=-0.600 KID= 0.42490\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 40, batch 0, d_loss=-0.588 g_loss=-0.836 KID= 0.20584\n",
      "epoch 40, batch 1, d_loss=-0.333 g_loss=-0.509 KID= 0.20584\n",
      "epoch 40, batch 2, d_loss=-0.253 g_loss=0.150 KID= 0.20584\n",
      "epoch 40, batch 3, d_loss=-0.046 g_loss=1.260 KID= 0.20584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40, batch 4, d_loss=-0.634 g_loss=2.150 KID= 0.20584\n",
      "epoch 40, batch 5, d_loss=-0.286 g_loss=1.507 KID= 0.20584\n",
      "epoch 40, batch 6, d_loss=-0.124 g_loss=0.660 KID= 0.20584\n",
      "epoch 40, batch 7, d_loss=-0.161 g_loss=0.514 KID= 0.20584\n",
      "epoch 40, batch 8, d_loss=0.033 g_loss=0.021 KID= 0.20584\n",
      "epoch 40, batch 9, d_loss=-0.144 g_loss=-0.354 KID= 0.20584\n",
      "epoch 40, batch 10, d_loss=-0.106 g_loss=-0.830 KID= 0.20584\n",
      "epoch 40, batch 11, d_loss=-0.370 g_loss=-1.180 KID= 0.20584\n",
      "epoch 40, batch 12, d_loss=-0.523 g_loss=-2.222 KID= 0.20584\n",
      "epoch 40, batch 13, d_loss=-0.418 g_loss=-2.092 KID= 0.20584\n",
      "epoch 40, batch 14, d_loss=-0.109 g_loss=-0.354 KID= 0.20584\n",
      "epoch 40, batch 15, d_loss=-0.246 g_loss=0.618 KID= 0.20584\n",
      "epoch 40, batch 16, d_loss=0.045 g_loss=1.722 KID= 0.20584\n",
      "epoch 40, batch 17, d_loss=-0.147 g_loss=2.580 KID= 0.20584\n",
      "epoch 40, batch 18, d_loss=-0.161 g_loss=2.911 KID= 0.20584\n",
      "epoch 40, batch 19, d_loss=-0.267 g_loss=3.299 KID= 0.20584\n",
      "epoch 41, batch 0, d_loss=-0.111 g_loss=2.773 KID= 0.20584\n",
      "epoch 41, batch 1, d_loss=-0.424 g_loss=2.599 KID= 0.20584\n",
      "epoch 41, batch 2, d_loss=-0.362 g_loss=2.355 KID= 0.20584\n",
      "epoch 41, batch 3, d_loss=-0.186 g_loss=1.644 KID= 0.20584\n",
      "epoch 41, batch 4, d_loss=-0.319 g_loss=1.249 KID= 0.20584\n",
      "epoch 41, batch 5, d_loss=-0.369 g_loss=1.310 KID= 0.20584\n",
      "epoch 41, batch 6, d_loss=-0.283 g_loss=1.368 KID= 0.20584\n",
      "epoch 41, batch 7, d_loss=-0.339 g_loss=1.189 KID= 0.20584\n",
      "epoch 41, batch 8, d_loss=-0.146 g_loss=0.849 KID= 0.20584\n",
      "epoch 41, batch 9, d_loss=-0.116 g_loss=0.395 KID= 0.20584\n",
      "epoch 41, batch 10, d_loss=-0.292 g_loss=0.104 KID= 0.20584\n",
      "epoch 41, batch 11, d_loss=-0.361 g_loss=-0.401 KID= 0.20584\n",
      "epoch 41, batch 12, d_loss=-0.396 g_loss=-0.902 KID= 0.20584\n",
      "epoch 41, batch 13, d_loss=-0.086 g_loss=-0.682 KID= 0.20584\n",
      "epoch 41, batch 14, d_loss=-0.384 g_loss=-0.408 KID= 0.20584\n",
      "epoch 41, batch 15, d_loss=-0.059 g_loss=-0.668 KID= 0.20584\n",
      "epoch 41, batch 16, d_loss=0.037 g_loss=-0.878 KID= 0.20584\n",
      "epoch 41, batch 17, d_loss=-0.291 g_loss=-1.121 KID= 0.20584\n",
      "epoch 41, batch 18, d_loss=-0.154 g_loss=-1.306 KID= 0.20584\n",
      "epoch 41, batch 19, d_loss=-0.196 g_loss=-1.607 KID= 0.20584\n",
      "epoch 42, batch 0, d_loss=-0.235 g_loss=-0.816 KID= 0.20584\n",
      "epoch 42, batch 1, d_loss=-0.353 g_loss=-0.442 KID= 0.20584\n",
      "epoch 42, batch 2, d_loss=-0.436 g_loss=-0.253 KID= 0.20584\n",
      "epoch 42, batch 3, d_loss=0.001 g_loss=0.906 KID= 0.20584\n",
      "epoch 42, batch 4, d_loss=-0.104 g_loss=2.029 KID= 0.20584\n",
      "epoch 42, batch 5, d_loss=-0.191 g_loss=2.579 KID= 0.20584\n",
      "epoch 42, batch 6, d_loss=-0.144 g_loss=3.113 KID= 0.20584\n",
      "epoch 42, batch 7, d_loss=-0.187 g_loss=3.623 KID= 0.20584\n",
      "epoch 42, batch 8, d_loss=-0.279 g_loss=3.859 KID= 0.20584\n",
      "epoch 42, batch 9, d_loss=-0.322 g_loss=4.015 KID= 0.20584\n",
      "epoch 42, batch 10, d_loss=0.076 g_loss=3.844 KID= 0.20584\n",
      "epoch 42, batch 11, d_loss=-0.092 g_loss=3.435 KID= 0.20584\n",
      "epoch 42, batch 12, d_loss=-0.071 g_loss=3.105 KID= 0.20584\n",
      "epoch 42, batch 13, d_loss=-0.101 g_loss=3.090 KID= 0.20584\n",
      "epoch 42, batch 14, d_loss=-0.267 g_loss=3.178 KID= 0.20584\n",
      "epoch 42, batch 15, d_loss=-0.379 g_loss=3.277 KID= 0.20584\n",
      "epoch 42, batch 16, d_loss=-0.303 g_loss=2.861 KID= 0.20584\n",
      "epoch 42, batch 17, d_loss=-0.442 g_loss=2.485 KID= 0.20584\n",
      "epoch 42, batch 18, d_loss=-0.385 g_loss=1.502 KID= 0.20584\n",
      "epoch 42, batch 19, d_loss=-0.170 g_loss=0.102 KID= 0.20584\n",
      "epoch 43, batch 0, d_loss=0.155 g_loss=-0.276 KID= 0.20584\n",
      "epoch 43, batch 1, d_loss=-0.218 g_loss=0.096 KID= 0.20584\n",
      "epoch 43, batch 2, d_loss=-0.216 g_loss=0.795 KID= 0.20584\n",
      "epoch 43, batch 3, d_loss=-0.247 g_loss=2.051 KID= 0.20584\n",
      "epoch 43, batch 4, d_loss=-0.263 g_loss=2.984 KID= 0.20584\n",
      "epoch 43, batch 5, d_loss=0.151 g_loss=3.033 KID= 0.20584\n",
      "epoch 43, batch 6, d_loss=0.079 g_loss=2.585 KID= 0.20584\n",
      "epoch 43, batch 7, d_loss=-0.027 g_loss=2.509 KID= 0.20584\n",
      "epoch 43, batch 8, d_loss=-0.117 g_loss=2.794 KID= 0.20584\n",
      "epoch 43, batch 9, d_loss=-0.264 g_loss=3.386 KID= 0.20584\n",
      "epoch 43, batch 10, d_loss=-0.512 g_loss=4.687 KID= 0.20584\n",
      "epoch 43, batch 11, d_loss=-0.262 g_loss=6.226 KID= 0.20584\n",
      "epoch 43, batch 12, d_loss=-0.342 g_loss=8.583 KID= 0.20584\n",
      "epoch 43, batch 13, d_loss=0.806 g_loss=6.520 KID= 0.20584\n",
      "epoch 43, batch 14, d_loss=0.071 g_loss=6.109 KID= 0.20584\n",
      "epoch 43, batch 15, d_loss=-0.252 g_loss=5.803 KID= 0.20584\n",
      "epoch 43, batch 16, d_loss=-0.059 g_loss=5.545 KID= 0.20584\n",
      "epoch 43, batch 17, d_loss=-0.197 g_loss=5.466 KID= 0.20584\n",
      "epoch 43, batch 18, d_loss=-0.057 g_loss=4.516 KID= 0.20584\n",
      "epoch 43, batch 19, d_loss=-0.201 g_loss=4.604 KID= 0.20584\n",
      "epoch 44, batch 0, d_loss=-0.315 g_loss=4.967 KID= 0.20584\n",
      "epoch 44, batch 1, d_loss=-0.091 g_loss=4.558 KID= 0.20584\n",
      "epoch 44, batch 2, d_loss=-0.062 g_loss=3.496 KID= 0.20584\n",
      "epoch 44, batch 3, d_loss=-0.082 g_loss=2.935 KID= 0.20584\n",
      "epoch 44, batch 4, d_loss=-0.094 g_loss=2.376 KID= 0.20584\n",
      "epoch 44, batch 5, d_loss=0.001 g_loss=1.033 KID= 0.20584\n",
      "epoch 44, batch 6, d_loss=-0.143 g_loss=-0.255 KID= 0.20584\n",
      "epoch 44, batch 7, d_loss=-0.267 g_loss=-1.134 KID= 0.20584\n",
      "epoch 44, batch 8, d_loss=-0.423 g_loss=-2.107 KID= 0.20584\n",
      "epoch 44, batch 9, d_loss=-0.369 g_loss=-2.801 KID= 0.20584\n",
      "epoch 44, batch 10, d_loss=0.316 g_loss=-1.514 KID= 0.20584\n",
      "epoch 44, batch 11, d_loss=-0.094 g_loss=-0.848 KID= 0.20584\n",
      "epoch 44, batch 12, d_loss=-0.065 g_loss=-0.304 KID= 0.20584\n",
      "epoch 44, batch 13, d_loss=0.061 g_loss=0.897 KID= 0.20584\n",
      "epoch 44, batch 14, d_loss=-0.173 g_loss=1.988 KID= 0.20584\n",
      "epoch 44, batch 15, d_loss=-0.319 g_loss=2.663 KID= 0.20584\n",
      "epoch 44, batch 16, d_loss=-0.317 g_loss=3.330 KID= 0.20584\n",
      "epoch 44, batch 17, d_loss=-0.412 g_loss=4.289 KID= 0.20584\n",
      "epoch 44, batch 18, d_loss=-0.185 g_loss=4.472 KID= 0.20584\n",
      "epoch 44, batch 19, d_loss=-0.240 g_loss=4.386 KID= 0.20584\n",
      "epoch 45, batch 0, d_loss=-0.388 g_loss=4.652 KID= 0.20584\n",
      "epoch 45, batch 1, d_loss=-0.140 g_loss=3.841 KID= 0.20584\n",
      "epoch 45, batch 2, d_loss=-0.038 g_loss=2.455 KID= 0.20584\n",
      "epoch 45, batch 3, d_loss=-0.271 g_loss=1.841 KID= 0.20584\n",
      "epoch 45, batch 4, d_loss=-0.270 g_loss=1.550 KID= 0.20584\n",
      "epoch 45, batch 5, d_loss=-0.220 g_loss=0.981 KID= 0.20584\n",
      "epoch 45, batch 6, d_loss=0.035 g_loss=0.030 KID= 0.20584\n",
      "epoch 45, batch 7, d_loss=-0.167 g_loss=-0.841 KID= 0.20584\n",
      "epoch 45, batch 8, d_loss=-0.086 g_loss=-1.357 KID= 0.20584\n",
      "epoch 45, batch 9, d_loss=0.062 g_loss=-1.867 KID= 0.20584\n",
      "epoch 45, batch 10, d_loss=0.186 g_loss=-1.751 KID= 0.20584\n",
      "epoch 45, batch 11, d_loss=-0.241 g_loss=-1.841 KID= 0.20584\n",
      "epoch 45, batch 12, d_loss=0.154 g_loss=-1.735 KID= 0.20584\n",
      "epoch 45, batch 13, d_loss=0.056 g_loss=-2.061 KID= 0.20584\n",
      "epoch 45, batch 14, d_loss=0.073 g_loss=-2.550 KID= 0.20584\n",
      "epoch 45, batch 15, d_loss=-0.065 g_loss=-2.493 KID= 0.20584\n",
      "epoch 45, batch 16, d_loss=0.102 g_loss=-2.030 KID= 0.20584\n",
      "epoch 45, batch 17, d_loss=0.034 g_loss=-1.640 KID= 0.20584\n",
      "epoch 45, batch 18, d_loss=0.041 g_loss=-1.048 KID= 0.20584\n",
      "epoch 45, batch 19, d_loss=-0.005 g_loss=-0.392 KID= 0.20584\n",
      "epoch 46, batch 0, d_loss=0.009 g_loss=-0.089 KID= 0.20584\n",
      "epoch 46, batch 1, d_loss=-0.100 g_loss=0.154 KID= 0.20584\n",
      "epoch 46, batch 2, d_loss=0.024 g_loss=0.333 KID= 0.20584\n",
      "epoch 46, batch 3, d_loss=-0.172 g_loss=0.422 KID= 0.20584\n",
      "epoch 46, batch 4, d_loss=-0.198 g_loss=0.624 KID= 0.20584\n",
      "epoch 46, batch 5, d_loss=-0.211 g_loss=0.836 KID= 0.20584\n",
      "epoch 46, batch 6, d_loss=-0.057 g_loss=0.960 KID= 0.20584\n",
      "epoch 46, batch 7, d_loss=-0.165 g_loss=1.065 KID= 0.20584\n",
      "epoch 46, batch 8, d_loss=-0.208 g_loss=1.049 KID= 0.20584\n",
      "epoch 46, batch 9, d_loss=-0.136 g_loss=0.916 KID= 0.20584\n",
      "epoch 46, batch 10, d_loss=-0.305 g_loss=0.608 KID= 0.20584\n",
      "epoch 46, batch 11, d_loss=-0.251 g_loss=0.228 KID= 0.20584\n",
      "epoch 46, batch 12, d_loss=-0.236 g_loss=-0.143 KID= 0.20584\n",
      "epoch 46, batch 13, d_loss=-0.266 g_loss=-0.457 KID= 0.20584\n",
      "epoch 46, batch 14, d_loss=-0.188 g_loss=-0.483 KID= 0.20584\n",
      "epoch 46, batch 15, d_loss=0.034 g_loss=-0.087 KID= 0.20584\n",
      "epoch 46, batch 16, d_loss=-0.061 g_loss=0.253 KID= 0.20584\n",
      "epoch 46, batch 17, d_loss=-0.278 g_loss=0.766 KID= 0.20584\n",
      "epoch 46, batch 18, d_loss=-0.261 g_loss=1.178 KID= 0.20584\n",
      "epoch 46, batch 19, d_loss=-0.390 g_loss=1.573 KID= 0.20584\n",
      "epoch 47, batch 0, d_loss=-0.284 g_loss=1.704 KID= 0.20584\n",
      "epoch 47, batch 1, d_loss=-0.345 g_loss=1.660 KID= 0.20584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47, batch 2, d_loss=-0.187 g_loss=1.568 KID= 0.20584\n",
      "epoch 47, batch 3, d_loss=0.585 g_loss=1.348 KID= 0.20584\n",
      "epoch 47, batch 4, d_loss=0.362 g_loss=1.344 KID= 0.20584\n",
      "epoch 47, batch 5, d_loss=-0.083 g_loss=1.456 KID= 0.20584\n",
      "epoch 47, batch 6, d_loss=-0.135 g_loss=1.440 KID= 0.20584\n",
      "epoch 47, batch 7, d_loss=-0.245 g_loss=1.230 KID= 0.20584\n",
      "epoch 47, batch 8, d_loss=-0.163 g_loss=0.648 KID= 0.20584\n",
      "epoch 47, batch 9, d_loss=-0.154 g_loss=0.128 KID= 0.20584\n",
      "epoch 47, batch 10, d_loss=-0.249 g_loss=-0.428 KID= 0.20584\n",
      "epoch 47, batch 11, d_loss=-0.217 g_loss=-0.976 KID= 0.20584\n",
      "epoch 47, batch 12, d_loss=-0.035 g_loss=-1.314 KID= 0.20584\n",
      "epoch 47, batch 13, d_loss=-0.251 g_loss=-1.488 KID= 0.20584\n",
      "epoch 47, batch 14, d_loss=-0.091 g_loss=-1.124 KID= 0.20584\n",
      "epoch 47, batch 15, d_loss=0.071 g_loss=-0.795 KID= 0.20584\n",
      "epoch 47, batch 16, d_loss=0.168 g_loss=-0.312 KID= 0.20584\n",
      "epoch 47, batch 17, d_loss=-0.160 g_loss=0.274 KID= 0.20584\n",
      "epoch 47, batch 18, d_loss=-0.025 g_loss=0.191 KID= 0.20584\n",
      "epoch 47, batch 19, d_loss=-0.214 g_loss=-0.110 KID= 0.20584\n",
      "epoch 48, batch 0, d_loss=-0.021 g_loss=-0.617 KID= 0.20584\n",
      "epoch 48, batch 1, d_loss=-0.141 g_loss=-1.001 KID= 0.20584\n",
      "epoch 48, batch 2, d_loss=-0.108 g_loss=-1.492 KID= 0.20584\n",
      "epoch 48, batch 3, d_loss=0.106 g_loss=-1.315 KID= 0.20584\n",
      "epoch 48, batch 4, d_loss=0.093 g_loss=-1.457 KID= 0.20584\n",
      "epoch 48, batch 5, d_loss=0.059 g_loss=-1.531 KID= 0.20584\n",
      "epoch 48, batch 6, d_loss=0.301 g_loss=-1.158 KID= 0.20584\n",
      "epoch 48, batch 7, d_loss=0.072 g_loss=-0.975 KID= 0.20584\n",
      "epoch 48, batch 8, d_loss=-0.179 g_loss=-0.941 KID= 0.20584\n",
      "epoch 48, batch 9, d_loss=-0.270 g_loss=-1.244 KID= 0.20584\n",
      "epoch 48, batch 10, d_loss=-0.294 g_loss=-1.681 KID= 0.20584\n",
      "epoch 48, batch 11, d_loss=-0.285 g_loss=-1.946 KID= 0.20584\n",
      "epoch 48, batch 12, d_loss=0.102 g_loss=-1.186 KID= 0.20584\n",
      "epoch 48, batch 13, d_loss=-0.163 g_loss=-0.750 KID= 0.20584\n",
      "epoch 48, batch 14, d_loss=-0.137 g_loss=-0.326 KID= 0.20584\n",
      "epoch 48, batch 15, d_loss=-0.280 g_loss=0.289 KID= 0.20584\n",
      "epoch 48, batch 16, d_loss=-0.247 g_loss=0.400 KID= 0.20584\n",
      "epoch 48, batch 17, d_loss=-0.240 g_loss=-0.121 KID= 0.20584\n",
      "epoch 48, batch 18, d_loss=-0.338 g_loss=-0.522 KID= 0.20584\n",
      "epoch 48, batch 19, d_loss=-0.393 g_loss=-1.191 KID= 0.20584\n",
      "epoch 49, batch 0, d_loss=0.426 g_loss=-1.676 KID= 0.20584\n",
      "epoch 49, batch 1, d_loss=0.154 g_loss=-1.859 KID= 0.20584\n",
      "epoch 49, batch 2, d_loss=0.030 g_loss=-1.343 KID= 0.20584\n",
      "epoch 49, batch 3, d_loss=-0.309 g_loss=-1.182 KID= 0.20584\n",
      "epoch 49, batch 4, d_loss=-0.304 g_loss=-1.374 KID= 0.20584\n",
      "epoch 49, batch 5, d_loss=-0.130 g_loss=-1.174 KID= 0.20584\n",
      "epoch 49, batch 6, d_loss=-0.055 g_loss=-0.769 KID= 0.20584\n",
      "epoch 49, batch 7, d_loss=0.029 g_loss=-0.274 KID= 0.20584\n",
      "epoch 49, batch 8, d_loss=-0.073 g_loss=0.426 KID= 0.20584\n",
      "epoch 49, batch 9, d_loss=-0.114 g_loss=1.067 KID= 0.20584\n",
      "epoch 49, batch 10, d_loss=-0.123 g_loss=1.475 KID= 0.20584\n",
      "epoch 49, batch 11, d_loss=-0.077 g_loss=1.831 KID= 0.20584\n",
      "epoch 49, batch 12, d_loss=-0.085 g_loss=2.504 KID= 0.20584\n",
      "epoch 49, batch 13, d_loss=-0.119 g_loss=2.572 KID= 0.20584\n",
      "epoch 49, batch 14, d_loss=-0.226 g_loss=2.582 KID= 0.20584\n",
      "epoch 49, batch 15, d_loss=-0.178 g_loss=3.024 KID= 0.20584\n",
      "epoch 49, batch 16, d_loss=0.155 g_loss=3.070 KID= 0.20584\n",
      "epoch 49, batch 17, d_loss=-0.068 g_loss=3.124 KID= 0.20584\n",
      "epoch 49, batch 18, d_loss=0.053 g_loss=3.343 KID= 0.20584\n",
      "epoch 49, batch 19, d_loss=0.097 g_loss=4.098 KID= 0.20584\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 50, batch 0, d_loss=0.171 g_loss=3.765 KID= 0.09153\n",
      "epoch 50, batch 1, d_loss=0.055 g_loss=2.966 KID= 0.09153\n",
      "epoch 50, batch 2, d_loss=0.041 g_loss=2.042 KID= 0.09153\n",
      "epoch 50, batch 3, d_loss=0.180 g_loss=1.120 KID= 0.09153\n",
      "epoch 50, batch 4, d_loss=0.129 g_loss=0.273 KID= 0.09153\n",
      "epoch 50, batch 5, d_loss=-0.076 g_loss=-0.306 KID= 0.09153\n",
      "epoch 50, batch 6, d_loss=-0.127 g_loss=-0.546 KID= 0.09153\n",
      "epoch 50, batch 7, d_loss=-0.038 g_loss=-0.842 KID= 0.09153\n",
      "epoch 50, batch 8, d_loss=-0.181 g_loss=-1.090 KID= 0.09153\n",
      "epoch 50, batch 9, d_loss=-0.101 g_loss=-1.122 KID= 0.09153\n",
      "epoch 50, batch 10, d_loss=-0.107 g_loss=-1.096 KID= 0.09153\n",
      "epoch 50, batch 11, d_loss=-0.081 g_loss=-1.063 KID= 0.09153\n",
      "epoch 50, batch 12, d_loss=-0.066 g_loss=-1.148 KID= 0.09153\n",
      "epoch 50, batch 13, d_loss=-0.113 g_loss=-1.170 KID= 0.09153\n",
      "epoch 50, batch 14, d_loss=-0.138 g_loss=-1.245 KID= 0.09153\n",
      "epoch 50, batch 15, d_loss=0.074 g_loss=-1.438 KID= 0.09153\n",
      "epoch 50, batch 16, d_loss=0.270 g_loss=-1.327 KID= 0.09153\n",
      "epoch 50, batch 17, d_loss=-0.109 g_loss=-1.158 KID= 0.09153\n",
      "epoch 50, batch 18, d_loss=-0.112 g_loss=-0.938 KID= 0.09153\n",
      "epoch 50, batch 19, d_loss=-0.332 g_loss=-1.139 KID= 0.09153\n",
      "epoch 51, batch 0, d_loss=-0.282 g_loss=-1.045 KID= 0.09153\n",
      "epoch 51, batch 1, d_loss=-0.334 g_loss=-1.461 KID= 0.09153\n",
      "epoch 51, batch 2, d_loss=-0.041 g_loss=-1.389 KID= 0.09153\n",
      "epoch 51, batch 3, d_loss=-0.064 g_loss=-0.935 KID= 0.09153\n",
      "epoch 51, batch 4, d_loss=0.119 g_loss=-0.660 KID= 0.09153\n",
      "epoch 51, batch 5, d_loss=0.142 g_loss=-0.023 KID= 0.09153\n",
      "epoch 51, batch 6, d_loss=0.068 g_loss=0.694 KID= 0.09153\n",
      "epoch 51, batch 7, d_loss=0.086 g_loss=1.059 KID= 0.09153\n",
      "epoch 51, batch 8, d_loss=-0.028 g_loss=1.355 KID= 0.09153\n",
      "epoch 51, batch 9, d_loss=-0.097 g_loss=1.689 KID= 0.09153\n",
      "epoch 51, batch 10, d_loss=-0.066 g_loss=2.124 KID= 0.09153\n",
      "epoch 51, batch 11, d_loss=-0.208 g_loss=2.596 KID= 0.09153\n",
      "epoch 51, batch 12, d_loss=-0.174 g_loss=2.930 KID= 0.09153\n",
      "epoch 51, batch 13, d_loss=-0.051 g_loss=3.258 KID= 0.09153\n",
      "epoch 51, batch 14, d_loss=-0.226 g_loss=3.776 KID= 0.09153\n",
      "epoch 51, batch 15, d_loss=0.180 g_loss=3.179 KID= 0.09153\n",
      "epoch 51, batch 16, d_loss=0.274 g_loss=2.419 KID= 0.09153\n",
      "epoch 51, batch 17, d_loss=-0.005 g_loss=2.405 KID= 0.09153\n",
      "epoch 51, batch 18, d_loss=-0.047 g_loss=2.681 KID= 0.09153\n",
      "epoch 51, batch 19, d_loss=-0.146 g_loss=3.282 KID= 0.09153\n",
      "epoch 52, batch 0, d_loss=0.046 g_loss=3.169 KID= 0.09153\n",
      "epoch 52, batch 1, d_loss=0.079 g_loss=3.166 KID= 0.09153\n",
      "epoch 52, batch 2, d_loss=-0.104 g_loss=3.027 KID= 0.09153\n",
      "epoch 52, batch 3, d_loss=0.424 g_loss=2.168 KID= 0.09153\n",
      "epoch 52, batch 4, d_loss=0.337 g_loss=1.960 KID= 0.09153\n",
      "epoch 52, batch 5, d_loss=-0.037 g_loss=1.856 KID= 0.09153\n",
      "epoch 52, batch 6, d_loss=-0.076 g_loss=1.654 KID= 0.09153\n",
      "epoch 52, batch 7, d_loss=-0.195 g_loss=1.721 KID= 0.09153\n",
      "epoch 52, batch 8, d_loss=-0.295 g_loss=1.655 KID= 0.09153\n",
      "epoch 52, batch 9, d_loss=-0.175 g_loss=1.408 KID= 0.09153\n",
      "epoch 52, batch 10, d_loss=-0.310 g_loss=1.348 KID= 0.09153\n",
      "epoch 52, batch 11, d_loss=-0.177 g_loss=1.385 KID= 0.09153\n",
      "epoch 52, batch 12, d_loss=-0.017 g_loss=1.393 KID= 0.09153\n",
      "epoch 52, batch 13, d_loss=-0.108 g_loss=1.407 KID= 0.09153\n",
      "epoch 52, batch 14, d_loss=-0.246 g_loss=1.582 KID= 0.09153\n",
      "epoch 52, batch 15, d_loss=0.144 g_loss=1.454 KID= 0.09153\n",
      "epoch 52, batch 16, d_loss=0.194 g_loss=1.384 KID= 0.09153\n",
      "epoch 52, batch 17, d_loss=-0.223 g_loss=1.579 KID= 0.09153\n",
      "epoch 52, batch 18, d_loss=0.050 g_loss=1.713 KID= 0.09153\n",
      "epoch 52, batch 19, d_loss=-0.050 g_loss=1.961 KID= 0.09153\n",
      "epoch 53, batch 0, d_loss=-0.143 g_loss=2.152 KID= 0.09153\n",
      "epoch 53, batch 1, d_loss=-0.062 g_loss=2.345 KID= 0.09153\n",
      "epoch 53, batch 2, d_loss=-0.159 g_loss=2.636 KID= 0.09153\n",
      "epoch 53, batch 3, d_loss=0.198 g_loss=2.299 KID= 0.09153\n",
      "epoch 53, batch 4, d_loss=0.182 g_loss=1.836 KID= 0.09153\n",
      "epoch 53, batch 5, d_loss=-0.206 g_loss=1.456 KID= 0.09153\n",
      "epoch 53, batch 6, d_loss=-0.036 g_loss=1.127 KID= 0.09153\n",
      "epoch 53, batch 7, d_loss=-0.003 g_loss=0.924 KID= 0.09153\n",
      "epoch 53, batch 8, d_loss=-0.141 g_loss=0.823 KID= 0.09153\n",
      "epoch 53, batch 9, d_loss=-0.019 g_loss=0.835 KID= 0.09153\n",
      "epoch 53, batch 10, d_loss=-0.117 g_loss=0.939 KID= 0.09153\n",
      "epoch 53, batch 11, d_loss=-0.178 g_loss=1.019 KID= 0.09153\n",
      "epoch 53, batch 12, d_loss=0.151 g_loss=0.611 KID= 0.09153\n",
      "epoch 53, batch 13, d_loss=0.085 g_loss=0.384 KID= 0.09153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53, batch 14, d_loss=-0.137 g_loss=0.603 KID= 0.09153\n",
      "epoch 53, batch 15, d_loss=0.179 g_loss=0.687 KID= 0.09153\n",
      "epoch 53, batch 16, d_loss=0.153 g_loss=0.773 KID= 0.09153\n",
      "epoch 53, batch 17, d_loss=-0.125 g_loss=0.875 KID= 0.09153\n",
      "epoch 53, batch 18, d_loss=0.008 g_loss=0.851 KID= 0.09153\n",
      "epoch 53, batch 19, d_loss=-0.239 g_loss=0.851 KID= 0.09153\n",
      "epoch 54, batch 0, d_loss=-0.159 g_loss=0.631 KID= 0.09153\n",
      "epoch 54, batch 1, d_loss=-0.183 g_loss=0.415 KID= 0.09153\n",
      "epoch 54, batch 2, d_loss=-0.172 g_loss=0.403 KID= 0.09153\n",
      "epoch 54, batch 3, d_loss=-0.043 g_loss=0.395 KID= 0.09153\n",
      "epoch 54, batch 4, d_loss=0.075 g_loss=0.465 KID= 0.09153\n",
      "epoch 54, batch 5, d_loss=-0.035 g_loss=0.878 KID= 0.09153\n",
      "epoch 54, batch 6, d_loss=-0.091 g_loss=1.457 KID= 0.09153\n",
      "epoch 54, batch 7, d_loss=0.083 g_loss=1.747 KID= 0.09153\n",
      "epoch 54, batch 8, d_loss=-0.010 g_loss=1.760 KID= 0.09153\n",
      "epoch 54, batch 9, d_loss=0.003 g_loss=1.657 KID= 0.09153\n",
      "epoch 54, batch 10, d_loss=-0.051 g_loss=1.462 KID= 0.09153\n",
      "epoch 54, batch 11, d_loss=-0.162 g_loss=1.410 KID= 0.09153\n",
      "epoch 54, batch 12, d_loss=-0.111 g_loss=1.469 KID= 0.09153\n",
      "epoch 54, batch 13, d_loss=-0.242 g_loss=1.754 KID= 0.09153\n",
      "epoch 54, batch 14, d_loss=-0.244 g_loss=2.271 KID= 0.09153\n",
      "epoch 54, batch 15, d_loss=-0.274 g_loss=2.750 KID= 0.09153\n",
      "epoch 54, batch 16, d_loss=-0.035 g_loss=2.952 KID= 0.09153\n",
      "epoch 54, batch 17, d_loss=-0.273 g_loss=3.388 KID= 0.09153\n",
      "epoch 54, batch 18, d_loss=-0.050 g_loss=3.467 KID= 0.09153\n",
      "epoch 54, batch 19, d_loss=-0.046 g_loss=3.568 KID= 0.09153\n",
      "epoch 55, batch 0, d_loss=0.010 g_loss=3.393 KID= 0.09153\n",
      "epoch 55, batch 1, d_loss=-0.053 g_loss=3.316 KID= 0.09153\n",
      "epoch 55, batch 2, d_loss=-0.031 g_loss=3.244 KID= 0.09153\n",
      "epoch 55, batch 3, d_loss=0.058 g_loss=2.740 KID= 0.09153\n",
      "epoch 55, batch 4, d_loss=0.019 g_loss=2.067 KID= 0.09153\n",
      "epoch 55, batch 5, d_loss=-0.090 g_loss=1.538 KID= 0.09153\n",
      "epoch 55, batch 6, d_loss=-0.011 g_loss=1.319 KID= 0.09153\n",
      "epoch 55, batch 7, d_loss=0.075 g_loss=0.946 KID= 0.09153\n",
      "epoch 55, batch 8, d_loss=-0.066 g_loss=0.569 KID= 0.09153\n",
      "epoch 55, batch 9, d_loss=-0.052 g_loss=0.528 KID= 0.09153\n",
      "epoch 55, batch 10, d_loss=-0.110 g_loss=0.234 KID= 0.09153\n",
      "epoch 55, batch 11, d_loss=-0.304 g_loss=-0.341 KID= 0.09153\n",
      "epoch 55, batch 12, d_loss=-0.261 g_loss=-0.877 KID= 0.09153\n",
      "epoch 55, batch 13, d_loss=-0.053 g_loss=-1.440 KID= 0.09153\n",
      "epoch 55, batch 14, d_loss=-0.241 g_loss=-2.276 KID= 0.09153\n",
      "epoch 55, batch 15, d_loss=0.320 g_loss=-1.902 KID= 0.09153\n",
      "epoch 55, batch 16, d_loss=0.315 g_loss=-1.159 KID= 0.09153\n",
      "epoch 55, batch 17, d_loss=0.031 g_loss=-0.659 KID= 0.09153\n",
      "epoch 55, batch 18, d_loss=-0.087 g_loss=-0.109 KID= 0.09153\n",
      "epoch 55, batch 19, d_loss=-0.182 g_loss=0.109 KID= 0.09153\n",
      "epoch 56, batch 0, d_loss=-0.173 g_loss=0.140 KID= 0.09153\n",
      "epoch 56, batch 1, d_loss=0.020 g_loss=0.069 KID= 0.09153\n",
      "epoch 56, batch 2, d_loss=-0.095 g_loss=0.021 KID= 0.09153\n",
      "epoch 56, batch 3, d_loss=0.131 g_loss=0.139 KID= 0.09153\n",
      "epoch 56, batch 4, d_loss=0.198 g_loss=0.533 KID= 0.09153\n",
      "epoch 56, batch 5, d_loss=-0.147 g_loss=0.838 KID= 0.09153\n",
      "epoch 56, batch 6, d_loss=-0.037 g_loss=1.026 KID= 0.09153\n",
      "epoch 56, batch 7, d_loss=0.115 g_loss=1.454 KID= 0.09153\n",
      "epoch 56, batch 8, d_loss=-0.095 g_loss=2.036 KID= 0.09153\n",
      "epoch 56, batch 9, d_loss=-0.217 g_loss=2.583 KID= 0.09153\n",
      "epoch 56, batch 10, d_loss=-0.276 g_loss=3.189 KID= 0.09153\n",
      "epoch 56, batch 11, d_loss=-0.387 g_loss=3.752 KID= 0.09153\n",
      "epoch 56, batch 12, d_loss=-0.172 g_loss=4.045 KID= 0.09153\n",
      "epoch 56, batch 13, d_loss=-0.244 g_loss=4.252 KID= 0.09153\n",
      "epoch 56, batch 14, d_loss=-0.331 g_loss=4.656 KID= 0.09153\n",
      "epoch 56, batch 15, d_loss=0.206 g_loss=4.100 KID= 0.09153\n",
      "epoch 56, batch 16, d_loss=0.426 g_loss=3.245 KID= 0.09153\n",
      "epoch 56, batch 17, d_loss=0.124 g_loss=2.513 KID= 0.09153\n",
      "epoch 56, batch 18, d_loss=0.137 g_loss=2.052 KID= 0.09153\n",
      "epoch 56, batch 19, d_loss=-0.058 g_loss=1.894 KID= 0.09153\n",
      "epoch 57, batch 0, d_loss=-0.037 g_loss=1.511 KID= 0.09153\n",
      "epoch 57, batch 1, d_loss=-0.044 g_loss=1.021 KID= 0.09153\n",
      "epoch 57, batch 2, d_loss=-0.174 g_loss=0.940 KID= 0.09153\n",
      "epoch 57, batch 3, d_loss=-0.083 g_loss=0.866 KID= 0.09153\n",
      "epoch 57, batch 4, d_loss=0.017 g_loss=0.019 KID= 0.09153\n",
      "epoch 57, batch 5, d_loss=-0.140 g_loss=-0.033 KID= 0.09153\n",
      "epoch 57, batch 6, d_loss=-0.133 g_loss=0.451 KID= 0.09153\n",
      "epoch 57, batch 7, d_loss=0.121 g_loss=0.152 KID= 0.09153\n",
      "epoch 57, batch 8, d_loss=-0.084 g_loss=0.007 KID= 0.09153\n",
      "epoch 57, batch 9, d_loss=-0.131 g_loss=0.435 KID= 0.09153\n",
      "epoch 57, batch 10, d_loss=-0.199 g_loss=0.369 KID= 0.09153\n",
      "epoch 57, batch 11, d_loss=-0.256 g_loss=-0.752 KID= 0.09153\n",
      "epoch 57, batch 12, d_loss=-0.036 g_loss=-1.293 KID= 0.09153\n",
      "epoch 57, batch 13, d_loss=-0.057 g_loss=-1.405 KID= 0.09153\n",
      "epoch 57, batch 14, d_loss=-0.302 g_loss=-2.241 KID= 0.09153\n",
      "epoch 57, batch 15, d_loss=0.243 g_loss=-1.359 KID= 0.09153\n",
      "epoch 57, batch 16, d_loss=0.164 g_loss=-0.183 KID= 0.09153\n",
      "epoch 57, batch 17, d_loss=-0.251 g_loss=0.642 KID= 0.09153\n",
      "epoch 57, batch 18, d_loss=-0.168 g_loss=1.332 KID= 0.09153\n",
      "epoch 57, batch 19, d_loss=-0.028 g_loss=1.770 KID= 0.09153\n",
      "epoch 58, batch 0, d_loss=-0.170 g_loss=1.991 KID= 0.09153\n",
      "epoch 58, batch 1, d_loss=-0.128 g_loss=2.441 KID= 0.09153\n",
      "epoch 58, batch 2, d_loss=-0.125 g_loss=2.947 KID= 0.09153\n",
      "epoch 58, batch 3, d_loss=0.134 g_loss=2.524 KID= 0.09153\n",
      "epoch 58, batch 4, d_loss=0.351 g_loss=2.010 KID= 0.09153\n",
      "epoch 58, batch 5, d_loss=0.053 g_loss=1.823 KID= 0.09153\n",
      "epoch 58, batch 6, d_loss=0.109 g_loss=1.836 KID= 0.09153\n",
      "epoch 58, batch 7, d_loss=0.229 g_loss=2.003 KID= 0.09153\n",
      "epoch 58, batch 8, d_loss=0.033 g_loss=2.159 KID= 0.09153\n",
      "epoch 58, batch 9, d_loss=-0.074 g_loss=2.147 KID= 0.09153\n",
      "epoch 58, batch 10, d_loss=-0.061 g_loss=2.057 KID= 0.09153\n",
      "epoch 58, batch 11, d_loss=-0.149 g_loss=1.964 KID= 0.09153\n",
      "epoch 58, batch 12, d_loss=-0.014 g_loss=2.023 KID= 0.09153\n",
      "epoch 58, batch 13, d_loss=-0.081 g_loss=1.649 KID= 0.09153\n",
      "epoch 58, batch 14, d_loss=-0.018 g_loss=1.543 KID= 0.09153\n",
      "epoch 58, batch 15, d_loss=0.118 g_loss=1.511 KID= 0.09153\n",
      "epoch 58, batch 16, d_loss=0.166 g_loss=1.465 KID= 0.09153\n",
      "epoch 58, batch 17, d_loss=-0.151 g_loss=1.655 KID= 0.09153\n",
      "epoch 58, batch 18, d_loss=-0.272 g_loss=1.759 KID= 0.09153\n",
      "epoch 58, batch 19, d_loss=-0.335 g_loss=1.684 KID= 0.09153\n",
      "epoch 59, batch 0, d_loss=-0.191 g_loss=1.463 KID= 0.09153\n",
      "epoch 59, batch 1, d_loss=-0.136 g_loss=1.287 KID= 0.09153\n",
      "epoch 59, batch 2, d_loss=-0.184 g_loss=1.127 KID= 0.09153\n",
      "epoch 59, batch 3, d_loss=-0.119 g_loss=0.917 KID= 0.09153\n",
      "epoch 59, batch 4, d_loss=0.201 g_loss=0.685 KID= 0.09153\n",
      "epoch 59, batch 5, d_loss=-0.045 g_loss=0.552 KID= 0.09153\n",
      "epoch 59, batch 6, d_loss=0.082 g_loss=0.678 KID= 0.09153\n",
      "epoch 59, batch 7, d_loss=0.112 g_loss=0.885 KID= 0.09153\n",
      "epoch 59, batch 8, d_loss=0.037 g_loss=1.193 KID= 0.09153\n",
      "epoch 59, batch 9, d_loss=-0.070 g_loss=1.569 KID= 0.09153\n",
      "epoch 59, batch 10, d_loss=-0.179 g_loss=1.656 KID= 0.09153\n",
      "epoch 59, batch 11, d_loss=-0.394 g_loss=1.554 KID= 0.09153\n",
      "epoch 59, batch 12, d_loss=-0.211 g_loss=1.338 KID= 0.09153\n",
      "epoch 59, batch 13, d_loss=0.038 g_loss=0.834 KID= 0.09153\n",
      "epoch 59, batch 14, d_loss=-0.135 g_loss=0.329 KID= 0.09153\n",
      "epoch 59, batch 15, d_loss=0.062 g_loss=0.211 KID= 0.09153\n",
      "epoch 59, batch 16, d_loss=0.160 g_loss=0.495 KID= 0.09153\n",
      "epoch 59, batch 17, d_loss=-0.148 g_loss=0.950 KID= 0.09153\n",
      "epoch 59, batch 18, d_loss=-0.293 g_loss=1.436 KID= 0.09153\n",
      "epoch 59, batch 19, d_loss=-0.363 g_loss=1.908 KID= 0.09153\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 60, batch 0, d_loss=-0.307 g_loss=1.880 KID= 0.10756\n",
      "epoch 60, batch 1, d_loss=-0.058 g_loss=1.697 KID= 0.10756\n",
      "epoch 60, batch 2, d_loss=0.133 g_loss=1.394 KID= 0.10756\n",
      "epoch 60, batch 3, d_loss=-0.046 g_loss=1.281 KID= 0.10756\n",
      "epoch 60, batch 4, d_loss=0.075 g_loss=1.028 KID= 0.10756\n",
      "epoch 60, batch 5, d_loss=-0.064 g_loss=0.846 KID= 0.10756\n",
      "epoch 60, batch 6, d_loss=-0.068 g_loss=0.823 KID= 0.10756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60, batch 7, d_loss=0.134 g_loss=0.368 KID= 0.10756\n",
      "epoch 60, batch 8, d_loss=0.202 g_loss=-0.469 KID= 0.10756\n",
      "epoch 60, batch 9, d_loss=-0.020 g_loss=-1.101 KID= 0.10756\n",
      "epoch 60, batch 10, d_loss=-0.107 g_loss=-2.446 KID= 0.10756\n",
      "epoch 60, batch 11, d_loss=-0.366 g_loss=-4.734 KID= 0.10756\n",
      "epoch 60, batch 12, d_loss=0.069 g_loss=-4.636 KID= 0.10756\n",
      "epoch 60, batch 13, d_loss=0.196 g_loss=-4.565 KID= 0.10756\n",
      "epoch 60, batch 14, d_loss=-0.140 g_loss=-4.514 KID= 0.10756\n",
      "epoch 60, batch 15, d_loss=0.491 g_loss=-2.653 KID= 0.10756\n",
      "epoch 60, batch 16, d_loss=0.218 g_loss=-1.141 KID= 0.10756\n",
      "epoch 60, batch 17, d_loss=-0.104 g_loss=-0.242 KID= 0.10756\n",
      "epoch 60, batch 18, d_loss=-0.168 g_loss=0.431 KID= 0.10756\n",
      "epoch 60, batch 19, d_loss=-0.315 g_loss=1.226 KID= 0.10756\n",
      "epoch 61, batch 0, d_loss=-0.439 g_loss=1.963 KID= 0.10756\n",
      "epoch 61, batch 1, d_loss=-0.120 g_loss=2.314 KID= 0.10756\n",
      "epoch 61, batch 2, d_loss=-0.149 g_loss=2.667 KID= 0.10756\n",
      "epoch 61, batch 3, d_loss=0.157 g_loss=2.933 KID= 0.10756\n",
      "epoch 61, batch 4, d_loss=0.257 g_loss=3.318 KID= 0.10756\n",
      "epoch 61, batch 5, d_loss=-0.090 g_loss=3.699 KID= 0.10756\n",
      "epoch 61, batch 6, d_loss=-0.094 g_loss=3.748 KID= 0.10756\n",
      "epoch 61, batch 7, d_loss=0.051 g_loss=3.629 KID= 0.10756\n",
      "epoch 61, batch 8, d_loss=0.011 g_loss=3.351 KID= 0.10756\n",
      "epoch 61, batch 9, d_loss=0.190 g_loss=2.357 KID= 0.10756\n",
      "epoch 61, batch 10, d_loss=0.016 g_loss=1.712 KID= 0.10756\n",
      "epoch 61, batch 11, d_loss=-0.087 g_loss=1.872 KID= 0.10756\n",
      "epoch 61, batch 12, d_loss=-0.047 g_loss=2.327 KID= 0.10756\n",
      "epoch 61, batch 13, d_loss=-0.049 g_loss=2.796 KID= 0.10756\n",
      "epoch 61, batch 14, d_loss=-0.331 g_loss=3.759 KID= 0.10756\n",
      "epoch 61, batch 15, d_loss=-0.119 g_loss=4.279 KID= 0.10756\n",
      "epoch 61, batch 16, d_loss=-0.016 g_loss=4.533 KID= 0.10756\n",
      "epoch 61, batch 17, d_loss=0.226 g_loss=3.911 KID= 0.10756\n",
      "epoch 61, batch 18, d_loss=0.252 g_loss=3.091 KID= 0.10756\n",
      "epoch 61, batch 19, d_loss=0.036 g_loss=2.415 KID= 0.10756\n",
      "epoch 62, batch 0, d_loss=0.014 g_loss=1.762 KID= 0.10756\n",
      "epoch 62, batch 1, d_loss=0.043 g_loss=1.209 KID= 0.10756\n",
      "epoch 62, batch 2, d_loss=-0.083 g_loss=0.977 KID= 0.10756\n",
      "epoch 62, batch 3, d_loss=-0.222 g_loss=0.874 KID= 0.10756\n",
      "epoch 62, batch 4, d_loss=-0.073 g_loss=0.779 KID= 0.10756\n",
      "epoch 62, batch 5, d_loss=-0.252 g_loss=0.993 KID= 0.10756\n",
      "epoch 62, batch 6, d_loss=-0.148 g_loss=1.338 KID= 0.10756\n",
      "epoch 62, batch 7, d_loss=-0.319 g_loss=1.628 KID= 0.10756\n",
      "epoch 62, batch 8, d_loss=-0.589 g_loss=2.114 KID= 0.10756\n",
      "epoch 62, batch 9, d_loss=-0.312 g_loss=2.599 KID= 0.10756\n",
      "epoch 62, batch 10, d_loss=-0.622 g_loss=3.043 KID= 0.10756\n",
      "epoch 62, batch 11, d_loss=-0.473 g_loss=2.919 KID= 0.10756\n",
      "epoch 62, batch 12, d_loss=0.280 g_loss=2.452 KID= 0.10756\n",
      "epoch 62, batch 13, d_loss=0.821 g_loss=1.920 KID= 0.10756\n",
      "epoch 62, batch 14, d_loss=0.374 g_loss=1.975 KID= 0.10756\n",
      "epoch 62, batch 15, d_loss=-0.112 g_loss=2.568 KID= 0.10756\n",
      "epoch 62, batch 16, d_loss=-0.318 g_loss=3.149 KID= 0.10756\n",
      "epoch 62, batch 17, d_loss=-0.327 g_loss=3.853 KID= 0.10756\n",
      "epoch 62, batch 18, d_loss=-0.155 g_loss=4.374 KID= 0.10756\n",
      "epoch 62, batch 19, d_loss=0.199 g_loss=4.115 KID= 0.10756\n",
      "epoch 63, batch 0, d_loss=0.196 g_loss=3.427 KID= 0.10756\n",
      "epoch 63, batch 1, d_loss=0.169 g_loss=2.739 KID= 0.10756\n",
      "epoch 63, batch 2, d_loss=0.142 g_loss=2.278 KID= 0.10756\n",
      "epoch 63, batch 3, d_loss=0.154 g_loss=1.826 KID= 0.10756\n",
      "epoch 63, batch 4, d_loss=0.013 g_loss=1.577 KID= 0.10756\n",
      "epoch 63, batch 5, d_loss=-0.006 g_loss=1.238 KID= 0.10756\n",
      "epoch 63, batch 6, d_loss=-0.076 g_loss=0.967 KID= 0.10756\n",
      "epoch 63, batch 7, d_loss=0.053 g_loss=0.495 KID= 0.10756\n",
      "epoch 63, batch 8, d_loss=-0.036 g_loss=-0.040 KID= 0.10756\n",
      "epoch 63, batch 9, d_loss=-0.143 g_loss=-0.433 KID= 0.10756\n",
      "epoch 63, batch 10, d_loss=-0.118 g_loss=-1.017 KID= 0.10756\n",
      "epoch 63, batch 11, d_loss=-0.130 g_loss=-1.512 KID= 0.10756\n",
      "epoch 63, batch 12, d_loss=-0.251 g_loss=-1.906 KID= 0.10756\n",
      "epoch 63, batch 13, d_loss=-0.278 g_loss=-2.451 KID= 0.10756\n",
      "epoch 63, batch 14, d_loss=-0.070 g_loss=-2.836 KID= 0.10756\n",
      "epoch 63, batch 15, d_loss=0.010 g_loss=-2.688 KID= 0.10756\n",
      "epoch 63, batch 16, d_loss=0.287 g_loss=-1.645 KID= 0.10756\n",
      "epoch 63, batch 17, d_loss=0.079 g_loss=-1.109 KID= 0.10756\n",
      "epoch 63, batch 18, d_loss=-0.011 g_loss=-0.707 KID= 0.10756\n",
      "epoch 63, batch 19, d_loss=0.170 g_loss=0.000 KID= 0.10756\n",
      "epoch 64, batch 0, d_loss=0.037 g_loss=0.437 KID= 0.10756\n",
      "epoch 64, batch 1, d_loss=-0.024 g_loss=0.439 KID= 0.10756\n",
      "epoch 64, batch 2, d_loss=-0.111 g_loss=0.546 KID= 0.10756\n",
      "epoch 64, batch 3, d_loss=0.080 g_loss=0.758 KID= 0.10756\n",
      "epoch 64, batch 4, d_loss=-0.157 g_loss=0.519 KID= 0.10756\n",
      "epoch 64, batch 5, d_loss=-0.231 g_loss=0.394 KID= 0.10756\n",
      "epoch 64, batch 6, d_loss=-0.272 g_loss=0.220 KID= 0.10756\n",
      "epoch 64, batch 7, d_loss=-0.118 g_loss=0.229 KID= 0.10756\n",
      "epoch 64, batch 8, d_loss=0.033 g_loss=0.317 KID= 0.10756\n",
      "epoch 64, batch 9, d_loss=-0.100 g_loss=0.486 KID= 0.10756\n",
      "epoch 64, batch 10, d_loss=-0.239 g_loss=0.483 KID= 0.10756\n",
      "epoch 64, batch 11, d_loss=-0.153 g_loss=0.252 KID= 0.10756\n",
      "epoch 64, batch 12, d_loss=-0.020 g_loss=-0.109 KID= 0.10756\n",
      "epoch 64, batch 13, d_loss=-0.043 g_loss=-0.226 KID= 0.10756\n",
      "epoch 64, batch 14, d_loss=-0.027 g_loss=-0.284 KID= 0.10756\n",
      "epoch 64, batch 15, d_loss=0.199 g_loss=0.204 KID= 0.10756\n",
      "epoch 64, batch 16, d_loss=-0.021 g_loss=1.167 KID= 0.10756\n",
      "epoch 64, batch 17, d_loss=-0.116 g_loss=1.643 KID= 0.10756\n",
      "epoch 64, batch 18, d_loss=-0.238 g_loss=2.240 KID= 0.10756\n",
      "epoch 64, batch 19, d_loss=-0.012 g_loss=2.224 KID= 0.10756\n",
      "epoch 65, batch 0, d_loss=0.059 g_loss=2.073 KID= 0.10756\n",
      "epoch 65, batch 1, d_loss=0.093 g_loss=1.632 KID= 0.10756\n",
      "epoch 65, batch 2, d_loss=0.097 g_loss=1.362 KID= 0.10756\n",
      "epoch 65, batch 3, d_loss=0.137 g_loss=1.431 KID= 0.10756\n",
      "epoch 65, batch 4, d_loss=-0.001 g_loss=2.019 KID= 0.10756\n",
      "epoch 65, batch 5, d_loss=-0.369 g_loss=2.811 KID= 0.10756\n",
      "epoch 65, batch 6, d_loss=-0.315 g_loss=3.272 KID= 0.10756\n",
      "epoch 65, batch 7, d_loss=-0.136 g_loss=3.292 KID= 0.10756\n",
      "epoch 65, batch 8, d_loss=0.112 g_loss=2.469 KID= 0.10756\n",
      "epoch 65, batch 9, d_loss=0.765 g_loss=0.631 KID= 0.10756\n",
      "epoch 65, batch 10, d_loss=0.451 g_loss=-0.544 KID= 0.10756\n",
      "epoch 65, batch 11, d_loss=0.150 g_loss=-1.692 KID= 0.10756\n",
      "epoch 65, batch 12, d_loss=0.097 g_loss=-3.027 KID= 0.10756\n",
      "epoch 65, batch 13, d_loss=-0.115 g_loss=-4.430 KID= 0.10756\n",
      "epoch 65, batch 14, d_loss=-0.139 g_loss=-5.348 KID= 0.10756\n",
      "epoch 65, batch 15, d_loss=-0.436 g_loss=-6.915 KID= 0.10756\n",
      "epoch 65, batch 16, d_loss=-0.363 g_loss=-7.076 KID= 0.10756\n",
      "epoch 65, batch 17, d_loss=-0.059 g_loss=-6.879 KID= 0.10756\n",
      "epoch 65, batch 18, d_loss=0.191 g_loss=-4.660 KID= 0.10756\n",
      "epoch 65, batch 19, d_loss=0.004 g_loss=-2.996 KID= 0.10756\n",
      "epoch 66, batch 0, d_loss=-0.120 g_loss=-1.665 KID= 0.10756\n",
      "epoch 66, batch 1, d_loss=-0.306 g_loss=-1.102 KID= 0.10756\n",
      "epoch 66, batch 2, d_loss=-0.454 g_loss=-1.351 KID= 0.10756\n",
      "epoch 66, batch 3, d_loss=-0.540 g_loss=-1.350 KID= 0.10756\n",
      "epoch 66, batch 4, d_loss=-0.681 g_loss=-1.915 KID= 0.10756\n",
      "epoch 66, batch 5, d_loss=0.195 g_loss=-0.799 KID= 0.10756\n",
      "epoch 66, batch 6, d_loss=0.366 g_loss=0.080 KID= 0.10756\n",
      "epoch 66, batch 7, d_loss=-0.030 g_loss=0.340 KID= 0.10756\n",
      "epoch 66, batch 8, d_loss=0.012 g_loss=0.429 KID= 0.10756\n",
      "epoch 66, batch 9, d_loss=-0.131 g_loss=0.847 KID= 0.10756\n",
      "epoch 66, batch 10, d_loss=-0.257 g_loss=0.898 KID= 0.10756\n",
      "epoch 66, batch 11, d_loss=-0.003 g_loss=0.907 KID= 0.10756\n",
      "epoch 66, batch 12, d_loss=-0.025 g_loss=1.199 KID= 0.10756\n",
      "epoch 66, batch 13, d_loss=-0.166 g_loss=1.597 KID= 0.10756\n",
      "epoch 66, batch 14, d_loss=-0.067 g_loss=1.908 KID= 0.10756\n",
      "epoch 66, batch 15, d_loss=-0.028 g_loss=1.831 KID= 0.10756\n",
      "epoch 66, batch 16, d_loss=0.020 g_loss=1.773 KID= 0.10756\n",
      "epoch 66, batch 17, d_loss=0.093 g_loss=1.677 KID= 0.10756\n",
      "epoch 66, batch 18, d_loss=-0.062 g_loss=1.742 KID= 0.10756\n",
      "epoch 66, batch 19, d_loss=-0.126 g_loss=1.956 KID= 0.10756\n",
      "epoch 67, batch 0, d_loss=-0.240 g_loss=2.223 KID= 0.10756\n",
      "epoch 67, batch 1, d_loss=-0.154 g_loss=2.436 KID= 0.10756\n",
      "epoch 67, batch 2, d_loss=-0.035 g_loss=2.681 KID= 0.10756\n",
      "epoch 67, batch 3, d_loss=0.199 g_loss=2.280 KID= 0.10756\n",
      "epoch 67, batch 4, d_loss=-0.017 g_loss=2.072 KID= 0.10756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 67, batch 5, d_loss=0.089 g_loss=1.579 KID= 0.10756\n",
      "epoch 67, batch 6, d_loss=0.115 g_loss=1.129 KID= 0.10756\n",
      "epoch 67, batch 7, d_loss=0.059 g_loss=0.777 KID= 0.10756\n",
      "epoch 67, batch 8, d_loss=0.026 g_loss=0.470 KID= 0.10756\n",
      "epoch 67, batch 9, d_loss=-0.050 g_loss=0.190 KID= 0.10756\n",
      "epoch 67, batch 10, d_loss=-0.123 g_loss=-0.157 KID= 0.10756\n",
      "epoch 67, batch 11, d_loss=0.030 g_loss=-0.481 KID= 0.10756\n",
      "epoch 67, batch 12, d_loss=0.017 g_loss=-0.854 KID= 0.10756\n",
      "epoch 67, batch 13, d_loss=-0.073 g_loss=-1.107 KID= 0.10756\n",
      "epoch 67, batch 14, d_loss=0.056 g_loss=-1.327 KID= 0.10756\n",
      "epoch 67, batch 15, d_loss=0.074 g_loss=-1.559 KID= 0.10756\n",
      "epoch 67, batch 16, d_loss=0.125 g_loss=-1.088 KID= 0.10756\n",
      "epoch 67, batch 17, d_loss=0.055 g_loss=-0.614 KID= 0.10756\n",
      "epoch 67, batch 18, d_loss=-0.028 g_loss=-0.444 KID= 0.10756\n",
      "epoch 67, batch 19, d_loss=0.049 g_loss=-0.083 KID= 0.10756\n",
      "epoch 68, batch 0, d_loss=-0.011 g_loss=0.095 KID= 0.10756\n",
      "epoch 68, batch 1, d_loss=0.024 g_loss=-0.211 KID= 0.10756\n",
      "epoch 68, batch 2, d_loss=0.170 g_loss=-0.169 KID= 0.10756\n",
      "epoch 68, batch 3, d_loss=0.171 g_loss=0.413 KID= 0.10756\n",
      "epoch 68, batch 4, d_loss=-0.020 g_loss=0.952 KID= 0.10756\n",
      "epoch 68, batch 5, d_loss=-0.102 g_loss=1.268 KID= 0.10756\n",
      "epoch 68, batch 6, d_loss=-0.201 g_loss=1.521 KID= 0.10756\n",
      "epoch 68, batch 7, d_loss=0.020 g_loss=1.708 KID= 0.10756\n",
      "epoch 68, batch 8, d_loss=0.061 g_loss=1.910 KID= 0.10756\n",
      "epoch 68, batch 9, d_loss=0.107 g_loss=2.003 KID= 0.10756\n",
      "epoch 68, batch 10, d_loss=0.045 g_loss=2.315 KID= 0.10756\n",
      "epoch 68, batch 11, d_loss=0.017 g_loss=3.038 KID= 0.10756\n",
      "epoch 68, batch 12, d_loss=-0.116 g_loss=3.788 KID= 0.10756\n",
      "epoch 68, batch 13, d_loss=-0.087 g_loss=4.405 KID= 0.10756\n",
      "epoch 68, batch 14, d_loss=-0.268 g_loss=5.118 KID= 0.10756\n",
      "epoch 68, batch 15, d_loss=-0.029 g_loss=4.275 KID= 0.10756\n",
      "epoch 68, batch 16, d_loss=0.056 g_loss=3.442 KID= 0.10756\n",
      "epoch 68, batch 17, d_loss=-0.090 g_loss=2.542 KID= 0.10756\n",
      "epoch 68, batch 18, d_loss=-0.237 g_loss=1.675 KID= 0.10756\n",
      "epoch 68, batch 19, d_loss=-0.085 g_loss=1.138 KID= 0.10756\n",
      "epoch 69, batch 0, d_loss=-0.161 g_loss=0.557 KID= 0.10756\n",
      "epoch 69, batch 1, d_loss=0.083 g_loss=-0.425 KID= 0.10756\n",
      "epoch 69, batch 2, d_loss=0.097 g_loss=-1.357 KID= 0.10756\n",
      "epoch 69, batch 3, d_loss=0.022 g_loss=-1.534 KID= 0.10756\n",
      "epoch 69, batch 4, d_loss=-0.198 g_loss=-1.682 KID= 0.10756\n",
      "epoch 69, batch 5, d_loss=-0.202 g_loss=-1.691 KID= 0.10756\n",
      "epoch 69, batch 6, d_loss=-0.277 g_loss=-1.386 KID= 0.10756\n",
      "epoch 69, batch 7, d_loss=-0.060 g_loss=-0.359 KID= 0.10756\n",
      "epoch 69, batch 8, d_loss=0.035 g_loss=0.725 KID= 0.10756\n",
      "epoch 69, batch 9, d_loss=-0.207 g_loss=1.495 KID= 0.10756\n",
      "epoch 69, batch 10, d_loss=-0.190 g_loss=2.065 KID= 0.10756\n",
      "epoch 69, batch 11, d_loss=-0.121 g_loss=2.632 KID= 0.10756\n",
      "epoch 69, batch 12, d_loss=-0.170 g_loss=3.473 KID= 0.10756\n",
      "epoch 69, batch 13, d_loss=0.249 g_loss=3.704 KID= 0.10756\n",
      "epoch 69, batch 14, d_loss=-0.195 g_loss=4.303 KID= 0.10756\n",
      "epoch 69, batch 15, d_loss=-0.250 g_loss=5.138 KID= 0.10756\n",
      "epoch 69, batch 16, d_loss=-0.097 g_loss=5.703 KID= 0.10756\n",
      "epoch 69, batch 17, d_loss=-0.037 g_loss=6.236 KID= 0.10756\n",
      "epoch 69, batch 18, d_loss=-0.111 g_loss=6.581 KID= 0.10756\n",
      "epoch 69, batch 19, d_loss=0.484 g_loss=4.678 KID= 0.10756\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 70, batch 0, d_loss=0.261 g_loss=3.442 KID= 0.12695\n",
      "epoch 70, batch 1, d_loss=0.203 g_loss=2.043 KID= 0.12695\n",
      "epoch 70, batch 2, d_loss=0.031 g_loss=1.232 KID= 0.12695\n",
      "epoch 70, batch 3, d_loss=0.097 g_loss=0.362 KID= 0.12695\n",
      "epoch 70, batch 4, d_loss=-0.045 g_loss=-0.371 KID= 0.12695\n",
      "epoch 70, batch 5, d_loss=-0.155 g_loss=-0.663 KID= 0.12695\n",
      "epoch 70, batch 6, d_loss=-0.149 g_loss=-0.723 KID= 0.12695\n",
      "epoch 70, batch 7, d_loss=-0.257 g_loss=-0.650 KID= 0.12695\n",
      "epoch 70, batch 8, d_loss=0.146 g_loss=-0.415 KID= 0.12695\n",
      "epoch 70, batch 9, d_loss=0.033 g_loss=0.028 KID= 0.12695\n",
      "epoch 70, batch 10, d_loss=0.292 g_loss=0.633 KID= 0.12695\n",
      "epoch 70, batch 11, d_loss=0.249 g_loss=0.976 KID= 0.12695\n",
      "epoch 70, batch 12, d_loss=0.033 g_loss=1.406 KID= 0.12695\n",
      "epoch 70, batch 13, d_loss=-0.156 g_loss=1.566 KID= 0.12695\n",
      "epoch 70, batch 14, d_loss=-0.237 g_loss=1.647 KID= 0.12695\n",
      "epoch 70, batch 15, d_loss=-0.250 g_loss=2.019 KID= 0.12695\n",
      "epoch 70, batch 16, d_loss=-0.105 g_loss=2.344 KID= 0.12695\n",
      "epoch 70, batch 17, d_loss=0.051 g_loss=2.446 KID= 0.12695\n",
      "epoch 70, batch 18, d_loss=-0.136 g_loss=2.638 KID= 0.12695\n",
      "epoch 70, batch 19, d_loss=0.124 g_loss=2.494 KID= 0.12695\n",
      "epoch 71, batch 0, d_loss=0.031 g_loss=2.301 KID= 0.12695\n",
      "epoch 71, batch 1, d_loss=-0.005 g_loss=2.343 KID= 0.12695\n",
      "epoch 71, batch 2, d_loss=-0.061 g_loss=2.663 KID= 0.12695\n",
      "epoch 71, batch 3, d_loss=-0.082 g_loss=2.577 KID= 0.12695\n",
      "epoch 71, batch 4, d_loss=0.055 g_loss=2.140 KID= 0.12695\n",
      "epoch 71, batch 5, d_loss=0.115 g_loss=1.582 KID= 0.12695\n",
      "epoch 71, batch 6, d_loss=-0.047 g_loss=1.298 KID= 0.12695\n",
      "epoch 71, batch 7, d_loss=0.045 g_loss=0.929 KID= 0.12695\n",
      "epoch 71, batch 8, d_loss=0.168 g_loss=0.524 KID= 0.12695\n",
      "epoch 71, batch 9, d_loss=-0.025 g_loss=0.455 KID= 0.12695\n",
      "epoch 71, batch 10, d_loss=-0.017 g_loss=0.531 KID= 0.12695\n",
      "epoch 71, batch 11, d_loss=-0.070 g_loss=0.537 KID= 0.12695\n",
      "epoch 71, batch 12, d_loss=-0.202 g_loss=0.657 KID= 0.12695\n",
      "epoch 71, batch 13, d_loss=-0.055 g_loss=0.448 KID= 0.12695\n",
      "epoch 71, batch 14, d_loss=-0.180 g_loss=-0.046 KID= 0.12695\n",
      "epoch 71, batch 15, d_loss=-0.083 g_loss=-0.683 KID= 0.12695\n",
      "epoch 71, batch 16, d_loss=0.077 g_loss=-0.856 KID= 0.12695\n",
      "epoch 71, batch 17, d_loss=0.126 g_loss=-0.863 KID= 0.12695\n",
      "epoch 71, batch 18, d_loss=-0.087 g_loss=-1.263 KID= 0.12695\n",
      "epoch 71, batch 19, d_loss=0.013 g_loss=-1.594 KID= 0.12695\n",
      "epoch 72, batch 0, d_loss=-0.138 g_loss=-2.267 KID= 0.12695\n",
      "epoch 72, batch 1, d_loss=0.085 g_loss=-2.576 KID= 0.12695\n",
      "epoch 72, batch 2, d_loss=0.063 g_loss=-2.381 KID= 0.12695\n",
      "epoch 72, batch 3, d_loss=-0.038 g_loss=-2.455 KID= 0.12695\n",
      "epoch 72, batch 4, d_loss=0.030 g_loss=-2.269 KID= 0.12695\n",
      "epoch 72, batch 5, d_loss=0.107 g_loss=-1.453 KID= 0.12695\n",
      "epoch 72, batch 6, d_loss=-0.025 g_loss=-0.962 KID= 0.12695\n",
      "epoch 72, batch 7, d_loss=-0.023 g_loss=-0.406 KID= 0.12695\n",
      "epoch 72, batch 8, d_loss=-0.068 g_loss=-0.109 KID= 0.12695\n",
      "epoch 72, batch 9, d_loss=-0.055 g_loss=0.157 KID= 0.12695\n",
      "epoch 72, batch 10, d_loss=-0.038 g_loss=0.372 KID= 0.12695\n",
      "epoch 72, batch 11, d_loss=-0.135 g_loss=0.326 KID= 0.12695\n",
      "epoch 72, batch 12, d_loss=-0.164 g_loss=0.385 KID= 0.12695\n",
      "epoch 72, batch 13, d_loss=0.010 g_loss=0.075 KID= 0.12695\n",
      "epoch 72, batch 14, d_loss=-0.098 g_loss=-0.275 KID= 0.12695\n",
      "epoch 72, batch 15, d_loss=0.081 g_loss=-0.238 KID= 0.12695\n",
      "epoch 72, batch 16, d_loss=0.160 g_loss=-0.114 KID= 0.12695\n",
      "epoch 72, batch 17, d_loss=0.110 g_loss=0.419 KID= 0.12695\n",
      "epoch 72, batch 18, d_loss=0.194 g_loss=0.809 KID= 0.12695\n",
      "epoch 72, batch 19, d_loss=0.045 g_loss=1.304 KID= 0.12695\n",
      "epoch 73, batch 0, d_loss=-0.086 g_loss=1.865 KID= 0.12695\n",
      "epoch 73, batch 1, d_loss=-0.047 g_loss=2.067 KID= 0.12695\n",
      "epoch 73, batch 2, d_loss=-0.119 g_loss=2.268 KID= 0.12695\n",
      "epoch 73, batch 3, d_loss=-0.288 g_loss=2.408 KID= 0.12695\n",
      "epoch 73, batch 4, d_loss=-0.061 g_loss=2.115 KID= 0.12695\n",
      "epoch 73, batch 5, d_loss=-0.049 g_loss=1.477 KID= 0.12695\n",
      "epoch 73, batch 6, d_loss=-0.141 g_loss=0.858 KID= 0.12695\n",
      "epoch 73, batch 7, d_loss=0.006 g_loss=0.407 KID= 0.12695\n",
      "epoch 73, batch 8, d_loss=0.031 g_loss=-0.382 KID= 0.12695\n",
      "epoch 73, batch 9, d_loss=-0.090 g_loss=-1.039 KID= 0.12695\n",
      "epoch 73, batch 10, d_loss=-0.067 g_loss=-1.360 KID= 0.12695\n",
      "epoch 73, batch 11, d_loss=-0.117 g_loss=-1.773 KID= 0.12695\n",
      "epoch 73, batch 12, d_loss=-0.097 g_loss=-1.704 KID= 0.12695\n",
      "epoch 73, batch 13, d_loss=0.032 g_loss=-1.441 KID= 0.12695\n",
      "epoch 73, batch 14, d_loss=0.038 g_loss=-0.892 KID= 0.12695\n",
      "epoch 73, batch 15, d_loss=-0.008 g_loss=-0.078 KID= 0.12695\n",
      "epoch 73, batch 16, d_loss=0.103 g_loss=0.518 KID= 0.12695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 73, batch 17, d_loss=0.012 g_loss=1.012 KID= 0.12695\n",
      "epoch 73, batch 18, d_loss=0.137 g_loss=1.494 KID= 0.12695\n",
      "epoch 73, batch 19, d_loss=0.013 g_loss=2.091 KID= 0.12695\n",
      "epoch 74, batch 0, d_loss=-0.137 g_loss=2.892 KID= 0.12695\n",
      "epoch 74, batch 1, d_loss=-0.249 g_loss=3.903 KID= 0.12695\n",
      "epoch 74, batch 2, d_loss=0.069 g_loss=4.212 KID= 0.12695\n",
      "epoch 74, batch 3, d_loss=0.065 g_loss=4.074 KID= 0.12695\n",
      "epoch 74, batch 4, d_loss=0.108 g_loss=2.969 KID= 0.12695\n",
      "epoch 74, batch 5, d_loss=0.108 g_loss=1.963 KID= 0.12695\n",
      "epoch 74, batch 6, d_loss=-0.084 g_loss=1.350 KID= 0.12695\n",
      "epoch 74, batch 7, d_loss=-0.155 g_loss=0.896 KID= 0.12695\n",
      "epoch 74, batch 8, d_loss=-0.094 g_loss=0.623 KID= 0.12695\n",
      "epoch 74, batch 9, d_loss=-0.108 g_loss=0.466 KID= 0.12695\n",
      "epoch 74, batch 10, d_loss=-0.064 g_loss=0.380 KID= 0.12695\n",
      "epoch 74, batch 11, d_loss=0.037 g_loss=0.368 KID= 0.12695\n",
      "epoch 74, batch 12, d_loss=-0.110 g_loss=0.406 KID= 0.12695\n",
      "epoch 74, batch 13, d_loss=-0.076 g_loss=0.417 KID= 0.12695\n",
      "epoch 74, batch 14, d_loss=-0.060 g_loss=0.349 KID= 0.12695\n",
      "epoch 74, batch 15, d_loss=-0.020 g_loss=0.215 KID= 0.12695\n",
      "epoch 74, batch 16, d_loss=-0.041 g_loss=0.100 KID= 0.12695\n",
      "epoch 74, batch 17, d_loss=0.070 g_loss=-0.024 KID= 0.12695\n",
      "epoch 74, batch 18, d_loss=-0.010 g_loss=-0.130 KID= 0.12695\n",
      "epoch 74, batch 19, d_loss=0.017 g_loss=-0.065 KID= 0.12695\n",
      "epoch 75, batch 0, d_loss=-0.019 g_loss=0.004 KID= 0.12695\n",
      "epoch 75, batch 1, d_loss=-0.067 g_loss=0.106 KID= 0.12695\n",
      "epoch 75, batch 2, d_loss=-0.057 g_loss=0.059 KID= 0.12695\n",
      "epoch 75, batch 3, d_loss=0.049 g_loss=0.228 KID= 0.12695\n",
      "epoch 75, batch 4, d_loss=-0.025 g_loss=0.287 KID= 0.12695\n",
      "epoch 75, batch 5, d_loss=-0.084 g_loss=0.311 KID= 0.12695\n",
      "epoch 75, batch 6, d_loss=0.042 g_loss=0.323 KID= 0.12695\n",
      "epoch 75, batch 7, d_loss=0.065 g_loss=0.393 KID= 0.12695\n",
      "epoch 75, batch 8, d_loss=0.117 g_loss=0.728 KID= 0.12695\n",
      "epoch 75, batch 9, d_loss=0.054 g_loss=0.983 KID= 0.12695\n",
      "epoch 75, batch 10, d_loss=-0.081 g_loss=1.056 KID= 0.12695\n",
      "epoch 75, batch 11, d_loss=-0.081 g_loss=0.975 KID= 0.12695\n",
      "epoch 75, batch 12, d_loss=0.077 g_loss=0.963 KID= 0.12695\n",
      "epoch 75, batch 13, d_loss=-0.192 g_loss=0.943 KID= 0.12695\n",
      "epoch 75, batch 14, d_loss=-0.153 g_loss=1.029 KID= 0.12695\n",
      "epoch 75, batch 15, d_loss=-0.158 g_loss=1.037 KID= 0.12695\n",
      "epoch 75, batch 16, d_loss=-0.035 g_loss=1.170 KID= 0.12695\n",
      "epoch 75, batch 17, d_loss=-0.018 g_loss=1.287 KID= 0.12695\n",
      "epoch 75, batch 18, d_loss=0.108 g_loss=1.044 KID= 0.12695\n",
      "epoch 75, batch 19, d_loss=0.079 g_loss=0.914 KID= 0.12695\n",
      "epoch 76, batch 0, d_loss=0.116 g_loss=0.715 KID= 0.12695\n",
      "epoch 76, batch 1, d_loss=0.089 g_loss=0.565 KID= 0.12695\n",
      "epoch 76, batch 2, d_loss=-0.100 g_loss=0.564 KID= 0.12695\n",
      "epoch 76, batch 3, d_loss=-0.008 g_loss=0.436 KID= 0.12695\n",
      "epoch 76, batch 4, d_loss=0.010 g_loss=0.240 KID= 0.12695\n",
      "epoch 76, batch 5, d_loss=0.174 g_loss=0.045 KID= 0.12695\n",
      "epoch 76, batch 6, d_loss=-0.021 g_loss=-0.011 KID= 0.12695\n",
      "epoch 76, batch 7, d_loss=0.064 g_loss=0.145 KID= 0.12695\n",
      "epoch 76, batch 8, d_loss=-0.035 g_loss=0.337 KID= 0.12695\n",
      "epoch 76, batch 9, d_loss=-0.182 g_loss=0.451 KID= 0.12695\n",
      "epoch 76, batch 10, d_loss=-0.116 g_loss=0.403 KID= 0.12695\n",
      "epoch 76, batch 11, d_loss=-0.111 g_loss=0.331 KID= 0.12695\n",
      "epoch 76, batch 12, d_loss=0.012 g_loss=0.298 KID= 0.12695\n",
      "epoch 76, batch 13, d_loss=0.211 g_loss=0.235 KID= 0.12695\n",
      "epoch 76, batch 14, d_loss=0.078 g_loss=0.000 KID= 0.12695\n",
      "epoch 76, batch 15, d_loss=-0.065 g_loss=-0.341 KID= 0.12695\n",
      "epoch 76, batch 16, d_loss=-0.069 g_loss=-0.499 KID= 0.12695\n",
      "epoch 76, batch 17, d_loss=0.030 g_loss=-0.865 KID= 0.12695\n",
      "epoch 76, batch 18, d_loss=0.081 g_loss=-0.932 KID= 0.12695\n",
      "epoch 76, batch 19, d_loss=0.120 g_loss=-0.938 KID= 0.12695\n",
      "epoch 77, batch 0, d_loss=0.059 g_loss=-0.636 KID= 0.12695\n",
      "epoch 77, batch 1, d_loss=0.082 g_loss=-0.586 KID= 0.12695\n",
      "epoch 77, batch 2, d_loss=0.291 g_loss=-0.427 KID= 0.12695\n",
      "epoch 77, batch 3, d_loss=0.090 g_loss=-0.039 KID= 0.12695\n",
      "epoch 77, batch 4, d_loss=0.054 g_loss=0.231 KID= 0.12695\n",
      "epoch 77, batch 5, d_loss=0.082 g_loss=0.574 KID= 0.12695\n",
      "epoch 77, batch 6, d_loss=-0.034 g_loss=1.162 KID= 0.12695\n",
      "epoch 77, batch 7, d_loss=-0.178 g_loss=1.614 KID= 0.12695\n",
      "epoch 77, batch 8, d_loss=-0.225 g_loss=2.827 KID= 0.12695\n",
      "epoch 77, batch 9, d_loss=-0.362 g_loss=4.020 KID= 0.12695\n",
      "epoch 77, batch 10, d_loss=-0.142 g_loss=4.768 KID= 0.12695\n",
      "epoch 77, batch 11, d_loss=-0.012 g_loss=5.070 KID= 0.12695\n",
      "epoch 77, batch 12, d_loss=0.012 g_loss=4.512 KID= 0.12695\n",
      "epoch 77, batch 13, d_loss=0.117 g_loss=4.554 KID= 0.12695\n",
      "epoch 77, batch 14, d_loss=-0.066 g_loss=4.383 KID= 0.12695\n",
      "epoch 77, batch 15, d_loss=-0.127 g_loss=3.857 KID= 0.12695\n",
      "epoch 77, batch 16, d_loss=-0.084 g_loss=3.846 KID= 0.12695\n",
      "epoch 77, batch 17, d_loss=0.037 g_loss=2.837 KID= 0.12695\n",
      "epoch 77, batch 18, d_loss=0.125 g_loss=1.804 KID= 0.12695\n",
      "epoch 77, batch 19, d_loss=0.072 g_loss=0.851 KID= 0.12695\n",
      "epoch 78, batch 0, d_loss=-0.036 g_loss=0.701 KID= 0.12695\n",
      "epoch 78, batch 1, d_loss=-0.064 g_loss=0.240 KID= 0.12695\n",
      "epoch 78, batch 2, d_loss=0.053 g_loss=0.506 KID= 0.12695\n",
      "epoch 78, batch 3, d_loss=-0.069 g_loss=0.726 KID= 0.12695\n",
      "epoch 78, batch 4, d_loss=-0.015 g_loss=0.436 KID= 0.12695\n",
      "epoch 78, batch 5, d_loss=0.236 g_loss=-0.349 KID= 0.12695\n",
      "epoch 78, batch 6, d_loss=0.190 g_loss=-0.741 KID= 0.12695\n",
      "epoch 78, batch 7, d_loss=0.152 g_loss=-1.162 KID= 0.12695\n",
      "epoch 78, batch 8, d_loss=0.027 g_loss=-1.626 KID= 0.12695\n",
      "epoch 78, batch 9, d_loss=-0.138 g_loss=-2.076 KID= 0.12695\n",
      "epoch 78, batch 10, d_loss=-0.127 g_loss=-2.510 KID= 0.12695\n",
      "epoch 78, batch 11, d_loss=-0.119 g_loss=-2.962 KID= 0.12695\n",
      "epoch 78, batch 12, d_loss=0.402 g_loss=-2.031 KID= 0.12695\n",
      "epoch 78, batch 13, d_loss=0.074 g_loss=-1.467 KID= 0.12695\n",
      "epoch 78, batch 14, d_loss=0.107 g_loss=-0.963 KID= 0.12695\n",
      "epoch 78, batch 15, d_loss=-0.011 g_loss=-0.490 KID= 0.12695\n",
      "epoch 78, batch 16, d_loss=-0.053 g_loss=-0.134 KID= 0.12695\n",
      "epoch 78, batch 17, d_loss=-0.065 g_loss=-0.031 KID= 0.12695\n",
      "epoch 78, batch 18, d_loss=-0.226 g_loss=0.102 KID= 0.12695\n",
      "epoch 78, batch 19, d_loss=-0.261 g_loss=0.084 KID= 0.12695\n",
      "epoch 79, batch 0, d_loss=-0.128 g_loss=0.315 KID= 0.12695\n",
      "epoch 79, batch 1, d_loss=-0.033 g_loss=0.643 KID= 0.12695\n",
      "epoch 79, batch 2, d_loss=-0.015 g_loss=0.780 KID= 0.12695\n",
      "epoch 79, batch 3, d_loss=0.097 g_loss=0.713 KID= 0.12695\n",
      "epoch 79, batch 4, d_loss=0.038 g_loss=0.597 KID= 0.12695\n",
      "epoch 79, batch 5, d_loss=0.017 g_loss=0.411 KID= 0.12695\n",
      "epoch 79, batch 6, d_loss=-0.084 g_loss=0.237 KID= 0.12695\n",
      "epoch 79, batch 7, d_loss=0.153 g_loss=-0.243 KID= 0.12695\n",
      "epoch 79, batch 8, d_loss=0.121 g_loss=-0.389 KID= 0.12695\n",
      "epoch 79, batch 9, d_loss=0.135 g_loss=-0.438 KID= 0.12695\n",
      "epoch 79, batch 10, d_loss=0.023 g_loss=-0.439 KID= 0.12695\n",
      "epoch 79, batch 11, d_loss=-0.148 g_loss=-0.479 KID= 0.12695\n",
      "epoch 79, batch 12, d_loss=0.201 g_loss=-0.249 KID= 0.12695\n",
      "epoch 79, batch 13, d_loss=0.030 g_loss=-0.192 KID= 0.12695\n",
      "epoch 79, batch 14, d_loss=-0.052 g_loss=-0.135 KID= 0.12695\n",
      "epoch 79, batch 15, d_loss=-0.058 g_loss=-0.056 KID= 0.12695\n",
      "epoch 79, batch 16, d_loss=-0.019 g_loss=0.056 KID= 0.12695\n",
      "epoch 79, batch 17, d_loss=0.008 g_loss=0.110 KID= 0.12695\n",
      "epoch 79, batch 18, d_loss=0.025 g_loss=0.249 KID= 0.12695\n",
      "epoch 79, batch 19, d_loss=-0.068 g_loss=0.475 KID= 0.12695\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 80, batch 0, d_loss=-0.031 g_loss=0.653 KID= 0.08602\n",
      "epoch 80, batch 1, d_loss=0.112 g_loss=0.728 KID= 0.08602\n",
      "epoch 80, batch 2, d_loss=0.129 g_loss=0.749 KID= 0.08602\n",
      "epoch 80, batch 3, d_loss=0.028 g_loss=0.830 KID= 0.08602\n",
      "epoch 80, batch 4, d_loss=0.046 g_loss=0.733 KID= 0.08602\n",
      "epoch 80, batch 5, d_loss=0.008 g_loss=0.668 KID= 0.08602\n",
      "epoch 80, batch 6, d_loss=0.088 g_loss=0.575 KID= 0.08602\n",
      "epoch 80, batch 7, d_loss=0.102 g_loss=0.437 KID= 0.08602\n",
      "epoch 80, batch 8, d_loss=-0.001 g_loss=0.500 KID= 0.08602\n",
      "epoch 80, batch 9, d_loss=-0.006 g_loss=0.566 KID= 0.08602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80, batch 10, d_loss=-0.018 g_loss=0.640 KID= 0.08602\n",
      "epoch 80, batch 11, d_loss=-0.021 g_loss=0.674 KID= 0.08602\n",
      "epoch 80, batch 12, d_loss=0.017 g_loss=0.692 KID= 0.08602\n",
      "epoch 80, batch 13, d_loss=0.125 g_loss=0.436 KID= 0.08602\n",
      "epoch 80, batch 14, d_loss=0.104 g_loss=0.197 KID= 0.08602\n",
      "epoch 80, batch 15, d_loss=0.183 g_loss=-0.056 KID= 0.08602\n",
      "epoch 80, batch 16, d_loss=0.094 g_loss=-0.241 KID= 0.08602\n",
      "epoch 80, batch 17, d_loss=0.024 g_loss=-0.340 KID= 0.08602\n",
      "epoch 80, batch 18, d_loss=-0.051 g_loss=-0.420 KID= 0.08602\n",
      "epoch 80, batch 19, d_loss=0.008 g_loss=-0.559 KID= 0.08602\n",
      "epoch 81, batch 0, d_loss=-0.123 g_loss=-0.569 KID= 0.08602\n",
      "epoch 81, batch 1, d_loss=0.078 g_loss=-0.471 KID= 0.08602\n",
      "epoch 81, batch 2, d_loss=0.275 g_loss=-0.458 KID= 0.08602\n",
      "epoch 81, batch 3, d_loss=0.105 g_loss=-0.493 KID= 0.08602\n",
      "epoch 81, batch 4, d_loss=0.152 g_loss=-0.360 KID= 0.08602\n",
      "epoch 81, batch 5, d_loss=0.092 g_loss=-0.210 KID= 0.08602\n",
      "epoch 81, batch 6, d_loss=0.051 g_loss=0.050 KID= 0.08602\n",
      "epoch 81, batch 7, d_loss=-0.039 g_loss=0.399 KID= 0.08602\n",
      "epoch 81, batch 8, d_loss=0.042 g_loss=0.626 KID= 0.08602\n",
      "epoch 81, batch 9, d_loss=0.107 g_loss=0.576 KID= 0.08602\n",
      "epoch 81, batch 10, d_loss=0.358 g_loss=0.173 KID= 0.08602\n",
      "epoch 81, batch 11, d_loss=0.252 g_loss=0.352 KID= 0.08602\n",
      "epoch 81, batch 12, d_loss=0.095 g_loss=0.619 KID= 0.08602\n",
      "epoch 81, batch 13, d_loss=-0.054 g_loss=0.683 KID= 0.08602\n",
      "epoch 81, batch 14, d_loss=-0.010 g_loss=0.717 KID= 0.08602\n",
      "epoch 81, batch 15, d_loss=0.027 g_loss=0.674 KID= 0.08602\n",
      "epoch 81, batch 16, d_loss=-0.028 g_loss=0.579 KID= 0.08602\n",
      "epoch 81, batch 17, d_loss=0.309 g_loss=0.424 KID= 0.08602\n",
      "epoch 81, batch 18, d_loss=0.260 g_loss=0.322 KID= 0.08602\n",
      "epoch 81, batch 19, d_loss=0.269 g_loss=0.345 KID= 0.08602\n",
      "epoch 82, batch 0, d_loss=0.262 g_loss=0.356 KID= 0.08602\n",
      "epoch 82, batch 1, d_loss=0.136 g_loss=0.360 KID= 0.08602\n",
      "epoch 82, batch 2, d_loss=0.077 g_loss=0.434 KID= 0.08602\n",
      "epoch 82, batch 3, d_loss=0.140 g_loss=0.564 KID= 0.08602\n",
      "epoch 82, batch 4, d_loss=0.107 g_loss=0.643 KID= 0.08602\n",
      "epoch 82, batch 5, d_loss=0.128 g_loss=0.763 KID= 0.08602\n",
      "epoch 82, batch 6, d_loss=0.116 g_loss=0.856 KID= 0.08602\n",
      "epoch 82, batch 7, d_loss=0.044 g_loss=0.940 KID= 0.08602\n",
      "epoch 82, batch 8, d_loss=0.092 g_loss=1.053 KID= 0.08602\n",
      "epoch 82, batch 9, d_loss=0.054 g_loss=1.169 KID= 0.08602\n",
      "epoch 82, batch 10, d_loss=-0.148 g_loss=1.332 KID= 0.08602\n",
      "epoch 82, batch 11, d_loss=-0.142 g_loss=1.382 KID= 0.08602\n",
      "epoch 82, batch 12, d_loss=-0.025 g_loss=1.431 KID= 0.08602\n",
      "epoch 82, batch 13, d_loss=-0.156 g_loss=1.494 KID= 0.08602\n",
      "epoch 82, batch 14, d_loss=0.108 g_loss=1.238 KID= 0.08602\n",
      "epoch 82, batch 15, d_loss=0.080 g_loss=0.998 KID= 0.08602\n",
      "epoch 82, batch 16, d_loss=0.227 g_loss=0.691 KID= 0.08602\n",
      "epoch 82, batch 17, d_loss=0.323 g_loss=0.411 KID= 0.08602\n",
      "epoch 82, batch 18, d_loss=0.192 g_loss=0.244 KID= 0.08602\n",
      "epoch 82, batch 19, d_loss=0.182 g_loss=0.193 KID= 0.08602\n",
      "epoch 83, batch 0, d_loss=0.083 g_loss=0.159 KID= 0.08602\n",
      "epoch 83, batch 1, d_loss=0.042 g_loss=0.172 KID= 0.08602\n",
      "epoch 83, batch 2, d_loss=0.029 g_loss=0.350 KID= 0.08602\n",
      "epoch 83, batch 3, d_loss=-0.035 g_loss=0.424 KID= 0.08602\n",
      "epoch 83, batch 4, d_loss=-0.034 g_loss=0.437 KID= 0.08602\n",
      "epoch 83, batch 5, d_loss=0.262 g_loss=0.145 KID= 0.08602\n",
      "epoch 83, batch 6, d_loss=0.232 g_loss=-0.120 KID= 0.08602\n",
      "epoch 83, batch 7, d_loss=0.179 g_loss=-0.280 KID= 0.08602\n",
      "epoch 83, batch 8, d_loss=0.209 g_loss=-0.268 KID= 0.08602\n",
      "epoch 83, batch 9, d_loss=0.111 g_loss=-0.133 KID= 0.08602\n",
      "epoch 83, batch 10, d_loss=0.035 g_loss=-0.147 KID= 0.08602\n",
      "epoch 83, batch 11, d_loss=-0.059 g_loss=-0.273 KID= 0.08602\n",
      "epoch 83, batch 12, d_loss=0.145 g_loss=0.071 KID= 0.08602\n",
      "epoch 83, batch 13, d_loss=0.180 g_loss=0.135 KID= 0.08602\n",
      "epoch 83, batch 14, d_loss=0.194 g_loss=0.398 KID= 0.08602\n",
      "epoch 83, batch 15, d_loss=0.122 g_loss=0.517 KID= 0.08602\n",
      "epoch 83, batch 16, d_loss=0.176 g_loss=0.609 KID= 0.08602\n",
      "epoch 83, batch 17, d_loss=0.173 g_loss=0.743 KID= 0.08602\n",
      "epoch 83, batch 18, d_loss=0.115 g_loss=0.845 KID= 0.08602\n",
      "epoch 83, batch 19, d_loss=0.106 g_loss=0.919 KID= 0.08602\n",
      "epoch 84, batch 0, d_loss=0.125 g_loss=1.005 KID= 0.08602\n",
      "epoch 84, batch 1, d_loss=0.183 g_loss=1.069 KID= 0.08602\n",
      "epoch 84, batch 2, d_loss=0.515 g_loss=1.025 KID= 0.08602\n",
      "epoch 84, batch 3, d_loss=0.220 g_loss=0.974 KID= 0.08602\n",
      "epoch 84, batch 4, d_loss=0.301 g_loss=0.889 KID= 0.08602\n",
      "epoch 84, batch 5, d_loss=0.554 g_loss=0.667 KID= 0.08602\n",
      "epoch 84, batch 6, d_loss=0.504 g_loss=0.451 KID= 0.08602\n",
      "epoch 84, batch 7, d_loss=0.650 g_loss=0.228 KID= 0.08602\n",
      "epoch 84, batch 8, d_loss=0.839 g_loss=0.079 KID= 0.08602\n",
      "epoch 84, batch 9, d_loss=0.948 g_loss=0.338 KID= 0.08602\n",
      "epoch 84, batch 10, d_loss=0.791 g_loss=1.033 KID= 0.08602\n",
      "epoch 84, batch 11, d_loss=0.256 g_loss=2.042 KID= 0.08602\n",
      "epoch 84, batch 12, d_loss=-0.277 g_loss=2.936 KID= 0.08602\n",
      "epoch 84, batch 13, d_loss=-0.050 g_loss=2.713 KID= 0.08602\n",
      "epoch 84, batch 14, d_loss=0.195 g_loss=2.284 KID= 0.08602\n",
      "epoch 84, batch 15, d_loss=0.300 g_loss=2.039 KID= 0.08602\n",
      "epoch 84, batch 16, d_loss=0.314 g_loss=1.867 KID= 0.08602\n",
      "epoch 84, batch 17, d_loss=0.219 g_loss=1.953 KID= 0.08602\n",
      "epoch 84, batch 18, d_loss=-0.030 g_loss=2.276 KID= 0.08602\n",
      "epoch 84, batch 19, d_loss=0.131 g_loss=2.525 KID= 0.08602\n",
      "epoch 85, batch 0, d_loss=-0.120 g_loss=2.793 KID= 0.08602\n",
      "epoch 85, batch 1, d_loss=0.001 g_loss=3.062 KID= 0.08602\n",
      "epoch 85, batch 2, d_loss=0.633 g_loss=3.353 KID= 0.08602\n",
      "epoch 85, batch 3, d_loss=0.592 g_loss=3.782 KID= 0.08602\n",
      "epoch 85, batch 4, d_loss=0.314 g_loss=4.389 KID= 0.08602\n",
      "epoch 85, batch 5, d_loss=0.770 g_loss=4.266 KID= 0.08602\n",
      "epoch 85, batch 6, d_loss=0.343 g_loss=4.248 KID= 0.08602\n",
      "epoch 85, batch 7, d_loss=0.120 g_loss=4.507 KID= 0.08602\n",
      "epoch 85, batch 8, d_loss=0.155 g_loss=5.176 KID= 0.08602\n",
      "epoch 85, batch 9, d_loss=-0.350 g_loss=6.004 KID= 0.08602\n",
      "epoch 85, batch 10, d_loss=0.051 g_loss=5.641 KID= 0.08602\n",
      "epoch 85, batch 11, d_loss=0.191 g_loss=5.558 KID= 0.08602\n",
      "epoch 85, batch 12, d_loss=-0.085 g_loss=6.154 KID= 0.08602\n",
      "epoch 85, batch 13, d_loss=0.242 g_loss=5.685 KID= 0.08602\n",
      "epoch 85, batch 14, d_loss=0.881 g_loss=4.530 KID= 0.08602\n",
      "epoch 85, batch 15, d_loss=0.557 g_loss=3.761 KID= 0.08602\n",
      "epoch 85, batch 16, d_loss=0.504 g_loss=3.072 KID= 0.08602\n",
      "epoch 85, batch 17, d_loss=0.392 g_loss=2.630 KID= 0.08602\n",
      "epoch 85, batch 18, d_loss=0.394 g_loss=2.280 KID= 0.08602\n",
      "epoch 85, batch 19, d_loss=0.642 g_loss=1.969 KID= 0.08602\n",
      "epoch 86, batch 0, d_loss=0.433 g_loss=1.928 KID= 0.08602\n",
      "epoch 86, batch 1, d_loss=0.379 g_loss=2.125 KID= 0.08602\n",
      "epoch 86, batch 2, d_loss=0.509 g_loss=1.998 KID= 0.08602\n",
      "epoch 86, batch 3, d_loss=0.310 g_loss=1.837 KID= 0.08602\n",
      "epoch 86, batch 4, d_loss=0.169 g_loss=1.969 KID= 0.08602\n",
      "epoch 86, batch 5, d_loss=0.278 g_loss=2.001 KID= 0.08602\n",
      "epoch 86, batch 6, d_loss=0.268 g_loss=2.007 KID= 0.08602\n",
      "epoch 86, batch 7, d_loss=0.430 g_loss=1.899 KID= 0.08602\n",
      "epoch 86, batch 8, d_loss=0.476 g_loss=1.688 KID= 0.08602\n",
      "epoch 86, batch 9, d_loss=0.500 g_loss=1.522 KID= 0.08602\n",
      "epoch 86, batch 10, d_loss=0.567 g_loss=1.276 KID= 0.08602\n",
      "epoch 86, batch 11, d_loss=0.610 g_loss=1.151 KID= 0.08602\n",
      "epoch 86, batch 12, d_loss=0.584 g_loss=1.277 KID= 0.08602\n",
      "epoch 86, batch 13, d_loss=0.529 g_loss=1.542 KID= 0.08602\n",
      "epoch 86, batch 14, d_loss=0.480 g_loss=1.860 KID= 0.08602\n",
      "epoch 86, batch 15, d_loss=0.213 g_loss=2.046 KID= 0.08602\n",
      "epoch 86, batch 16, d_loss=-0.020 g_loss=2.015 KID= 0.08602\n",
      "epoch 86, batch 17, d_loss=0.028 g_loss=1.663 KID= 0.08602\n",
      "epoch 86, batch 18, d_loss=0.007 g_loss=1.423 KID= 0.08602\n",
      "epoch 86, batch 19, d_loss=0.023 g_loss=1.275 KID= 0.08602\n",
      "epoch 87, batch 0, d_loss=-0.066 g_loss=1.181 KID= 0.08602\n",
      "epoch 87, batch 1, d_loss=-0.072 g_loss=1.062 KID= 0.08602\n",
      "epoch 87, batch 2, d_loss=0.500 g_loss=0.981 KID= 0.08602\n",
      "epoch 87, batch 3, d_loss=0.506 g_loss=1.202 KID= 0.08602\n",
      "epoch 87, batch 4, d_loss=0.257 g_loss=1.443 KID= 0.08602\n",
      "epoch 87, batch 5, d_loss=0.556 g_loss=1.508 KID= 0.08602\n",
      "epoch 87, batch 6, d_loss=0.223 g_loss=1.864 KID= 0.08602\n",
      "epoch 87, batch 7, d_loss=0.411 g_loss=2.071 KID= 0.08602\n",
      "epoch 87, batch 8, d_loss=0.118 g_loss=2.356 KID= 0.08602\n",
      "epoch 87, batch 9, d_loss=0.255 g_loss=2.352 KID= 0.08602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 87, batch 10, d_loss=0.300 g_loss=2.279 KID= 0.08602\n",
      "epoch 87, batch 11, d_loss=0.452 g_loss=2.197 KID= 0.08602\n",
      "epoch 87, batch 12, d_loss=0.275 g_loss=2.265 KID= 0.08602\n",
      "epoch 87, batch 13, d_loss=0.270 g_loss=2.405 KID= 0.08602\n",
      "epoch 87, batch 14, d_loss=0.311 g_loss=2.468 KID= 0.08602\n",
      "epoch 87, batch 15, d_loss=0.255 g_loss=2.526 KID= 0.08602\n",
      "epoch 87, batch 16, d_loss=0.197 g_loss=2.599 KID= 0.08602\n",
      "epoch 87, batch 17, d_loss=0.196 g_loss=2.772 KID= 0.08602\n",
      "epoch 87, batch 18, d_loss=0.205 g_loss=2.795 KID= 0.08602\n",
      "epoch 87, batch 19, d_loss=0.181 g_loss=2.941 KID= 0.08602\n",
      "epoch 88, batch 0, d_loss=0.245 g_loss=2.749 KID= 0.08602\n",
      "epoch 88, batch 1, d_loss=0.160 g_loss=2.816 KID= 0.08602\n",
      "epoch 88, batch 2, d_loss=0.512 g_loss=2.075 KID= 0.08602\n",
      "epoch 88, batch 3, d_loss=0.450 g_loss=1.334 KID= 0.08602\n",
      "epoch 88, batch 4, d_loss=0.299 g_loss=0.909 KID= 0.08602\n",
      "epoch 88, batch 5, d_loss=0.354 g_loss=0.462 KID= 0.08602\n",
      "epoch 88, batch 6, d_loss=0.244 g_loss=0.236 KID= 0.08602\n",
      "epoch 88, batch 7, d_loss=0.233 g_loss=0.238 KID= 0.08602\n",
      "epoch 88, batch 8, d_loss=0.268 g_loss=0.236 KID= 0.08602\n",
      "epoch 88, batch 9, d_loss=0.439 g_loss=0.274 KID= 0.08602\n",
      "epoch 88, batch 10, d_loss=0.335 g_loss=0.489 KID= 0.08602\n",
      "epoch 88, batch 11, d_loss=0.300 g_loss=0.916 KID= 0.08602\n",
      "epoch 88, batch 12, d_loss=0.139 g_loss=1.224 KID= 0.08602\n",
      "epoch 88, batch 13, d_loss=0.143 g_loss=1.369 KID= 0.08602\n",
      "epoch 88, batch 14, d_loss=0.097 g_loss=1.606 KID= 0.08602\n",
      "epoch 88, batch 15, d_loss=0.350 g_loss=1.621 KID= 0.08602\n",
      "epoch 88, batch 16, d_loss=0.434 g_loss=1.800 KID= 0.08602\n",
      "epoch 88, batch 17, d_loss=0.224 g_loss=2.102 KID= 0.08602\n",
      "epoch 88, batch 18, d_loss=0.325 g_loss=1.937 KID= 0.08602\n",
      "epoch 88, batch 19, d_loss=0.572 g_loss=1.853 KID= 0.08602\n",
      "epoch 89, batch 0, d_loss=0.243 g_loss=1.895 KID= 0.08602\n",
      "epoch 89, batch 1, d_loss=0.315 g_loss=1.952 KID= 0.08602\n",
      "epoch 89, batch 2, d_loss=0.220 g_loss=2.291 KID= 0.08602\n",
      "epoch 89, batch 3, d_loss=0.110 g_loss=2.622 KID= 0.08602\n",
      "epoch 89, batch 4, d_loss=0.302 g_loss=2.576 KID= 0.08602\n",
      "epoch 89, batch 5, d_loss=0.324 g_loss=2.414 KID= 0.08602\n",
      "epoch 89, batch 6, d_loss=0.194 g_loss=2.353 KID= 0.08602\n",
      "epoch 89, batch 7, d_loss=0.585 g_loss=1.594 KID= 0.08602\n",
      "epoch 89, batch 8, d_loss=0.554 g_loss=1.008 KID= 0.08602\n",
      "epoch 89, batch 9, d_loss=0.376 g_loss=0.759 KID= 0.08602\n",
      "epoch 89, batch 10, d_loss=0.541 g_loss=0.433 KID= 0.08602\n",
      "epoch 89, batch 11, d_loss=0.505 g_loss=0.213 KID= 0.08602\n",
      "epoch 89, batch 12, d_loss=0.495 g_loss=0.170 KID= 0.08602\n",
      "epoch 89, batch 13, d_loss=0.518 g_loss=0.261 KID= 0.08602\n",
      "epoch 89, batch 14, d_loss=0.543 g_loss=0.434 KID= 0.08602\n",
      "epoch 89, batch 15, d_loss=0.568 g_loss=0.460 KID= 0.08602\n",
      "epoch 89, batch 16, d_loss=0.296 g_loss=0.659 KID= 0.08602\n",
      "epoch 89, batch 17, d_loss=0.143 g_loss=0.833 KID= 0.08602\n",
      "epoch 89, batch 18, d_loss=0.048 g_loss=0.803 KID= 0.08602\n",
      "epoch 89, batch 19, d_loss=0.165 g_loss=0.747 KID= 0.08602\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 90, batch 0, d_loss=-0.117 g_loss=0.740 KID= 0.14530\n",
      "epoch 90, batch 1, d_loss=0.011 g_loss=0.766 KID= 0.14530\n",
      "epoch 90, batch 2, d_loss=0.218 g_loss=0.839 KID= 0.14530\n",
      "epoch 90, batch 3, d_loss=0.312 g_loss=0.946 KID= 0.14530\n",
      "epoch 90, batch 4, d_loss=0.256 g_loss=1.011 KID= 0.14530\n",
      "epoch 90, batch 5, d_loss=0.256 g_loss=0.879 KID= 0.14530\n",
      "epoch 90, batch 6, d_loss=0.218 g_loss=0.710 KID= 0.14530\n",
      "epoch 90, batch 7, d_loss=0.067 g_loss=0.567 KID= 0.14530\n",
      "epoch 90, batch 8, d_loss=0.128 g_loss=0.311 KID= 0.14530\n",
      "epoch 90, batch 9, d_loss=-0.005 g_loss=0.246 KID= 0.14530\n",
      "epoch 90, batch 10, d_loss=0.228 g_loss=0.131 KID= 0.14530\n",
      "epoch 90, batch 11, d_loss=0.197 g_loss=-0.015 KID= 0.14530\n",
      "epoch 90, batch 12, d_loss=0.326 g_loss=0.085 KID= 0.14530\n",
      "epoch 90, batch 13, d_loss=0.302 g_loss=0.219 KID= 0.14530\n",
      "epoch 90, batch 14, d_loss=0.387 g_loss=0.275 KID= 0.14530\n",
      "epoch 90, batch 15, d_loss=0.359 g_loss=0.243 KID= 0.14530\n",
      "epoch 90, batch 16, d_loss=0.252 g_loss=0.197 KID= 0.14530\n",
      "epoch 90, batch 17, d_loss=0.226 g_loss=0.196 KID= 0.14530\n",
      "epoch 90, batch 18, d_loss=0.092 g_loss=0.166 KID= 0.14530\n",
      "epoch 90, batch 19, d_loss=0.290 g_loss=0.180 KID= 0.14530\n",
      "epoch 91, batch 0, d_loss=0.222 g_loss=0.203 KID= 0.14530\n",
      "epoch 91, batch 1, d_loss=0.227 g_loss=0.555 KID= 0.14530\n",
      "epoch 91, batch 2, d_loss=0.396 g_loss=0.608 KID= 0.14530\n",
      "epoch 91, batch 3, d_loss=0.371 g_loss=0.620 KID= 0.14530\n",
      "epoch 91, batch 4, d_loss=0.165 g_loss=0.847 KID= 0.14530\n",
      "epoch 91, batch 5, d_loss=0.310 g_loss=0.941 KID= 0.14530\n",
      "epoch 91, batch 6, d_loss=0.190 g_loss=0.982 KID= 0.14530\n",
      "epoch 91, batch 7, d_loss=0.150 g_loss=1.096 KID= 0.14530\n",
      "epoch 91, batch 8, d_loss=0.098 g_loss=1.152 KID= 0.14530\n",
      "epoch 91, batch 9, d_loss=0.017 g_loss=1.177 KID= 0.14530\n",
      "epoch 91, batch 10, d_loss=0.070 g_loss=1.183 KID= 0.14530\n",
      "epoch 91, batch 11, d_loss=0.312 g_loss=1.176 KID= 0.14530\n",
      "epoch 91, batch 12, d_loss=0.116 g_loss=1.133 KID= 0.14530\n",
      "epoch 91, batch 13, d_loss=0.318 g_loss=0.944 KID= 0.14530\n",
      "epoch 91, batch 14, d_loss=0.404 g_loss=0.770 KID= 0.14530\n",
      "epoch 91, batch 15, d_loss=0.268 g_loss=0.569 KID= 0.14530\n",
      "epoch 91, batch 16, d_loss=0.343 g_loss=0.371 KID= 0.14530\n",
      "epoch 91, batch 17, d_loss=0.326 g_loss=0.296 KID= 0.14530\n",
      "epoch 91, batch 18, d_loss=0.231 g_loss=0.285 KID= 0.14530\n",
      "epoch 91, batch 19, d_loss=0.375 g_loss=0.436 KID= 0.14530\n",
      "epoch 92, batch 0, d_loss=0.359 g_loss=0.651 KID= 0.14530\n",
      "epoch 92, batch 1, d_loss=0.250 g_loss=1.008 KID= 0.14530\n",
      "epoch 92, batch 2, d_loss=0.341 g_loss=1.232 KID= 0.14530\n",
      "epoch 92, batch 3, d_loss=0.238 g_loss=1.642 KID= 0.14530\n",
      "epoch 92, batch 4, d_loss=0.250 g_loss=1.669 KID= 0.14530\n",
      "epoch 92, batch 5, d_loss=0.231 g_loss=1.471 KID= 0.14530\n",
      "epoch 92, batch 6, d_loss=0.302 g_loss=1.154 KID= 0.14530\n",
      "epoch 92, batch 7, d_loss=0.286 g_loss=0.920 KID= 0.14530\n",
      "epoch 92, batch 8, d_loss=0.319 g_loss=0.743 KID= 0.14530\n",
      "epoch 92, batch 9, d_loss=0.384 g_loss=0.832 KID= 0.14530\n",
      "epoch 92, batch 10, d_loss=0.241 g_loss=1.052 KID= 0.14530\n",
      "epoch 92, batch 11, d_loss=0.218 g_loss=1.303 KID= 0.14530\n",
      "epoch 92, batch 12, d_loss=0.268 g_loss=1.593 KID= 0.14530\n",
      "epoch 92, batch 13, d_loss=0.248 g_loss=1.993 KID= 0.14530\n",
      "epoch 92, batch 14, d_loss=0.154 g_loss=2.253 KID= 0.14530\n",
      "epoch 92, batch 15, d_loss=0.314 g_loss=2.005 KID= 0.14530\n",
      "epoch 92, batch 16, d_loss=0.222 g_loss=1.847 KID= 0.14530\n",
      "epoch 92, batch 17, d_loss=0.360 g_loss=1.418 KID= 0.14530\n",
      "epoch 92, batch 18, d_loss=0.305 g_loss=1.261 KID= 0.14530\n",
      "epoch 92, batch 19, d_loss=0.133 g_loss=1.459 KID= 0.14530\n",
      "epoch 93, batch 0, d_loss=0.221 g_loss=1.473 KID= 0.14530\n",
      "epoch 93, batch 1, d_loss=0.220 g_loss=1.348 KID= 0.14530\n",
      "epoch 93, batch 2, d_loss=0.152 g_loss=1.370 KID= 0.14530\n",
      "epoch 93, batch 3, d_loss=0.300 g_loss=1.297 KID= 0.14530\n",
      "epoch 93, batch 4, d_loss=0.305 g_loss=1.022 KID= 0.14530\n",
      "epoch 93, batch 5, d_loss=0.330 g_loss=0.753 KID= 0.14530\n",
      "epoch 93, batch 6, d_loss=0.329 g_loss=0.432 KID= 0.14530\n",
      "epoch 93, batch 7, d_loss=0.308 g_loss=0.147 KID= 0.14530\n",
      "epoch 93, batch 8, d_loss=0.186 g_loss=0.010 KID= 0.14530\n",
      "epoch 93, batch 9, d_loss=0.220 g_loss=-0.292 KID= 0.14530\n",
      "epoch 93, batch 10, d_loss=0.233 g_loss=-0.557 KID= 0.14530\n",
      "epoch 93, batch 11, d_loss=0.297 g_loss=-0.309 KID= 0.14530\n",
      "epoch 93, batch 12, d_loss=0.436 g_loss=0.175 KID= 0.14530\n",
      "epoch 93, batch 13, d_loss=0.183 g_loss=0.761 KID= 0.14530\n",
      "epoch 93, batch 14, d_loss=0.062 g_loss=1.180 KID= 0.14530\n",
      "epoch 93, batch 15, d_loss=-0.037 g_loss=1.471 KID= 0.14530\n",
      "epoch 93, batch 16, d_loss=0.181 g_loss=1.338 KID= 0.14530\n",
      "epoch 93, batch 17, d_loss=0.215 g_loss=1.305 KID= 0.14530\n",
      "epoch 93, batch 18, d_loss=0.298 g_loss=1.560 KID= 0.14530\n",
      "epoch 93, batch 19, d_loss=0.523 g_loss=2.065 KID= 0.14530\n",
      "epoch 94, batch 0, d_loss=0.368 g_loss=2.685 KID= 0.14530\n",
      "epoch 94, batch 1, d_loss=0.117 g_loss=3.462 KID= 0.14530\n",
      "epoch 94, batch 2, d_loss=0.233 g_loss=3.649 KID= 0.14530\n",
      "epoch 94, batch 3, d_loss=0.152 g_loss=4.091 KID= 0.14530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94, batch 4, d_loss=0.329 g_loss=3.516 KID= 0.14530\n",
      "epoch 94, batch 5, d_loss=0.511 g_loss=2.678 KID= 0.14530\n",
      "epoch 94, batch 6, d_loss=0.201 g_loss=2.428 KID= 0.14530\n",
      "epoch 94, batch 7, d_loss=0.243 g_loss=2.141 KID= 0.14530\n",
      "epoch 94, batch 8, d_loss=0.302 g_loss=1.670 KID= 0.14530\n",
      "epoch 94, batch 9, d_loss=0.133 g_loss=1.416 KID= 0.14530\n",
      "epoch 94, batch 10, d_loss=0.079 g_loss=1.239 KID= 0.14530\n",
      "epoch 94, batch 11, d_loss=0.173 g_loss=0.980 KID= 0.14530\n",
      "epoch 94, batch 12, d_loss=0.115 g_loss=0.778 KID= 0.14530\n",
      "epoch 94, batch 13, d_loss=0.310 g_loss=0.659 KID= 0.14530\n",
      "epoch 94, batch 14, d_loss=0.354 g_loss=0.485 KID= 0.14530\n",
      "epoch 94, batch 15, d_loss=0.255 g_loss=0.543 KID= 0.14530\n",
      "epoch 94, batch 16, d_loss=0.295 g_loss=0.581 KID= 0.14530\n",
      "epoch 94, batch 17, d_loss=0.222 g_loss=0.659 KID= 0.14530\n",
      "epoch 94, batch 18, d_loss=0.166 g_loss=0.787 KID= 0.14530\n",
      "epoch 94, batch 19, d_loss=0.207 g_loss=0.841 KID= 0.14530\n",
      "epoch 95, batch 0, d_loss=0.230 g_loss=0.913 KID= 0.14530\n",
      "epoch 95, batch 1, d_loss=0.061 g_loss=0.950 KID= 0.14530\n",
      "epoch 95, batch 2, d_loss=0.159 g_loss=0.889 KID= 0.14530\n",
      "epoch 95, batch 3, d_loss=0.139 g_loss=0.956 KID= 0.14530\n",
      "epoch 95, batch 4, d_loss=0.266 g_loss=0.871 KID= 0.14530\n",
      "epoch 95, batch 5, d_loss=0.368 g_loss=0.800 KID= 0.14530\n",
      "epoch 95, batch 6, d_loss=0.325 g_loss=0.948 KID= 0.14530\n",
      "epoch 95, batch 7, d_loss=0.293 g_loss=1.122 KID= 0.14530\n",
      "epoch 95, batch 8, d_loss=0.303 g_loss=1.336 KID= 0.14530\n",
      "epoch 95, batch 9, d_loss=0.196 g_loss=1.633 KID= 0.14530\n",
      "epoch 95, batch 10, d_loss=0.192 g_loss=1.913 KID= 0.14530\n",
      "epoch 95, batch 11, d_loss=0.114 g_loss=2.227 KID= 0.14530\n",
      "epoch 95, batch 12, d_loss=0.116 g_loss=2.460 KID= 0.14530\n",
      "epoch 95, batch 13, d_loss=0.110 g_loss=2.579 KID= 0.14530\n",
      "epoch 95, batch 14, d_loss=0.327 g_loss=2.558 KID= 0.14530\n",
      "epoch 95, batch 15, d_loss=0.479 g_loss=2.455 KID= 0.14530\n",
      "epoch 95, batch 16, d_loss=0.480 g_loss=2.273 KID= 0.14530\n",
      "epoch 95, batch 17, d_loss=0.415 g_loss=1.944 KID= 0.14530\n",
      "epoch 95, batch 18, d_loss=0.235 g_loss=1.815 KID= 0.14530\n",
      "epoch 95, batch 19, d_loss=0.295 g_loss=1.889 KID= 0.14530\n",
      "epoch 96, batch 0, d_loss=0.060 g_loss=2.082 KID= 0.14530\n",
      "epoch 96, batch 1, d_loss=0.146 g_loss=1.960 KID= 0.14530\n",
      "epoch 96, batch 2, d_loss=0.098 g_loss=1.659 KID= 0.14530\n",
      "epoch 96, batch 3, d_loss=0.152 g_loss=1.464 KID= 0.14530\n",
      "epoch 96, batch 4, d_loss=0.270 g_loss=1.200 KID= 0.14530\n",
      "epoch 96, batch 5, d_loss=0.402 g_loss=0.908 KID= 0.14530\n",
      "epoch 96, batch 6, d_loss=0.321 g_loss=0.914 KID= 0.14530\n",
      "epoch 96, batch 7, d_loss=0.316 g_loss=1.104 KID= 0.14530\n",
      "epoch 96, batch 8, d_loss=0.333 g_loss=1.260 KID= 0.14530\n",
      "epoch 96, batch 9, d_loss=0.124 g_loss=1.458 KID= 0.14530\n",
      "epoch 96, batch 10, d_loss=0.079 g_loss=1.579 KID= 0.14530\n",
      "epoch 96, batch 11, d_loss=0.265 g_loss=1.523 KID= 0.14530\n",
      "epoch 96, batch 12, d_loss=0.396 g_loss=1.288 KID= 0.14530\n",
      "epoch 96, batch 13, d_loss=0.284 g_loss=1.219 KID= 0.14530\n",
      "epoch 96, batch 14, d_loss=0.338 g_loss=1.353 KID= 0.14530\n",
      "epoch 96, batch 15, d_loss=0.236 g_loss=1.617 KID= 0.14530\n",
      "epoch 96, batch 16, d_loss=0.200 g_loss=1.930 KID= 0.14530\n",
      "epoch 96, batch 17, d_loss=0.166 g_loss=2.090 KID= 0.14530\n",
      "epoch 96, batch 18, d_loss=0.086 g_loss=2.332 KID= 0.14530\n",
      "epoch 96, batch 19, d_loss=0.492 g_loss=1.911 KID= 0.14530\n",
      "epoch 97, batch 0, d_loss=0.423 g_loss=1.806 KID= 0.14530\n",
      "epoch 97, batch 1, d_loss=0.173 g_loss=1.760 KID= 0.14530\n",
      "epoch 97, batch 2, d_loss=0.059 g_loss=1.700 KID= 0.14530\n",
      "epoch 97, batch 3, d_loss=-0.030 g_loss=1.674 KID= 0.14530\n",
      "epoch 97, batch 4, d_loss=0.043 g_loss=1.550 KID= 0.14530\n",
      "epoch 97, batch 5, d_loss=0.308 g_loss=1.298 KID= 0.14530\n",
      "epoch 97, batch 6, d_loss=0.040 g_loss=1.248 KID= 0.14530\n",
      "epoch 97, batch 7, d_loss=0.395 g_loss=1.030 KID= 0.14530\n",
      "epoch 97, batch 8, d_loss=0.622 g_loss=0.788 KID= 0.14530\n",
      "epoch 97, batch 9, d_loss=0.424 g_loss=0.657 KID= 0.14530\n",
      "epoch 97, batch 10, d_loss=0.386 g_loss=0.663 KID= 0.14530\n",
      "epoch 97, batch 11, d_loss=0.356 g_loss=0.758 KID= 0.14530\n",
      "epoch 97, batch 12, d_loss=0.212 g_loss=1.077 KID= 0.14530\n",
      "epoch 97, batch 13, d_loss=0.240 g_loss=1.416 KID= 0.14530\n",
      "epoch 97, batch 14, d_loss=0.160 g_loss=1.632 KID= 0.14530\n",
      "epoch 97, batch 15, d_loss=0.094 g_loss=1.943 KID= 0.14530\n",
      "epoch 97, batch 16, d_loss=0.385 g_loss=1.959 KID= 0.14530\n",
      "epoch 97, batch 17, d_loss=0.294 g_loss=2.061 KID= 0.14530\n",
      "epoch 97, batch 18, d_loss=0.165 g_loss=2.357 KID= 0.14530\n",
      "epoch 97, batch 19, d_loss=0.468 g_loss=2.192 KID= 0.14530\n",
      "epoch 98, batch 0, d_loss=0.498 g_loss=2.159 KID= 0.14530\n",
      "epoch 98, batch 1, d_loss=0.216 g_loss=2.324 KID= 0.14530\n",
      "epoch 98, batch 2, d_loss=0.645 g_loss=1.905 KID= 0.14530\n",
      "epoch 98, batch 3, d_loss=0.431 g_loss=2.059 KID= 0.14530\n",
      "epoch 98, batch 4, d_loss=0.403 g_loss=2.593 KID= 0.14530\n",
      "epoch 98, batch 5, d_loss=0.092 g_loss=3.341 KID= 0.14530\n",
      "epoch 98, batch 6, d_loss=0.028 g_loss=3.907 KID= 0.14530\n",
      "epoch 98, batch 7, d_loss=0.058 g_loss=4.167 KID= 0.14530\n",
      "epoch 98, batch 8, d_loss=0.346 g_loss=3.754 KID= 0.14530\n",
      "epoch 98, batch 9, d_loss=0.228 g_loss=3.593 KID= 0.14530\n",
      "epoch 98, batch 10, d_loss=0.082 g_loss=3.595 KID= 0.14530\n",
      "epoch 98, batch 11, d_loss=0.317 g_loss=3.171 KID= 0.14530\n",
      "epoch 98, batch 12, d_loss=0.220 g_loss=2.661 KID= 0.14530\n",
      "epoch 98, batch 13, d_loss=0.033 g_loss=2.537 KID= 0.14530\n",
      "epoch 98, batch 14, d_loss=0.236 g_loss=2.206 KID= 0.14530\n",
      "epoch 98, batch 15, d_loss=0.560 g_loss=1.595 KID= 0.14530\n",
      "epoch 98, batch 16, d_loss=0.487 g_loss=1.305 KID= 0.14530\n",
      "epoch 98, batch 17, d_loss=0.436 g_loss=1.245 KID= 0.14530\n",
      "epoch 98, batch 18, d_loss=0.318 g_loss=1.386 KID= 0.14530\n",
      "epoch 98, batch 19, d_loss=0.148 g_loss=1.653 KID= 0.14530\n",
      "epoch 99, batch 0, d_loss=0.143 g_loss=2.022 KID= 0.14530\n",
      "epoch 99, batch 1, d_loss=0.131 g_loss=2.391 KID= 0.14530\n",
      "epoch 99, batch 2, d_loss=0.010 g_loss=2.788 KID= 0.14530\n",
      "epoch 99, batch 3, d_loss=0.159 g_loss=2.982 KID= 0.14530\n",
      "epoch 99, batch 4, d_loss=0.390 g_loss=2.565 KID= 0.14530\n",
      "epoch 99, batch 5, d_loss=0.239 g_loss=2.543 KID= 0.14530\n",
      "epoch 99, batch 6, d_loss=0.388 g_loss=2.068 KID= 0.14530\n",
      "epoch 99, batch 7, d_loss=0.173 g_loss=1.752 KID= 0.14530\n",
      "epoch 99, batch 8, d_loss=0.054 g_loss=1.602 KID= 0.14530\n",
      "epoch 99, batch 9, d_loss=0.049 g_loss=1.563 KID= 0.14530\n",
      "epoch 99, batch 10, d_loss=-0.049 g_loss=1.452 KID= 0.14530\n",
      "epoch 99, batch 11, d_loss=0.011 g_loss=1.309 KID= 0.14530\n",
      "epoch 99, batch 12, d_loss=0.357 g_loss=1.152 KID= 0.14530\n",
      "epoch 99, batch 13, d_loss=0.446 g_loss=1.107 KID= 0.14530\n",
      "epoch 99, batch 14, d_loss=0.201 g_loss=1.177 KID= 0.14530\n",
      "epoch 99, batch 15, d_loss=0.284 g_loss=1.322 KID= 0.14530\n",
      "epoch 99, batch 16, d_loss=0.151 g_loss=1.527 KID= 0.14530\n",
      "epoch 99, batch 17, d_loss=0.091 g_loss=1.827 KID= 0.14530\n",
      "epoch 99, batch 18, d_loss=0.089 g_loss=2.035 KID= 0.14530\n",
      "epoch 99, batch 19, d_loss=0.284 g_loss=1.991 KID= 0.14530\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 100, batch 0, d_loss=0.475 g_loss=1.794 KID= 0.12366\n",
      "epoch 100, batch 1, d_loss=0.454 g_loss=1.762 KID= 0.12366\n",
      "epoch 100, batch 2, d_loss=0.320 g_loss=1.698 KID= 0.12366\n",
      "epoch 100, batch 3, d_loss=0.365 g_loss=1.649 KID= 0.12366\n",
      "epoch 100, batch 4, d_loss=0.292 g_loss=1.654 KID= 0.12366\n",
      "epoch 100, batch 5, d_loss=0.174 g_loss=1.670 KID= 0.12366\n",
      "epoch 100, batch 6, d_loss=0.073 g_loss=1.808 KID= 0.12366\n",
      "epoch 100, batch 7, d_loss=0.089 g_loss=1.719 KID= 0.12366\n",
      "epoch 100, batch 8, d_loss=0.150 g_loss=1.415 KID= 0.12366\n",
      "epoch 100, batch 9, d_loss=-0.014 g_loss=1.274 KID= 0.12366\n",
      "epoch 100, batch 10, d_loss=-0.113 g_loss=1.111 KID= 0.12366\n",
      "epoch 100, batch 11, d_loss=0.097 g_loss=0.853 KID= 0.12366\n",
      "epoch 100, batch 12, d_loss=0.226 g_loss=0.485 KID= 0.12366\n",
      "epoch 100, batch 13, d_loss=0.350 g_loss=0.103 KID= 0.12366\n",
      "epoch 100, batch 14, d_loss=0.400 g_loss=-0.175 KID= 0.12366\n",
      "epoch 100, batch 15, d_loss=0.457 g_loss=-0.400 KID= 0.12366\n",
      "epoch 100, batch 16, d_loss=0.364 g_loss=-0.478 KID= 0.12366\n",
      "epoch 100, batch 17, d_loss=0.252 g_loss=-0.484 KID= 0.12366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100, batch 18, d_loss=0.135 g_loss=-0.460 KID= 0.12366\n",
      "epoch 100, batch 19, d_loss=0.124 g_loss=-0.426 KID= 0.12366\n",
      "epoch 101, batch 0, d_loss=0.253 g_loss=-0.364 KID= 0.12366\n",
      "epoch 101, batch 1, d_loss=0.066 g_loss=-0.315 KID= 0.12366\n",
      "epoch 101, batch 2, d_loss=0.087 g_loss=-0.298 KID= 0.12366\n",
      "epoch 101, batch 3, d_loss=0.173 g_loss=-0.254 KID= 0.12366\n",
      "epoch 101, batch 4, d_loss=0.224 g_loss=-0.178 KID= 0.12366\n",
      "epoch 101, batch 5, d_loss=0.167 g_loss=-0.078 KID= 0.12366\n",
      "epoch 101, batch 6, d_loss=0.371 g_loss=0.072 KID= 0.12366\n",
      "epoch 101, batch 7, d_loss=0.292 g_loss=0.248 KID= 0.12366\n",
      "epoch 101, batch 8, d_loss=0.232 g_loss=0.383 KID= 0.12366\n",
      "epoch 101, batch 9, d_loss=0.221 g_loss=0.538 KID= 0.12366\n",
      "epoch 101, batch 10, d_loss=0.233 g_loss=0.773 KID= 0.12366\n",
      "epoch 101, batch 11, d_loss=0.188 g_loss=0.986 KID= 0.12366\n",
      "epoch 101, batch 12, d_loss=0.223 g_loss=1.057 KID= 0.12366\n",
      "epoch 101, batch 13, d_loss=0.278 g_loss=1.090 KID= 0.12366\n",
      "epoch 101, batch 14, d_loss=0.250 g_loss=1.084 KID= 0.12366\n",
      "epoch 101, batch 15, d_loss=0.496 g_loss=0.999 KID= 0.12366\n",
      "epoch 101, batch 16, d_loss=0.291 g_loss=0.956 KID= 0.12366\n",
      "epoch 101, batch 17, d_loss=0.425 g_loss=0.915 KID= 0.12366\n",
      "epoch 101, batch 18, d_loss=0.502 g_loss=0.920 KID= 0.12366\n",
      "epoch 101, batch 19, d_loss=0.333 g_loss=0.892 KID= 0.12366\n",
      "epoch 102, batch 0, d_loss=0.196 g_loss=0.972 KID= 0.12366\n",
      "epoch 102, batch 1, d_loss=0.241 g_loss=1.114 KID= 0.12366\n",
      "epoch 102, batch 2, d_loss=0.300 g_loss=1.273 KID= 0.12366\n",
      "epoch 102, batch 3, d_loss=0.163 g_loss=1.313 KID= 0.12366\n",
      "epoch 102, batch 4, d_loss=0.119 g_loss=1.160 KID= 0.12366\n",
      "epoch 102, batch 5, d_loss=0.023 g_loss=1.126 KID= 0.12366\n",
      "epoch 102, batch 6, d_loss=0.347 g_loss=0.858 KID= 0.12366\n",
      "epoch 102, batch 7, d_loss=0.157 g_loss=0.648 KID= 0.12366\n",
      "epoch 102, batch 8, d_loss=0.159 g_loss=0.563 KID= 0.12366\n",
      "epoch 102, batch 9, d_loss=0.364 g_loss=0.559 KID= 0.12366\n",
      "epoch 102, batch 10, d_loss=0.627 g_loss=0.519 KID= 0.12366\n",
      "epoch 102, batch 11, d_loss=0.264 g_loss=0.548 KID= 0.12366\n",
      "epoch 102, batch 12, d_loss=0.214 g_loss=0.502 KID= 0.12366\n",
      "epoch 102, batch 13, d_loss=0.232 g_loss=0.410 KID= 0.12366\n",
      "epoch 102, batch 14, d_loss=0.184 g_loss=0.306 KID= 0.12366\n",
      "epoch 102, batch 15, d_loss=0.146 g_loss=0.258 KID= 0.12366\n",
      "epoch 102, batch 16, d_loss=0.107 g_loss=0.169 KID= 0.12366\n",
      "epoch 102, batch 17, d_loss=0.146 g_loss=0.167 KID= 0.12366\n",
      "epoch 102, batch 18, d_loss=0.146 g_loss=0.214 KID= 0.12366\n",
      "epoch 102, batch 19, d_loss=0.104 g_loss=0.258 KID= 0.12366\n",
      "epoch 103, batch 0, d_loss=-0.068 g_loss=0.110 KID= 0.12366\n",
      "epoch 103, batch 1, d_loss=0.419 g_loss=0.275 KID= 0.12366\n",
      "epoch 103, batch 2, d_loss=0.484 g_loss=0.667 KID= 0.12366\n",
      "epoch 103, batch 3, d_loss=0.263 g_loss=1.021 KID= 0.12366\n",
      "epoch 103, batch 4, d_loss=0.155 g_loss=1.282 KID= 0.12366\n",
      "epoch 103, batch 5, d_loss=0.098 g_loss=1.454 KID= 0.12366\n",
      "epoch 103, batch 6, d_loss=0.159 g_loss=1.565 KID= 0.12366\n",
      "epoch 103, batch 7, d_loss=0.107 g_loss=1.691 KID= 0.12366\n",
      "epoch 103, batch 8, d_loss=0.050 g_loss=1.799 KID= 0.12366\n",
      "epoch 103, batch 9, d_loss=0.182 g_loss=1.778 KID= 0.12366\n",
      "epoch 103, batch 10, d_loss=0.379 g_loss=1.725 KID= 0.12366\n",
      "epoch 103, batch 11, d_loss=0.234 g_loss=1.797 KID= 0.12366\n",
      "epoch 103, batch 12, d_loss=0.321 g_loss=1.665 KID= 0.12366\n",
      "epoch 103, batch 13, d_loss=0.328 g_loss=1.553 KID= 0.12366\n",
      "epoch 103, batch 14, d_loss=0.229 g_loss=1.421 KID= 0.12366\n",
      "epoch 103, batch 15, d_loss=0.205 g_loss=1.269 KID= 0.12366\n",
      "epoch 103, batch 16, d_loss=0.203 g_loss=1.182 KID= 0.12366\n",
      "epoch 103, batch 17, d_loss=0.284 g_loss=1.112 KID= 0.12366\n",
      "epoch 103, batch 18, d_loss=0.287 g_loss=1.071 KID= 0.12366\n",
      "epoch 103, batch 19, d_loss=0.259 g_loss=1.024 KID= 0.12366\n",
      "epoch 104, batch 0, d_loss=0.107 g_loss=1.197 KID= 0.12366\n",
      "epoch 104, batch 1, d_loss=0.251 g_loss=1.301 KID= 0.12366\n",
      "epoch 104, batch 2, d_loss=0.297 g_loss=1.241 KID= 0.12366\n",
      "epoch 104, batch 3, d_loss=0.160 g_loss=1.276 KID= 0.12366\n",
      "epoch 104, batch 4, d_loss=0.281 g_loss=1.132 KID= 0.12366\n",
      "epoch 104, batch 5, d_loss=0.250 g_loss=1.057 KID= 0.12366\n",
      "epoch 104, batch 6, d_loss=0.175 g_loss=1.032 KID= 0.12366\n",
      "epoch 104, batch 7, d_loss=0.112 g_loss=1.033 KID= 0.12366\n",
      "epoch 104, batch 8, d_loss=0.024 g_loss=1.036 KID= 0.12366\n",
      "epoch 104, batch 9, d_loss=0.068 g_loss=1.030 KID= 0.12366\n",
      "epoch 104, batch 10, d_loss=0.226 g_loss=1.097 KID= 0.12366\n",
      "epoch 104, batch 11, d_loss=0.124 g_loss=1.241 KID= 0.12366\n",
      "epoch 104, batch 12, d_loss=0.181 g_loss=1.443 KID= 0.12366\n",
      "epoch 104, batch 13, d_loss=0.127 g_loss=1.635 KID= 0.12366\n",
      "epoch 104, batch 14, d_loss=0.129 g_loss=1.553 KID= 0.12366\n",
      "epoch 104, batch 15, d_loss=0.169 g_loss=1.374 KID= 0.12366\n",
      "epoch 104, batch 16, d_loss=0.247 g_loss=1.207 KID= 0.12366\n",
      "epoch 104, batch 17, d_loss=0.223 g_loss=1.074 KID= 0.12366\n",
      "epoch 104, batch 18, d_loss=0.212 g_loss=0.914 KID= 0.12366\n",
      "epoch 104, batch 19, d_loss=0.218 g_loss=0.875 KID= 0.12366\n",
      "epoch 105, batch 0, d_loss=0.137 g_loss=1.087 KID= 0.12366\n",
      "epoch 105, batch 1, d_loss=0.236 g_loss=1.299 KID= 0.12366\n",
      "epoch 105, batch 2, d_loss=0.418 g_loss=1.437 KID= 0.12366\n",
      "epoch 105, batch 3, d_loss=0.197 g_loss=1.910 KID= 0.12366\n",
      "epoch 105, batch 4, d_loss=0.155 g_loss=2.212 KID= 0.12366\n",
      "epoch 105, batch 5, d_loss=0.100 g_loss=2.218 KID= 0.12366\n",
      "epoch 105, batch 6, d_loss=0.149 g_loss=2.182 KID= 0.12366\n",
      "epoch 105, batch 7, d_loss=0.181 g_loss=1.934 KID= 0.12366\n",
      "epoch 105, batch 8, d_loss=0.109 g_loss=1.516 KID= 0.12366\n",
      "epoch 105, batch 9, d_loss=0.283 g_loss=1.201 KID= 0.12366\n",
      "epoch 105, batch 10, d_loss=0.479 g_loss=0.705 KID= 0.12366\n",
      "epoch 105, batch 11, d_loss=0.261 g_loss=0.314 KID= 0.12366\n",
      "epoch 105, batch 12, d_loss=0.223 g_loss=0.045 KID= 0.12366\n",
      "epoch 105, batch 13, d_loss=0.341 g_loss=-0.155 KID= 0.12366\n",
      "epoch 105, batch 14, d_loss=0.366 g_loss=-0.270 KID= 0.12366\n",
      "epoch 105, batch 15, d_loss=0.404 g_loss=-0.097 KID= 0.12366\n",
      "epoch 105, batch 16, d_loss=0.523 g_loss=0.134 KID= 0.12366\n",
      "epoch 105, batch 17, d_loss=0.507 g_loss=0.671 KID= 0.12366\n",
      "epoch 105, batch 18, d_loss=0.513 g_loss=1.326 KID= 0.12366\n",
      "epoch 105, batch 19, d_loss=0.332 g_loss=2.218 KID= 0.12366\n",
      "epoch 106, batch 0, d_loss=0.072 g_loss=3.297 KID= 0.12366\n",
      "epoch 106, batch 1, d_loss=-0.036 g_loss=4.130 KID= 0.12366\n",
      "epoch 106, batch 2, d_loss=0.021 g_loss=4.087 KID= 0.12366\n",
      "epoch 106, batch 3, d_loss=-0.111 g_loss=3.823 KID= 0.12366\n",
      "epoch 106, batch 4, d_loss=0.208 g_loss=2.968 KID= 0.12366\n",
      "epoch 106, batch 5, d_loss=0.295 g_loss=2.235 KID= 0.12366\n",
      "epoch 106, batch 6, d_loss=0.046 g_loss=1.710 KID= 0.12366\n",
      "epoch 106, batch 7, d_loss=0.063 g_loss=1.251 KID= 0.12366\n",
      "epoch 106, batch 8, d_loss=0.140 g_loss=0.830 KID= 0.12366\n",
      "epoch 106, batch 9, d_loss=0.008 g_loss=0.457 KID= 0.12366\n",
      "epoch 106, batch 10, d_loss=0.202 g_loss=0.321 KID= 0.12366\n",
      "epoch 106, batch 11, d_loss=0.233 g_loss=0.343 KID= 0.12366\n",
      "epoch 106, batch 12, d_loss=0.095 g_loss=0.439 KID= 0.12366\n",
      "epoch 106, batch 13, d_loss=0.176 g_loss=0.656 KID= 0.12366\n",
      "epoch 106, batch 14, d_loss=0.167 g_loss=0.754 KID= 0.12366\n",
      "epoch 106, batch 15, d_loss=0.076 g_loss=0.730 KID= 0.12366\n",
      "epoch 106, batch 16, d_loss=0.339 g_loss=0.704 KID= 0.12366\n",
      "epoch 106, batch 17, d_loss=0.392 g_loss=0.769 KID= 0.12366\n",
      "epoch 106, batch 18, d_loss=0.255 g_loss=0.883 KID= 0.12366\n",
      "epoch 106, batch 19, d_loss=0.299 g_loss=1.004 KID= 0.12366\n",
      "epoch 107, batch 0, d_loss=0.198 g_loss=1.302 KID= 0.12366\n",
      "epoch 107, batch 1, d_loss=0.014 g_loss=1.696 KID= 0.12366\n",
      "epoch 107, batch 2, d_loss=0.034 g_loss=1.943 KID= 0.12366\n",
      "epoch 107, batch 3, d_loss=-0.015 g_loss=2.303 KID= 0.12366\n",
      "epoch 107, batch 4, d_loss=0.010 g_loss=2.403 KID= 0.12366\n",
      "epoch 107, batch 5, d_loss=0.316 g_loss=2.225 KID= 0.12366\n",
      "epoch 107, batch 6, d_loss=0.428 g_loss=2.034 KID= 0.12366\n",
      "epoch 107, batch 7, d_loss=0.372 g_loss=1.761 KID= 0.12366\n",
      "epoch 107, batch 8, d_loss=0.422 g_loss=1.468 KID= 0.12366\n",
      "epoch 107, batch 9, d_loss=0.062 g_loss=1.333 KID= 0.12366\n",
      "epoch 107, batch 10, d_loss=0.008 g_loss=1.308 KID= 0.12366\n",
      "epoch 107, batch 11, d_loss=0.043 g_loss=1.287 KID= 0.12366\n",
      "epoch 107, batch 12, d_loss=0.025 g_loss=1.284 KID= 0.12366\n",
      "epoch 107, batch 13, d_loss=-0.003 g_loss=1.238 KID= 0.12366\n",
      "epoch 107, batch 14, d_loss=0.088 g_loss=1.035 KID= 0.12366\n",
      "epoch 107, batch 15, d_loss=0.040 g_loss=0.834 KID= 0.12366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107, batch 16, d_loss=0.163 g_loss=0.582 KID= 0.12366\n",
      "epoch 107, batch 17, d_loss=0.199 g_loss=0.333 KID= 0.12366\n",
      "epoch 107, batch 18, d_loss=0.089 g_loss=0.117 KID= 0.12366\n",
      "epoch 107, batch 19, d_loss=0.205 g_loss=-0.133 KID= 0.12366\n",
      "epoch 108, batch 0, d_loss=0.369 g_loss=-0.307 KID= 0.12366\n",
      "epoch 108, batch 1, d_loss=0.357 g_loss=-0.338 KID= 0.12366\n",
      "epoch 108, batch 2, d_loss=0.387 g_loss=-0.070 KID= 0.12366\n",
      "epoch 108, batch 3, d_loss=0.422 g_loss=0.488 KID= 0.12366\n",
      "epoch 108, batch 4, d_loss=0.221 g_loss=1.164 KID= 0.12366\n",
      "epoch 108, batch 5, d_loss=0.125 g_loss=1.809 KID= 0.12366\n",
      "epoch 108, batch 6, d_loss=0.053 g_loss=2.376 KID= 0.12366\n",
      "epoch 108, batch 7, d_loss=-0.001 g_loss=2.857 KID= 0.12366\n",
      "epoch 108, batch 8, d_loss=0.114 g_loss=2.798 KID= 0.12366\n",
      "epoch 108, batch 9, d_loss=0.140 g_loss=2.643 KID= 0.12366\n",
      "epoch 108, batch 10, d_loss=-0.028 g_loss=2.526 KID= 0.12366\n",
      "epoch 108, batch 11, d_loss=0.098 g_loss=2.145 KID= 0.12366\n",
      "epoch 108, batch 12, d_loss=0.274 g_loss=1.740 KID= 0.12366\n",
      "epoch 108, batch 13, d_loss=0.142 g_loss=1.318 KID= 0.12366\n",
      "epoch 108, batch 14, d_loss=0.164 g_loss=0.939 KID= 0.12366\n",
      "epoch 108, batch 15, d_loss=0.248 g_loss=0.607 KID= 0.12366\n",
      "epoch 108, batch 16, d_loss=0.227 g_loss=0.571 KID= 0.12366\n",
      "epoch 108, batch 17, d_loss=0.205 g_loss=0.710 KID= 0.12366\n",
      "epoch 108, batch 18, d_loss=0.141 g_loss=0.935 KID= 0.12366\n",
      "epoch 108, batch 19, d_loss=0.141 g_loss=1.110 KID= 0.12366\n",
      "epoch 109, batch 0, d_loss=0.331 g_loss=1.141 KID= 0.12366\n",
      "epoch 109, batch 1, d_loss=0.295 g_loss=1.098 KID= 0.12366\n",
      "epoch 109, batch 2, d_loss=0.118 g_loss=1.123 KID= 0.12366\n",
      "epoch 109, batch 3, d_loss=0.205 g_loss=1.024 KID= 0.12366\n",
      "epoch 109, batch 4, d_loss=0.146 g_loss=0.911 KID= 0.12366\n",
      "epoch 109, batch 5, d_loss=0.042 g_loss=0.722 KID= 0.12366\n",
      "epoch 109, batch 6, d_loss=0.058 g_loss=0.515 KID= 0.12366\n",
      "epoch 109, batch 7, d_loss=0.083 g_loss=0.298 KID= 0.12366\n",
      "epoch 109, batch 8, d_loss=0.150 g_loss=0.214 KID= 0.12366\n",
      "epoch 109, batch 9, d_loss=0.118 g_loss=0.104 KID= 0.12366\n",
      "epoch 109, batch 10, d_loss=0.058 g_loss=-0.080 KID= 0.12366\n",
      "epoch 109, batch 11, d_loss=0.215 g_loss=-0.170 KID= 0.12366\n",
      "epoch 109, batch 12, d_loss=0.301 g_loss=-0.114 KID= 0.12366\n",
      "epoch 109, batch 13, d_loss=0.135 g_loss=-0.028 KID= 0.12366\n",
      "epoch 109, batch 14, d_loss=0.186 g_loss=0.086 KID= 0.12366\n",
      "epoch 109, batch 15, d_loss=0.130 g_loss=0.189 KID= 0.12366\n",
      "epoch 109, batch 16, d_loss=0.128 g_loss=0.296 KID= 0.12366\n",
      "epoch 109, batch 17, d_loss=0.095 g_loss=0.415 KID= 0.12366\n",
      "epoch 109, batch 18, d_loss=0.081 g_loss=0.525 KID= 0.12366\n",
      "epoch 109, batch 19, d_loss=0.076 g_loss=0.640 KID= 0.12366\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 110, batch 0, d_loss=0.126 g_loss=0.724 KID= 0.13157\n",
      "epoch 110, batch 1, d_loss=0.164 g_loss=0.950 KID= 0.13157\n",
      "epoch 110, batch 2, d_loss=0.248 g_loss=1.181 KID= 0.13157\n",
      "epoch 110, batch 3, d_loss=0.229 g_loss=1.417 KID= 0.13157\n",
      "epoch 110, batch 4, d_loss=0.085 g_loss=1.639 KID= 0.13157\n",
      "epoch 110, batch 5, d_loss=0.063 g_loss=1.655 KID= 0.13157\n",
      "epoch 110, batch 6, d_loss=0.116 g_loss=1.659 KID= 0.13157\n",
      "epoch 110, batch 7, d_loss=0.072 g_loss=1.691 KID= 0.13157\n",
      "epoch 110, batch 8, d_loss=0.233 g_loss=1.628 KID= 0.13157\n",
      "epoch 110, batch 9, d_loss=0.178 g_loss=1.558 KID= 0.13157\n",
      "epoch 110, batch 10, d_loss=0.125 g_loss=1.470 KID= 0.13157\n",
      "epoch 110, batch 11, d_loss=0.154 g_loss=1.351 KID= 0.13157\n",
      "epoch 110, batch 12, d_loss=0.272 g_loss=1.319 KID= 0.13157\n",
      "epoch 110, batch 13, d_loss=0.243 g_loss=1.389 KID= 0.13157\n",
      "epoch 110, batch 14, d_loss=0.250 g_loss=1.442 KID= 0.13157\n",
      "epoch 110, batch 15, d_loss=0.122 g_loss=1.711 KID= 0.13157\n",
      "epoch 110, batch 16, d_loss=0.094 g_loss=1.839 KID= 0.13157\n",
      "epoch 110, batch 17, d_loss=0.131 g_loss=1.879 KID= 0.13157\n",
      "epoch 110, batch 18, d_loss=0.008 g_loss=1.932 KID= 0.13157\n",
      "epoch 110, batch 19, d_loss=0.087 g_loss=1.834 KID= 0.13157\n",
      "epoch 111, batch 0, d_loss=0.310 g_loss=1.532 KID= 0.13157\n",
      "epoch 111, batch 1, d_loss=0.372 g_loss=1.129 KID= 0.13157\n",
      "epoch 111, batch 2, d_loss=0.241 g_loss=0.796 KID= 0.13157\n",
      "epoch 111, batch 3, d_loss=0.286 g_loss=0.503 KID= 0.13157\n",
      "epoch 111, batch 4, d_loss=0.261 g_loss=0.270 KID= 0.13157\n",
      "epoch 111, batch 5, d_loss=0.203 g_loss=0.067 KID= 0.13157\n",
      "epoch 111, batch 6, d_loss=0.207 g_loss=-0.090 KID= 0.13157\n",
      "epoch 111, batch 7, d_loss=0.151 g_loss=-0.194 KID= 0.13157\n",
      "epoch 111, batch 8, d_loss=0.166 g_loss=-0.222 KID= 0.13157\n",
      "epoch 111, batch 9, d_loss=0.060 g_loss=-0.195 KID= 0.13157\n",
      "epoch 111, batch 10, d_loss=-0.018 g_loss=-0.147 KID= 0.13157\n",
      "epoch 111, batch 11, d_loss=0.024 g_loss=-0.126 KID= 0.13157\n",
      "epoch 111, batch 12, d_loss=0.177 g_loss=0.022 KID= 0.13157\n",
      "epoch 111, batch 13, d_loss=0.124 g_loss=0.205 KID= 0.13157\n",
      "epoch 111, batch 14, d_loss=0.259 g_loss=0.290 KID= 0.13157\n",
      "epoch 111, batch 15, d_loss=0.242 g_loss=0.382 KID= 0.13157\n",
      "epoch 111, batch 16, d_loss=0.189 g_loss=0.396 KID= 0.13157\n",
      "epoch 111, batch 17, d_loss=0.150 g_loss=0.385 KID= 0.13157\n",
      "epoch 111, batch 18, d_loss=0.093 g_loss=0.489 KID= 0.13157\n",
      "epoch 111, batch 19, d_loss=0.081 g_loss=0.668 KID= 0.13157\n",
      "epoch 112, batch 0, d_loss=0.122 g_loss=0.834 KID= 0.13157\n",
      "epoch 112, batch 1, d_loss=0.067 g_loss=0.994 KID= 0.13157\n",
      "epoch 112, batch 2, d_loss=0.480 g_loss=1.186 KID= 0.13157\n",
      "epoch 112, batch 3, d_loss=0.454 g_loss=1.362 KID= 0.13157\n",
      "epoch 112, batch 4, d_loss=0.236 g_loss=1.561 KID= 0.13157\n",
      "epoch 112, batch 5, d_loss=0.184 g_loss=1.550 KID= 0.13157\n",
      "epoch 112, batch 6, d_loss=0.191 g_loss=1.543 KID= 0.13157\n",
      "epoch 112, batch 7, d_loss=0.117 g_loss=1.474 KID= 0.13157\n",
      "epoch 112, batch 8, d_loss=0.083 g_loss=1.232 KID= 0.13157\n",
      "epoch 112, batch 9, d_loss=-0.011 g_loss=1.073 KID= 0.13157\n",
      "epoch 112, batch 10, d_loss=-0.015 g_loss=0.947 KID= 0.13157\n",
      "epoch 112, batch 11, d_loss=0.115 g_loss=0.875 KID= 0.13157\n",
      "epoch 112, batch 12, d_loss=0.029 g_loss=0.745 KID= 0.13157\n",
      "epoch 112, batch 13, d_loss=0.169 g_loss=0.635 KID= 0.13157\n",
      "epoch 112, batch 14, d_loss=0.373 g_loss=0.592 KID= 0.13157\n",
      "epoch 112, batch 15, d_loss=0.501 g_loss=0.545 KID= 0.13157\n",
      "epoch 112, batch 16, d_loss=0.332 g_loss=0.565 KID= 0.13157\n",
      "epoch 112, batch 17, d_loss=0.256 g_loss=0.680 KID= 0.13157\n",
      "epoch 112, batch 18, d_loss=0.155 g_loss=0.890 KID= 0.13157\n",
      "epoch 112, batch 19, d_loss=0.071 g_loss=1.154 KID= 0.13157\n",
      "epoch 113, batch 0, d_loss=0.085 g_loss=1.438 KID= 0.13157\n",
      "epoch 113, batch 1, d_loss=0.040 g_loss=1.764 KID= 0.13157\n",
      "epoch 113, batch 2, d_loss=0.272 g_loss=1.711 KID= 0.13157\n",
      "epoch 113, batch 3, d_loss=0.219 g_loss=1.755 KID= 0.13157\n",
      "epoch 113, batch 4, d_loss=0.098 g_loss=1.804 KID= 0.13157\n",
      "epoch 113, batch 5, d_loss=0.116 g_loss=1.608 KID= 0.13157\n",
      "epoch 113, batch 6, d_loss=0.045 g_loss=1.529 KID= 0.13157\n",
      "epoch 113, batch 7, d_loss=-0.005 g_loss=1.587 KID= 0.13157\n",
      "epoch 113, batch 8, d_loss=-0.028 g_loss=1.571 KID= 0.13157\n",
      "epoch 113, batch 9, d_loss=-0.046 g_loss=1.515 KID= 0.13157\n",
      "epoch 113, batch 10, d_loss=0.054 g_loss=1.413 KID= 0.13157\n",
      "epoch 113, batch 11, d_loss=0.200 g_loss=1.318 KID= 0.13157\n",
      "epoch 113, batch 12, d_loss=0.227 g_loss=1.286 KID= 0.13157\n",
      "epoch 113, batch 13, d_loss=0.292 g_loss=1.315 KID= 0.13157\n",
      "epoch 113, batch 14, d_loss=0.323 g_loss=1.343 KID= 0.13157\n",
      "epoch 113, batch 15, d_loss=0.325 g_loss=1.406 KID= 0.13157\n",
      "epoch 113, batch 16, d_loss=0.262 g_loss=1.536 KID= 0.13157\n",
      "epoch 113, batch 17, d_loss=0.104 g_loss=1.824 KID= 0.13157\n",
      "epoch 113, batch 18, d_loss=0.105 g_loss=2.064 KID= 0.13157\n",
      "epoch 113, batch 19, d_loss=0.051 g_loss=2.309 KID= 0.13157\n",
      "epoch 114, batch 0, d_loss=0.024 g_loss=2.455 KID= 0.13157\n",
      "epoch 114, batch 1, d_loss=0.084 g_loss=2.502 KID= 0.13157\n",
      "epoch 114, batch 2, d_loss=0.412 g_loss=1.923 KID= 0.13157\n",
      "epoch 114, batch 3, d_loss=0.277 g_loss=1.450 KID= 0.13157\n",
      "epoch 114, batch 4, d_loss=0.221 g_loss=1.021 KID= 0.13157\n",
      "epoch 114, batch 5, d_loss=0.127 g_loss=0.702 KID= 0.13157\n",
      "epoch 114, batch 6, d_loss=0.076 g_loss=0.456 KID= 0.13157\n",
      "epoch 114, batch 7, d_loss=0.115 g_loss=0.224 KID= 0.13157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 114, batch 8, d_loss=0.110 g_loss=0.063 KID= 0.13157\n",
      "epoch 114, batch 9, d_loss=0.060 g_loss=-0.035 KID= 0.13157\n",
      "epoch 114, batch 10, d_loss=0.181 g_loss=-0.118 KID= 0.13157\n",
      "epoch 114, batch 11, d_loss=0.221 g_loss=-0.155 KID= 0.13157\n",
      "epoch 114, batch 12, d_loss=0.152 g_loss=0.005 KID= 0.13157\n",
      "epoch 114, batch 13, d_loss=0.163 g_loss=0.210 KID= 0.13157\n",
      "epoch 114, batch 14, d_loss=0.092 g_loss=0.366 KID= 0.13157\n",
      "epoch 114, batch 15, d_loss=0.100 g_loss=0.302 KID= 0.13157\n",
      "epoch 114, batch 16, d_loss=0.153 g_loss=0.233 KID= 0.13157\n",
      "epoch 114, batch 17, d_loss=0.164 g_loss=0.248 KID= 0.13157\n",
      "epoch 114, batch 18, d_loss=0.181 g_loss=0.245 KID= 0.13157\n",
      "epoch 114, batch 19, d_loss=0.197 g_loss=0.262 KID= 0.13157\n",
      "epoch 115, batch 0, d_loss=0.177 g_loss=0.315 KID= 0.13157\n",
      "epoch 115, batch 1, d_loss=0.084 g_loss=0.398 KID= 0.13157\n",
      "epoch 115, batch 2, d_loss=0.179 g_loss=0.683 KID= 0.13157\n",
      "epoch 115, batch 3, d_loss=0.100 g_loss=0.963 KID= 0.13157\n",
      "epoch 115, batch 4, d_loss=0.052 g_loss=1.075 KID= 0.13157\n",
      "epoch 115, batch 5, d_loss=0.014 g_loss=1.126 KID= 0.13157\n",
      "epoch 115, batch 6, d_loss=0.141 g_loss=1.056 KID= 0.13157\n",
      "epoch 115, batch 7, d_loss=0.122 g_loss=0.970 KID= 0.13157\n",
      "epoch 115, batch 8, d_loss=0.186 g_loss=0.778 KID= 0.13157\n",
      "epoch 115, batch 9, d_loss=0.222 g_loss=0.657 KID= 0.13157\n",
      "epoch 115, batch 10, d_loss=0.216 g_loss=0.545 KID= 0.13157\n",
      "epoch 115, batch 11, d_loss=0.209 g_loss=0.461 KID= 0.13157\n",
      "epoch 115, batch 12, d_loss=0.134 g_loss=0.483 KID= 0.13157\n",
      "epoch 115, batch 13, d_loss=0.121 g_loss=0.560 KID= 0.13157\n",
      "epoch 115, batch 14, d_loss=0.071 g_loss=0.649 KID= 0.13157\n",
      "epoch 115, batch 15, d_loss=0.150 g_loss=0.744 KID= 0.13157\n",
      "epoch 115, batch 16, d_loss=0.061 g_loss=0.858 KID= 0.13157\n",
      "epoch 115, batch 17, d_loss=0.119 g_loss=1.012 KID= 0.13157\n",
      "epoch 115, batch 18, d_loss=0.077 g_loss=1.082 KID= 0.13157\n",
      "epoch 115, batch 19, d_loss=0.091 g_loss=1.123 KID= 0.13157\n",
      "epoch 116, batch 0, d_loss=0.122 g_loss=1.120 KID= 0.13157\n",
      "epoch 116, batch 1, d_loss=0.148 g_loss=1.198 KID= 0.13157\n",
      "epoch 116, batch 2, d_loss=0.126 g_loss=1.164 KID= 0.13157\n",
      "epoch 116, batch 3, d_loss=0.181 g_loss=1.073 KID= 0.13157\n",
      "epoch 116, batch 4, d_loss=0.220 g_loss=0.990 KID= 0.13157\n",
      "epoch 116, batch 5, d_loss=0.087 g_loss=0.837 KID= 0.13157\n",
      "epoch 116, batch 6, d_loss=0.186 g_loss=0.740 KID= 0.13157\n",
      "epoch 116, batch 7, d_loss=0.196 g_loss=0.715 KID= 0.13157\n",
      "epoch 116, batch 8, d_loss=0.140 g_loss=0.749 KID= 0.13157\n",
      "epoch 116, batch 9, d_loss=0.119 g_loss=0.793 KID= 0.13157\n",
      "epoch 116, batch 10, d_loss=0.139 g_loss=0.797 KID= 0.13157\n",
      "epoch 116, batch 11, d_loss=0.223 g_loss=0.663 KID= 0.13157\n",
      "epoch 116, batch 12, d_loss=0.365 g_loss=0.577 KID= 0.13157\n",
      "epoch 116, batch 13, d_loss=0.279 g_loss=0.679 KID= 0.13157\n",
      "epoch 116, batch 14, d_loss=0.165 g_loss=0.873 KID= 0.13157\n",
      "epoch 116, batch 15, d_loss=0.205 g_loss=1.068 KID= 0.13157\n",
      "epoch 116, batch 16, d_loss=0.131 g_loss=1.055 KID= 0.13157\n",
      "epoch 116, batch 17, d_loss=0.133 g_loss=0.998 KID= 0.13157\n",
      "epoch 116, batch 18, d_loss=0.096 g_loss=0.879 KID= 0.13157\n",
      "epoch 116, batch 19, d_loss=0.096 g_loss=0.678 KID= 0.13157\n",
      "epoch 117, batch 0, d_loss=0.092 g_loss=0.454 KID= 0.13157\n",
      "epoch 117, batch 1, d_loss=0.002 g_loss=0.217 KID= 0.13157\n",
      "epoch 117, batch 2, d_loss=-0.016 g_loss=0.101 KID= 0.13157\n",
      "epoch 117, batch 3, d_loss=0.115 g_loss=0.031 KID= 0.13157\n",
      "epoch 117, batch 4, d_loss=0.200 g_loss=-0.050 KID= 0.13157\n",
      "epoch 117, batch 5, d_loss=0.162 g_loss=0.016 KID= 0.13157\n",
      "epoch 117, batch 6, d_loss=0.176 g_loss=0.110 KID= 0.13157\n",
      "epoch 117, batch 7, d_loss=0.122 g_loss=0.222 KID= 0.13157\n",
      "epoch 117, batch 8, d_loss=0.119 g_loss=0.328 KID= 0.13157\n",
      "epoch 117, batch 9, d_loss=0.064 g_loss=0.406 KID= 0.13157\n",
      "epoch 117, batch 10, d_loss=0.044 g_loss=0.410 KID= 0.13157\n",
      "epoch 117, batch 11, d_loss=0.123 g_loss=0.385 KID= 0.13157\n",
      "epoch 117, batch 12, d_loss=0.461 g_loss=0.470 KID= 0.13157\n",
      "epoch 117, batch 13, d_loss=0.348 g_loss=0.564 KID= 0.13157\n",
      "epoch 117, batch 14, d_loss=0.245 g_loss=0.693 KID= 0.13157\n",
      "epoch 117, batch 15, d_loss=0.197 g_loss=0.728 KID= 0.13157\n",
      "epoch 117, batch 16, d_loss=0.104 g_loss=0.660 KID= 0.13157\n",
      "epoch 117, batch 17, d_loss=0.103 g_loss=0.577 KID= 0.13157\n",
      "epoch 117, batch 18, d_loss=0.054 g_loss=0.404 KID= 0.13157\n",
      "epoch 117, batch 19, d_loss=0.033 g_loss=0.282 KID= 0.13157\n",
      "epoch 118, batch 0, d_loss=0.092 g_loss=0.289 KID= 0.13157\n",
      "epoch 118, batch 1, d_loss=0.178 g_loss=0.322 KID= 0.13157\n",
      "epoch 118, batch 2, d_loss=0.107 g_loss=0.589 KID= 0.13157\n",
      "epoch 118, batch 3, d_loss=0.242 g_loss=1.045 KID= 0.13157\n",
      "epoch 118, batch 4, d_loss=0.342 g_loss=1.405 KID= 0.13157\n",
      "epoch 118, batch 5, d_loss=0.156 g_loss=1.849 KID= 0.13157\n",
      "epoch 118, batch 6, d_loss=0.222 g_loss=2.041 KID= 0.13157\n",
      "epoch 118, batch 7, d_loss=0.156 g_loss=2.323 KID= 0.13157\n",
      "epoch 118, batch 8, d_loss=0.064 g_loss=2.364 KID= 0.13157\n",
      "epoch 118, batch 9, d_loss=0.071 g_loss=2.214 KID= 0.13157\n",
      "epoch 118, batch 10, d_loss=0.096 g_loss=2.129 KID= 0.13157\n",
      "epoch 118, batch 11, d_loss=0.059 g_loss=1.871 KID= 0.13157\n",
      "epoch 118, batch 12, d_loss=0.319 g_loss=1.616 KID= 0.13157\n",
      "epoch 118, batch 13, d_loss=0.192 g_loss=1.497 KID= 0.13157\n",
      "epoch 118, batch 14, d_loss=0.112 g_loss=1.494 KID= 0.13157\n",
      "epoch 118, batch 15, d_loss=0.248 g_loss=1.380 KID= 0.13157\n",
      "epoch 118, batch 16, d_loss=0.161 g_loss=1.219 KID= 0.13157\n",
      "epoch 118, batch 17, d_loss=0.093 g_loss=1.111 KID= 0.13157\n",
      "epoch 118, batch 18, d_loss=0.169 g_loss=0.898 KID= 0.13157\n",
      "epoch 118, batch 19, d_loss=0.165 g_loss=0.703 KID= 0.13157\n",
      "epoch 119, batch 0, d_loss=0.191 g_loss=0.540 KID= 0.13157\n",
      "epoch 119, batch 1, d_loss=0.134 g_loss=0.388 KID= 0.13157\n",
      "epoch 119, batch 2, d_loss=0.072 g_loss=0.350 KID= 0.13157\n",
      "epoch 119, batch 3, d_loss=0.225 g_loss=0.338 KID= 0.13157\n",
      "epoch 119, batch 4, d_loss=0.300 g_loss=0.354 KID= 0.13157\n",
      "epoch 119, batch 5, d_loss=0.197 g_loss=0.449 KID= 0.13157\n",
      "epoch 119, batch 6, d_loss=0.220 g_loss=0.540 KID= 0.13157\n",
      "epoch 119, batch 7, d_loss=0.182 g_loss=0.671 KID= 0.13157\n",
      "epoch 119, batch 8, d_loss=0.035 g_loss=0.786 KID= 0.13157\n",
      "epoch 119, batch 9, d_loss=0.043 g_loss=0.772 KID= 0.13157\n",
      "epoch 119, batch 10, d_loss=0.051 g_loss=0.750 KID= 0.13157\n",
      "epoch 119, batch 11, d_loss=0.242 g_loss=0.705 KID= 0.13157\n",
      "epoch 119, batch 12, d_loss=0.306 g_loss=0.576 KID= 0.13157\n",
      "epoch 119, batch 13, d_loss=0.159 g_loss=0.523 KID= 0.13157\n",
      "epoch 119, batch 14, d_loss=0.091 g_loss=0.423 KID= 0.13157\n",
      "epoch 119, batch 15, d_loss=0.137 g_loss=0.322 KID= 0.13157\n",
      "epoch 119, batch 16, d_loss=0.144 g_loss=0.287 KID= 0.13157\n",
      "epoch 119, batch 17, d_loss=0.050 g_loss=0.296 KID= 0.13157\n",
      "epoch 119, batch 18, d_loss=0.026 g_loss=0.295 KID= 0.13157\n",
      "epoch 119, batch 19, d_loss=-0.013 g_loss=0.297 KID= 0.13157\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 120, batch 0, d_loss=0.149 g_loss=0.468 KID= 0.08489\n",
      "epoch 120, batch 1, d_loss=0.161 g_loss=0.544 KID= 0.08489\n",
      "epoch 120, batch 2, d_loss=0.136 g_loss=0.731 KID= 0.08489\n",
      "epoch 120, batch 3, d_loss=0.150 g_loss=0.905 KID= 0.08489\n",
      "epoch 120, batch 4, d_loss=0.203 g_loss=1.024 KID= 0.08489\n",
      "epoch 120, batch 5, d_loss=0.092 g_loss=1.152 KID= 0.08489\n",
      "epoch 120, batch 6, d_loss=0.061 g_loss=1.252 KID= 0.08489\n",
      "epoch 120, batch 7, d_loss=0.082 g_loss=1.459 KID= 0.08489\n",
      "epoch 120, batch 8, d_loss=-0.025 g_loss=1.602 KID= 0.08489\n",
      "epoch 120, batch 9, d_loss=0.096 g_loss=1.556 KID= 0.08489\n",
      "epoch 120, batch 10, d_loss=0.010 g_loss=1.602 KID= 0.08489\n",
      "epoch 120, batch 11, d_loss=0.187 g_loss=1.506 KID= 0.08489\n",
      "epoch 120, batch 12, d_loss=0.233 g_loss=1.366 KID= 0.08489\n",
      "epoch 120, batch 13, d_loss=0.233 g_loss=1.285 KID= 0.08489\n",
      "epoch 120, batch 14, d_loss=0.161 g_loss=1.237 KID= 0.08489\n",
      "epoch 120, batch 15, d_loss=0.246 g_loss=1.183 KID= 0.08489\n",
      "epoch 120, batch 16, d_loss=0.190 g_loss=1.141 KID= 0.08489\n",
      "epoch 120, batch 17, d_loss=0.141 g_loss=1.116 KID= 0.08489\n",
      "epoch 120, batch 18, d_loss=0.169 g_loss=0.972 KID= 0.08489\n",
      "epoch 120, batch 19, d_loss=0.140 g_loss=0.905 KID= 0.08489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 121, batch 0, d_loss=0.192 g_loss=0.832 KID= 0.08489\n",
      "epoch 121, batch 1, d_loss=0.164 g_loss=0.754 KID= 0.08489\n",
      "epoch 121, batch 2, d_loss=0.082 g_loss=0.806 KID= 0.08489\n",
      "epoch 121, batch 3, d_loss=0.083 g_loss=0.936 KID= 0.08489\n",
      "epoch 121, batch 4, d_loss=0.082 g_loss=1.046 KID= 0.08489\n",
      "epoch 121, batch 5, d_loss=0.042 g_loss=1.128 KID= 0.08489\n",
      "epoch 121, batch 6, d_loss=0.009 g_loss=1.165 KID= 0.08489\n",
      "epoch 121, batch 7, d_loss=0.104 g_loss=1.166 KID= 0.08489\n",
      "epoch 121, batch 8, d_loss=0.124 g_loss=1.012 KID= 0.08489\n",
      "epoch 121, batch 9, d_loss=0.145 g_loss=0.918 KID= 0.08489\n",
      "epoch 121, batch 10, d_loss=0.097 g_loss=0.812 KID= 0.08489\n",
      "epoch 121, batch 11, d_loss=0.325 g_loss=0.670 KID= 0.08489\n",
      "epoch 121, batch 12, d_loss=0.161 g_loss=0.616 KID= 0.08489\n",
      "epoch 121, batch 13, d_loss=0.140 g_loss=0.647 KID= 0.08489\n",
      "epoch 121, batch 14, d_loss=0.141 g_loss=0.643 KID= 0.08489\n",
      "epoch 121, batch 15, d_loss=0.094 g_loss=0.731 KID= 0.08489\n",
      "epoch 121, batch 16, d_loss=0.141 g_loss=0.831 KID= 0.08489\n",
      "epoch 121, batch 17, d_loss=0.147 g_loss=0.912 KID= 0.08489\n",
      "epoch 121, batch 18, d_loss=0.137 g_loss=0.917 KID= 0.08489\n",
      "epoch 121, batch 19, d_loss=0.043 g_loss=1.014 KID= 0.08489\n",
      "epoch 122, batch 0, d_loss=0.047 g_loss=1.048 KID= 0.08489\n",
      "epoch 122, batch 1, d_loss=0.089 g_loss=0.923 KID= 0.08489\n",
      "epoch 122, batch 2, d_loss=0.250 g_loss=0.945 KID= 0.08489\n",
      "epoch 122, batch 3, d_loss=0.215 g_loss=1.076 KID= 0.08489\n",
      "epoch 122, batch 4, d_loss=0.180 g_loss=1.087 KID= 0.08489\n",
      "epoch 122, batch 5, d_loss=0.239 g_loss=0.995 KID= 0.08489\n",
      "epoch 122, batch 6, d_loss=0.222 g_loss=0.834 KID= 0.08489\n",
      "epoch 122, batch 7, d_loss=0.180 g_loss=0.729 KID= 0.08489\n",
      "epoch 122, batch 8, d_loss=0.179 g_loss=0.587 KID= 0.08489\n",
      "epoch 122, batch 9, d_loss=0.150 g_loss=0.554 KID= 0.08489\n",
      "epoch 122, batch 10, d_loss=0.151 g_loss=0.523 KID= 0.08489\n",
      "epoch 122, batch 11, d_loss=0.157 g_loss=0.479 KID= 0.08489\n",
      "epoch 122, batch 12, d_loss=0.116 g_loss=0.487 KID= 0.08489\n",
      "epoch 122, batch 13, d_loss=0.093 g_loss=0.594 KID= 0.08489\n",
      "epoch 122, batch 14, d_loss=0.054 g_loss=0.719 KID= 0.08489\n",
      "epoch 122, batch 15, d_loss=0.008 g_loss=0.813 KID= 0.08489\n",
      "epoch 122, batch 16, d_loss=-0.010 g_loss=0.823 KID= 0.08489\n",
      "epoch 122, batch 17, d_loss=0.062 g_loss=0.787 KID= 0.08489\n",
      "epoch 122, batch 18, d_loss=0.139 g_loss=0.749 KID= 0.08489\n",
      "epoch 122, batch 19, d_loss=0.072 g_loss=0.727 KID= 0.08489\n",
      "epoch 123, batch 0, d_loss=0.061 g_loss=0.766 KID= 0.08489\n",
      "epoch 123, batch 1, d_loss=0.297 g_loss=0.851 KID= 0.08489\n",
      "epoch 123, batch 2, d_loss=0.229 g_loss=1.068 KID= 0.08489\n",
      "epoch 123, batch 3, d_loss=0.167 g_loss=1.298 KID= 0.08489\n",
      "epoch 123, batch 4, d_loss=0.168 g_loss=1.365 KID= 0.08489\n",
      "epoch 123, batch 5, d_loss=0.129 g_loss=1.370 KID= 0.08489\n",
      "epoch 123, batch 6, d_loss=0.286 g_loss=1.279 KID= 0.08489\n",
      "epoch 123, batch 7, d_loss=0.228 g_loss=1.208 KID= 0.08489\n",
      "epoch 123, batch 8, d_loss=0.171 g_loss=1.184 KID= 0.08489\n",
      "epoch 123, batch 9, d_loss=0.130 g_loss=1.234 KID= 0.08489\n",
      "epoch 123, batch 10, d_loss=0.090 g_loss=1.377 KID= 0.08489\n",
      "epoch 123, batch 11, d_loss=0.065 g_loss=1.591 KID= 0.08489\n",
      "epoch 123, batch 12, d_loss=0.084 g_loss=1.723 KID= 0.08489\n",
      "epoch 123, batch 13, d_loss=-0.003 g_loss=1.890 KID= 0.08489\n",
      "epoch 123, batch 14, d_loss=0.135 g_loss=1.792 KID= 0.08489\n",
      "epoch 123, batch 15, d_loss=0.194 g_loss=1.565 KID= 0.08489\n",
      "epoch 123, batch 16, d_loss=0.252 g_loss=1.216 KID= 0.08489\n",
      "epoch 123, batch 17, d_loss=0.286 g_loss=0.859 KID= 0.08489\n",
      "epoch 123, batch 18, d_loss=0.302 g_loss=0.603 KID= 0.08489\n",
      "epoch 123, batch 19, d_loss=0.153 g_loss=0.398 KID= 0.08489\n",
      "epoch 124, batch 0, d_loss=0.122 g_loss=0.214 KID= 0.08489\n",
      "epoch 124, batch 1, d_loss=0.216 g_loss=0.027 KID= 0.08489\n",
      "epoch 124, batch 2, d_loss=0.104 g_loss=-0.108 KID= 0.08489\n",
      "epoch 124, batch 3, d_loss=0.086 g_loss=-0.189 KID= 0.08489\n",
      "epoch 124, batch 4, d_loss=0.056 g_loss=-0.251 KID= 0.08489\n",
      "epoch 124, batch 5, d_loss=0.089 g_loss=-0.272 KID= 0.08489\n",
      "epoch 124, batch 6, d_loss=0.157 g_loss=-0.222 KID= 0.08489\n",
      "epoch 124, batch 7, d_loss=0.095 g_loss=-0.142 KID= 0.08489\n",
      "epoch 124, batch 8, d_loss=0.120 g_loss=-0.021 KID= 0.08489\n",
      "epoch 124, batch 9, d_loss=0.070 g_loss=0.174 KID= 0.08489\n",
      "epoch 124, batch 10, d_loss=0.152 g_loss=0.440 KID= 0.08489\n",
      "epoch 124, batch 11, d_loss=-0.020 g_loss=0.665 KID= 0.08489\n",
      "epoch 124, batch 12, d_loss=0.080 g_loss=0.940 KID= 0.08489\n",
      "epoch 124, batch 13, d_loss=0.039 g_loss=1.137 KID= 0.08489\n",
      "epoch 124, batch 14, d_loss=0.225 g_loss=1.278 KID= 0.08489\n",
      "epoch 124, batch 15, d_loss=0.173 g_loss=1.312 KID= 0.08489\n",
      "epoch 124, batch 16, d_loss=0.133 g_loss=1.335 KID= 0.08489\n",
      "epoch 124, batch 17, d_loss=0.218 g_loss=1.314 KID= 0.08489\n",
      "epoch 124, batch 18, d_loss=0.233 g_loss=1.399 KID= 0.08489\n",
      "epoch 124, batch 19, d_loss=0.062 g_loss=1.472 KID= 0.08489\n",
      "epoch 125, batch 0, d_loss=0.118 g_loss=1.399 KID= 0.08489\n",
      "epoch 125, batch 1, d_loss=0.152 g_loss=1.401 KID= 0.08489\n",
      "epoch 125, batch 2, d_loss=-0.020 g_loss=1.369 KID= 0.08489\n",
      "epoch 125, batch 3, d_loss=0.083 g_loss=1.347 KID= 0.08489\n",
      "epoch 125, batch 4, d_loss=0.009 g_loss=1.290 KID= 0.08489\n",
      "epoch 125, batch 5, d_loss=0.122 g_loss=1.289 KID= 0.08489\n",
      "epoch 125, batch 6, d_loss=0.158 g_loss=1.351 KID= 0.08489\n",
      "epoch 125, batch 7, d_loss=0.204 g_loss=1.409 KID= 0.08489\n",
      "epoch 125, batch 8, d_loss=0.078 g_loss=1.704 KID= 0.08489\n",
      "epoch 125, batch 9, d_loss=0.209 g_loss=1.907 KID= 0.08489\n",
      "epoch 125, batch 10, d_loss=0.162 g_loss=2.105 KID= 0.08489\n",
      "epoch 125, batch 11, d_loss=0.109 g_loss=2.214 KID= 0.08489\n",
      "epoch 125, batch 12, d_loss=0.231 g_loss=1.996 KID= 0.08489\n",
      "epoch 125, batch 13, d_loss=0.256 g_loss=1.748 KID= 0.08489\n",
      "epoch 125, batch 14, d_loss=0.281 g_loss=1.561 KID= 0.08489\n",
      "epoch 125, batch 15, d_loss=0.144 g_loss=1.276 KID= 0.08489\n",
      "epoch 125, batch 16, d_loss=0.092 g_loss=0.992 KID= 0.08489\n",
      "epoch 125, batch 17, d_loss=0.102 g_loss=0.728 KID= 0.08489\n",
      "epoch 125, batch 18, d_loss=0.076 g_loss=0.459 KID= 0.08489\n",
      "epoch 125, batch 19, d_loss=0.077 g_loss=0.260 KID= 0.08489\n",
      "epoch 126, batch 0, d_loss=0.140 g_loss=0.191 KID= 0.08489\n",
      "epoch 126, batch 1, d_loss=0.330 g_loss=0.269 KID= 0.08489\n",
      "epoch 126, batch 2, d_loss=0.218 g_loss=0.419 KID= 0.08489\n",
      "epoch 126, batch 3, d_loss=0.146 g_loss=0.532 KID= 0.08489\n",
      "epoch 126, batch 4, d_loss=0.062 g_loss=0.617 KID= 0.08489\n",
      "epoch 126, batch 5, d_loss=0.159 g_loss=0.622 KID= 0.08489\n",
      "epoch 126, batch 6, d_loss=0.147 g_loss=0.574 KID= 0.08489\n",
      "epoch 126, batch 7, d_loss=0.075 g_loss=0.496 KID= 0.08489\n",
      "epoch 126, batch 8, d_loss=0.112 g_loss=0.507 KID= 0.08489\n",
      "epoch 126, batch 9, d_loss=0.122 g_loss=0.474 KID= 0.08489\n",
      "epoch 126, batch 10, d_loss=0.119 g_loss=0.431 KID= 0.08489\n",
      "epoch 126, batch 11, d_loss=0.168 g_loss=0.465 KID= 0.08489\n",
      "epoch 126, batch 12, d_loss=0.155 g_loss=0.578 KID= 0.08489\n",
      "epoch 126, batch 13, d_loss=0.129 g_loss=0.690 KID= 0.08489\n",
      "epoch 126, batch 14, d_loss=0.179 g_loss=0.837 KID= 0.08489\n",
      "epoch 126, batch 15, d_loss=0.165 g_loss=0.960 KID= 0.08489\n",
      "epoch 126, batch 16, d_loss=0.157 g_loss=1.051 KID= 0.08489\n",
      "epoch 126, batch 17, d_loss=0.151 g_loss=1.177 KID= 0.08489\n",
      "epoch 126, batch 18, d_loss=0.186 g_loss=1.291 KID= 0.08489\n",
      "epoch 126, batch 19, d_loss=0.196 g_loss=1.395 KID= 0.08489\n",
      "epoch 127, batch 0, d_loss=0.231 g_loss=1.478 KID= 0.08489\n",
      "epoch 127, batch 1, d_loss=0.313 g_loss=1.459 KID= 0.08489\n",
      "epoch 127, batch 2, d_loss=0.300 g_loss=1.391 KID= 0.08489\n",
      "epoch 127, batch 3, d_loss=0.265 g_loss=1.345 KID= 0.08489\n",
      "epoch 127, batch 4, d_loss=0.162 g_loss=1.402 KID= 0.08489\n",
      "epoch 127, batch 5, d_loss=0.165 g_loss=1.432 KID= 0.08489\n",
      "epoch 127, batch 6, d_loss=0.050 g_loss=1.508 KID= 0.08489\n",
      "epoch 127, batch 7, d_loss=0.029 g_loss=1.530 KID= 0.08489\n",
      "epoch 127, batch 8, d_loss=-0.012 g_loss=1.386 KID= 0.08489\n",
      "epoch 127, batch 9, d_loss=0.100 g_loss=1.130 KID= 0.08489\n",
      "epoch 127, batch 10, d_loss=0.085 g_loss=0.957 KID= 0.08489\n",
      "epoch 127, batch 11, d_loss=0.330 g_loss=0.532 KID= 0.08489\n",
      "epoch 127, batch 12, d_loss=0.218 g_loss=0.201 KID= 0.08489\n",
      "epoch 127, batch 13, d_loss=0.107 g_loss=-0.011 KID= 0.08489\n",
      "epoch 127, batch 14, d_loss=0.179 g_loss=-0.336 KID= 0.08489\n",
      "epoch 127, batch 15, d_loss=0.098 g_loss=-0.527 KID= 0.08489\n",
      "epoch 127, batch 16, d_loss=0.145 g_loss=-0.635 KID= 0.08489\n",
      "epoch 127, batch 17, d_loss=0.081 g_loss=-0.672 KID= 0.08489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 127, batch 18, d_loss=0.261 g_loss=-0.528 KID= 0.08489\n",
      "epoch 127, batch 19, d_loss=0.143 g_loss=-0.351 KID= 0.08489\n",
      "epoch 128, batch 0, d_loss=0.271 g_loss=-0.056 KID= 0.08489\n",
      "epoch 128, batch 1, d_loss=0.227 g_loss=0.214 KID= 0.08489\n",
      "epoch 128, batch 2, d_loss=0.216 g_loss=0.481 KID= 0.08489\n",
      "epoch 128, batch 3, d_loss=0.206 g_loss=0.812 KID= 0.08489\n",
      "epoch 128, batch 4, d_loss=0.106 g_loss=1.153 KID= 0.08489\n",
      "epoch 128, batch 5, d_loss=0.056 g_loss=1.453 KID= 0.08489\n",
      "epoch 128, batch 6, d_loss=-0.020 g_loss=1.678 KID= 0.08489\n",
      "epoch 128, batch 7, d_loss=0.117 g_loss=1.690 KID= 0.08489\n",
      "epoch 128, batch 8, d_loss=0.043 g_loss=1.598 KID= 0.08489\n",
      "epoch 128, batch 9, d_loss=0.200 g_loss=1.448 KID= 0.08489\n",
      "epoch 128, batch 10, d_loss=0.136 g_loss=1.419 KID= 0.08489\n",
      "epoch 128, batch 11, d_loss=0.241 g_loss=1.612 KID= 0.08489\n",
      "epoch 128, batch 12, d_loss=0.086 g_loss=1.933 KID= 0.08489\n",
      "epoch 128, batch 13, d_loss=0.060 g_loss=2.054 KID= 0.08489\n",
      "epoch 128, batch 14, d_loss=0.117 g_loss=2.042 KID= 0.08489\n",
      "epoch 128, batch 15, d_loss=0.032 g_loss=2.042 KID= 0.08489\n",
      "epoch 128, batch 16, d_loss=0.172 g_loss=1.719 KID= 0.08489\n",
      "epoch 128, batch 17, d_loss=0.114 g_loss=1.418 KID= 0.08489\n",
      "epoch 128, batch 18, d_loss=0.122 g_loss=1.144 KID= 0.08489\n",
      "epoch 128, batch 19, d_loss=0.087 g_loss=0.875 KID= 0.08489\n",
      "epoch 129, batch 0, d_loss=0.067 g_loss=0.593 KID= 0.08489\n",
      "epoch 129, batch 1, d_loss=0.079 g_loss=0.407 KID= 0.08489\n",
      "epoch 129, batch 2, d_loss=0.114 g_loss=0.309 KID= 0.08489\n",
      "epoch 129, batch 3, d_loss=0.098 g_loss=0.243 KID= 0.08489\n",
      "epoch 129, batch 4, d_loss=0.154 g_loss=0.298 KID= 0.08489\n",
      "epoch 129, batch 5, d_loss=0.220 g_loss=0.411 KID= 0.08489\n",
      "epoch 129, batch 6, d_loss=0.119 g_loss=0.589 KID= 0.08489\n",
      "epoch 129, batch 7, d_loss=0.130 g_loss=0.771 KID= 0.08489\n",
      "epoch 129, batch 8, d_loss=0.201 g_loss=0.842 KID= 0.08489\n",
      "epoch 129, batch 9, d_loss=0.120 g_loss=0.928 KID= 0.08489\n",
      "epoch 129, batch 10, d_loss=0.116 g_loss=0.940 KID= 0.08489\n",
      "epoch 129, batch 11, d_loss=0.166 g_loss=0.904 KID= 0.08489\n",
      "epoch 129, batch 12, d_loss=0.083 g_loss=0.837 KID= 0.08489\n",
      "epoch 129, batch 13, d_loss=0.098 g_loss=0.762 KID= 0.08489\n",
      "epoch 129, batch 14, d_loss=0.082 g_loss=0.709 KID= 0.08489\n",
      "epoch 129, batch 15, d_loss=0.066 g_loss=0.631 KID= 0.08489\n",
      "epoch 129, batch 16, d_loss=0.081 g_loss=0.618 KID= 0.08489\n",
      "epoch 129, batch 17, d_loss=0.098 g_loss=0.592 KID= 0.08489\n",
      "epoch 129, batch 18, d_loss=0.076 g_loss=0.561 KID= 0.08489\n",
      "epoch 129, batch 19, d_loss=0.123 g_loss=0.527 KID= 0.08489\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 130, batch 0, d_loss=0.154 g_loss=0.572 KID= 0.09394\n",
      "epoch 130, batch 1, d_loss=0.170 g_loss=0.478 KID= 0.09394\n",
      "epoch 130, batch 2, d_loss=0.151 g_loss=0.397 KID= 0.09394\n",
      "epoch 130, batch 3, d_loss=0.114 g_loss=0.350 KID= 0.09394\n",
      "epoch 130, batch 4, d_loss=0.160 g_loss=0.222 KID= 0.09394\n",
      "epoch 130, batch 5, d_loss=0.089 g_loss=0.122 KID= 0.09394\n",
      "epoch 130, batch 6, d_loss=0.099 g_loss=0.116 KID= 0.09394\n",
      "epoch 130, batch 7, d_loss=0.066 g_loss=0.058 KID= 0.09394\n",
      "epoch 130, batch 8, d_loss=0.109 g_loss=0.045 KID= 0.09394\n",
      "epoch 130, batch 9, d_loss=0.038 g_loss=0.006 KID= 0.09394\n",
      "epoch 130, batch 10, d_loss=0.037 g_loss=-0.054 KID= 0.09394\n",
      "epoch 130, batch 11, d_loss=0.201 g_loss=-0.069 KID= 0.09394\n",
      "epoch 130, batch 12, d_loss=0.166 g_loss=0.001 KID= 0.09394\n",
      "epoch 130, batch 13, d_loss=0.102 g_loss=0.090 KID= 0.09394\n",
      "epoch 130, batch 14, d_loss=0.024 g_loss=0.127 KID= 0.09394\n",
      "epoch 130, batch 15, d_loss=0.108 g_loss=0.224 KID= 0.09394\n",
      "epoch 130, batch 16, d_loss=0.106 g_loss=0.310 KID= 0.09394\n",
      "epoch 130, batch 17, d_loss=0.076 g_loss=0.392 KID= 0.09394\n",
      "epoch 130, batch 18, d_loss=0.219 g_loss=0.553 KID= 0.09394\n",
      "epoch 130, batch 19, d_loss=0.121 g_loss=0.682 KID= 0.09394\n",
      "epoch 131, batch 0, d_loss=0.111 g_loss=0.802 KID= 0.09394\n",
      "epoch 131, batch 1, d_loss=0.044 g_loss=0.857 KID= 0.09394\n",
      "epoch 131, batch 2, d_loss=0.026 g_loss=0.960 KID= 0.09394\n",
      "epoch 131, batch 3, d_loss=0.060 g_loss=0.969 KID= 0.09394\n",
      "epoch 131, batch 4, d_loss=0.181 g_loss=1.006 KID= 0.09394\n",
      "epoch 131, batch 5, d_loss=0.051 g_loss=1.029 KID= 0.09394\n",
      "epoch 131, batch 6, d_loss=0.190 g_loss=1.108 KID= 0.09394\n",
      "epoch 131, batch 7, d_loss=0.307 g_loss=1.251 KID= 0.09394\n",
      "epoch 131, batch 8, d_loss=0.158 g_loss=1.383 KID= 0.09394\n",
      "epoch 131, batch 9, d_loss=0.115 g_loss=1.434 KID= 0.09394\n",
      "epoch 131, batch 10, d_loss=0.112 g_loss=1.457 KID= 0.09394\n",
      "epoch 131, batch 11, d_loss=0.117 g_loss=1.409 KID= 0.09394\n",
      "epoch 131, batch 12, d_loss=0.102 g_loss=1.325 KID= 0.09394\n",
      "epoch 131, batch 13, d_loss=0.104 g_loss=1.172 KID= 0.09394\n",
      "epoch 131, batch 14, d_loss=0.037 g_loss=1.152 KID= 0.09394\n",
      "epoch 131, batch 15, d_loss=0.131 g_loss=0.952 KID= 0.09394\n",
      "epoch 131, batch 16, d_loss=0.094 g_loss=0.740 KID= 0.09394\n",
      "epoch 131, batch 17, d_loss=0.021 g_loss=0.573 KID= 0.09394\n",
      "epoch 131, batch 18, d_loss=0.043 g_loss=0.368 KID= 0.09394\n",
      "epoch 131, batch 19, d_loss=-0.005 g_loss=0.270 KID= 0.09394\n",
      "epoch 132, batch 0, d_loss=-0.034 g_loss=0.195 KID= 0.09394\n",
      "epoch 132, batch 1, d_loss=0.023 g_loss=0.267 KID= 0.09394\n",
      "epoch 132, batch 2, d_loss=0.085 g_loss=0.477 KID= 0.09394\n",
      "epoch 132, batch 3, d_loss=0.162 g_loss=0.641 KID= 0.09394\n",
      "epoch 132, batch 4, d_loss=0.284 g_loss=0.802 KID= 0.09394\n",
      "epoch 132, batch 5, d_loss=0.101 g_loss=0.923 KID= 0.09394\n",
      "epoch 132, batch 6, d_loss=0.177 g_loss=0.954 KID= 0.09394\n",
      "epoch 132, batch 7, d_loss=0.147 g_loss=0.921 KID= 0.09394\n",
      "epoch 132, batch 8, d_loss=0.260 g_loss=0.866 KID= 0.09394\n",
      "epoch 132, batch 9, d_loss=0.197 g_loss=0.748 KID= 0.09394\n",
      "epoch 132, batch 10, d_loss=0.150 g_loss=0.692 KID= 0.09394\n",
      "epoch 132, batch 11, d_loss=0.238 g_loss=0.663 KID= 0.09394\n",
      "epoch 132, batch 12, d_loss=0.220 g_loss=0.698 KID= 0.09394\n",
      "epoch 132, batch 13, d_loss=0.090 g_loss=0.814 KID= 0.09394\n",
      "epoch 132, batch 14, d_loss=0.118 g_loss=0.968 KID= 0.09394\n",
      "epoch 132, batch 15, d_loss=0.113 g_loss=1.241 KID= 0.09394\n",
      "epoch 132, batch 16, d_loss=0.012 g_loss=1.448 KID= 0.09394\n",
      "epoch 132, batch 17, d_loss=0.085 g_loss=1.522 KID= 0.09394\n",
      "epoch 132, batch 18, d_loss=0.008 g_loss=1.606 KID= 0.09394\n",
      "epoch 132, batch 19, d_loss=0.120 g_loss=1.585 KID= 0.09394\n",
      "epoch 133, batch 0, d_loss=0.264 g_loss=1.525 KID= 0.09394\n",
      "epoch 133, batch 1, d_loss=0.128 g_loss=1.471 KID= 0.09394\n",
      "epoch 133, batch 2, d_loss=0.108 g_loss=1.397 KID= 0.09394\n",
      "epoch 133, batch 3, d_loss=0.169 g_loss=1.360 KID= 0.09394\n",
      "epoch 133, batch 4, d_loss=0.258 g_loss=1.405 KID= 0.09394\n",
      "epoch 133, batch 5, d_loss=0.103 g_loss=1.504 KID= 0.09394\n",
      "epoch 133, batch 6, d_loss=0.115 g_loss=1.604 KID= 0.09394\n",
      "epoch 133, batch 7, d_loss=0.053 g_loss=1.764 KID= 0.09394\n",
      "epoch 133, batch 8, d_loss=0.177 g_loss=1.722 KID= 0.09394\n",
      "epoch 133, batch 9, d_loss=0.069 g_loss=1.712 KID= 0.09394\n",
      "epoch 133, batch 10, d_loss=0.045 g_loss=1.711 KID= 0.09394\n",
      "epoch 133, batch 11, d_loss=0.283 g_loss=1.544 KID= 0.09394\n",
      "epoch 133, batch 12, d_loss=0.277 g_loss=1.397 KID= 0.09394\n",
      "epoch 133, batch 13, d_loss=0.107 g_loss=1.318 KID= 0.09394\n",
      "epoch 133, batch 14, d_loss=0.073 g_loss=1.209 KID= 0.09394\n",
      "epoch 133, batch 15, d_loss=0.123 g_loss=1.126 KID= 0.09394\n",
      "epoch 133, batch 16, d_loss=0.100 g_loss=1.032 KID= 0.09394\n",
      "epoch 133, batch 17, d_loss=0.108 g_loss=0.878 KID= 0.09394\n",
      "epoch 133, batch 18, d_loss=0.013 g_loss=0.806 KID= 0.09394\n",
      "epoch 133, batch 19, d_loss=0.019 g_loss=0.744 KID= 0.09394\n",
      "epoch 134, batch 0, d_loss=0.067 g_loss=0.688 KID= 0.09394\n",
      "epoch 134, batch 1, d_loss=0.045 g_loss=0.704 KID= 0.09394\n",
      "epoch 134, batch 2, d_loss=-0.012 g_loss=0.834 KID= 0.09394\n",
      "epoch 134, batch 3, d_loss=0.161 g_loss=0.874 KID= 0.09394\n",
      "epoch 134, batch 4, d_loss=0.246 g_loss=0.854 KID= 0.09394\n",
      "epoch 134, batch 5, d_loss=0.092 g_loss=0.764 KID= 0.09394\n",
      "epoch 134, batch 6, d_loss=0.170 g_loss=0.620 KID= 0.09394\n",
      "epoch 134, batch 7, d_loss=0.128 g_loss=0.475 KID= 0.09394\n",
      "epoch 134, batch 8, d_loss=0.196 g_loss=0.355 KID= 0.09394\n",
      "epoch 134, batch 9, d_loss=0.174 g_loss=0.306 KID= 0.09394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 134, batch 10, d_loss=0.187 g_loss=0.335 KID= 0.09394\n",
      "epoch 134, batch 11, d_loss=0.193 g_loss=0.446 KID= 0.09394\n",
      "epoch 134, batch 12, d_loss=0.184 g_loss=0.571 KID= 0.09394\n",
      "epoch 134, batch 13, d_loss=0.053 g_loss=0.705 KID= 0.09394\n",
      "epoch 134, batch 14, d_loss=0.038 g_loss=0.740 KID= 0.09394\n",
      "epoch 134, batch 15, d_loss=0.072 g_loss=0.734 KID= 0.09394\n",
      "epoch 134, batch 16, d_loss=0.044 g_loss=0.722 KID= 0.09394\n",
      "epoch 134, batch 17, d_loss=0.076 g_loss=0.658 KID= 0.09394\n",
      "epoch 134, batch 18, d_loss=0.110 g_loss=0.637 KID= 0.09394\n",
      "epoch 134, batch 19, d_loss=0.047 g_loss=0.589 KID= 0.09394\n",
      "epoch 135, batch 0, d_loss=0.092 g_loss=0.566 KID= 0.09394\n",
      "epoch 135, batch 1, d_loss=0.197 g_loss=0.563 KID= 0.09394\n",
      "epoch 135, batch 2, d_loss=0.230 g_loss=0.542 KID= 0.09394\n",
      "epoch 135, batch 3, d_loss=0.100 g_loss=0.575 KID= 0.09394\n",
      "epoch 135, batch 4, d_loss=0.072 g_loss=0.588 KID= 0.09394\n",
      "epoch 135, batch 5, d_loss=0.097 g_loss=0.590 KID= 0.09394\n",
      "epoch 135, batch 6, d_loss=0.101 g_loss=0.608 KID= 0.09394\n",
      "epoch 135, batch 7, d_loss=0.076 g_loss=0.566 KID= 0.09394\n",
      "epoch 135, batch 8, d_loss=0.218 g_loss=0.566 KID= 0.09394\n",
      "epoch 135, batch 9, d_loss=0.171 g_loss=0.654 KID= 0.09394\n",
      "epoch 135, batch 10, d_loss=0.085 g_loss=0.728 KID= 0.09394\n",
      "epoch 135, batch 11, d_loss=0.110 g_loss=0.764 KID= 0.09394\n",
      "epoch 135, batch 12, d_loss=-0.004 g_loss=0.812 KID= 0.09394\n",
      "epoch 135, batch 13, d_loss=0.080 g_loss=0.806 KID= 0.09394\n",
      "epoch 135, batch 14, d_loss=0.168 g_loss=0.785 KID= 0.09394\n",
      "epoch 135, batch 15, d_loss=0.047 g_loss=0.801 KID= 0.09394\n",
      "epoch 135, batch 16, d_loss=0.118 g_loss=0.819 KID= 0.09394\n",
      "epoch 135, batch 17, d_loss=0.190 g_loss=0.803 KID= 0.09394\n",
      "epoch 135, batch 18, d_loss=0.080 g_loss=0.770 KID= 0.09394\n",
      "epoch 135, batch 19, d_loss=0.067 g_loss=0.690 KID= 0.09394\n",
      "epoch 136, batch 0, d_loss=0.087 g_loss=0.534 KID= 0.09394\n",
      "epoch 136, batch 1, d_loss=0.161 g_loss=0.403 KID= 0.09394\n",
      "epoch 136, batch 2, d_loss=0.218 g_loss=0.314 KID= 0.09394\n",
      "epoch 136, batch 3, d_loss=0.150 g_loss=0.276 KID= 0.09394\n",
      "epoch 136, batch 4, d_loss=0.116 g_loss=0.249 KID= 0.09394\n",
      "epoch 136, batch 5, d_loss=0.275 g_loss=0.273 KID= 0.09394\n",
      "epoch 136, batch 6, d_loss=0.154 g_loss=0.324 KID= 0.09394\n",
      "epoch 136, batch 7, d_loss=0.069 g_loss=0.323 KID= 0.09394\n",
      "epoch 136, batch 8, d_loss=0.211 g_loss=0.346 KID= 0.09394\n",
      "epoch 136, batch 9, d_loss=0.135 g_loss=0.396 KID= 0.09394\n",
      "epoch 136, batch 10, d_loss=0.204 g_loss=0.371 KID= 0.09394\n",
      "epoch 136, batch 11, d_loss=0.292 g_loss=0.475 KID= 0.09394\n",
      "epoch 136, batch 12, d_loss=0.196 g_loss=0.512 KID= 0.09394\n",
      "epoch 136, batch 13, d_loss=0.128 g_loss=0.609 KID= 0.09394\n",
      "epoch 136, batch 14, d_loss=0.129 g_loss=0.738 KID= 0.09394\n",
      "epoch 136, batch 15, d_loss=-0.027 g_loss=0.781 KID= 0.09394\n",
      "epoch 136, batch 16, d_loss=0.035 g_loss=0.808 KID= 0.09394\n",
      "epoch 136, batch 17, d_loss=0.094 g_loss=0.824 KID= 0.09394\n",
      "epoch 136, batch 18, d_loss=0.060 g_loss=0.823 KID= 0.09394\n",
      "epoch 136, batch 19, d_loss=0.098 g_loss=0.770 KID= 0.09394\n",
      "epoch 137, batch 0, d_loss=0.155 g_loss=0.770 KID= 0.09394\n",
      "epoch 137, batch 1, d_loss=0.109 g_loss=0.752 KID= 0.09394\n",
      "epoch 137, batch 2, d_loss=0.191 g_loss=0.728 KID= 0.09394\n",
      "epoch 137, batch 3, d_loss=0.169 g_loss=0.774 KID= 0.09394\n",
      "epoch 137, batch 4, d_loss=0.227 g_loss=0.872 KID= 0.09394\n",
      "epoch 137, batch 5, d_loss=0.142 g_loss=0.999 KID= 0.09394\n",
      "epoch 137, batch 6, d_loss=0.156 g_loss=1.139 KID= 0.09394\n",
      "epoch 137, batch 7, d_loss=0.043 g_loss=1.309 KID= 0.09394\n",
      "epoch 137, batch 8, d_loss=0.043 g_loss=1.381 KID= 0.09394\n",
      "epoch 137, batch 9, d_loss=0.043 g_loss=1.385 KID= 0.09394\n",
      "epoch 137, batch 10, d_loss=-0.016 g_loss=1.395 KID= 0.09394\n",
      "epoch 137, batch 11, d_loss=0.288 g_loss=1.156 KID= 0.09394\n",
      "epoch 137, batch 12, d_loss=0.195 g_loss=1.028 KID= 0.09394\n",
      "epoch 137, batch 13, d_loss=0.162 g_loss=0.854 KID= 0.09394\n",
      "epoch 137, batch 14, d_loss=0.150 g_loss=0.689 KID= 0.09394\n",
      "epoch 137, batch 15, d_loss=0.136 g_loss=0.545 KID= 0.09394\n",
      "epoch 137, batch 16, d_loss=0.065 g_loss=0.385 KID= 0.09394\n",
      "epoch 137, batch 17, d_loss=0.037 g_loss=0.291 KID= 0.09394\n",
      "epoch 137, batch 18, d_loss=0.028 g_loss=0.163 KID= 0.09394\n",
      "epoch 137, batch 19, d_loss=0.011 g_loss=0.013 KID= 0.09394\n",
      "epoch 138, batch 0, d_loss=0.036 g_loss=-0.069 KID= 0.09394\n",
      "epoch 138, batch 1, d_loss=0.133 g_loss=-0.090 KID= 0.09394\n",
      "epoch 138, batch 2, d_loss=0.212 g_loss=-0.046 KID= 0.09394\n",
      "epoch 138, batch 3, d_loss=0.097 g_loss=0.086 KID= 0.09394\n",
      "epoch 138, batch 4, d_loss=0.110 g_loss=0.266 KID= 0.09394\n",
      "epoch 138, batch 5, d_loss=-0.018 g_loss=0.407 KID= 0.09394\n",
      "epoch 138, batch 6, d_loss=0.014 g_loss=0.486 KID= 0.09394\n",
      "epoch 138, batch 7, d_loss=0.098 g_loss=0.461 KID= 0.09394\n",
      "epoch 138, batch 8, d_loss=0.137 g_loss=0.392 KID= 0.09394\n",
      "epoch 138, batch 9, d_loss=0.108 g_loss=0.388 KID= 0.09394\n",
      "epoch 138, batch 10, d_loss=0.143 g_loss=0.452 KID= 0.09394\n",
      "epoch 138, batch 11, d_loss=0.111 g_loss=0.558 KID= 0.09394\n",
      "epoch 138, batch 12, d_loss=0.048 g_loss=0.604 KID= 0.09394\n",
      "epoch 138, batch 13, d_loss=0.071 g_loss=0.663 KID= 0.09394\n",
      "epoch 138, batch 14, d_loss=0.022 g_loss=0.726 KID= 0.09394\n",
      "epoch 138, batch 15, d_loss=0.120 g_loss=0.706 KID= 0.09394\n",
      "epoch 138, batch 16, d_loss=0.086 g_loss=0.689 KID= 0.09394\n",
      "epoch 138, batch 17, d_loss=0.056 g_loss=0.713 KID= 0.09394\n",
      "epoch 138, batch 18, d_loss=0.188 g_loss=0.713 KID= 0.09394\n",
      "epoch 138, batch 19, d_loss=0.176 g_loss=0.734 KID= 0.09394\n",
      "epoch 139, batch 0, d_loss=0.143 g_loss=0.790 KID= 0.09394\n",
      "epoch 139, batch 1, d_loss=0.206 g_loss=0.821 KID= 0.09394\n",
      "epoch 139, batch 2, d_loss=0.200 g_loss=0.835 KID= 0.09394\n",
      "epoch 139, batch 3, d_loss=0.041 g_loss=0.898 KID= 0.09394\n",
      "epoch 139, batch 4, d_loss=0.123 g_loss=0.904 KID= 0.09394\n",
      "epoch 139, batch 5, d_loss=-0.005 g_loss=0.875 KID= 0.09394\n",
      "epoch 139, batch 6, d_loss=0.095 g_loss=0.806 KID= 0.09394\n",
      "epoch 139, batch 7, d_loss=0.229 g_loss=0.712 KID= 0.09394\n",
      "epoch 139, batch 8, d_loss=0.133 g_loss=0.649 KID= 0.09394\n",
      "epoch 139, batch 9, d_loss=0.109 g_loss=0.604 KID= 0.09394\n",
      "epoch 139, batch 10, d_loss=0.123 g_loss=0.585 KID= 0.09394\n",
      "epoch 139, batch 11, d_loss=0.134 g_loss=0.524 KID= 0.09394\n",
      "epoch 139, batch 12, d_loss=0.107 g_loss=0.441 KID= 0.09394\n",
      "epoch 139, batch 13, d_loss=0.048 g_loss=0.370 KID= 0.09394\n",
      "epoch 139, batch 14, d_loss=0.038 g_loss=0.319 KID= 0.09394\n",
      "epoch 139, batch 15, d_loss=0.170 g_loss=0.320 KID= 0.09394\n",
      "epoch 139, batch 16, d_loss=0.121 g_loss=0.346 KID= 0.09394\n",
      "epoch 139, batch 17, d_loss=0.117 g_loss=0.389 KID= 0.09394\n",
      "epoch 139, batch 18, d_loss=0.174 g_loss=0.557 KID= 0.09394\n",
      "epoch 139, batch 19, d_loss=0.074 g_loss=0.764 KID= 0.09394\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 140, batch 0, d_loss=0.033 g_loss=0.817 KID= 0.09651\n",
      "epoch 140, batch 1, d_loss=0.091 g_loss=0.800 KID= 0.09651\n",
      "epoch 140, batch 2, d_loss=0.035 g_loss=0.757 KID= 0.09651\n",
      "epoch 140, batch 3, d_loss=0.212 g_loss=0.715 KID= 0.09651\n",
      "epoch 140, batch 4, d_loss=0.351 g_loss=0.680 KID= 0.09651\n",
      "epoch 140, batch 5, d_loss=0.106 g_loss=0.674 KID= 0.09651\n",
      "epoch 140, batch 6, d_loss=0.198 g_loss=0.675 KID= 0.09651\n",
      "epoch 140, batch 7, d_loss=0.165 g_loss=0.695 KID= 0.09651\n",
      "epoch 140, batch 8, d_loss=0.073 g_loss=0.709 KID= 0.09651\n",
      "epoch 140, batch 9, d_loss=0.110 g_loss=0.712 KID= 0.09651\n",
      "epoch 140, batch 10, d_loss=0.102 g_loss=0.733 KID= 0.09651\n",
      "epoch 140, batch 11, d_loss=0.084 g_loss=0.727 KID= 0.09651\n",
      "epoch 140, batch 12, d_loss=0.199 g_loss=0.690 KID= 0.09651\n",
      "epoch 140, batch 13, d_loss=0.072 g_loss=0.728 KID= 0.09651\n",
      "epoch 140, batch 14, d_loss=0.052 g_loss=0.863 KID= 0.09651\n",
      "epoch 140, batch 15, d_loss=0.160 g_loss=0.923 KID= 0.09651\n",
      "epoch 140, batch 16, d_loss=0.078 g_loss=1.023 KID= 0.09651\n",
      "epoch 140, batch 17, d_loss=0.069 g_loss=1.125 KID= 0.09651\n",
      "epoch 140, batch 18, d_loss=0.151 g_loss=1.159 KID= 0.09651\n",
      "epoch 140, batch 19, d_loss=0.100 g_loss=1.072 KID= 0.09651\n",
      "epoch 141, batch 0, d_loss=0.026 g_loss=0.934 KID= 0.09651\n",
      "epoch 141, batch 1, d_loss=0.183 g_loss=0.643 KID= 0.09651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 141, batch 2, d_loss=-0.072 g_loss=0.402 KID= 0.09651\n",
      "epoch 141, batch 3, d_loss=0.100 g_loss=0.132 KID= 0.09651\n",
      "epoch 141, batch 4, d_loss=0.136 g_loss=-0.180 KID= 0.09651\n",
      "epoch 141, batch 5, d_loss=-0.131 g_loss=-0.364 KID= 0.09651\n",
      "epoch 141, batch 6, d_loss=0.133 g_loss=-0.476 KID= 0.09651\n",
      "epoch 141, batch 7, d_loss=0.067 g_loss=-0.577 KID= 0.09651\n",
      "epoch 141, batch 8, d_loss=0.023 g_loss=-0.670 KID= 0.09651\n",
      "epoch 141, batch 9, d_loss=0.068 g_loss=-0.678 KID= 0.09651\n",
      "epoch 141, batch 10, d_loss=0.141 g_loss=-0.655 KID= 0.09651\n",
      "epoch 141, batch 11, d_loss=0.098 g_loss=-0.732 KID= 0.09651\n",
      "epoch 141, batch 12, d_loss=0.253 g_loss=-0.575 KID= 0.09651\n",
      "epoch 141, batch 13, d_loss=0.202 g_loss=-0.431 KID= 0.09651\n",
      "epoch 141, batch 14, d_loss=0.180 g_loss=-0.207 KID= 0.09651\n",
      "epoch 141, batch 15, d_loss=0.209 g_loss=0.047 KID= 0.09651\n",
      "epoch 141, batch 16, d_loss=0.068 g_loss=0.295 KID= 0.09651\n",
      "epoch 141, batch 17, d_loss=-0.030 g_loss=0.505 KID= 0.09651\n",
      "epoch 141, batch 18, d_loss=-0.013 g_loss=0.616 KID= 0.09651\n",
      "epoch 141, batch 19, d_loss=-0.031 g_loss=0.729 KID= 0.09651\n",
      "epoch 142, batch 0, d_loss=-0.051 g_loss=0.755 KID= 0.09651\n",
      "epoch 142, batch 1, d_loss=0.282 g_loss=0.810 KID= 0.09651\n",
      "epoch 142, batch 2, d_loss=0.221 g_loss=0.919 KID= 0.09651\n",
      "epoch 142, batch 3, d_loss=0.208 g_loss=0.942 KID= 0.09651\n",
      "epoch 142, batch 4, d_loss=0.292 g_loss=0.894 KID= 0.09651\n",
      "epoch 142, batch 5, d_loss=0.137 g_loss=0.859 KID= 0.09651\n",
      "epoch 142, batch 6, d_loss=0.128 g_loss=0.784 KID= 0.09651\n",
      "epoch 142, batch 7, d_loss=0.112 g_loss=0.726 KID= 0.09651\n",
      "epoch 142, batch 8, d_loss=0.090 g_loss=0.729 KID= 0.09651\n",
      "epoch 142, batch 9, d_loss=0.117 g_loss=0.733 KID= 0.09651\n",
      "epoch 142, batch 10, d_loss=0.105 g_loss=0.735 KID= 0.09651\n",
      "epoch 142, batch 11, d_loss=0.027 g_loss=0.756 KID= 0.09651\n",
      "epoch 142, batch 12, d_loss=0.121 g_loss=0.766 KID= 0.09651\n",
      "epoch 142, batch 13, d_loss=0.136 g_loss=0.736 KID= 0.09651\n",
      "epoch 142, batch 14, d_loss=0.069 g_loss=0.661 KID= 0.09651\n",
      "epoch 142, batch 15, d_loss=0.188 g_loss=0.578 KID= 0.09651\n",
      "epoch 142, batch 16, d_loss=0.153 g_loss=0.526 KID= 0.09651\n",
      "epoch 142, batch 17, d_loss=0.057 g_loss=0.436 KID= 0.09651\n",
      "epoch 142, batch 18, d_loss=0.089 g_loss=0.409 KID= 0.09651\n",
      "epoch 142, batch 19, d_loss=-0.011 g_loss=0.389 KID= 0.09651\n",
      "epoch 143, batch 0, d_loss=-0.002 g_loss=0.270 KID= 0.09651\n",
      "epoch 143, batch 1, d_loss=0.178 g_loss=0.256 KID= 0.09651\n",
      "epoch 143, batch 2, d_loss=0.170 g_loss=0.359 KID= 0.09651\n",
      "epoch 143, batch 3, d_loss=0.151 g_loss=0.471 KID= 0.09651\n",
      "epoch 143, batch 4, d_loss=0.246 g_loss=0.610 KID= 0.09651\n",
      "epoch 143, batch 5, d_loss=0.099 g_loss=0.637 KID= 0.09651\n",
      "epoch 143, batch 6, d_loss=0.104 g_loss=0.660 KID= 0.09651\n",
      "epoch 143, batch 7, d_loss=0.154 g_loss=0.671 KID= 0.09651\n",
      "epoch 143, batch 8, d_loss=0.095 g_loss=0.645 KID= 0.09651\n",
      "epoch 143, batch 9, d_loss=0.144 g_loss=0.558 KID= 0.09651\n",
      "epoch 143, batch 10, d_loss=0.108 g_loss=0.530 KID= 0.09651\n",
      "epoch 143, batch 11, d_loss=0.081 g_loss=0.517 KID= 0.09651\n",
      "epoch 143, batch 12, d_loss=0.118 g_loss=0.580 KID= 0.09651\n",
      "epoch 143, batch 13, d_loss=0.101 g_loss=0.633 KID= 0.09651\n",
      "epoch 143, batch 14, d_loss=0.052 g_loss=0.756 KID= 0.09651\n",
      "epoch 143, batch 15, d_loss=0.070 g_loss=0.858 KID= 0.09651\n",
      "epoch 143, batch 16, d_loss=0.025 g_loss=0.949 KID= 0.09651\n",
      "epoch 143, batch 17, d_loss=0.001 g_loss=0.985 KID= 0.09651\n",
      "epoch 143, batch 18, d_loss=0.066 g_loss=0.936 KID= 0.09651\n",
      "epoch 143, batch 19, d_loss=0.039 g_loss=0.871 KID= 0.09651\n",
      "epoch 144, batch 0, d_loss=0.096 g_loss=0.794 KID= 0.09651\n",
      "epoch 144, batch 1, d_loss=0.250 g_loss=0.710 KID= 0.09651\n",
      "epoch 144, batch 2, d_loss=0.163 g_loss=0.666 KID= 0.09651\n",
      "epoch 144, batch 3, d_loss=0.131 g_loss=0.638 KID= 0.09651\n",
      "epoch 144, batch 4, d_loss=0.154 g_loss=0.649 KID= 0.09651\n",
      "epoch 144, batch 5, d_loss=0.011 g_loss=0.617 KID= 0.09651\n",
      "epoch 144, batch 6, d_loss=0.080 g_loss=0.658 KID= 0.09651\n",
      "epoch 144, batch 7, d_loss=0.126 g_loss=0.684 KID= 0.09651\n",
      "epoch 144, batch 8, d_loss=-0.010 g_loss=0.669 KID= 0.09651\n",
      "epoch 144, batch 9, d_loss=0.054 g_loss=0.622 KID= 0.09651\n",
      "epoch 144, batch 10, d_loss=0.111 g_loss=0.604 KID= 0.09651\n",
      "epoch 144, batch 11, d_loss=0.065 g_loss=0.624 KID= 0.09651\n",
      "epoch 144, batch 12, d_loss=0.177 g_loss=0.640 KID= 0.09651\n",
      "epoch 144, batch 13, d_loss=0.137 g_loss=0.591 KID= 0.09651\n",
      "epoch 144, batch 14, d_loss=0.084 g_loss=0.596 KID= 0.09651\n",
      "epoch 144, batch 15, d_loss=0.174 g_loss=0.601 KID= 0.09651\n",
      "epoch 144, batch 16, d_loss=0.094 g_loss=0.606 KID= 0.09651\n",
      "epoch 144, batch 17, d_loss=0.074 g_loss=0.599 KID= 0.09651\n",
      "epoch 144, batch 18, d_loss=0.096 g_loss=0.599 KID= 0.09651\n",
      "epoch 144, batch 19, d_loss=-0.027 g_loss=0.606 KID= 0.09651\n",
      "epoch 145, batch 0, d_loss=0.026 g_loss=0.625 KID= 0.09651\n",
      "epoch 145, batch 1, d_loss=0.122 g_loss=0.680 KID= 0.09651\n",
      "epoch 145, batch 2, d_loss=-0.031 g_loss=0.756 KID= 0.09651\n",
      "epoch 145, batch 3, d_loss=0.196 g_loss=0.781 KID= 0.09651\n",
      "epoch 145, batch 4, d_loss=0.159 g_loss=0.779 KID= 0.09651\n",
      "epoch 145, batch 5, d_loss=0.050 g_loss=0.757 KID= 0.09651\n",
      "epoch 145, batch 6, d_loss=0.106 g_loss=0.775 KID= 0.09651\n",
      "epoch 145, batch 7, d_loss=0.008 g_loss=0.809 KID= 0.09651\n",
      "epoch 145, batch 8, d_loss=-0.056 g_loss=0.762 KID= 0.09651\n",
      "epoch 145, batch 9, d_loss=0.078 g_loss=0.638 KID= 0.09651\n",
      "epoch 145, batch 10, d_loss=0.158 g_loss=0.611 KID= 0.09651\n",
      "epoch 145, batch 11, d_loss=0.151 g_loss=0.582 KID= 0.09651\n",
      "epoch 145, batch 12, d_loss=0.373 g_loss=0.627 KID= 0.09651\n",
      "epoch 145, batch 13, d_loss=0.195 g_loss=0.613 KID= 0.09651\n",
      "epoch 145, batch 14, d_loss=0.187 g_loss=0.628 KID= 0.09651\n",
      "epoch 145, batch 15, d_loss=0.131 g_loss=0.649 KID= 0.09651\n",
      "epoch 145, batch 16, d_loss=0.040 g_loss=0.692 KID= 0.09651\n",
      "epoch 145, batch 17, d_loss=0.036 g_loss=0.747 KID= 0.09651\n",
      "epoch 145, batch 18, d_loss=0.012 g_loss=0.776 KID= 0.09651\n",
      "epoch 145, batch 19, d_loss=-0.065 g_loss=0.796 KID= 0.09651\n",
      "epoch 146, batch 0, d_loss=-0.038 g_loss=0.787 KID= 0.09651\n",
      "epoch 146, batch 1, d_loss=0.118 g_loss=0.731 KID= 0.09651\n",
      "epoch 146, batch 2, d_loss=0.033 g_loss=0.652 KID= 0.09651\n",
      "epoch 146, batch 3, d_loss=0.157 g_loss=0.619 KID= 0.09651\n",
      "epoch 146, batch 4, d_loss=0.174 g_loss=0.659 KID= 0.09651\n",
      "epoch 146, batch 5, d_loss=0.149 g_loss=0.711 KID= 0.09651\n",
      "epoch 146, batch 6, d_loss=0.115 g_loss=0.758 KID= 0.09651\n",
      "epoch 146, batch 7, d_loss=0.058 g_loss=0.822 KID= 0.09651\n",
      "epoch 146, batch 8, d_loss=0.074 g_loss=0.859 KID= 0.09651\n",
      "epoch 146, batch 9, d_loss=0.161 g_loss=0.953 KID= 0.09651\n",
      "epoch 146, batch 10, d_loss=0.091 g_loss=1.051 KID= 0.09651\n",
      "epoch 146, batch 11, d_loss=0.082 g_loss=1.096 KID= 0.09651\n",
      "epoch 146, batch 12, d_loss=0.136 g_loss=1.250 KID= 0.09651\n",
      "epoch 146, batch 13, d_loss=0.104 g_loss=1.365 KID= 0.09651\n",
      "epoch 146, batch 14, d_loss=0.142 g_loss=1.349 KID= 0.09651\n",
      "epoch 146, batch 15, d_loss=0.041 g_loss=1.370 KID= 0.09651\n",
      "epoch 146, batch 16, d_loss=0.064 g_loss=1.369 KID= 0.09651\n",
      "epoch 146, batch 17, d_loss=0.130 g_loss=1.273 KID= 0.09651\n",
      "epoch 146, batch 18, d_loss=0.081 g_loss=1.115 KID= 0.09651\n",
      "epoch 146, batch 19, d_loss=0.032 g_loss=0.929 KID= 0.09651\n",
      "epoch 147, batch 0, d_loss=0.115 g_loss=0.746 KID= 0.09651\n",
      "epoch 147, batch 1, d_loss=0.195 g_loss=0.670 KID= 0.09651\n",
      "epoch 147, batch 2, d_loss=0.166 g_loss=0.662 KID= 0.09651\n",
      "epoch 147, batch 3, d_loss=0.105 g_loss=0.720 KID= 0.09651\n",
      "epoch 147, batch 4, d_loss=0.053 g_loss=0.789 KID= 0.09651\n",
      "epoch 147, batch 5, d_loss=0.112 g_loss=0.891 KID= 0.09651\n",
      "epoch 147, batch 6, d_loss=0.087 g_loss=0.959 KID= 0.09651\n",
      "epoch 147, batch 7, d_loss=0.059 g_loss=0.988 KID= 0.09651\n",
      "epoch 147, batch 8, d_loss=0.109 g_loss=0.970 KID= 0.09651\n",
      "epoch 147, batch 9, d_loss=0.214 g_loss=0.926 KID= 0.09651\n",
      "epoch 147, batch 10, d_loss=0.165 g_loss=0.865 KID= 0.09651\n",
      "epoch 147, batch 11, d_loss=0.126 g_loss=0.810 KID= 0.09651\n",
      "epoch 147, batch 12, d_loss=0.129 g_loss=0.820 KID= 0.09651\n",
      "epoch 147, batch 13, d_loss=0.153 g_loss=0.920 KID= 0.09651\n",
      "epoch 147, batch 14, d_loss=0.224 g_loss=0.990 KID= 0.09651\n",
      "epoch 147, batch 15, d_loss=0.129 g_loss=1.136 KID= 0.09651\n",
      "epoch 147, batch 16, d_loss=0.061 g_loss=1.226 KID= 0.09651\n",
      "epoch 147, batch 17, d_loss=0.062 g_loss=1.276 KID= 0.09651\n",
      "epoch 147, batch 18, d_loss=0.046 g_loss=1.280 KID= 0.09651\n",
      "epoch 147, batch 19, d_loss=0.047 g_loss=1.226 KID= 0.09651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 148, batch 0, d_loss=0.034 g_loss=1.174 KID= 0.09651\n",
      "epoch 148, batch 1, d_loss=0.174 g_loss=1.071 KID= 0.09651\n",
      "epoch 148, batch 2, d_loss=0.190 g_loss=0.982 KID= 0.09651\n",
      "epoch 148, batch 3, d_loss=0.108 g_loss=0.884 KID= 0.09651\n",
      "epoch 148, batch 4, d_loss=0.072 g_loss=0.834 KID= 0.09651\n",
      "epoch 148, batch 5, d_loss=0.138 g_loss=0.870 KID= 0.09651\n",
      "epoch 148, batch 6, d_loss=0.105 g_loss=1.009 KID= 0.09651\n",
      "epoch 148, batch 7, d_loss=0.085 g_loss=1.111 KID= 0.09651\n",
      "epoch 148, batch 8, d_loss=0.042 g_loss=1.167 KID= 0.09651\n",
      "epoch 148, batch 9, d_loss=0.083 g_loss=1.232 KID= 0.09651\n",
      "epoch 148, batch 10, d_loss=0.088 g_loss=1.180 KID= 0.09651\n",
      "epoch 148, batch 11, d_loss=0.105 g_loss=1.065 KID= 0.09651\n",
      "epoch 148, batch 12, d_loss=0.066 g_loss=0.984 KID= 0.09651\n",
      "epoch 148, batch 13, d_loss=0.131 g_loss=0.791 KID= 0.09651\n",
      "epoch 148, batch 14, d_loss=0.220 g_loss=0.569 KID= 0.09651\n",
      "epoch 148, batch 15, d_loss=0.158 g_loss=0.461 KID= 0.09651\n",
      "epoch 148, batch 16, d_loss=0.144 g_loss=0.489 KID= 0.09651\n",
      "epoch 148, batch 17, d_loss=0.171 g_loss=0.506 KID= 0.09651\n",
      "epoch 148, batch 18, d_loss=0.079 g_loss=0.520 KID= 0.09651\n",
      "epoch 148, batch 19, d_loss=0.061 g_loss=0.524 KID= 0.09651\n",
      "epoch 149, batch 0, d_loss=0.094 g_loss=0.552 KID= 0.09651\n",
      "epoch 149, batch 1, d_loss=0.119 g_loss=0.583 KID= 0.09651\n",
      "epoch 149, batch 2, d_loss=0.077 g_loss=0.597 KID= 0.09651\n",
      "epoch 149, batch 3, d_loss=0.130 g_loss=0.612 KID= 0.09651\n",
      "epoch 149, batch 4, d_loss=-0.006 g_loss=0.598 KID= 0.09651\n",
      "epoch 149, batch 5, d_loss=0.161 g_loss=0.549 KID= 0.09651\n",
      "epoch 149, batch 6, d_loss=0.135 g_loss=0.515 KID= 0.09651\n",
      "epoch 149, batch 7, d_loss=0.031 g_loss=0.419 KID= 0.09651\n",
      "epoch 149, batch 8, d_loss=0.097 g_loss=0.310 KID= 0.09651\n",
      "epoch 149, batch 9, d_loss=0.211 g_loss=0.275 KID= 0.09651\n",
      "epoch 149, batch 10, d_loss=0.268 g_loss=0.273 KID= 0.09651\n",
      "epoch 149, batch 11, d_loss=0.165 g_loss=0.323 KID= 0.09651\n",
      "epoch 149, batch 12, d_loss=0.157 g_loss=0.491 KID= 0.09651\n",
      "epoch 149, batch 13, d_loss=0.007 g_loss=0.646 KID= 0.09651\n",
      "epoch 149, batch 14, d_loss=0.092 g_loss=0.755 KID= 0.09651\n",
      "epoch 149, batch 15, d_loss=-0.007 g_loss=0.885 KID= 0.09651\n",
      "epoch 149, batch 16, d_loss=0.055 g_loss=0.945 KID= 0.09651\n",
      "epoch 149, batch 17, d_loss=0.178 g_loss=0.911 KID= 0.09651\n",
      "epoch 149, batch 18, d_loss=0.203 g_loss=0.830 KID= 0.09651\n",
      "epoch 149, batch 19, d_loss=0.081 g_loss=0.784 KID= 0.09651\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 150, batch 0, d_loss=0.128 g_loss=0.742 KID= 0.14232\n",
      "epoch 150, batch 1, d_loss=0.187 g_loss=0.706 KID= 0.14232\n",
      "epoch 150, batch 2, d_loss=0.122 g_loss=0.697 KID= 0.14232\n",
      "epoch 150, batch 3, d_loss=0.128 g_loss=0.698 KID= 0.14232\n",
      "epoch 150, batch 4, d_loss=0.117 g_loss=0.769 KID= 0.14232\n",
      "epoch 150, batch 5, d_loss=0.098 g_loss=0.886 KID= 0.14232\n",
      "epoch 150, batch 6, d_loss=0.037 g_loss=1.030 KID= 0.14232\n",
      "epoch 150, batch 7, d_loss=-0.037 g_loss=1.219 KID= 0.14232\n",
      "epoch 150, batch 8, d_loss=-0.036 g_loss=1.343 KID= 0.14232\n",
      "epoch 150, batch 9, d_loss=0.083 g_loss=1.350 KID= 0.14232\n",
      "epoch 150, batch 10, d_loss=0.068 g_loss=1.327 KID= 0.14232\n",
      "epoch 150, batch 11, d_loss=0.035 g_loss=1.249 KID= 0.14232\n",
      "epoch 150, batch 12, d_loss=0.165 g_loss=1.160 KID= 0.14232\n",
      "epoch 150, batch 13, d_loss=0.226 g_loss=1.139 KID= 0.14232\n",
      "epoch 150, batch 14, d_loss=0.156 g_loss=1.108 KID= 0.14232\n",
      "epoch 150, batch 15, d_loss=0.090 g_loss=1.094 KID= 0.14232\n",
      "epoch 150, batch 16, d_loss=-0.032 g_loss=1.138 KID= 0.14232\n",
      "epoch 150, batch 17, d_loss=0.003 g_loss=1.114 KID= 0.14232\n",
      "epoch 150, batch 18, d_loss=-0.100 g_loss=1.095 KID= 0.14232\n",
      "epoch 150, batch 19, d_loss=-0.037 g_loss=1.092 KID= 0.14232\n",
      "epoch 151, batch 0, d_loss=0.064 g_loss=1.035 KID= 0.14232\n",
      "epoch 151, batch 1, d_loss=0.221 g_loss=0.943 KID= 0.14232\n",
      "epoch 151, batch 2, d_loss=0.110 g_loss=0.943 KID= 0.14232\n",
      "epoch 151, batch 3, d_loss=0.151 g_loss=0.922 KID= 0.14232\n",
      "epoch 151, batch 4, d_loss=0.152 g_loss=0.920 KID= 0.14232\n",
      "epoch 151, batch 5, d_loss=0.077 g_loss=0.930 KID= 0.14232\n",
      "epoch 151, batch 6, d_loss=0.073 g_loss=0.928 KID= 0.14232\n",
      "epoch 151, batch 7, d_loss=0.063 g_loss=0.900 KID= 0.14232\n",
      "epoch 151, batch 8, d_loss=0.094 g_loss=0.816 KID= 0.14232\n",
      "epoch 151, batch 9, d_loss=0.104 g_loss=0.764 KID= 0.14232\n",
      "epoch 151, batch 10, d_loss=0.090 g_loss=0.729 KID= 0.14232\n",
      "epoch 151, batch 11, d_loss=0.098 g_loss=0.680 KID= 0.14232\n",
      "epoch 151, batch 12, d_loss=0.152 g_loss=0.702 KID= 0.14232\n",
      "epoch 151, batch 13, d_loss=0.122 g_loss=0.796 KID= 0.14232\n",
      "epoch 151, batch 14, d_loss=0.086 g_loss=0.934 KID= 0.14232\n",
      "epoch 151, batch 15, d_loss=0.104 g_loss=1.056 KID= 0.14232\n",
      "epoch 151, batch 16, d_loss=0.038 g_loss=1.214 KID= 0.14232\n",
      "epoch 151, batch 17, d_loss=0.089 g_loss=1.197 KID= 0.14232\n",
      "epoch 151, batch 18, d_loss=0.034 g_loss=1.191 KID= 0.14232\n",
      "epoch 151, batch 19, d_loss=0.038 g_loss=1.206 KID= 0.14232\n",
      "epoch 152, batch 0, d_loss=0.129 g_loss=1.181 KID= 0.14232\n",
      "epoch 152, batch 1, d_loss=0.176 g_loss=1.185 KID= 0.14232\n",
      "epoch 152, batch 2, d_loss=0.044 g_loss=1.183 KID= 0.14232\n",
      "epoch 152, batch 3, d_loss=0.154 g_loss=1.110 KID= 0.14232\n",
      "epoch 152, batch 4, d_loss=0.151 g_loss=1.025 KID= 0.14232\n",
      "epoch 152, batch 5, d_loss=0.083 g_loss=0.929 KID= 0.14232\n",
      "epoch 152, batch 6, d_loss=0.131 g_loss=0.871 KID= 0.14232\n",
      "epoch 152, batch 7, d_loss=0.075 g_loss=0.791 KID= 0.14232\n",
      "epoch 152, batch 8, d_loss=0.100 g_loss=0.729 KID= 0.14232\n",
      "epoch 152, batch 9, d_loss=0.160 g_loss=0.672 KID= 0.14232\n",
      "epoch 152, batch 10, d_loss=0.128 g_loss=0.620 KID= 0.14232\n",
      "epoch 152, batch 11, d_loss=0.027 g_loss=0.548 KID= 0.14232\n",
      "epoch 152, batch 12, d_loss=0.098 g_loss=0.529 KID= 0.14232\n",
      "epoch 152, batch 13, d_loss=0.049 g_loss=0.553 KID= 0.14232\n",
      "epoch 152, batch 14, d_loss=-0.023 g_loss=0.589 KID= 0.14232\n",
      "epoch 152, batch 15, d_loss=0.021 g_loss=0.574 KID= 0.14232\n",
      "epoch 152, batch 16, d_loss=-0.003 g_loss=0.552 KID= 0.14232\n",
      "epoch 152, batch 17, d_loss=0.131 g_loss=0.493 KID= 0.14232\n",
      "epoch 152, batch 18, d_loss=0.046 g_loss=0.467 KID= 0.14232\n",
      "epoch 152, batch 19, d_loss=0.023 g_loss=0.428 KID= 0.14232\n",
      "epoch 153, batch 0, d_loss=0.045 g_loss=0.329 KID= 0.14232\n",
      "epoch 153, batch 1, d_loss=0.191 g_loss=0.193 KID= 0.14232\n",
      "epoch 153, batch 2, d_loss=0.069 g_loss=0.099 KID= 0.14232\n",
      "epoch 153, batch 3, d_loss=0.052 g_loss=0.054 KID= 0.14232\n",
      "epoch 153, batch 4, d_loss=0.115 g_loss=0.037 KID= 0.14232\n",
      "epoch 153, batch 5, d_loss=0.087 g_loss=0.039 KID= 0.14232\n",
      "epoch 153, batch 6, d_loss=0.076 g_loss=0.060 KID= 0.14232\n",
      "epoch 153, batch 7, d_loss=0.087 g_loss=0.116 KID= 0.14232\n",
      "epoch 153, batch 8, d_loss=0.076 g_loss=0.196 KID= 0.14232\n",
      "epoch 153, batch 9, d_loss=0.096 g_loss=0.278 KID= 0.14232\n",
      "epoch 153, batch 10, d_loss=0.101 g_loss=0.345 KID= 0.14232\n",
      "epoch 153, batch 11, d_loss=-0.028 g_loss=0.351 KID= 0.14232\n",
      "epoch 153, batch 12, d_loss=0.071 g_loss=0.333 KID= 0.14232\n",
      "epoch 153, batch 13, d_loss=0.185 g_loss=0.406 KID= 0.14232\n",
      "epoch 153, batch 14, d_loss=0.084 g_loss=0.448 KID= 0.14232\n",
      "epoch 153, batch 15, d_loss=0.142 g_loss=0.478 KID= 0.14232\n",
      "epoch 153, batch 16, d_loss=0.147 g_loss=0.544 KID= 0.14232\n",
      "epoch 153, batch 17, d_loss=0.102 g_loss=0.552 KID= 0.14232\n",
      "epoch 153, batch 18, d_loss=0.022 g_loss=0.560 KID= 0.14232\n",
      "epoch 153, batch 19, d_loss=0.088 g_loss=0.587 KID= 0.14232\n",
      "epoch 154, batch 0, d_loss=0.112 g_loss=0.629 KID= 0.14232\n",
      "epoch 154, batch 1, d_loss=0.194 g_loss=0.634 KID= 0.14232\n",
      "epoch 154, batch 2, d_loss=0.114 g_loss=0.731 KID= 0.14232\n",
      "epoch 154, batch 3, d_loss=0.109 g_loss=0.746 KID= 0.14232\n",
      "epoch 154, batch 4, d_loss=0.101 g_loss=0.742 KID= 0.14232\n",
      "epoch 154, batch 5, d_loss=0.077 g_loss=0.713 KID= 0.14232\n",
      "epoch 154, batch 6, d_loss=0.062 g_loss=0.664 KID= 0.14232\n",
      "epoch 154, batch 7, d_loss=0.054 g_loss=0.618 KID= 0.14232\n",
      "epoch 154, batch 8, d_loss=0.122 g_loss=0.539 KID= 0.14232\n",
      "epoch 154, batch 9, d_loss=0.077 g_loss=0.460 KID= 0.14232\n",
      "epoch 154, batch 10, d_loss=0.051 g_loss=0.358 KID= 0.14232\n",
      "epoch 154, batch 11, d_loss=0.140 g_loss=0.307 KID= 0.14232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 154, batch 12, d_loss=0.172 g_loss=0.311 KID= 0.14232\n",
      "epoch 154, batch 13, d_loss=0.132 g_loss=0.338 KID= 0.14232\n",
      "epoch 154, batch 14, d_loss=0.138 g_loss=0.470 KID= 0.14232\n",
      "epoch 154, batch 15, d_loss=0.031 g_loss=0.571 KID= 0.14232\n",
      "epoch 154, batch 16, d_loss=0.008 g_loss=0.553 KID= 0.14232\n",
      "epoch 154, batch 17, d_loss=0.105 g_loss=0.495 KID= 0.14232\n",
      "epoch 154, batch 18, d_loss=0.045 g_loss=0.455 KID= 0.14232\n",
      "epoch 154, batch 19, d_loss=0.048 g_loss=0.433 KID= 0.14232\n",
      "epoch 155, batch 0, d_loss=0.067 g_loss=0.434 KID= 0.14232\n",
      "epoch 155, batch 1, d_loss=0.064 g_loss=0.478 KID= 0.14232\n",
      "epoch 155, batch 2, d_loss=0.010 g_loss=0.542 KID= 0.14232\n",
      "epoch 155, batch 3, d_loss=0.077 g_loss=0.535 KID= 0.14232\n",
      "epoch 155, batch 4, d_loss=0.071 g_loss=0.554 KID= 0.14232\n",
      "epoch 155, batch 5, d_loss=0.126 g_loss=0.548 KID= 0.14232\n",
      "epoch 155, batch 6, d_loss=0.161 g_loss=0.545 KID= 0.14232\n",
      "epoch 155, batch 7, d_loss=0.108 g_loss=0.552 KID= 0.14232\n",
      "epoch 155, batch 8, d_loss=0.129 g_loss=0.559 KID= 0.14232\n",
      "epoch 155, batch 9, d_loss=0.179 g_loss=0.631 KID= 0.14232\n",
      "epoch 155, batch 10, d_loss=0.108 g_loss=0.697 KID= 0.14232\n",
      "epoch 155, batch 11, d_loss=0.053 g_loss=0.710 KID= 0.14232\n",
      "epoch 155, batch 12, d_loss=0.054 g_loss=0.741 KID= 0.14232\n",
      "epoch 155, batch 13, d_loss=0.015 g_loss=0.789 KID= 0.14232\n",
      "epoch 155, batch 14, d_loss=0.113 g_loss=0.799 KID= 0.14232\n",
      "epoch 155, batch 15, d_loss=0.026 g_loss=0.799 KID= 0.14232\n",
      "epoch 155, batch 16, d_loss=0.021 g_loss=0.759 KID= 0.14232\n",
      "epoch 155, batch 17, d_loss=0.113 g_loss=0.729 KID= 0.14232\n",
      "epoch 155, batch 18, d_loss=0.094 g_loss=0.637 KID= 0.14232\n",
      "epoch 155, batch 19, d_loss=0.083 g_loss=0.594 KID= 0.14232\n",
      "epoch 156, batch 0, d_loss=0.111 g_loss=0.591 KID= 0.14232\n",
      "epoch 156, batch 1, d_loss=0.086 g_loss=0.575 KID= 0.14232\n",
      "epoch 156, batch 2, d_loss=0.062 g_loss=0.619 KID= 0.14232\n",
      "epoch 156, batch 3, d_loss=0.092 g_loss=0.611 KID= 0.14232\n",
      "epoch 156, batch 4, d_loss=0.012 g_loss=0.630 KID= 0.14232\n",
      "epoch 156, batch 5, d_loss=0.091 g_loss=0.612 KID= 0.14232\n",
      "epoch 156, batch 6, d_loss=0.160 g_loss=0.633 KID= 0.14232\n",
      "epoch 156, batch 7, d_loss=0.030 g_loss=0.622 KID= 0.14232\n",
      "epoch 156, batch 8, d_loss=0.039 g_loss=0.580 KID= 0.14232\n",
      "epoch 156, batch 9, d_loss=0.082 g_loss=0.548 KID= 0.14232\n",
      "epoch 156, batch 10, d_loss=0.085 g_loss=0.472 KID= 0.14232\n",
      "epoch 156, batch 11, d_loss=0.222 g_loss=0.483 KID= 0.14232\n",
      "epoch 156, batch 12, d_loss=0.228 g_loss=0.533 KID= 0.14232\n",
      "epoch 156, batch 13, d_loss=0.128 g_loss=0.546 KID= 0.14232\n",
      "epoch 156, batch 14, d_loss=0.186 g_loss=0.594 KID= 0.14232\n",
      "epoch 156, batch 15, d_loss=0.128 g_loss=0.593 KID= 0.14232\n",
      "epoch 156, batch 16, d_loss=0.066 g_loss=0.610 KID= 0.14232\n",
      "epoch 156, batch 17, d_loss=0.128 g_loss=0.631 KID= 0.14232\n",
      "epoch 156, batch 18, d_loss=0.085 g_loss=0.637 KID= 0.14232\n",
      "epoch 156, batch 19, d_loss=0.099 g_loss=0.660 KID= 0.14232\n",
      "epoch 157, batch 0, d_loss=0.061 g_loss=0.722 KID= 0.14232\n",
      "epoch 157, batch 1, d_loss=0.052 g_loss=0.709 KID= 0.14232\n",
      "epoch 157, batch 2, d_loss=0.009 g_loss=0.657 KID= 0.14232\n",
      "epoch 157, batch 3, d_loss=-0.002 g_loss=0.642 KID= 0.14232\n",
      "epoch 157, batch 4, d_loss=0.032 g_loss=0.575 KID= 0.14232\n",
      "epoch 157, batch 5, d_loss=0.101 g_loss=0.542 KID= 0.14232\n",
      "epoch 157, batch 6, d_loss=0.162 g_loss=0.496 KID= 0.14232\n",
      "epoch 157, batch 7, d_loss=0.126 g_loss=0.445 KID= 0.14232\n",
      "epoch 157, batch 8, d_loss=0.131 g_loss=0.381 KID= 0.14232\n",
      "epoch 157, batch 9, d_loss=0.043 g_loss=0.308 KID= 0.14232\n",
      "epoch 157, batch 10, d_loss=0.082 g_loss=0.250 KID= 0.14232\n",
      "epoch 157, batch 11, d_loss=0.088 g_loss=0.146 KID= 0.14232\n",
      "epoch 157, batch 12, d_loss=0.044 g_loss=0.073 KID= 0.14232\n",
      "epoch 157, batch 13, d_loss=0.088 g_loss=0.020 KID= 0.14232\n",
      "epoch 157, batch 14, d_loss=0.065 g_loss=-0.033 KID= 0.14232\n",
      "epoch 157, batch 15, d_loss=0.082 g_loss=-0.049 KID= 0.14232\n",
      "epoch 157, batch 16, d_loss=0.075 g_loss=-0.058 KID= 0.14232\n",
      "epoch 157, batch 17, d_loss=0.109 g_loss=-0.061 KID= 0.14232\n",
      "epoch 157, batch 18, d_loss=0.096 g_loss=-0.080 KID= 0.14232\n",
      "epoch 157, batch 19, d_loss=0.125 g_loss=-0.064 KID= 0.14232\n",
      "epoch 158, batch 0, d_loss=0.129 g_loss=-0.044 KID= 0.14232\n",
      "epoch 158, batch 1, d_loss=0.126 g_loss=-0.035 KID= 0.14232\n",
      "epoch 158, batch 2, d_loss=0.137 g_loss=0.127 KID= 0.14232\n",
      "epoch 158, batch 3, d_loss=0.072 g_loss=0.289 KID= 0.14232\n",
      "epoch 158, batch 4, d_loss=0.076 g_loss=0.358 KID= 0.14232\n",
      "epoch 158, batch 5, d_loss=-0.005 g_loss=0.414 KID= 0.14232\n",
      "epoch 158, batch 6, d_loss=0.079 g_loss=0.450 KID= 0.14232\n",
      "epoch 158, batch 7, d_loss=0.031 g_loss=0.425 KID= 0.14232\n",
      "epoch 158, batch 8, d_loss=0.093 g_loss=0.404 KID= 0.14232\n",
      "epoch 158, batch 9, d_loss=0.104 g_loss=0.499 KID= 0.14232\n",
      "epoch 158, batch 10, d_loss=0.116 g_loss=0.533 KID= 0.14232\n",
      "epoch 158, batch 11, d_loss=0.055 g_loss=0.493 KID= 0.14232\n",
      "epoch 158, batch 12, d_loss=0.118 g_loss=0.492 KID= 0.14232\n",
      "epoch 158, batch 13, d_loss=0.081 g_loss=0.505 KID= 0.14232\n",
      "epoch 158, batch 14, d_loss=0.035 g_loss=0.483 KID= 0.14232\n",
      "epoch 158, batch 15, d_loss=0.104 g_loss=0.480 KID= 0.14232\n",
      "epoch 158, batch 16, d_loss=0.026 g_loss=0.509 KID= 0.14232\n",
      "epoch 158, batch 17, d_loss=0.082 g_loss=0.531 KID= 0.14232\n",
      "epoch 158, batch 18, d_loss=0.059 g_loss=0.552 KID= 0.14232\n",
      "epoch 158, batch 19, d_loss=0.099 g_loss=0.576 KID= 0.14232\n",
      "epoch 159, batch 0, d_loss=0.138 g_loss=0.598 KID= 0.14232\n",
      "epoch 159, batch 1, d_loss=0.107 g_loss=0.575 KID= 0.14232\n",
      "epoch 159, batch 2, d_loss=0.085 g_loss=0.633 KID= 0.14232\n",
      "epoch 159, batch 3, d_loss=0.045 g_loss=0.726 KID= 0.14232\n",
      "epoch 159, batch 4, d_loss=0.082 g_loss=0.831 KID= 0.14232\n",
      "epoch 159, batch 5, d_loss=0.018 g_loss=0.937 KID= 0.14232\n",
      "epoch 159, batch 6, d_loss=0.096 g_loss=1.014 KID= 0.14232\n",
      "epoch 159, batch 7, d_loss=0.071 g_loss=1.078 KID= 0.14232\n",
      "epoch 159, batch 8, d_loss=0.105 g_loss=1.012 KID= 0.14232\n",
      "epoch 159, batch 9, d_loss=0.085 g_loss=0.967 KID= 0.14232\n",
      "epoch 159, batch 10, d_loss=0.043 g_loss=0.887 KID= 0.14232\n",
      "epoch 159, batch 11, d_loss=0.097 g_loss=0.793 KID= 0.14232\n",
      "epoch 159, batch 12, d_loss=0.078 g_loss=0.728 KID= 0.14232\n",
      "epoch 159, batch 13, d_loss=0.060 g_loss=0.643 KID= 0.14232\n",
      "epoch 159, batch 14, d_loss=0.012 g_loss=0.585 KID= 0.14232\n",
      "epoch 159, batch 15, d_loss=0.104 g_loss=0.512 KID= 0.14232\n",
      "epoch 159, batch 16, d_loss=0.101 g_loss=0.455 KID= 0.14232\n",
      "epoch 159, batch 17, d_loss=0.133 g_loss=0.423 KID= 0.14232\n",
      "epoch 159, batch 18, d_loss=0.124 g_loss=0.423 KID= 0.14232\n",
      "epoch 159, batch 19, d_loss=0.160 g_loss=0.433 KID= 0.14232\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 160, batch 0, d_loss=0.225 g_loss=0.450 KID= 0.08692\n",
      "epoch 160, batch 1, d_loss=0.104 g_loss=0.452 KID= 0.08692\n",
      "epoch 160, batch 2, d_loss=0.116 g_loss=0.449 KID= 0.08692\n",
      "epoch 160, batch 3, d_loss=0.049 g_loss=0.416 KID= 0.08692\n",
      "epoch 160, batch 4, d_loss=0.038 g_loss=0.331 KID= 0.08692\n",
      "epoch 160, batch 5, d_loss=-0.030 g_loss=0.265 KID= 0.08692\n",
      "epoch 160, batch 6, d_loss=0.020 g_loss=0.127 KID= 0.08692\n",
      "epoch 160, batch 7, d_loss=0.078 g_loss=0.049 KID= 0.08692\n",
      "epoch 160, batch 8, d_loss=0.144 g_loss=0.017 KID= 0.08692\n",
      "epoch 160, batch 9, d_loss=0.082 g_loss=0.034 KID= 0.08692\n",
      "epoch 160, batch 10, d_loss=0.034 g_loss=0.058 KID= 0.08692\n",
      "epoch 160, batch 11, d_loss=0.025 g_loss=0.164 KID= 0.08692\n",
      "epoch 160, batch 12, d_loss=0.023 g_loss=0.220 KID= 0.08692\n",
      "epoch 160, batch 13, d_loss=0.034 g_loss=0.243 KID= 0.08692\n",
      "epoch 160, batch 14, d_loss=-0.047 g_loss=0.282 KID= 0.08692\n",
      "epoch 160, batch 15, d_loss=0.046 g_loss=0.274 KID= 0.08692\n",
      "epoch 160, batch 16, d_loss=0.083 g_loss=0.294 KID= 0.08692\n",
      "epoch 160, batch 17, d_loss=0.118 g_loss=0.294 KID= 0.08692\n",
      "epoch 160, batch 18, d_loss=0.178 g_loss=0.345 KID= 0.08692\n",
      "epoch 160, batch 19, d_loss=0.175 g_loss=0.428 KID= 0.08692\n",
      "epoch 161, batch 0, d_loss=0.161 g_loss=0.521 KID= 0.08692\n",
      "epoch 161, batch 1, d_loss=0.059 g_loss=0.621 KID= 0.08692\n",
      "epoch 161, batch 2, d_loss=0.056 g_loss=0.673 KID= 0.08692\n",
      "epoch 161, batch 3, d_loss=-0.009 g_loss=0.711 KID= 0.08692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 161, batch 4, d_loss=0.102 g_loss=0.692 KID= 0.08692\n",
      "epoch 161, batch 5, d_loss=0.042 g_loss=0.663 KID= 0.08692\n",
      "epoch 161, batch 6, d_loss=0.077 g_loss=0.591 KID= 0.08692\n",
      "epoch 161, batch 7, d_loss=0.082 g_loss=0.548 KID= 0.08692\n",
      "epoch 161, batch 8, d_loss=0.051 g_loss=0.496 KID= 0.08692\n",
      "epoch 161, batch 9, d_loss=0.063 g_loss=0.410 KID= 0.08692\n",
      "epoch 161, batch 10, d_loss=0.133 g_loss=0.298 KID= 0.08692\n",
      "epoch 161, batch 11, d_loss=0.147 g_loss=0.209 KID= 0.08692\n",
      "epoch 161, batch 12, d_loss=0.071 g_loss=0.201 KID= 0.08692\n",
      "epoch 161, batch 13, d_loss=0.073 g_loss=0.152 KID= 0.08692\n",
      "epoch 161, batch 14, d_loss=0.048 g_loss=0.111 KID= 0.08692\n",
      "epoch 161, batch 15, d_loss=0.097 g_loss=0.130 KID= 0.08692\n",
      "epoch 161, batch 16, d_loss=0.041 g_loss=0.203 KID= 0.08692\n",
      "epoch 161, batch 17, d_loss=0.070 g_loss=0.258 KID= 0.08692\n",
      "epoch 161, batch 18, d_loss=-0.009 g_loss=0.266 KID= 0.08692\n",
      "epoch 161, batch 19, d_loss=0.090 g_loss=0.280 KID= 0.08692\n",
      "epoch 162, batch 0, d_loss=0.064 g_loss=0.276 KID= 0.08692\n",
      "epoch 162, batch 1, d_loss=0.045 g_loss=0.229 KID= 0.08692\n",
      "epoch 162, batch 2, d_loss=0.183 g_loss=0.177 KID= 0.08692\n",
      "epoch 162, batch 3, d_loss=0.163 g_loss=0.139 KID= 0.08692\n",
      "epoch 162, batch 4, d_loss=0.104 g_loss=0.101 KID= 0.08692\n",
      "epoch 162, batch 5, d_loss=0.058 g_loss=0.074 KID= 0.08692\n",
      "epoch 162, batch 6, d_loss=0.003 g_loss=0.056 KID= 0.08692\n",
      "epoch 162, batch 7, d_loss=-0.032 g_loss=0.028 KID= 0.08692\n",
      "epoch 162, batch 8, d_loss=-0.006 g_loss=0.030 KID= 0.08692\n",
      "epoch 162, batch 9, d_loss=-0.018 g_loss=0.005 KID= 0.08692\n",
      "epoch 162, batch 10, d_loss=0.151 g_loss=-0.025 KID= 0.08692\n",
      "epoch 162, batch 11, d_loss=0.235 g_loss=0.097 KID= 0.08692\n",
      "epoch 162, batch 12, d_loss=0.144 g_loss=0.350 KID= 0.08692\n",
      "epoch 162, batch 13, d_loss=0.044 g_loss=0.516 KID= 0.08692\n",
      "epoch 162, batch 14, d_loss=0.123 g_loss=0.569 KID= 0.08692\n",
      "epoch 162, batch 15, d_loss=0.095 g_loss=0.551 KID= 0.08692\n",
      "epoch 162, batch 16, d_loss=0.071 g_loss=0.521 KID= 0.08692\n",
      "epoch 162, batch 17, d_loss=0.003 g_loss=0.446 KID= 0.08692\n",
      "epoch 162, batch 18, d_loss=0.040 g_loss=0.367 KID= 0.08692\n",
      "epoch 162, batch 19, d_loss=0.091 g_loss=0.354 KID= 0.08692\n",
      "epoch 163, batch 0, d_loss=-0.003 g_loss=0.367 KID= 0.08692\n",
      "epoch 163, batch 1, d_loss=0.054 g_loss=0.435 KID= 0.08692\n",
      "epoch 163, batch 2, d_loss=0.176 g_loss=0.541 KID= 0.08692\n",
      "epoch 163, batch 3, d_loss=0.181 g_loss=0.625 KID= 0.08692\n",
      "epoch 163, batch 4, d_loss=0.097 g_loss=0.683 KID= 0.08692\n",
      "epoch 163, batch 5, d_loss=0.096 g_loss=0.714 KID= 0.08692\n",
      "epoch 163, batch 6, d_loss=0.055 g_loss=0.730 KID= 0.08692\n",
      "epoch 163, batch 7, d_loss=0.081 g_loss=0.701 KID= 0.08692\n",
      "epoch 163, batch 8, d_loss=0.007 g_loss=0.663 KID= 0.08692\n",
      "epoch 163, batch 9, d_loss=0.016 g_loss=0.565 KID= 0.08692\n",
      "epoch 163, batch 10, d_loss=0.250 g_loss=0.568 KID= 0.08692\n",
      "epoch 163, batch 11, d_loss=0.259 g_loss=0.629 KID= 0.08692\n",
      "epoch 163, batch 12, d_loss=0.119 g_loss=0.699 KID= 0.08692\n",
      "epoch 163, batch 13, d_loss=0.117 g_loss=0.708 KID= 0.08692\n",
      "epoch 163, batch 14, d_loss=0.123 g_loss=0.723 KID= 0.08692\n",
      "epoch 163, batch 15, d_loss=0.072 g_loss=0.718 KID= 0.08692\n",
      "epoch 163, batch 16, d_loss=0.116 g_loss=0.700 KID= 0.08692\n",
      "epoch 163, batch 17, d_loss=0.104 g_loss=0.680 KID= 0.08692\n",
      "epoch 163, batch 18, d_loss=0.025 g_loss=0.657 KID= 0.08692\n",
      "epoch 163, batch 19, d_loss=0.054 g_loss=0.654 KID= 0.08692\n",
      "epoch 164, batch 0, d_loss=-0.048 g_loss=0.672 KID= 0.08692\n",
      "epoch 164, batch 1, d_loss=-0.067 g_loss=0.681 KID= 0.08692\n",
      "epoch 164, batch 2, d_loss=0.103 g_loss=0.645 KID= 0.08692\n",
      "epoch 164, batch 3, d_loss=0.145 g_loss=0.605 KID= 0.08692\n",
      "epoch 164, batch 4, d_loss=0.094 g_loss=0.567 KID= 0.08692\n",
      "epoch 164, batch 5, d_loss=0.158 g_loss=0.520 KID= 0.08692\n",
      "epoch 164, batch 6, d_loss=0.091 g_loss=0.523 KID= 0.08692\n",
      "epoch 164, batch 7, d_loss=0.020 g_loss=0.510 KID= 0.08692\n",
      "epoch 164, batch 8, d_loss=-0.004 g_loss=0.466 KID= 0.08692\n",
      "epoch 164, batch 9, d_loss=-0.021 g_loss=0.423 KID= 0.08692\n",
      "epoch 164, batch 10, d_loss=0.146 g_loss=0.274 KID= 0.08692\n",
      "epoch 164, batch 11, d_loss=0.243 g_loss=0.174 KID= 0.08692\n",
      "epoch 164, batch 12, d_loss=0.090 g_loss=0.114 KID= 0.08692\n",
      "epoch 164, batch 13, d_loss=0.102 g_loss=0.090 KID= 0.08692\n",
      "epoch 164, batch 14, d_loss=0.115 g_loss=0.076 KID= 0.08692\n",
      "epoch 164, batch 15, d_loss=0.049 g_loss=0.095 KID= 0.08692\n",
      "epoch 164, batch 16, d_loss=0.040 g_loss=0.135 KID= 0.08692\n",
      "epoch 164, batch 17, d_loss=0.056 g_loss=0.165 KID= 0.08692\n",
      "epoch 164, batch 18, d_loss=0.027 g_loss=0.179 KID= 0.08692\n",
      "epoch 164, batch 19, d_loss=0.058 g_loss=0.178 KID= 0.08692\n",
      "epoch 165, batch 0, d_loss=0.101 g_loss=0.137 KID= 0.08692\n",
      "epoch 165, batch 1, d_loss=0.063 g_loss=0.095 KID= 0.08692\n",
      "epoch 165, batch 2, d_loss=0.183 g_loss=0.096 KID= 0.08692\n",
      "epoch 165, batch 3, d_loss=0.201 g_loss=0.115 KID= 0.08692\n",
      "epoch 165, batch 4, d_loss=0.078 g_loss=0.198 KID= 0.08692\n",
      "epoch 165, batch 5, d_loss=0.021 g_loss=0.294 KID= 0.08692\n",
      "epoch 165, batch 6, d_loss=-0.019 g_loss=0.344 KID= 0.08692\n",
      "epoch 165, batch 7, d_loss=-0.085 g_loss=0.385 KID= 0.08692\n",
      "epoch 165, batch 8, d_loss=-0.059 g_loss=0.384 KID= 0.08692\n",
      "epoch 165, batch 9, d_loss=0.035 g_loss=0.324 KID= 0.08692\n",
      "epoch 165, batch 10, d_loss=0.146 g_loss=0.335 KID= 0.08692\n",
      "epoch 165, batch 11, d_loss=0.290 g_loss=0.367 KID= 0.08692\n",
      "epoch 165, batch 12, d_loss=0.139 g_loss=0.428 KID= 0.08692\n",
      "epoch 165, batch 13, d_loss=0.128 g_loss=0.409 KID= 0.08692\n",
      "epoch 165, batch 14, d_loss=0.202 g_loss=0.376 KID= 0.08692\n",
      "epoch 165, batch 15, d_loss=0.176 g_loss=0.357 KID= 0.08692\n",
      "epoch 165, batch 16, d_loss=0.169 g_loss=0.395 KID= 0.08692\n",
      "epoch 165, batch 17, d_loss=0.104 g_loss=0.437 KID= 0.08692\n",
      "epoch 165, batch 18, d_loss=0.118 g_loss=0.479 KID= 0.08692\n",
      "epoch 165, batch 19, d_loss=0.107 g_loss=0.533 KID= 0.08692\n",
      "epoch 166, batch 0, d_loss=0.066 g_loss=0.576 KID= 0.08692\n",
      "epoch 166, batch 1, d_loss=0.027 g_loss=0.608 KID= 0.08692\n",
      "epoch 166, batch 2, d_loss=0.054 g_loss=0.635 KID= 0.08692\n",
      "epoch 166, batch 3, d_loss=0.088 g_loss=0.566 KID= 0.08692\n",
      "epoch 166, batch 4, d_loss=0.020 g_loss=0.547 KID= 0.08692\n",
      "epoch 166, batch 5, d_loss=0.136 g_loss=0.503 KID= 0.08692\n",
      "epoch 166, batch 6, d_loss=0.091 g_loss=0.479 KID= 0.08692\n",
      "epoch 166, batch 7, d_loss=0.162 g_loss=0.495 KID= 0.08692\n",
      "epoch 166, batch 8, d_loss=0.014 g_loss=0.508 KID= 0.08692\n",
      "epoch 166, batch 9, d_loss=0.040 g_loss=0.505 KID= 0.08692\n",
      "epoch 166, batch 10, d_loss=0.108 g_loss=0.521 KID= 0.08692\n",
      "epoch 166, batch 11, d_loss=0.046 g_loss=0.500 KID= 0.08692\n",
      "epoch 166, batch 12, d_loss=0.038 g_loss=0.491 KID= 0.08692\n",
      "epoch 166, batch 13, d_loss=0.069 g_loss=0.467 KID= 0.08692\n",
      "epoch 166, batch 14, d_loss=0.084 g_loss=0.458 KID= 0.08692\n",
      "epoch 166, batch 15, d_loss=0.023 g_loss=0.424 KID= 0.08692\n",
      "epoch 166, batch 16, d_loss=0.026 g_loss=0.424 KID= 0.08692\n",
      "epoch 166, batch 17, d_loss=-0.022 g_loss=0.448 KID= 0.08692\n",
      "epoch 166, batch 18, d_loss=0.009 g_loss=0.463 KID= 0.08692\n",
      "epoch 166, batch 19, d_loss=0.088 g_loss=0.490 KID= 0.08692\n",
      "epoch 167, batch 0, d_loss=0.172 g_loss=0.576 KID= 0.08692\n",
      "epoch 167, batch 1, d_loss=0.078 g_loss=0.603 KID= 0.08692\n",
      "epoch 167, batch 2, d_loss=0.120 g_loss=0.627 KID= 0.08692\n",
      "epoch 167, batch 3, d_loss=0.121 g_loss=0.620 KID= 0.08692\n",
      "epoch 167, batch 4, d_loss=0.006 g_loss=0.647 KID= 0.08692\n",
      "epoch 167, batch 5, d_loss=0.053 g_loss=0.725 KID= 0.08692\n",
      "epoch 167, batch 6, d_loss=0.037 g_loss=0.824 KID= 0.08692\n",
      "epoch 167, batch 7, d_loss=-0.006 g_loss=1.047 KID= 0.08692\n",
      "epoch 167, batch 8, d_loss=-0.064 g_loss=1.264 KID= 0.08692\n",
      "epoch 167, batch 9, d_loss=-0.147 g_loss=1.509 KID= 0.08692\n",
      "epoch 167, batch 10, d_loss=-0.020 g_loss=1.714 KID= 0.08692\n",
      "epoch 167, batch 11, d_loss=0.093 g_loss=1.713 KID= 0.08692\n",
      "epoch 167, batch 12, d_loss=0.030 g_loss=1.583 KID= 0.08692\n",
      "epoch 167, batch 13, d_loss=0.167 g_loss=1.318 KID= 0.08692\n",
      "epoch 167, batch 14, d_loss=0.289 g_loss=0.990 KID= 0.08692\n",
      "epoch 167, batch 15, d_loss=0.185 g_loss=0.666 KID= 0.08692\n",
      "epoch 167, batch 16, d_loss=0.164 g_loss=0.425 KID= 0.08692\n",
      "epoch 167, batch 17, d_loss=0.095 g_loss=0.237 KID= 0.08692\n",
      "epoch 167, batch 18, d_loss=0.083 g_loss=0.095 KID= 0.08692\n",
      "epoch 167, batch 19, d_loss=0.052 g_loss=0.022 KID= 0.08692\n",
      "epoch 168, batch 0, d_loss=0.009 g_loss=-0.033 KID= 0.08692\n",
      "epoch 168, batch 1, d_loss=-0.046 g_loss=-0.103 KID= 0.08692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168, batch 2, d_loss=0.060 g_loss=-0.122 KID= 0.08692\n",
      "epoch 168, batch 3, d_loss=0.099 g_loss=-0.122 KID= 0.08692\n",
      "epoch 168, batch 4, d_loss=0.023 g_loss=-0.123 KID= 0.08692\n",
      "epoch 168, batch 5, d_loss=0.080 g_loss=-0.124 KID= 0.08692\n",
      "epoch 168, batch 6, d_loss=0.056 g_loss=-0.099 KID= 0.08692\n",
      "epoch 168, batch 7, d_loss=0.167 g_loss=-0.062 KID= 0.08692\n",
      "epoch 168, batch 8, d_loss=-0.005 g_loss=-0.038 KID= 0.08692\n",
      "epoch 168, batch 9, d_loss=0.006 g_loss=-0.044 KID= 0.08692\n",
      "epoch 168, batch 10, d_loss=0.135 g_loss=0.008 KID= 0.08692\n",
      "epoch 168, batch 11, d_loss=0.105 g_loss=0.054 KID= 0.08692\n",
      "epoch 168, batch 12, d_loss=0.115 g_loss=0.067 KID= 0.08692\n",
      "epoch 168, batch 13, d_loss=0.081 g_loss=0.067 KID= 0.08692\n",
      "epoch 168, batch 14, d_loss=0.171 g_loss=0.074 KID= 0.08692\n",
      "epoch 168, batch 15, d_loss=0.180 g_loss=0.099 KID= 0.08692\n",
      "epoch 168, batch 16, d_loss=0.159 g_loss=0.122 KID= 0.08692\n",
      "epoch 168, batch 17, d_loss=0.167 g_loss=0.196 KID= 0.08692\n",
      "epoch 168, batch 18, d_loss=0.169 g_loss=0.243 KID= 0.08692\n",
      "epoch 168, batch 19, d_loss=0.098 g_loss=0.320 KID= 0.08692\n",
      "epoch 169, batch 0, d_loss=0.123 g_loss=0.430 KID= 0.08692\n",
      "epoch 169, batch 1, d_loss=0.044 g_loss=0.555 KID= 0.08692\n",
      "epoch 169, batch 2, d_loss=0.021 g_loss=0.656 KID= 0.08692\n",
      "epoch 169, batch 3, d_loss=0.027 g_loss=0.694 KID= 0.08692\n",
      "epoch 169, batch 4, d_loss=0.030 g_loss=0.698 KID= 0.08692\n",
      "epoch 169, batch 5, d_loss=0.048 g_loss=0.717 KID= 0.08692\n",
      "epoch 169, batch 6, d_loss=0.071 g_loss=0.675 KID= 0.08692\n",
      "epoch 169, batch 7, d_loss=0.122 g_loss=0.746 KID= 0.08692\n",
      "epoch 169, batch 8, d_loss=0.077 g_loss=0.730 KID= 0.08692\n",
      "epoch 169, batch 9, d_loss=0.072 g_loss=0.690 KID= 0.08692\n",
      "epoch 169, batch 10, d_loss=0.080 g_loss=0.716 KID= 0.08692\n",
      "epoch 169, batch 11, d_loss=0.020 g_loss=0.719 KID= 0.08692\n",
      "epoch 169, batch 12, d_loss=0.051 g_loss=0.635 KID= 0.08692\n",
      "epoch 169, batch 13, d_loss=0.077 g_loss=0.550 KID= 0.08692\n",
      "epoch 169, batch 14, d_loss=0.050 g_loss=0.444 KID= 0.08692\n",
      "epoch 169, batch 15, d_loss=0.105 g_loss=0.379 KID= 0.08692\n",
      "epoch 169, batch 16, d_loss=0.107 g_loss=0.316 KID= 0.08692\n",
      "epoch 169, batch 17, d_loss=0.090 g_loss=0.315 KID= 0.08692\n",
      "epoch 169, batch 18, d_loss=0.103 g_loss=0.278 KID= 0.08692\n",
      "epoch 169, batch 19, d_loss=0.142 g_loss=0.277 KID= 0.08692\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 170, batch 0, d_loss=0.079 g_loss=0.308 KID= 0.08526\n",
      "epoch 170, batch 1, d_loss=0.057 g_loss=0.343 KID= 0.08526\n",
      "epoch 170, batch 2, d_loss=0.043 g_loss=0.357 KID= 0.08526\n",
      "epoch 170, batch 3, d_loss=0.059 g_loss=0.326 KID= 0.08526\n",
      "epoch 170, batch 4, d_loss=0.020 g_loss=0.296 KID= 0.08526\n",
      "epoch 170, batch 5, d_loss=-0.018 g_loss=0.281 KID= 0.08526\n",
      "epoch 170, batch 6, d_loss=0.102 g_loss=0.197 KID= 0.08526\n",
      "epoch 170, batch 7, d_loss=0.062 g_loss=0.210 KID= 0.08526\n",
      "epoch 170, batch 8, d_loss=0.138 g_loss=0.156 KID= 0.08526\n",
      "epoch 170, batch 9, d_loss=0.112 g_loss=0.129 KID= 0.08526\n",
      "epoch 170, batch 10, d_loss=0.194 g_loss=0.173 KID= 0.08526\n",
      "epoch 170, batch 11, d_loss=0.141 g_loss=0.184 KID= 0.08526\n",
      "epoch 170, batch 12, d_loss=0.072 g_loss=0.165 KID= 0.08526\n",
      "epoch 170, batch 13, d_loss=0.065 g_loss=0.146 KID= 0.08526\n",
      "epoch 170, batch 14, d_loss=0.040 g_loss=0.120 KID= 0.08526\n",
      "epoch 170, batch 15, d_loss=0.097 g_loss=0.139 KID= 0.08526\n",
      "epoch 170, batch 16, d_loss=0.002 g_loss=0.124 KID= 0.08526\n",
      "epoch 170, batch 17, d_loss=0.090 g_loss=0.157 KID= 0.08526\n",
      "epoch 170, batch 18, d_loss=0.002 g_loss=0.143 KID= 0.08526\n",
      "epoch 170, batch 19, d_loss=0.091 g_loss=0.170 KID= 0.08526\n",
      "epoch 171, batch 0, d_loss=0.048 g_loss=0.213 KID= 0.08526\n",
      "epoch 171, batch 1, d_loss=0.035 g_loss=0.262 KID= 0.08526\n",
      "epoch 171, batch 2, d_loss=0.084 g_loss=0.316 KID= 0.08526\n",
      "epoch 171, batch 3, d_loss=0.116 g_loss=0.413 KID= 0.08526\n",
      "epoch 171, batch 4, d_loss=0.014 g_loss=0.552 KID= 0.08526\n",
      "epoch 171, batch 5, d_loss=0.042 g_loss=0.670 KID= 0.08526\n",
      "epoch 171, batch 6, d_loss=0.023 g_loss=0.746 KID= 0.08526\n",
      "epoch 171, batch 7, d_loss=-0.074 g_loss=0.808 KID= 0.08526\n",
      "epoch 171, batch 8, d_loss=0.077 g_loss=0.747 KID= 0.08526\n",
      "epoch 171, batch 9, d_loss=-0.013 g_loss=0.668 KID= 0.08526\n",
      "epoch 171, batch 10, d_loss=0.079 g_loss=0.581 KID= 0.08526\n",
      "epoch 171, batch 11, d_loss=0.180 g_loss=0.475 KID= 0.08526\n",
      "epoch 171, batch 12, d_loss=0.192 g_loss=0.377 KID= 0.08526\n",
      "epoch 171, batch 13, d_loss=0.158 g_loss=0.282 KID= 0.08526\n",
      "epoch 171, batch 14, d_loss=0.153 g_loss=0.214 KID= 0.08526\n",
      "epoch 171, batch 15, d_loss=0.083 g_loss=0.223 KID= 0.08526\n",
      "epoch 171, batch 16, d_loss=-0.001 g_loss=0.219 KID= 0.08526\n",
      "epoch 171, batch 17, d_loss=0.054 g_loss=0.254 KID= 0.08526\n",
      "epoch 171, batch 18, d_loss=-0.061 g_loss=0.269 KID= 0.08526\n",
      "epoch 171, batch 19, d_loss=0.009 g_loss=0.258 KID= 0.08526\n",
      "epoch 172, batch 0, d_loss=0.133 g_loss=0.289 KID= 0.08526\n",
      "epoch 172, batch 1, d_loss=0.077 g_loss=0.374 KID= 0.08526\n",
      "epoch 172, batch 2, d_loss=0.105 g_loss=0.426 KID= 0.08526\n",
      "epoch 172, batch 3, d_loss=0.128 g_loss=0.516 KID= 0.08526\n",
      "epoch 172, batch 4, d_loss=0.134 g_loss=0.630 KID= 0.08526\n",
      "epoch 172, batch 5, d_loss=0.115 g_loss=0.738 KID= 0.08526\n",
      "epoch 172, batch 6, d_loss=0.095 g_loss=0.805 KID= 0.08526\n",
      "epoch 172, batch 7, d_loss=0.016 g_loss=0.891 KID= 0.08526\n",
      "epoch 172, batch 8, d_loss=0.060 g_loss=0.922 KID= 0.08526\n",
      "epoch 172, batch 9, d_loss=0.011 g_loss=0.972 KID= 0.08526\n",
      "epoch 172, batch 10, d_loss=0.052 g_loss=0.942 KID= 0.08526\n",
      "epoch 172, batch 11, d_loss=0.057 g_loss=0.858 KID= 0.08526\n",
      "epoch 172, batch 12, d_loss=0.023 g_loss=0.717 KID= 0.08526\n",
      "epoch 172, batch 13, d_loss=0.128 g_loss=0.604 KID= 0.08526\n",
      "epoch 172, batch 14, d_loss=0.031 g_loss=0.473 KID= 0.08526\n",
      "epoch 172, batch 15, d_loss=0.108 g_loss=0.348 KID= 0.08526\n",
      "epoch 172, batch 16, d_loss=0.125 g_loss=0.276 KID= 0.08526\n",
      "epoch 172, batch 17, d_loss=0.206 g_loss=0.278 KID= 0.08526\n",
      "epoch 172, batch 18, d_loss=0.122 g_loss=0.278 KID= 0.08526\n",
      "epoch 172, batch 19, d_loss=0.193 g_loss=0.341 KID= 0.08526\n",
      "epoch 173, batch 0, d_loss=0.227 g_loss=0.449 KID= 0.08526\n",
      "epoch 173, batch 1, d_loss=0.148 g_loss=0.570 KID= 0.08526\n",
      "epoch 173, batch 2, d_loss=0.112 g_loss=0.640 KID= 0.08526\n",
      "epoch 173, batch 3, d_loss=0.043 g_loss=0.699 KID= 0.08526\n",
      "epoch 173, batch 4, d_loss=0.102 g_loss=0.724 KID= 0.08526\n",
      "epoch 173, batch 5, d_loss=0.053 g_loss=0.689 KID= 0.08526\n",
      "epoch 173, batch 6, d_loss=0.041 g_loss=0.660 KID= 0.08526\n",
      "epoch 173, batch 7, d_loss=0.122 g_loss=0.657 KID= 0.08526\n",
      "epoch 173, batch 8, d_loss=0.137 g_loss=0.650 KID= 0.08526\n",
      "epoch 173, batch 9, d_loss=0.117 g_loss=0.625 KID= 0.08526\n",
      "epoch 173, batch 10, d_loss=0.123 g_loss=0.651 KID= 0.08526\n",
      "epoch 173, batch 11, d_loss=0.085 g_loss=0.681 KID= 0.08526\n",
      "epoch 173, batch 12, d_loss=0.068 g_loss=0.677 KID= 0.08526\n",
      "epoch 173, batch 13, d_loss=0.120 g_loss=0.673 KID= 0.08526\n",
      "epoch 173, batch 14, d_loss=0.025 g_loss=0.662 KID= 0.08526\n",
      "epoch 173, batch 15, d_loss=0.061 g_loss=0.626 KID= 0.08526\n",
      "epoch 173, batch 16, d_loss=0.081 g_loss=0.580 KID= 0.08526\n",
      "epoch 173, batch 17, d_loss=0.044 g_loss=0.569 KID= 0.08526\n",
      "epoch 173, batch 18, d_loss=0.045 g_loss=0.550 KID= 0.08526\n",
      "epoch 173, batch 19, d_loss=0.066 g_loss=0.513 KID= 0.08526\n",
      "epoch 174, batch 0, d_loss=0.050 g_loss=0.549 KID= 0.08526\n",
      "epoch 174, batch 1, d_loss=0.067 g_loss=0.612 KID= 0.08526\n",
      "epoch 174, batch 2, d_loss=0.071 g_loss=0.567 KID= 0.08526\n",
      "epoch 174, batch 3, d_loss=0.102 g_loss=0.455 KID= 0.08526\n",
      "epoch 174, batch 4, d_loss=0.047 g_loss=0.367 KID= 0.08526\n",
      "epoch 174, batch 5, d_loss=0.051 g_loss=0.264 KID= 0.08526\n",
      "epoch 174, batch 6, d_loss=0.039 g_loss=0.140 KID= 0.08526\n",
      "epoch 174, batch 7, d_loss=0.098 g_loss=0.146 KID= 0.08526\n",
      "epoch 174, batch 8, d_loss=0.069 g_loss=0.102 KID= 0.08526\n",
      "epoch 174, batch 9, d_loss=0.037 g_loss=0.046 KID= 0.08526\n",
      "epoch 174, batch 10, d_loss=0.203 g_loss=0.099 KID= 0.08526\n",
      "epoch 174, batch 11, d_loss=0.143 g_loss=0.244 KID= 0.08526\n",
      "epoch 174, batch 12, d_loss=0.051 g_loss=0.330 KID= 0.08526\n",
      "epoch 174, batch 13, d_loss=0.096 g_loss=0.358 KID= 0.08526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 174, batch 14, d_loss=0.052 g_loss=0.423 KID= 0.08526\n",
      "epoch 174, batch 15, d_loss=0.053 g_loss=0.472 KID= 0.08526\n",
      "epoch 174, batch 16, d_loss=0.032 g_loss=0.477 KID= 0.08526\n",
      "epoch 174, batch 17, d_loss=-0.018 g_loss=0.536 KID= 0.08526\n",
      "epoch 174, batch 18, d_loss=0.037 g_loss=0.546 KID= 0.08526\n",
      "epoch 174, batch 19, d_loss=0.057 g_loss=0.545 KID= 0.08526\n",
      "epoch 175, batch 0, d_loss=0.042 g_loss=0.569 KID= 0.08526\n",
      "epoch 175, batch 1, d_loss=0.082 g_loss=0.581 KID= 0.08526\n",
      "epoch 175, batch 2, d_loss=0.111 g_loss=0.598 KID= 0.08526\n",
      "epoch 175, batch 3, d_loss=0.158 g_loss=0.601 KID= 0.08526\n",
      "epoch 175, batch 4, d_loss=0.073 g_loss=0.574 KID= 0.08526\n",
      "epoch 175, batch 5, d_loss=0.061 g_loss=0.566 KID= 0.08526\n",
      "epoch 175, batch 6, d_loss=0.023 g_loss=0.525 KID= 0.08526\n",
      "epoch 175, batch 7, d_loss=0.105 g_loss=0.519 KID= 0.08526\n",
      "epoch 175, batch 8, d_loss=0.036 g_loss=0.524 KID= 0.08526\n",
      "epoch 175, batch 9, d_loss=0.111 g_loss=0.508 KID= 0.08526\n",
      "epoch 175, batch 10, d_loss=0.183 g_loss=0.565 KID= 0.08526\n",
      "epoch 175, batch 11, d_loss=0.174 g_loss=0.620 KID= 0.08526\n",
      "epoch 175, batch 12, d_loss=0.129 g_loss=0.593 KID= 0.08526\n",
      "epoch 175, batch 13, d_loss=0.081 g_loss=0.573 KID= 0.08526\n",
      "epoch 175, batch 14, d_loss=0.036 g_loss=0.518 KID= 0.08526\n",
      "epoch 175, batch 15, d_loss=0.008 g_loss=0.415 KID= 0.08526\n",
      "epoch 175, batch 16, d_loss=0.040 g_loss=0.282 KID= 0.08526\n",
      "epoch 175, batch 17, d_loss=-0.045 g_loss=0.223 KID= 0.08526\n",
      "epoch 175, batch 18, d_loss=0.043 g_loss=0.128 KID= 0.08526\n",
      "epoch 175, batch 19, d_loss=0.021 g_loss=-0.022 KID= 0.08526\n",
      "epoch 176, batch 0, d_loss=0.083 g_loss=-0.105 KID= 0.08526\n",
      "epoch 176, batch 1, d_loss=0.134 g_loss=-0.099 KID= 0.08526\n",
      "epoch 176, batch 2, d_loss=0.222 g_loss=-0.026 KID= 0.08526\n",
      "epoch 176, batch 3, d_loss=0.257 g_loss=0.125 KID= 0.08526\n",
      "epoch 176, batch 4, d_loss=0.098 g_loss=0.268 KID= 0.08526\n",
      "epoch 176, batch 5, d_loss=0.146 g_loss=0.313 KID= 0.08526\n",
      "epoch 176, batch 6, d_loss=0.125 g_loss=0.275 KID= 0.08526\n",
      "epoch 176, batch 7, d_loss=0.141 g_loss=0.263 KID= 0.08526\n",
      "epoch 176, batch 8, d_loss=0.017 g_loss=0.236 KID= 0.08526\n",
      "epoch 176, batch 9, d_loss=-0.014 g_loss=0.175 KID= 0.08526\n",
      "epoch 176, batch 10, d_loss=0.044 g_loss=0.156 KID= 0.08526\n",
      "epoch 176, batch 11, d_loss=0.139 g_loss=0.186 KID= 0.08526\n",
      "epoch 176, batch 12, d_loss=0.047 g_loss=0.166 KID= 0.08526\n",
      "epoch 176, batch 13, d_loss=0.016 g_loss=0.081 KID= 0.08526\n",
      "epoch 176, batch 14, d_loss=0.098 g_loss=0.075 KID= 0.08526\n",
      "epoch 176, batch 15, d_loss=0.033 g_loss=0.053 KID= 0.08526\n",
      "epoch 176, batch 16, d_loss=-0.006 g_loss=0.037 KID= 0.08526\n",
      "epoch 176, batch 17, d_loss=0.034 g_loss=0.055 KID= 0.08526\n",
      "epoch 176, batch 18, d_loss=0.027 g_loss=0.014 KID= 0.08526\n",
      "epoch 176, batch 19, d_loss=0.037 g_loss=-0.039 KID= 0.08526\n",
      "epoch 177, batch 0, d_loss=0.077 g_loss=-0.076 KID= 0.08526\n",
      "epoch 177, batch 1, d_loss=0.017 g_loss=-0.109 KID= 0.08526\n",
      "epoch 177, batch 2, d_loss=0.075 g_loss=-0.098 KID= 0.08526\n",
      "epoch 177, batch 3, d_loss=0.149 g_loss=-0.100 KID= 0.08526\n",
      "epoch 177, batch 4, d_loss=0.080 g_loss=-0.072 KID= 0.08526\n",
      "epoch 177, batch 5, d_loss=0.086 g_loss=-0.001 KID= 0.08526\n",
      "epoch 177, batch 6, d_loss=0.058 g_loss=0.048 KID= 0.08526\n",
      "epoch 177, batch 7, d_loss=0.053 g_loss=0.124 KID= 0.08526\n",
      "epoch 177, batch 8, d_loss=0.032 g_loss=0.202 KID= 0.08526\n",
      "epoch 177, batch 9, d_loss=0.037 g_loss=0.236 KID= 0.08526\n",
      "epoch 177, batch 10, d_loss=-0.008 g_loss=0.294 KID= 0.08526\n",
      "epoch 177, batch 11, d_loss=0.064 g_loss=0.389 KID= 0.08526\n",
      "epoch 177, batch 12, d_loss=0.067 g_loss=0.433 KID= 0.08526\n",
      "epoch 177, batch 13, d_loss=0.073 g_loss=0.418 KID= 0.08526\n",
      "epoch 177, batch 14, d_loss=0.025 g_loss=0.442 KID= 0.08526\n",
      "epoch 177, batch 15, d_loss=0.012 g_loss=0.445 KID= 0.08526\n",
      "epoch 177, batch 16, d_loss=0.024 g_loss=0.417 KID= 0.08526\n",
      "epoch 177, batch 17, d_loss=0.040 g_loss=0.388 KID= 0.08526\n",
      "epoch 177, batch 18, d_loss=0.020 g_loss=0.360 KID= 0.08526\n",
      "epoch 177, batch 19, d_loss=0.012 g_loss=0.306 KID= 0.08526\n",
      "epoch 178, batch 0, d_loss=0.184 g_loss=0.243 KID= 0.08526\n",
      "epoch 178, batch 1, d_loss=0.174 g_loss=0.184 KID= 0.08526\n",
      "epoch 178, batch 2, d_loss=0.076 g_loss=0.182 KID= 0.08526\n",
      "epoch 178, batch 3, d_loss=0.141 g_loss=0.177 KID= 0.08526\n",
      "epoch 178, batch 4, d_loss=0.037 g_loss=0.224 KID= 0.08526\n",
      "epoch 178, batch 5, d_loss=0.058 g_loss=0.295 KID= 0.08526\n",
      "epoch 178, batch 6, d_loss=0.016 g_loss=0.332 KID= 0.08526\n",
      "epoch 178, batch 7, d_loss=0.037 g_loss=0.393 KID= 0.08526\n",
      "epoch 178, batch 8, d_loss=0.034 g_loss=0.459 KID= 0.08526\n",
      "epoch 178, batch 9, d_loss=0.031 g_loss=0.477 KID= 0.08526\n",
      "epoch 178, batch 10, d_loss=0.024 g_loss=0.468 KID= 0.08526\n",
      "epoch 178, batch 11, d_loss=0.021 g_loss=0.489 KID= 0.08526\n",
      "epoch 178, batch 12, d_loss=0.042 g_loss=0.488 KID= 0.08526\n",
      "epoch 178, batch 13, d_loss=0.097 g_loss=0.465 KID= 0.08526\n",
      "epoch 178, batch 14, d_loss=0.049 g_loss=0.456 KID= 0.08526\n",
      "epoch 178, batch 15, d_loss=0.058 g_loss=0.469 KID= 0.08526\n",
      "epoch 178, batch 16, d_loss=0.076 g_loss=0.478 KID= 0.08526\n",
      "epoch 178, batch 17, d_loss=0.108 g_loss=0.480 KID= 0.08526\n",
      "epoch 178, batch 18, d_loss=0.064 g_loss=0.510 KID= 0.08526\n",
      "epoch 178, batch 19, d_loss=0.021 g_loss=0.496 KID= 0.08526\n",
      "epoch 179, batch 0, d_loss=0.075 g_loss=0.575 KID= 0.08526\n",
      "epoch 179, batch 1, d_loss=0.083 g_loss=0.713 KID= 0.08526\n",
      "epoch 179, batch 2, d_loss=0.085 g_loss=0.741 KID= 0.08526\n",
      "epoch 179, batch 3, d_loss=0.100 g_loss=0.676 KID= 0.08526\n",
      "epoch 179, batch 4, d_loss=0.185 g_loss=0.657 KID= 0.08526\n",
      "epoch 179, batch 5, d_loss=0.201 g_loss=0.577 KID= 0.08526\n",
      "epoch 179, batch 6, d_loss=0.144 g_loss=0.512 KID= 0.08526\n",
      "epoch 179, batch 7, d_loss=0.141 g_loss=0.466 KID= 0.08526\n",
      "epoch 179, batch 8, d_loss=0.068 g_loss=0.402 KID= 0.08526\n",
      "epoch 179, batch 9, d_loss=0.071 g_loss=0.303 KID= 0.08526\n",
      "epoch 179, batch 10, d_loss=0.059 g_loss=0.270 KID= 0.08526\n",
      "epoch 179, batch 11, d_loss=0.033 g_loss=0.269 KID= 0.08526\n",
      "epoch 179, batch 12, d_loss=0.013 g_loss=0.205 KID= 0.08526\n",
      "epoch 179, batch 13, d_loss=0.089 g_loss=0.124 KID= 0.08526\n",
      "epoch 179, batch 14, d_loss=-0.004 g_loss=0.072 KID= 0.08526\n",
      "epoch 179, batch 15, d_loss=0.066 g_loss=0.063 KID= 0.08526\n",
      "epoch 179, batch 16, d_loss=0.084 g_loss=0.101 KID= 0.08526\n",
      "epoch 179, batch 17, d_loss=0.076 g_loss=0.200 KID= 0.08526\n",
      "epoch 179, batch 18, d_loss=0.057 g_loss=0.233 KID= 0.08526\n",
      "epoch 179, batch 19, d_loss=0.018 g_loss=0.229 KID= 0.08526\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 180, batch 0, d_loss=0.242 g_loss=0.235 KID= 0.10515\n",
      "epoch 180, batch 1, d_loss=0.178 g_loss=0.258 KID= 0.10515\n",
      "epoch 180, batch 2, d_loss=0.077 g_loss=0.267 KID= 0.10515\n",
      "epoch 180, batch 3, d_loss=0.056 g_loss=0.215 KID= 0.10515\n",
      "epoch 180, batch 4, d_loss=-0.003 g_loss=0.195 KID= 0.10515\n",
      "epoch 180, batch 5, d_loss=0.000 g_loss=0.154 KID= 0.10515\n",
      "epoch 180, batch 6, d_loss=-0.010 g_loss=0.093 KID= 0.10515\n",
      "epoch 180, batch 7, d_loss=0.007 g_loss=0.033 KID= 0.10515\n",
      "epoch 180, batch 8, d_loss=0.056 g_loss=-0.007 KID= 0.10515\n",
      "epoch 180, batch 9, d_loss=0.149 g_loss=-0.088 KID= 0.10515\n",
      "epoch 180, batch 10, d_loss=0.016 g_loss=-0.192 KID= 0.10515\n",
      "epoch 180, batch 11, d_loss=0.139 g_loss=-0.223 KID= 0.10515\n",
      "epoch 180, batch 12, d_loss=0.131 g_loss=-0.280 KID= 0.10515\n",
      "epoch 180, batch 13, d_loss=0.087 g_loss=-0.371 KID= 0.10515\n",
      "epoch 180, batch 14, d_loss=0.067 g_loss=-0.362 KID= 0.10515\n",
      "epoch 180, batch 15, d_loss=-0.002 g_loss=-0.366 KID= 0.10515\n",
      "epoch 180, batch 16, d_loss=-0.033 g_loss=-0.417 KID= 0.10515\n",
      "epoch 180, batch 17, d_loss=-0.015 g_loss=-0.447 KID= 0.10515\n",
      "epoch 180, batch 18, d_loss=0.016 g_loss=-0.518 KID= 0.10515\n",
      "epoch 180, batch 19, d_loss=-0.028 g_loss=-0.649 KID= 0.10515\n",
      "epoch 181, batch 0, d_loss=0.282 g_loss=-0.569 KID= 0.10515\n",
      "epoch 181, batch 1, d_loss=0.219 g_loss=-0.466 KID= 0.10515\n",
      "epoch 181, batch 2, d_loss=0.124 g_loss=-0.442 KID= 0.10515\n",
      "epoch 181, batch 3, d_loss=0.150 g_loss=-0.447 KID= 0.10515\n",
      "epoch 181, batch 4, d_loss=0.114 g_loss=-0.424 KID= 0.10515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 181, batch 5, d_loss=0.088 g_loss=-0.393 KID= 0.10515\n",
      "epoch 181, batch 6, d_loss=0.025 g_loss=-0.401 KID= 0.10515\n",
      "epoch 181, batch 7, d_loss=0.049 g_loss=-0.368 KID= 0.10515\n",
      "epoch 181, batch 8, d_loss=0.018 g_loss=-0.355 KID= 0.10515\n",
      "epoch 181, batch 9, d_loss=0.076 g_loss=-0.285 KID= 0.10515\n",
      "epoch 181, batch 10, d_loss=0.021 g_loss=-0.282 KID= 0.10515\n",
      "epoch 181, batch 11, d_loss=0.044 g_loss=-0.237 KID= 0.10515\n",
      "epoch 181, batch 12, d_loss=0.117 g_loss=-0.179 KID= 0.10515\n",
      "epoch 181, batch 13, d_loss=0.177 g_loss=-0.156 KID= 0.10515\n",
      "epoch 181, batch 14, d_loss=0.006 g_loss=-0.116 KID= 0.10515\n",
      "epoch 181, batch 15, d_loss=0.055 g_loss=-0.081 KID= 0.10515\n",
      "epoch 181, batch 16, d_loss=0.051 g_loss=-0.088 KID= 0.10515\n",
      "epoch 181, batch 17, d_loss=0.019 g_loss=-0.095 KID= 0.10515\n",
      "epoch 181, batch 18, d_loss=0.017 g_loss=-0.115 KID= 0.10515\n",
      "epoch 181, batch 19, d_loss=0.035 g_loss=-0.136 KID= 0.10515\n",
      "epoch 182, batch 0, d_loss=0.130 g_loss=-0.129 KID= 0.10515\n",
      "epoch 182, batch 1, d_loss=0.185 g_loss=-0.081 KID= 0.10515\n",
      "epoch 182, batch 2, d_loss=0.107 g_loss=-0.057 KID= 0.10515\n",
      "epoch 182, batch 3, d_loss=0.079 g_loss=-0.099 KID= 0.10515\n",
      "epoch 182, batch 4, d_loss=0.195 g_loss=-0.086 KID= 0.10515\n",
      "epoch 182, batch 5, d_loss=0.122 g_loss=-0.071 KID= 0.10515\n",
      "epoch 182, batch 6, d_loss=0.070 g_loss=-0.005 KID= 0.10515\n",
      "epoch 182, batch 7, d_loss=0.115 g_loss=0.077 KID= 0.10515\n",
      "epoch 182, batch 8, d_loss=0.065 g_loss=0.198 KID= 0.10515\n",
      "epoch 182, batch 9, d_loss=0.055 g_loss=0.310 KID= 0.10515\n",
      "epoch 182, batch 10, d_loss=-0.006 g_loss=0.418 KID= 0.10515\n",
      "epoch 182, batch 11, d_loss=-0.045 g_loss=0.579 KID= 0.10515\n",
      "epoch 182, batch 12, d_loss=-0.007 g_loss=0.691 KID= 0.10515\n",
      "epoch 182, batch 13, d_loss=0.103 g_loss=0.734 KID= 0.10515\n",
      "epoch 182, batch 14, d_loss=-0.059 g_loss=0.761 KID= 0.10515\n",
      "epoch 182, batch 15, d_loss=0.104 g_loss=0.699 KID= 0.10515\n",
      "epoch 182, batch 16, d_loss=0.188 g_loss=0.579 KID= 0.10515\n",
      "epoch 182, batch 17, d_loss=0.059 g_loss=0.484 KID= 0.10515\n",
      "epoch 182, batch 18, d_loss=-0.003 g_loss=0.428 KID= 0.10515\n",
      "epoch 182, batch 19, d_loss=0.074 g_loss=0.330 KID= 0.10515\n",
      "epoch 183, batch 0, d_loss=0.188 g_loss=0.215 KID= 0.10515\n",
      "epoch 183, batch 1, d_loss=0.130 g_loss=0.240 KID= 0.10515\n",
      "epoch 183, batch 2, d_loss=0.080 g_loss=0.236 KID= 0.10515\n",
      "epoch 183, batch 3, d_loss=0.060 g_loss=0.163 KID= 0.10515\n",
      "epoch 183, batch 4, d_loss=0.035 g_loss=0.107 KID= 0.10515\n",
      "epoch 183, batch 5, d_loss=0.031 g_loss=0.060 KID= 0.10515\n",
      "epoch 183, batch 6, d_loss=-0.058 g_loss=-0.077 KID= 0.10515\n",
      "epoch 183, batch 7, d_loss=0.044 g_loss=-0.167 KID= 0.10515\n",
      "epoch 183, batch 8, d_loss=0.099 g_loss=-0.201 KID= 0.10515\n",
      "epoch 183, batch 9, d_loss=0.070 g_loss=-0.249 KID= 0.10515\n",
      "epoch 183, batch 10, d_loss=-0.008 g_loss=-0.315 KID= 0.10515\n",
      "epoch 183, batch 11, d_loss=0.069 g_loss=-0.305 KID= 0.10515\n",
      "epoch 183, batch 12, d_loss=0.131 g_loss=-0.253 KID= 0.10515\n",
      "epoch 183, batch 13, d_loss=0.132 g_loss=-0.250 KID= 0.10515\n",
      "epoch 183, batch 14, d_loss=0.007 g_loss=-0.210 KID= 0.10515\n",
      "epoch 183, batch 15, d_loss=0.029 g_loss=-0.197 KID= 0.10515\n",
      "epoch 183, batch 16, d_loss=0.049 g_loss=-0.203 KID= 0.10515\n",
      "epoch 183, batch 17, d_loss=0.021 g_loss=-0.185 KID= 0.10515\n",
      "epoch 183, batch 18, d_loss=-0.056 g_loss=-0.185 KID= 0.10515\n",
      "epoch 183, batch 19, d_loss=-0.031 g_loss=-0.183 KID= 0.10515\n",
      "epoch 184, batch 0, d_loss=0.167 g_loss=-0.148 KID= 0.10515\n",
      "epoch 184, batch 1, d_loss=0.134 g_loss=-0.043 KID= 0.10515\n",
      "epoch 184, batch 2, d_loss=-0.001 g_loss=0.007 KID= 0.10515\n",
      "epoch 184, batch 3, d_loss=0.088 g_loss=0.031 KID= 0.10515\n",
      "epoch 184, batch 4, d_loss=0.150 g_loss=0.025 KID= 0.10515\n",
      "epoch 184, batch 5, d_loss=0.092 g_loss=0.022 KID= 0.10515\n",
      "epoch 184, batch 6, d_loss=0.116 g_loss=0.037 KID= 0.10515\n",
      "epoch 184, batch 7, d_loss=0.109 g_loss=0.092 KID= 0.10515\n",
      "epoch 184, batch 8, d_loss=0.125 g_loss=0.170 KID= 0.10515\n",
      "epoch 184, batch 9, d_loss=0.122 g_loss=0.214 KID= 0.10515\n",
      "epoch 184, batch 10, d_loss=0.059 g_loss=0.260 KID= 0.10515\n",
      "epoch 184, batch 11, d_loss=0.022 g_loss=0.329 KID= 0.10515\n",
      "epoch 184, batch 12, d_loss=0.115 g_loss=0.303 KID= 0.10515\n",
      "epoch 184, batch 13, d_loss=0.121 g_loss=0.220 KID= 0.10515\n",
      "epoch 184, batch 14, d_loss=0.009 g_loss=0.163 KID= 0.10515\n",
      "epoch 184, batch 15, d_loss=0.105 g_loss=0.130 KID= 0.10515\n",
      "epoch 184, batch 16, d_loss=0.126 g_loss=0.069 KID= 0.10515\n",
      "epoch 184, batch 17, d_loss=0.082 g_loss=0.004 KID= 0.10515\n",
      "epoch 184, batch 18, d_loss=0.031 g_loss=-0.024 KID= 0.10515\n",
      "epoch 184, batch 19, d_loss=0.046 g_loss=-0.097 KID= 0.10515\n",
      "epoch 185, batch 0, d_loss=0.101 g_loss=-0.147 KID= 0.10515\n",
      "epoch 185, batch 1, d_loss=0.086 g_loss=-0.163 KID= 0.10515\n",
      "epoch 185, batch 2, d_loss=0.066 g_loss=-0.180 KID= 0.10515\n",
      "epoch 185, batch 3, d_loss=0.029 g_loss=-0.207 KID= 0.10515\n",
      "epoch 185, batch 4, d_loss=0.053 g_loss=-0.240 KID= 0.10515\n",
      "epoch 185, batch 5, d_loss=0.002 g_loss=-0.305 KID= 0.10515\n",
      "epoch 185, batch 6, d_loss=-0.021 g_loss=-0.357 KID= 0.10515\n",
      "epoch 185, batch 7, d_loss=0.044 g_loss=-0.418 KID= 0.10515\n",
      "epoch 185, batch 8, d_loss=0.129 g_loss=-0.364 KID= 0.10515\n",
      "epoch 185, batch 9, d_loss=0.104 g_loss=-0.288 KID= 0.10515\n",
      "epoch 185, batch 10, d_loss=0.128 g_loss=-0.149 KID= 0.10515\n",
      "epoch 185, batch 11, d_loss=0.121 g_loss=0.014 KID= 0.10515\n",
      "epoch 185, batch 12, d_loss=0.036 g_loss=0.104 KID= 0.10515\n",
      "epoch 185, batch 13, d_loss=0.055 g_loss=0.117 KID= 0.10515\n",
      "epoch 185, batch 14, d_loss=-0.017 g_loss=0.138 KID= 0.10515\n",
      "epoch 185, batch 15, d_loss=0.031 g_loss=0.179 KID= 0.10515\n",
      "epoch 185, batch 16, d_loss=0.048 g_loss=0.213 KID= 0.10515\n",
      "epoch 185, batch 17, d_loss=0.021 g_loss=0.258 KID= 0.10515\n",
      "epoch 185, batch 18, d_loss=0.036 g_loss=0.287 KID= 0.10515\n",
      "epoch 185, batch 19, d_loss=0.039 g_loss=0.349 KID= 0.10515\n",
      "epoch 186, batch 0, d_loss=0.029 g_loss=0.323 KID= 0.10515\n",
      "epoch 186, batch 1, d_loss=-0.056 g_loss=0.291 KID= 0.10515\n",
      "epoch 186, batch 2, d_loss=0.190 g_loss=0.304 KID= 0.10515\n",
      "epoch 186, batch 3, d_loss=0.194 g_loss=0.263 KID= 0.10515\n",
      "epoch 186, batch 4, d_loss=0.064 g_loss=0.222 KID= 0.10515\n",
      "epoch 186, batch 5, d_loss=0.099 g_loss=0.189 KID= 0.10515\n",
      "epoch 186, batch 6, d_loss=0.045 g_loss=0.121 KID= 0.10515\n",
      "epoch 186, batch 7, d_loss=-0.005 g_loss=0.059 KID= 0.10515\n",
      "epoch 186, batch 8, d_loss=0.032 g_loss=0.019 KID= 0.10515\n",
      "epoch 186, batch 9, d_loss=0.008 g_loss=-0.034 KID= 0.10515\n",
      "epoch 186, batch 10, d_loss=0.062 g_loss=-0.094 KID= 0.10515\n",
      "epoch 186, batch 11, d_loss=0.192 g_loss=-0.106 KID= 0.10515\n",
      "epoch 186, batch 12, d_loss=-0.023 g_loss=-0.174 KID= 0.10515\n",
      "epoch 186, batch 13, d_loss=0.080 g_loss=-0.236 KID= 0.10515\n",
      "epoch 186, batch 14, d_loss=0.116 g_loss=-0.257 KID= 0.10515\n",
      "epoch 186, batch 15, d_loss=0.045 g_loss=-0.241 KID= 0.10515\n",
      "epoch 186, batch 16, d_loss=0.063 g_loss=-0.208 KID= 0.10515\n",
      "epoch 186, batch 17, d_loss=0.070 g_loss=-0.173 KID= 0.10515\n",
      "epoch 186, batch 18, d_loss=0.081 g_loss=-0.102 KID= 0.10515\n",
      "epoch 186, batch 19, d_loss=0.047 g_loss=-0.065 KID= 0.10515\n",
      "epoch 187, batch 0, d_loss=0.037 g_loss=-0.007 KID= 0.10515\n",
      "epoch 187, batch 1, d_loss=-0.023 g_loss=0.056 KID= 0.10515\n",
      "epoch 187, batch 2, d_loss=0.091 g_loss=0.099 KID= 0.10515\n",
      "epoch 187, batch 3, d_loss=0.090 g_loss=0.075 KID= 0.10515\n",
      "epoch 187, batch 4, d_loss=0.047 g_loss=0.043 KID= 0.10515\n",
      "epoch 187, batch 5, d_loss=0.094 g_loss=0.032 KID= 0.10515\n",
      "epoch 187, batch 6, d_loss=0.046 g_loss=-0.057 KID= 0.10515\n",
      "epoch 187, batch 7, d_loss=0.088 g_loss=-0.105 KID= 0.10515\n",
      "epoch 187, batch 8, d_loss=0.061 g_loss=-0.140 KID= 0.10515\n",
      "epoch 187, batch 9, d_loss=0.048 g_loss=-0.155 KID= 0.10515\n",
      "epoch 187, batch 10, d_loss=0.053 g_loss=-0.174 KID= 0.10515\n",
      "epoch 187, batch 11, d_loss=0.078 g_loss=-0.149 KID= 0.10515\n",
      "epoch 187, batch 12, d_loss=0.043 g_loss=-0.153 KID= 0.10515\n",
      "epoch 187, batch 13, d_loss=0.014 g_loss=-0.157 KID= 0.10515\n",
      "epoch 187, batch 14, d_loss=0.092 g_loss=-0.109 KID= 0.10515\n",
      "epoch 187, batch 15, d_loss=0.063 g_loss=-0.095 KID= 0.10515\n",
      "epoch 187, batch 16, d_loss=0.080 g_loss=-0.046 KID= 0.10515\n",
      "epoch 187, batch 17, d_loss=0.011 g_loss=-0.008 KID= 0.10515\n",
      "epoch 187, batch 18, d_loss=0.036 g_loss=0.073 KID= 0.10515\n",
      "epoch 187, batch 19, d_loss=0.009 g_loss=0.109 KID= 0.10515\n",
      "epoch 188, batch 0, d_loss=0.092 g_loss=0.185 KID= 0.10515\n",
      "epoch 188, batch 1, d_loss=0.044 g_loss=0.299 KID= 0.10515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 188, batch 2, d_loss=0.047 g_loss=0.338 KID= 0.10515\n",
      "epoch 188, batch 3, d_loss=0.122 g_loss=0.315 KID= 0.10515\n",
      "epoch 188, batch 4, d_loss=0.057 g_loss=0.305 KID= 0.10515\n",
      "epoch 188, batch 5, d_loss=0.106 g_loss=0.306 KID= 0.10515\n",
      "epoch 188, batch 6, d_loss=0.109 g_loss=0.290 KID= 0.10515\n",
      "epoch 188, batch 7, d_loss=0.108 g_loss=0.270 KID= 0.10515\n",
      "epoch 188, batch 8, d_loss=0.096 g_loss=0.298 KID= 0.10515\n",
      "epoch 188, batch 9, d_loss=0.114 g_loss=0.282 KID= 0.10515\n",
      "epoch 188, batch 10, d_loss=0.046 g_loss=0.271 KID= 0.10515\n",
      "epoch 188, batch 11, d_loss=0.052 g_loss=0.267 KID= 0.10515\n",
      "epoch 188, batch 12, d_loss=0.134 g_loss=0.268 KID= 0.10515\n",
      "epoch 188, batch 13, d_loss=0.075 g_loss=0.259 KID= 0.10515\n",
      "epoch 188, batch 14, d_loss=0.074 g_loss=0.292 KID= 0.10515\n",
      "epoch 188, batch 15, d_loss=0.027 g_loss=0.299 KID= 0.10515\n",
      "epoch 188, batch 16, d_loss=0.010 g_loss=0.313 KID= 0.10515\n",
      "epoch 188, batch 17, d_loss=-0.085 g_loss=0.316 KID= 0.10515\n",
      "epoch 188, batch 18, d_loss=-0.099 g_loss=0.235 KID= 0.10515\n",
      "epoch 188, batch 19, d_loss=0.004 g_loss=0.138 KID= 0.10515\n",
      "epoch 189, batch 0, d_loss=0.306 g_loss=0.154 KID= 0.10515\n",
      "epoch 189, batch 1, d_loss=0.234 g_loss=0.305 KID= 0.10515\n",
      "epoch 189, batch 2, d_loss=0.046 g_loss=0.393 KID= 0.10515\n",
      "epoch 189, batch 3, d_loss=0.140 g_loss=0.352 KID= 0.10515\n",
      "epoch 189, batch 4, d_loss=0.169 g_loss=0.312 KID= 0.10515\n",
      "epoch 189, batch 5, d_loss=0.110 g_loss=0.304 KID= 0.10515\n",
      "epoch 189, batch 6, d_loss=0.052 g_loss=0.307 KID= 0.10515\n",
      "epoch 189, batch 7, d_loss=0.025 g_loss=0.299 KID= 0.10515\n",
      "epoch 189, batch 8, d_loss=0.033 g_loss=0.286 KID= 0.10515\n",
      "epoch 189, batch 9, d_loss=0.029 g_loss=0.242 KID= 0.10515\n",
      "epoch 189, batch 10, d_loss=0.037 g_loss=0.251 KID= 0.10515\n",
      "epoch 189, batch 11, d_loss=0.019 g_loss=0.274 KID= 0.10515\n",
      "epoch 189, batch 12, d_loss=0.082 g_loss=0.278 KID= 0.10515\n",
      "epoch 189, batch 13, d_loss=0.089 g_loss=0.202 KID= 0.10515\n",
      "epoch 189, batch 14, d_loss=0.078 g_loss=0.149 KID= 0.10515\n",
      "epoch 189, batch 15, d_loss=0.100 g_loss=0.127 KID= 0.10515\n",
      "epoch 189, batch 16, d_loss=0.090 g_loss=0.081 KID= 0.10515\n",
      "epoch 189, batch 17, d_loss=0.091 g_loss=0.058 KID= 0.10515\n",
      "epoch 189, batch 18, d_loss=0.034 g_loss=0.055 KID= 0.10515\n",
      "epoch 189, batch 19, d_loss=0.025 g_loss=0.026 KID= 0.10515\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 190, batch 0, d_loss=0.035 g_loss=0.007 KID= 0.05664\n",
      "epoch 190, batch 1, d_loss=0.039 g_loss=0.010 KID= 0.05664\n",
      "epoch 190, batch 2, d_loss=0.021 g_loss=0.028 KID= 0.05664\n",
      "epoch 190, batch 3, d_loss=0.055 g_loss=0.017 KID= 0.05664\n",
      "epoch 190, batch 4, d_loss=0.149 g_loss=0.091 KID= 0.05664\n",
      "epoch 190, batch 5, d_loss=0.125 g_loss=0.221 KID= 0.05664\n",
      "epoch 190, batch 6, d_loss=0.066 g_loss=0.334 KID= 0.05664\n",
      "epoch 190, batch 7, d_loss=0.004 g_loss=0.418 KID= 0.05664\n",
      "epoch 190, batch 8, d_loss=0.033 g_loss=0.513 KID= 0.05664\n",
      "epoch 190, batch 9, d_loss=0.045 g_loss=0.588 KID= 0.05664\n",
      "epoch 190, batch 10, d_loss=0.036 g_loss=0.637 KID= 0.05664\n",
      "epoch 190, batch 11, d_loss=0.006 g_loss=0.680 KID= 0.05664\n",
      "epoch 190, batch 12, d_loss=0.122 g_loss=0.666 KID= 0.05664\n",
      "epoch 190, batch 13, d_loss=0.207 g_loss=0.592 KID= 0.05664\n",
      "epoch 190, batch 14, d_loss=0.104 g_loss=0.526 KID= 0.05664\n",
      "epoch 190, batch 15, d_loss=0.138 g_loss=0.483 KID= 0.05664\n",
      "epoch 190, batch 16, d_loss=0.115 g_loss=0.415 KID= 0.05664\n",
      "epoch 190, batch 17, d_loss=0.133 g_loss=0.315 KID= 0.05664\n",
      "epoch 190, batch 18, d_loss=0.086 g_loss=0.244 KID= 0.05664\n",
      "epoch 190, batch 19, d_loss=0.002 g_loss=0.130 KID= 0.05664\n",
      "epoch 191, batch 0, d_loss=0.030 g_loss=0.055 KID= 0.05664\n",
      "epoch 191, batch 1, d_loss=0.020 g_loss=-0.004 KID= 0.05664\n",
      "epoch 191, batch 2, d_loss=-0.007 g_loss=-0.093 KID= 0.05664\n",
      "epoch 191, batch 3, d_loss=-0.014 g_loss=-0.227 KID= 0.05664\n",
      "epoch 191, batch 4, d_loss=0.136 g_loss=-0.278 KID= 0.05664\n",
      "epoch 191, batch 5, d_loss=0.120 g_loss=-0.347 KID= 0.05664\n",
      "epoch 191, batch 6, d_loss=0.097 g_loss=-0.333 KID= 0.05664\n",
      "epoch 191, batch 7, d_loss=0.023 g_loss=-0.333 KID= 0.05664\n",
      "epoch 191, batch 8, d_loss=0.052 g_loss=-0.260 KID= 0.05664\n",
      "epoch 191, batch 9, d_loss=0.062 g_loss=-0.153 KID= 0.05664\n",
      "epoch 191, batch 10, d_loss=0.040 g_loss=-0.038 KID= 0.05664\n",
      "epoch 191, batch 11, d_loss=0.009 g_loss=0.095 KID= 0.05664\n",
      "epoch 191, batch 12, d_loss=0.047 g_loss=0.142 KID= 0.05664\n",
      "epoch 191, batch 13, d_loss=0.092 g_loss=0.162 KID= 0.05664\n",
      "epoch 191, batch 14, d_loss=0.037 g_loss=0.181 KID= 0.05664\n",
      "epoch 191, batch 15, d_loss=0.084 g_loss=0.214 KID= 0.05664\n",
      "epoch 191, batch 16, d_loss=0.150 g_loss=0.230 KID= 0.05664\n",
      "epoch 191, batch 17, d_loss=0.087 g_loss=0.221 KID= 0.05664\n",
      "epoch 191, batch 18, d_loss=0.025 g_loss=0.216 KID= 0.05664\n",
      "epoch 191, batch 19, d_loss=0.058 g_loss=0.245 KID= 0.05664\n",
      "epoch 192, batch 0, d_loss=0.017 g_loss=0.307 KID= 0.05664\n",
      "epoch 192, batch 1, d_loss=0.010 g_loss=0.422 KID= 0.05664\n",
      "epoch 192, batch 2, d_loss=0.058 g_loss=0.444 KID= 0.05664\n",
      "epoch 192, batch 3, d_loss=0.036 g_loss=0.453 KID= 0.05664\n",
      "epoch 192, batch 4, d_loss=0.095 g_loss=0.444 KID= 0.05664\n",
      "epoch 192, batch 5, d_loss=0.140 g_loss=0.447 KID= 0.05664\n",
      "epoch 192, batch 6, d_loss=0.029 g_loss=0.428 KID= 0.05664\n",
      "epoch 192, batch 7, d_loss=0.091 g_loss=0.376 KID= 0.05664\n",
      "epoch 192, batch 8, d_loss=0.139 g_loss=0.334 KID= 0.05664\n",
      "epoch 192, batch 9, d_loss=0.045 g_loss=0.331 KID= 0.05664\n",
      "epoch 192, batch 10, d_loss=0.027 g_loss=0.287 KID= 0.05664\n",
      "epoch 192, batch 11, d_loss=-0.042 g_loss=0.245 KID= 0.05664\n",
      "epoch 192, batch 12, d_loss=-0.069 g_loss=0.184 KID= 0.05664\n",
      "epoch 192, batch 13, d_loss=0.040 g_loss=0.103 KID= 0.05664\n",
      "epoch 192, batch 14, d_loss=-0.043 g_loss=0.018 KID= 0.05664\n",
      "epoch 192, batch 15, d_loss=0.026 g_loss=0.000 KID= 0.05664\n",
      "epoch 192, batch 16, d_loss=0.178 g_loss=0.041 KID= 0.05664\n",
      "epoch 192, batch 17, d_loss=0.087 g_loss=0.022 KID= 0.05664\n",
      "epoch 192, batch 18, d_loss=0.060 g_loss=0.079 KID= 0.05664\n",
      "epoch 192, batch 19, d_loss=0.096 g_loss=0.198 KID= 0.05664\n",
      "epoch 193, batch 0, d_loss=0.093 g_loss=0.252 KID= 0.05664\n",
      "epoch 193, batch 1, d_loss=-0.004 g_loss=0.256 KID= 0.05664\n",
      "epoch 193, batch 2, d_loss=0.124 g_loss=0.250 KID= 0.05664\n",
      "epoch 193, batch 3, d_loss=0.020 g_loss=0.217 KID= 0.05664\n",
      "epoch 193, batch 4, d_loss=0.078 g_loss=0.198 KID= 0.05664\n",
      "epoch 193, batch 5, d_loss=0.082 g_loss=0.238 KID= 0.05664\n",
      "epoch 193, batch 6, d_loss=0.003 g_loss=0.263 KID= 0.05664\n",
      "epoch 193, batch 7, d_loss=0.065 g_loss=0.333 KID= 0.05664\n",
      "epoch 193, batch 8, d_loss=0.119 g_loss=0.428 KID= 0.05664\n",
      "epoch 193, batch 9, d_loss=0.052 g_loss=0.508 KID= 0.05664\n",
      "epoch 193, batch 10, d_loss=0.128 g_loss=0.514 KID= 0.05664\n",
      "epoch 193, batch 11, d_loss=0.126 g_loss=0.505 KID= 0.05664\n",
      "epoch 193, batch 12, d_loss=0.004 g_loss=0.508 KID= 0.05664\n",
      "epoch 193, batch 13, d_loss=0.031 g_loss=0.459 KID= 0.05664\n",
      "epoch 193, batch 14, d_loss=0.007 g_loss=0.416 KID= 0.05664\n",
      "epoch 193, batch 15, d_loss=-0.054 g_loss=0.380 KID= 0.05664\n",
      "epoch 193, batch 16, d_loss=0.122 g_loss=0.285 KID= 0.05664\n",
      "epoch 193, batch 17, d_loss=0.024 g_loss=0.158 KID= 0.05664\n",
      "epoch 193, batch 18, d_loss=0.059 g_loss=0.080 KID= 0.05664\n",
      "epoch 193, batch 19, d_loss=0.120 g_loss=0.032 KID= 0.05664\n",
      "epoch 194, batch 0, d_loss=0.135 g_loss=-0.007 KID= 0.05664\n",
      "epoch 194, batch 1, d_loss=0.102 g_loss=0.001 KID= 0.05664\n",
      "epoch 194, batch 2, d_loss=0.149 g_loss=0.056 KID= 0.05664\n",
      "epoch 194, batch 3, d_loss=0.055 g_loss=0.096 KID= 0.05664\n",
      "epoch 194, batch 4, d_loss=-0.001 g_loss=0.158 KID= 0.05664\n",
      "epoch 194, batch 5, d_loss=0.010 g_loss=0.285 KID= 0.05664\n",
      "epoch 194, batch 6, d_loss=-0.096 g_loss=0.282 KID= 0.05664\n",
      "epoch 194, batch 7, d_loss=0.037 g_loss=0.319 KID= 0.05664\n",
      "epoch 194, batch 8, d_loss=0.124 g_loss=0.406 KID= 0.05664\n",
      "epoch 194, batch 9, d_loss=0.129 g_loss=0.465 KID= 0.05664\n",
      "epoch 194, batch 10, d_loss=0.136 g_loss=0.515 KID= 0.05664\n",
      "epoch 194, batch 11, d_loss=0.132 g_loss=0.601 KID= 0.05664\n",
      "epoch 194, batch 12, d_loss=0.115 g_loss=0.662 KID= 0.05664\n",
      "epoch 194, batch 13, d_loss=0.105 g_loss=0.633 KID= 0.05664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 194, batch 14, d_loss=0.061 g_loss=0.583 KID= 0.05664\n",
      "epoch 194, batch 15, d_loss=0.015 g_loss=0.560 KID= 0.05664\n",
      "epoch 194, batch 16, d_loss=0.074 g_loss=0.525 KID= 0.05664\n",
      "epoch 194, batch 17, d_loss=0.010 g_loss=0.473 KID= 0.05664\n",
      "epoch 194, batch 18, d_loss=-0.022 g_loss=0.444 KID= 0.05664\n",
      "epoch 194, batch 19, d_loss=0.023 g_loss=0.428 KID= 0.05664\n",
      "epoch 195, batch 0, d_loss=0.067 g_loss=0.402 KID= 0.05664\n",
      "epoch 195, batch 1, d_loss=0.035 g_loss=0.406 KID= 0.05664\n",
      "epoch 195, batch 2, d_loss=0.019 g_loss=0.380 KID= 0.05664\n",
      "epoch 195, batch 3, d_loss=0.062 g_loss=0.362 KID= 0.05664\n",
      "epoch 195, batch 4, d_loss=0.062 g_loss=0.318 KID= 0.05664\n",
      "epoch 195, batch 5, d_loss=0.015 g_loss=0.300 KID= 0.05664\n",
      "epoch 195, batch 6, d_loss=-0.009 g_loss=0.327 KID= 0.05664\n",
      "epoch 195, batch 7, d_loss=-0.053 g_loss=0.271 KID= 0.05664\n",
      "epoch 195, batch 8, d_loss=0.029 g_loss=0.239 KID= 0.05664\n",
      "epoch 195, batch 9, d_loss=0.026 g_loss=0.198 KID= 0.05664\n",
      "epoch 195, batch 10, d_loss=0.132 g_loss=0.207 KID= 0.05664\n",
      "epoch 195, batch 11, d_loss=0.100 g_loss=0.272 KID= 0.05664\n",
      "epoch 195, batch 12, d_loss=0.113 g_loss=0.292 KID= 0.05664\n",
      "epoch 195, batch 13, d_loss=0.092 g_loss=0.246 KID= 0.05664\n",
      "epoch 195, batch 14, d_loss=0.072 g_loss=0.220 KID= 0.05664\n",
      "epoch 195, batch 15, d_loss=0.119 g_loss=0.203 KID= 0.05664\n",
      "epoch 195, batch 16, d_loss=0.122 g_loss=0.214 KID= 0.05664\n",
      "epoch 195, batch 17, d_loss=0.093 g_loss=0.251 KID= 0.05664\n",
      "epoch 195, batch 18, d_loss=0.047 g_loss=0.304 KID= 0.05664\n",
      "epoch 195, batch 19, d_loss=0.029 g_loss=0.319 KID= 0.05664\n",
      "epoch 196, batch 0, d_loss=0.049 g_loss=0.301 KID= 0.05664\n",
      "epoch 196, batch 1, d_loss=0.022 g_loss=0.250 KID= 0.05664\n",
      "epoch 196, batch 2, d_loss=0.107 g_loss=0.221 KID= 0.05664\n",
      "epoch 196, batch 3, d_loss=0.104 g_loss=0.175 KID= 0.05664\n",
      "epoch 196, batch 4, d_loss=0.082 g_loss=0.136 KID= 0.05664\n",
      "epoch 196, batch 5, d_loss=0.034 g_loss=0.122 KID= 0.05664\n",
      "epoch 196, batch 6, d_loss=0.045 g_loss=0.106 KID= 0.05664\n",
      "epoch 196, batch 7, d_loss=-0.051 g_loss=0.047 KID= 0.05664\n",
      "epoch 196, batch 8, d_loss=0.032 g_loss=0.025 KID= 0.05664\n",
      "epoch 196, batch 9, d_loss=-0.008 g_loss=0.006 KID= 0.05664\n",
      "epoch 196, batch 10, d_loss=0.106 g_loss=-0.048 KID= 0.05664\n",
      "epoch 196, batch 11, d_loss=0.095 g_loss=-0.026 KID= 0.05664\n",
      "epoch 196, batch 12, d_loss=0.030 g_loss=-0.058 KID= 0.05664\n",
      "epoch 196, batch 13, d_loss=0.045 g_loss=-0.115 KID= 0.05664\n",
      "epoch 196, batch 14, d_loss=0.074 g_loss=-0.082 KID= 0.05664\n",
      "epoch 196, batch 15, d_loss=0.084 g_loss=-0.001 KID= 0.05664\n",
      "epoch 196, batch 16, d_loss=0.015 g_loss=0.083 KID= 0.05664\n",
      "epoch 196, batch 17, d_loss=0.021 g_loss=0.175 KID= 0.05664\n",
      "epoch 196, batch 18, d_loss=0.023 g_loss=0.261 KID= 0.05664\n",
      "epoch 196, batch 19, d_loss=0.064 g_loss=0.366 KID= 0.05664\n",
      "epoch 197, batch 0, d_loss=0.013 g_loss=0.370 KID= 0.05664\n",
      "epoch 197, batch 1, d_loss=0.008 g_loss=0.396 KID= 0.05664\n",
      "epoch 197, batch 2, d_loss=0.051 g_loss=0.438 KID= 0.05664\n",
      "epoch 197, batch 3, d_loss=0.129 g_loss=0.422 KID= 0.05664\n",
      "epoch 197, batch 4, d_loss=0.008 g_loss=0.405 KID= 0.05664\n",
      "epoch 197, batch 5, d_loss=0.024 g_loss=0.425 KID= 0.05664\n",
      "epoch 197, batch 6, d_loss=0.061 g_loss=0.402 KID= 0.05664\n",
      "epoch 197, batch 7, d_loss=-0.016 g_loss=0.380 KID= 0.05664\n",
      "epoch 197, batch 8, d_loss=0.037 g_loss=0.365 KID= 0.05664\n",
      "epoch 197, batch 9, d_loss=-0.015 g_loss=0.371 KID= 0.05664\n",
      "epoch 197, batch 10, d_loss=0.205 g_loss=0.413 KID= 0.05664\n",
      "epoch 197, batch 11, d_loss=0.142 g_loss=0.425 KID= 0.05664\n",
      "epoch 197, batch 12, d_loss=0.098 g_loss=0.394 KID= 0.05664\n",
      "epoch 197, batch 13, d_loss=0.053 g_loss=0.362 KID= 0.05664\n",
      "epoch 197, batch 14, d_loss=0.128 g_loss=0.350 KID= 0.05664\n",
      "epoch 197, batch 15, d_loss=0.079 g_loss=0.371 KID= 0.05664\n",
      "epoch 197, batch 16, d_loss=0.059 g_loss=0.387 KID= 0.05664\n",
      "epoch 197, batch 17, d_loss=0.051 g_loss=0.386 KID= 0.05664\n",
      "epoch 197, batch 18, d_loss=0.061 g_loss=0.395 KID= 0.05664\n",
      "epoch 197, batch 19, d_loss=0.025 g_loss=0.394 KID= 0.05664\n",
      "epoch 198, batch 0, d_loss=0.013 g_loss=0.362 KID= 0.05664\n",
      "epoch 198, batch 1, d_loss=0.026 g_loss=0.327 KID= 0.05664\n",
      "epoch 198, batch 2, d_loss=0.094 g_loss=0.281 KID= 0.05664\n",
      "epoch 198, batch 3, d_loss=0.080 g_loss=0.232 KID= 0.05664\n",
      "epoch 198, batch 4, d_loss=0.077 g_loss=0.183 KID= 0.05664\n",
      "epoch 198, batch 5, d_loss=0.060 g_loss=0.152 KID= 0.05664\n",
      "epoch 198, batch 6, d_loss=0.017 g_loss=0.126 KID= 0.05664\n",
      "epoch 198, batch 7, d_loss=0.010 g_loss=0.123 KID= 0.05664\n",
      "epoch 198, batch 8, d_loss=0.027 g_loss=0.136 KID= 0.05664\n",
      "epoch 198, batch 9, d_loss=0.023 g_loss=0.177 KID= 0.05664\n",
      "epoch 198, batch 10, d_loss=0.114 g_loss=0.240 KID= 0.05664\n",
      "epoch 198, batch 11, d_loss=0.066 g_loss=0.303 KID= 0.05664\n",
      "epoch 198, batch 12, d_loss=0.028 g_loss=0.351 KID= 0.05664\n",
      "epoch 198, batch 13, d_loss=0.109 g_loss=0.366 KID= 0.05664\n",
      "epoch 198, batch 14, d_loss=0.061 g_loss=0.359 KID= 0.05664\n",
      "epoch 198, batch 15, d_loss=0.039 g_loss=0.380 KID= 0.05664\n",
      "epoch 198, batch 16, d_loss=0.055 g_loss=0.346 KID= 0.05664\n",
      "epoch 198, batch 17, d_loss=0.008 g_loss=0.268 KID= 0.05664\n",
      "epoch 198, batch 18, d_loss=0.026 g_loss=0.200 KID= 0.05664\n",
      "epoch 198, batch 19, d_loss=0.051 g_loss=0.184 KID= 0.05664\n",
      "epoch 199, batch 0, d_loss=0.017 g_loss=0.161 KID= 0.05664\n",
      "epoch 199, batch 1, d_loss=0.033 g_loss=0.154 KID= 0.05664\n",
      "epoch 199, batch 2, d_loss=0.109 g_loss=0.141 KID= 0.05664\n",
      "epoch 199, batch 3, d_loss=0.084 g_loss=0.105 KID= 0.05664\n",
      "epoch 199, batch 4, d_loss=0.148 g_loss=0.095 KID= 0.05664\n",
      "epoch 199, batch 5, d_loss=0.125 g_loss=0.085 KID= 0.05664\n",
      "epoch 199, batch 6, d_loss=0.068 g_loss=0.082 KID= 0.05664\n",
      "epoch 199, batch 7, d_loss=0.041 g_loss=0.087 KID= 0.05664\n",
      "epoch 199, batch 8, d_loss=0.029 g_loss=0.081 KID= 0.05664\n",
      "epoch 199, batch 9, d_loss=-0.078 g_loss=0.087 KID= 0.05664\n",
      "epoch 199, batch 10, d_loss=-0.017 g_loss=0.085 KID= 0.05664\n",
      "epoch 199, batch 11, d_loss=-0.043 g_loss=0.044 KID= 0.05664\n",
      "epoch 199, batch 12, d_loss=-0.133 g_loss=-0.089 KID= 0.05664\n",
      "epoch 199, batch 13, d_loss=0.150 g_loss=-0.166 KID= 0.05664\n",
      "epoch 199, batch 14, d_loss=0.151 g_loss=-0.192 KID= 0.05664\n",
      "epoch 199, batch 15, d_loss=0.152 g_loss=-0.021 KID= 0.05664\n",
      "epoch 199, batch 16, d_loss=0.059 g_loss=0.140 KID= 0.05664\n",
      "epoch 199, batch 17, d_loss=0.016 g_loss=0.149 KID= 0.05664\n",
      "epoch 199, batch 18, d_loss=0.073 g_loss=0.154 KID= 0.05664\n",
      "epoch 199, batch 19, d_loss=0.137 g_loss=0.150 KID= 0.05664\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 200, batch 0, d_loss=0.104 g_loss=0.204 KID= 0.10651\n",
      "epoch 200, batch 1, d_loss=0.059 g_loss=0.251 KID= 0.10651\n",
      "epoch 200, batch 2, d_loss=0.045 g_loss=0.271 KID= 0.10651\n",
      "epoch 200, batch 3, d_loss=-0.037 g_loss=0.233 KID= 0.10651\n",
      "epoch 200, batch 4, d_loss=0.036 g_loss=0.212 KID= 0.10651\n",
      "epoch 200, batch 5, d_loss=0.040 g_loss=0.189 KID= 0.10651\n",
      "epoch 200, batch 6, d_loss=0.055 g_loss=0.155 KID= 0.10651\n",
      "epoch 200, batch 7, d_loss=0.029 g_loss=0.117 KID= 0.10651\n",
      "epoch 200, batch 8, d_loss=0.020 g_loss=0.097 KID= 0.10651\n",
      "epoch 200, batch 9, d_loss=0.023 g_loss=0.110 KID= 0.10651\n",
      "epoch 200, batch 10, d_loss=-0.011 g_loss=0.052 KID= 0.10651\n",
      "epoch 200, batch 11, d_loss=0.019 g_loss=-0.021 KID= 0.10651\n",
      "epoch 200, batch 12, d_loss=0.040 g_loss=-0.075 KID= 0.10651\n",
      "epoch 200, batch 13, d_loss=0.065 g_loss=-0.162 KID= 0.10651\n",
      "epoch 200, batch 14, d_loss=0.050 g_loss=-0.222 KID= 0.10651\n",
      "epoch 200, batch 15, d_loss=0.110 g_loss=-0.177 KID= 0.10651\n",
      "epoch 200, batch 16, d_loss=0.046 g_loss=-0.203 KID= 0.10651\n",
      "epoch 200, batch 17, d_loss=0.037 g_loss=-0.152 KID= 0.10651\n",
      "epoch 200, batch 18, d_loss=0.068 g_loss=-0.121 KID= 0.10651\n",
      "epoch 200, batch 19, d_loss=0.078 g_loss=-0.062 KID= 0.10651\n",
      "epoch 201, batch 0, d_loss=0.079 g_loss=0.009 KID= 0.10651\n",
      "epoch 201, batch 1, d_loss=0.057 g_loss=0.023 KID= 0.10651\n",
      "epoch 201, batch 2, d_loss=0.073 g_loss=0.073 KID= 0.10651\n",
      "epoch 201, batch 3, d_loss=0.074 g_loss=-0.007 KID= 0.10651\n",
      "epoch 201, batch 4, d_loss=0.066 g_loss=-0.061 KID= 0.10651\n",
      "epoch 201, batch 5, d_loss=0.012 g_loss=-0.111 KID= 0.10651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 201, batch 6, d_loss=0.043 g_loss=-0.159 KID= 0.10651\n",
      "epoch 201, batch 7, d_loss=0.013 g_loss=-0.182 KID= 0.10651\n",
      "epoch 201, batch 8, d_loss=0.040 g_loss=-0.178 KID= 0.10651\n",
      "epoch 201, batch 9, d_loss=0.078 g_loss=-0.092 KID= 0.10651\n",
      "epoch 201, batch 10, d_loss=0.091 g_loss=-0.029 KID= 0.10651\n",
      "epoch 201, batch 11, d_loss=0.072 g_loss=0.055 KID= 0.10651\n",
      "epoch 201, batch 12, d_loss=0.043 g_loss=0.158 KID= 0.10651\n",
      "epoch 201, batch 13, d_loss=0.032 g_loss=0.227 KID= 0.10651\n",
      "epoch 201, batch 14, d_loss=0.006 g_loss=0.258 KID= 0.10651\n",
      "epoch 201, batch 15, d_loss=0.050 g_loss=0.271 KID= 0.10651\n",
      "epoch 201, batch 16, d_loss=0.013 g_loss=0.301 KID= 0.10651\n",
      "epoch 201, batch 17, d_loss=0.074 g_loss=0.324 KID= 0.10651\n",
      "epoch 201, batch 18, d_loss=0.112 g_loss=0.331 KID= 0.10651\n",
      "epoch 201, batch 19, d_loss=0.043 g_loss=0.354 KID= 0.10651\n",
      "epoch 202, batch 0, d_loss=0.112 g_loss=0.374 KID= 0.10651\n",
      "epoch 202, batch 1, d_loss=0.080 g_loss=0.375 KID= 0.10651\n",
      "epoch 202, batch 2, d_loss=0.074 g_loss=0.390 KID= 0.10651\n",
      "epoch 202, batch 3, d_loss=0.086 g_loss=0.396 KID= 0.10651\n",
      "epoch 202, batch 4, d_loss=0.094 g_loss=0.392 KID= 0.10651\n",
      "epoch 202, batch 5, d_loss=0.024 g_loss=0.404 KID= 0.10651\n",
      "epoch 202, batch 6, d_loss=0.048 g_loss=0.369 KID= 0.10651\n",
      "epoch 202, batch 7, d_loss=0.020 g_loss=0.317 KID= 0.10651\n",
      "epoch 202, batch 8, d_loss=0.065 g_loss=0.252 KID= 0.10651\n",
      "epoch 202, batch 9, d_loss=0.117 g_loss=0.171 KID= 0.10651\n",
      "epoch 202, batch 10, d_loss=0.084 g_loss=0.091 KID= 0.10651\n",
      "epoch 202, batch 11, d_loss=0.046 g_loss=0.032 KID= 0.10651\n",
      "epoch 202, batch 12, d_loss=0.020 g_loss=-0.033 KID= 0.10651\n",
      "epoch 202, batch 13, d_loss=0.042 g_loss=-0.096 KID= 0.10651\n",
      "epoch 202, batch 14, d_loss=0.021 g_loss=-0.173 KID= 0.10651\n",
      "epoch 202, batch 15, d_loss=0.100 g_loss=-0.176 KID= 0.10651\n",
      "epoch 202, batch 16, d_loss=0.045 g_loss=-0.163 KID= 0.10651\n",
      "epoch 202, batch 17, d_loss=0.048 g_loss=-0.132 KID= 0.10651\n",
      "epoch 202, batch 18, d_loss=0.022 g_loss=-0.065 KID= 0.10651\n",
      "epoch 202, batch 19, d_loss=-0.053 g_loss=-0.026 KID= 0.10651\n",
      "epoch 203, batch 0, d_loss=0.015 g_loss=0.010 KID= 0.10651\n",
      "epoch 203, batch 1, d_loss=0.057 g_loss=0.102 KID= 0.10651\n",
      "epoch 203, batch 2, d_loss=0.044 g_loss=0.211 KID= 0.10651\n",
      "epoch 203, batch 3, d_loss=0.101 g_loss=0.267 KID= 0.10651\n",
      "epoch 203, batch 4, d_loss=0.128 g_loss=0.357 KID= 0.10651\n",
      "epoch 203, batch 5, d_loss=0.057 g_loss=0.436 KID= 0.10651\n",
      "epoch 203, batch 6, d_loss=0.059 g_loss=0.522 KID= 0.10651\n",
      "epoch 203, batch 7, d_loss=0.006 g_loss=0.561 KID= 0.10651\n",
      "epoch 203, batch 8, d_loss=-0.007 g_loss=0.552 KID= 0.10651\n",
      "epoch 203, batch 9, d_loss=0.068 g_loss=0.540 KID= 0.10651\n",
      "epoch 203, batch 10, d_loss=0.165 g_loss=0.481 KID= 0.10651\n",
      "epoch 203, batch 11, d_loss=0.065 g_loss=0.392 KID= 0.10651\n",
      "epoch 203, batch 12, d_loss=0.069 g_loss=0.281 KID= 0.10651\n",
      "epoch 203, batch 13, d_loss=0.090 g_loss=0.210 KID= 0.10651\n",
      "epoch 203, batch 14, d_loss=0.020 g_loss=0.122 KID= 0.10651\n",
      "epoch 203, batch 15, d_loss=0.076 g_loss=0.095 KID= 0.10651\n",
      "epoch 203, batch 16, d_loss=0.065 g_loss=0.110 KID= 0.10651\n",
      "epoch 203, batch 17, d_loss=0.024 g_loss=0.122 KID= 0.10651\n",
      "epoch 203, batch 18, d_loss=-0.006 g_loss=0.110 KID= 0.10651\n",
      "epoch 203, batch 19, d_loss=-0.036 g_loss=0.138 KID= 0.10651\n",
      "epoch 204, batch 0, d_loss=-0.000 g_loss=0.156 KID= 0.10651\n",
      "epoch 204, batch 1, d_loss=0.027 g_loss=0.204 KID= 0.10651\n",
      "epoch 204, batch 2, d_loss=-0.039 g_loss=0.234 KID= 0.10651\n",
      "epoch 204, batch 3, d_loss=-0.031 g_loss=0.230 KID= 0.10651\n",
      "epoch 204, batch 4, d_loss=-0.012 g_loss=0.226 KID= 0.10651\n",
      "epoch 204, batch 5, d_loss=-0.020 g_loss=0.210 KID= 0.10651\n",
      "epoch 204, batch 6, d_loss=0.059 g_loss=0.218 KID= 0.10651\n",
      "epoch 204, batch 7, d_loss=0.115 g_loss=0.314 KID= 0.10651\n",
      "epoch 204, batch 8, d_loss=0.058 g_loss=0.376 KID= 0.10651\n",
      "epoch 204, batch 9, d_loss=0.075 g_loss=0.405 KID= 0.10651\n",
      "epoch 204, batch 10, d_loss=0.059 g_loss=0.375 KID= 0.10651\n",
      "epoch 204, batch 11, d_loss=0.013 g_loss=0.307 KID= 0.10651\n",
      "epoch 204, batch 12, d_loss=0.005 g_loss=0.224 KID= 0.10651\n",
      "epoch 204, batch 13, d_loss=0.062 g_loss=0.129 KID= 0.10651\n",
      "epoch 204, batch 14, d_loss=0.037 g_loss=0.034 KID= 0.10651\n",
      "epoch 204, batch 15, d_loss=0.097 g_loss=-0.043 KID= 0.10651\n",
      "epoch 204, batch 16, d_loss=0.010 g_loss=-0.076 KID= 0.10651\n",
      "epoch 204, batch 17, d_loss=0.039 g_loss=-0.075 KID= 0.10651\n",
      "epoch 204, batch 18, d_loss=0.059 g_loss=-0.048 KID= 0.10651\n",
      "epoch 204, batch 19, d_loss=0.004 g_loss=0.051 KID= 0.10651\n",
      "epoch 205, batch 0, d_loss=-0.033 g_loss=0.035 KID= 0.10651\n",
      "epoch 205, batch 1, d_loss=0.033 g_loss=0.001 KID= 0.10651\n",
      "epoch 205, batch 2, d_loss=0.089 g_loss=0.042 KID= 0.10651\n",
      "epoch 205, batch 3, d_loss=0.028 g_loss=0.021 KID= 0.10651\n",
      "epoch 205, batch 4, d_loss=0.076 g_loss=0.031 KID= 0.10651\n",
      "epoch 205, batch 5, d_loss=0.047 g_loss=0.026 KID= 0.10651\n",
      "epoch 205, batch 6, d_loss=0.047 g_loss=0.063 KID= 0.10651\n",
      "epoch 205, batch 7, d_loss=0.004 g_loss=0.056 KID= 0.10651\n",
      "epoch 205, batch 8, d_loss=-0.043 g_loss=0.041 KID= 0.10651\n",
      "epoch 205, batch 9, d_loss=-0.003 g_loss=0.069 KID= 0.10651\n",
      "epoch 205, batch 10, d_loss=0.114 g_loss=0.073 KID= 0.10651\n",
      "epoch 205, batch 11, d_loss=-0.018 g_loss=0.091 KID= 0.10651\n",
      "epoch 205, batch 12, d_loss=-0.022 g_loss=0.121 KID= 0.10651\n",
      "epoch 205, batch 13, d_loss=0.096 g_loss=0.090 KID= 0.10651\n",
      "epoch 205, batch 14, d_loss=0.030 g_loss=0.070 KID= 0.10651\n",
      "epoch 205, batch 15, d_loss=0.080 g_loss=0.096 KID= 0.10651\n",
      "epoch 205, batch 16, d_loss=0.025 g_loss=0.094 KID= 0.10651\n",
      "epoch 205, batch 17, d_loss=0.072 g_loss=0.062 KID= 0.10651\n",
      "epoch 205, batch 18, d_loss=0.102 g_loss=0.042 KID= 0.10651\n",
      "epoch 205, batch 19, d_loss=0.070 g_loss=0.142 KID= 0.10651\n",
      "epoch 206, batch 0, d_loss=0.045 g_loss=0.221 KID= 0.10651\n",
      "epoch 206, batch 1, d_loss=0.053 g_loss=0.224 KID= 0.10651\n",
      "epoch 206, batch 2, d_loss=0.022 g_loss=0.198 KID= 0.10651\n",
      "epoch 206, batch 3, d_loss=0.002 g_loss=0.158 KID= 0.10651\n",
      "epoch 206, batch 4, d_loss=0.121 g_loss=0.084 KID= 0.10651\n",
      "epoch 206, batch 5, d_loss=0.086 g_loss=0.040 KID= 0.10651\n",
      "epoch 206, batch 6, d_loss=0.131 g_loss=0.034 KID= 0.10651\n",
      "epoch 206, batch 7, d_loss=0.116 g_loss=-0.024 KID= 0.10651\n",
      "epoch 206, batch 8, d_loss=0.088 g_loss=-0.075 KID= 0.10651\n",
      "epoch 206, batch 9, d_loss=0.026 g_loss=-0.100 KID= 0.10651\n",
      "epoch 206, batch 10, d_loss=0.030 g_loss=-0.163 KID= 0.10651\n",
      "epoch 206, batch 11, d_loss=0.044 g_loss=-0.251 KID= 0.10651\n",
      "epoch 206, batch 12, d_loss=0.032 g_loss=-0.338 KID= 0.10651\n",
      "epoch 206, batch 13, d_loss=0.012 g_loss=-0.380 KID= 0.10651\n",
      "epoch 206, batch 14, d_loss=-0.074 g_loss=-0.515 KID= 0.10651\n",
      "epoch 206, batch 15, d_loss=0.046 g_loss=-0.543 KID= 0.10651\n",
      "epoch 206, batch 16, d_loss=-0.059 g_loss=-0.599 KID= 0.10651\n",
      "epoch 206, batch 17, d_loss=0.007 g_loss=-0.602 KID= 0.10651\n",
      "epoch 206, batch 18, d_loss=0.067 g_loss=-0.533 KID= 0.10651\n",
      "epoch 206, batch 19, d_loss=0.182 g_loss=-0.415 KID= 0.10651\n",
      "epoch 207, batch 0, d_loss=0.129 g_loss=-0.362 KID= 0.10651\n",
      "epoch 207, batch 1, d_loss=0.020 g_loss=-0.379 KID= 0.10651\n",
      "epoch 207, batch 2, d_loss=0.006 g_loss=-0.416 KID= 0.10651\n",
      "epoch 207, batch 3, d_loss=0.000 g_loss=-0.485 KID= 0.10651\n",
      "epoch 207, batch 4, d_loss=0.027 g_loss=-0.566 KID= 0.10651\n",
      "epoch 207, batch 5, d_loss=-0.010 g_loss=-0.648 KID= 0.10651\n",
      "epoch 207, batch 6, d_loss=0.109 g_loss=-0.589 KID= 0.10651\n",
      "epoch 207, batch 7, d_loss=0.096 g_loss=-0.542 KID= 0.10651\n",
      "epoch 207, batch 8, d_loss=0.107 g_loss=-0.457 KID= 0.10651\n",
      "epoch 207, batch 9, d_loss=0.093 g_loss=-0.348 KID= 0.10651\n",
      "epoch 207, batch 10, d_loss=0.030 g_loss=-0.285 KID= 0.10651\n",
      "epoch 207, batch 11, d_loss=0.049 g_loss=-0.238 KID= 0.10651\n",
      "epoch 207, batch 12, d_loss=0.029 g_loss=-0.224 KID= 0.10651\n",
      "epoch 207, batch 13, d_loss=0.001 g_loss=-0.207 KID= 0.10651\n",
      "epoch 207, batch 14, d_loss=-0.019 g_loss=-0.237 KID= 0.10651\n",
      "epoch 207, batch 15, d_loss=0.073 g_loss=-0.263 KID= 0.10651\n",
      "epoch 207, batch 16, d_loss=-0.030 g_loss=-0.283 KID= 0.10651\n",
      "epoch 207, batch 17, d_loss=0.026 g_loss=-0.377 KID= 0.10651\n",
      "epoch 207, batch 18, d_loss=0.018 g_loss=-0.414 KID= 0.10651\n",
      "epoch 207, batch 19, d_loss=0.115 g_loss=-0.303 KID= 0.10651\n",
      "epoch 208, batch 0, d_loss=0.108 g_loss=-0.257 KID= 0.10651\n",
      "epoch 208, batch 1, d_loss=0.055 g_loss=-0.219 KID= 0.10651\n",
      "epoch 208, batch 2, d_loss=0.050 g_loss=-0.219 KID= 0.10651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 208, batch 3, d_loss=0.072 g_loss=-0.196 KID= 0.10651\n",
      "epoch 208, batch 4, d_loss=0.046 g_loss=-0.171 KID= 0.10651\n",
      "epoch 208, batch 5, d_loss=-0.037 g_loss=-0.154 KID= 0.10651\n",
      "epoch 208, batch 6, d_loss=0.024 g_loss=-0.137 KID= 0.10651\n",
      "epoch 208, batch 7, d_loss=-0.043 g_loss=-0.176 KID= 0.10651\n",
      "epoch 208, batch 8, d_loss=0.051 g_loss=-0.187 KID= 0.10651\n",
      "epoch 208, batch 9, d_loss=0.084 g_loss=-0.088 KID= 0.10651\n",
      "epoch 208, batch 10, d_loss=0.058 g_loss=-0.111 KID= 0.10651\n",
      "epoch 208, batch 11, d_loss=0.147 g_loss=-0.096 KID= 0.10651\n",
      "epoch 208, batch 12, d_loss=0.111 g_loss=-0.115 KID= 0.10651\n",
      "epoch 208, batch 13, d_loss=0.076 g_loss=-0.109 KID= 0.10651\n",
      "epoch 208, batch 14, d_loss=0.045 g_loss=-0.084 KID= 0.10651\n",
      "epoch 208, batch 15, d_loss=0.044 g_loss=-0.074 KID= 0.10651\n",
      "epoch 208, batch 16, d_loss=-0.054 g_loss=-0.036 KID= 0.10651\n",
      "epoch 208, batch 17, d_loss=0.027 g_loss=-0.051 KID= 0.10651\n",
      "epoch 208, batch 18, d_loss=-0.011 g_loss=-0.048 KID= 0.10651\n",
      "epoch 208, batch 19, d_loss=0.123 g_loss=0.059 KID= 0.10651\n",
      "epoch 209, batch 0, d_loss=0.083 g_loss=0.109 KID= 0.10651\n",
      "epoch 209, batch 1, d_loss=0.012 g_loss=0.111 KID= 0.10651\n",
      "epoch 209, batch 2, d_loss=0.099 g_loss=0.130 KID= 0.10651\n",
      "epoch 209, batch 3, d_loss=0.062 g_loss=0.127 KID= 0.10651\n",
      "epoch 209, batch 4, d_loss=0.036 g_loss=0.106 KID= 0.10651\n",
      "epoch 209, batch 5, d_loss=0.037 g_loss=0.100 KID= 0.10651\n",
      "epoch 209, batch 6, d_loss=0.081 g_loss=0.133 KID= 0.10651\n",
      "epoch 209, batch 7, d_loss=0.032 g_loss=0.154 KID= 0.10651\n",
      "epoch 209, batch 8, d_loss=0.041 g_loss=0.205 KID= 0.10651\n",
      "epoch 209, batch 9, d_loss=0.104 g_loss=0.275 KID= 0.10651\n",
      "epoch 209, batch 10, d_loss=0.028 g_loss=0.315 KID= 0.10651\n",
      "epoch 209, batch 11, d_loss=0.060 g_loss=0.322 KID= 0.10651\n",
      "epoch 209, batch 12, d_loss=0.021 g_loss=0.289 KID= 0.10651\n",
      "epoch 209, batch 13, d_loss=-0.002 g_loss=0.241 KID= 0.10651\n",
      "epoch 209, batch 14, d_loss=0.059 g_loss=0.208 KID= 0.10651\n",
      "epoch 209, batch 15, d_loss=0.073 g_loss=0.142 KID= 0.10651\n",
      "epoch 209, batch 16, d_loss=-0.034 g_loss=0.147 KID= 0.10651\n",
      "epoch 209, batch 17, d_loss=0.055 g_loss=0.129 KID= 0.10651\n",
      "epoch 209, batch 18, d_loss=0.079 g_loss=0.127 KID= 0.10651\n",
      "epoch 209, batch 19, d_loss=0.032 g_loss=0.172 KID= 0.10651\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 210, batch 0, d_loss=0.154 g_loss=0.224 KID= 0.04707\n",
      "epoch 210, batch 1, d_loss=0.084 g_loss=0.244 KID= 0.04707\n",
      "epoch 210, batch 2, d_loss=0.116 g_loss=0.237 KID= 0.04707\n",
      "epoch 210, batch 3, d_loss=0.039 g_loss=0.225 KID= 0.04707\n",
      "epoch 210, batch 4, d_loss=0.061 g_loss=0.174 KID= 0.04707\n",
      "epoch 210, batch 5, d_loss=0.055 g_loss=0.124 KID= 0.04707\n",
      "epoch 210, batch 6, d_loss=0.101 g_loss=0.139 KID= 0.04707\n",
      "epoch 210, batch 7, d_loss=0.023 g_loss=0.134 KID= 0.04707\n",
      "epoch 210, batch 8, d_loss=0.029 g_loss=0.111 KID= 0.04707\n",
      "epoch 210, batch 9, d_loss=0.099 g_loss=0.208 KID= 0.04707\n",
      "epoch 210, batch 10, d_loss=0.019 g_loss=0.269 KID= 0.04707\n",
      "epoch 210, batch 11, d_loss=0.065 g_loss=0.272 KID= 0.04707\n",
      "epoch 210, batch 12, d_loss=0.019 g_loss=0.231 KID= 0.04707\n",
      "epoch 210, batch 13, d_loss=0.084 g_loss=0.190 KID= 0.04707\n",
      "epoch 210, batch 14, d_loss=0.045 g_loss=0.149 KID= 0.04707\n",
      "epoch 210, batch 15, d_loss=0.044 g_loss=0.134 KID= 0.04707\n",
      "epoch 210, batch 16, d_loss=-0.044 g_loss=0.146 KID= 0.04707\n",
      "epoch 210, batch 17, d_loss=0.030 g_loss=0.161 KID= 0.04707\n",
      "epoch 210, batch 18, d_loss=0.022 g_loss=0.119 KID= 0.04707\n",
      "epoch 210, batch 19, d_loss=0.066 g_loss=0.109 KID= 0.04707\n",
      "epoch 211, batch 0, d_loss=0.089 g_loss=0.113 KID= 0.04707\n",
      "epoch 211, batch 1, d_loss=0.087 g_loss=0.091 KID= 0.04707\n",
      "epoch 211, batch 2, d_loss=0.105 g_loss=0.094 KID= 0.04707\n",
      "epoch 211, batch 3, d_loss=-0.011 g_loss=0.090 KID= 0.04707\n",
      "epoch 211, batch 4, d_loss=0.053 g_loss=0.085 KID= 0.04707\n",
      "epoch 211, batch 5, d_loss=0.050 g_loss=0.110 KID= 0.04707\n",
      "epoch 211, batch 6, d_loss=0.099 g_loss=0.198 KID= 0.04707\n",
      "epoch 211, batch 7, d_loss=0.019 g_loss=0.266 KID= 0.04707\n",
      "epoch 211, batch 8, d_loss=-0.028 g_loss=0.315 KID= 0.04707\n",
      "epoch 211, batch 9, d_loss=0.008 g_loss=0.355 KID= 0.04707\n",
      "epoch 211, batch 10, d_loss=0.049 g_loss=0.360 KID= 0.04707\n",
      "epoch 211, batch 11, d_loss=0.028 g_loss=0.323 KID= 0.04707\n",
      "epoch 211, batch 12, d_loss=0.102 g_loss=0.283 KID= 0.04707\n",
      "epoch 211, batch 13, d_loss=0.174 g_loss=0.267 KID= 0.04707\n",
      "epoch 211, batch 14, d_loss=0.102 g_loss=0.301 KID= 0.04707\n",
      "epoch 211, batch 15, d_loss=0.062 g_loss=0.260 KID= 0.04707\n",
      "epoch 211, batch 16, d_loss=0.038 g_loss=0.236 KID= 0.04707\n",
      "epoch 211, batch 17, d_loss=0.005 g_loss=0.218 KID= 0.04707\n",
      "epoch 211, batch 18, d_loss=-0.046 g_loss=0.140 KID= 0.04707\n",
      "epoch 211, batch 19, d_loss=0.015 g_loss=0.115 KID= 0.04707\n",
      "epoch 212, batch 0, d_loss=-0.027 g_loss=0.073 KID= 0.04707\n",
      "epoch 212, batch 1, d_loss=-0.029 g_loss=0.025 KID= 0.04707\n",
      "epoch 212, batch 2, d_loss=0.066 g_loss=-0.032 KID= 0.04707\n",
      "epoch 212, batch 3, d_loss=-0.086 g_loss=-0.108 KID= 0.04707\n",
      "epoch 212, batch 4, d_loss=-0.019 g_loss=-0.177 KID= 0.04707\n",
      "epoch 212, batch 5, d_loss=-0.032 g_loss=-0.345 KID= 0.04707\n",
      "epoch 212, batch 6, d_loss=0.140 g_loss=-0.231 KID= 0.04707\n",
      "epoch 212, batch 7, d_loss=0.074 g_loss=-0.197 KID= 0.04707\n",
      "epoch 212, batch 8, d_loss=0.212 g_loss=-0.055 KID= 0.04707\n",
      "epoch 212, batch 9, d_loss=0.073 g_loss=-0.021 KID= 0.04707\n",
      "epoch 212, batch 10, d_loss=0.174 g_loss=0.025 KID= 0.04707\n",
      "epoch 212, batch 11, d_loss=0.183 g_loss=0.083 KID= 0.04707\n",
      "epoch 212, batch 12, d_loss=0.195 g_loss=0.097 KID= 0.04707\n",
      "epoch 212, batch 13, d_loss=0.052 g_loss=0.163 KID= 0.04707\n",
      "epoch 212, batch 14, d_loss=0.028 g_loss=0.280 KID= 0.04707\n",
      "epoch 212, batch 15, d_loss=0.035 g_loss=0.407 KID= 0.04707\n",
      "epoch 212, batch 16, d_loss=-0.129 g_loss=0.529 KID= 0.04707\n",
      "epoch 212, batch 17, d_loss=0.111 g_loss=0.473 KID= 0.04707\n",
      "epoch 212, batch 18, d_loss=-0.032 g_loss=0.448 KID= 0.04707\n",
      "epoch 212, batch 19, d_loss=0.333 g_loss=0.231 KID= 0.04707\n",
      "epoch 213, batch 0, d_loss=0.246 g_loss=0.120 KID= 0.04707\n",
      "epoch 213, batch 1, d_loss=0.077 g_loss=0.062 KID= 0.04707\n",
      "epoch 213, batch 2, d_loss=0.076 g_loss=-0.032 KID= 0.04707\n",
      "epoch 213, batch 3, d_loss=0.087 g_loss=-0.058 KID= 0.04707\n",
      "epoch 213, batch 4, d_loss=0.047 g_loss=-0.068 KID= 0.04707\n",
      "epoch 213, batch 5, d_loss=0.056 g_loss=-0.104 KID= 0.04707\n",
      "epoch 213, batch 6, d_loss=0.084 g_loss=-0.056 KID= 0.04707\n",
      "epoch 213, batch 7, d_loss=0.032 g_loss=-0.031 KID= 0.04707\n",
      "epoch 213, batch 8, d_loss=0.068 g_loss=0.018 KID= 0.04707\n",
      "epoch 213, batch 9, d_loss=-0.020 g_loss=0.042 KID= 0.04707\n",
      "epoch 213, batch 10, d_loss=0.011 g_loss=0.036 KID= 0.04707\n",
      "epoch 213, batch 11, d_loss=0.095 g_loss=0.073 KID= 0.04707\n",
      "epoch 213, batch 12, d_loss=0.101 g_loss=0.102 KID= 0.04707\n",
      "epoch 213, batch 13, d_loss=0.000 g_loss=0.101 KID= 0.04707\n",
      "epoch 213, batch 14, d_loss=0.028 g_loss=0.091 KID= 0.04707\n",
      "epoch 213, batch 15, d_loss=0.121 g_loss=0.071 KID= 0.04707\n",
      "epoch 213, batch 16, d_loss=0.057 g_loss=0.081 KID= 0.04707\n",
      "epoch 213, batch 17, d_loss=-0.005 g_loss=-0.007 KID= 0.04707\n",
      "epoch 213, batch 18, d_loss=0.020 g_loss=-0.039 KID= 0.04707\n",
      "epoch 213, batch 19, d_loss=0.229 g_loss=-0.028 KID= 0.04707\n",
      "epoch 214, batch 0, d_loss=0.180 g_loss=-0.030 KID= 0.04707\n",
      "epoch 214, batch 1, d_loss=0.146 g_loss=-0.066 KID= 0.04707\n",
      "epoch 214, batch 2, d_loss=0.079 g_loss=-0.110 KID= 0.04707\n",
      "epoch 214, batch 3, d_loss=0.058 g_loss=-0.112 KID= 0.04707\n",
      "epoch 214, batch 4, d_loss=0.026 g_loss=-0.126 KID= 0.04707\n",
      "epoch 214, batch 5, d_loss=-0.041 g_loss=-0.133 KID= 0.04707\n",
      "epoch 214, batch 6, d_loss=0.051 g_loss=-0.078 KID= 0.04707\n",
      "epoch 214, batch 7, d_loss=0.005 g_loss=-0.035 KID= 0.04707\n",
      "epoch 214, batch 8, d_loss=0.011 g_loss=0.003 KID= 0.04707\n",
      "epoch 214, batch 9, d_loss=-0.013 g_loss=0.055 KID= 0.04707\n",
      "epoch 214, batch 10, d_loss=-0.046 g_loss=0.114 KID= 0.04707\n",
      "epoch 214, batch 11, d_loss=0.013 g_loss=0.124 KID= 0.04707\n",
      "epoch 214, batch 12, d_loss=0.069 g_loss=0.135 KID= 0.04707\n",
      "epoch 214, batch 13, d_loss=-0.034 g_loss=0.160 KID= 0.04707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 214, batch 14, d_loss=0.062 g_loss=0.166 KID= 0.04707\n",
      "epoch 214, batch 15, d_loss=0.091 g_loss=0.159 KID= 0.04707\n",
      "epoch 214, batch 16, d_loss=0.014 g_loss=0.182 KID= 0.04707\n",
      "epoch 214, batch 17, d_loss=0.035 g_loss=0.218 KID= 0.04707\n",
      "epoch 214, batch 18, d_loss=-0.029 g_loss=0.219 KID= 0.04707\n",
      "epoch 214, batch 19, d_loss=0.119 g_loss=0.205 KID= 0.04707\n",
      "epoch 215, batch 0, d_loss=0.076 g_loss=0.145 KID= 0.04707\n",
      "epoch 215, batch 1, d_loss=-0.014 g_loss=0.077 KID= 0.04707\n",
      "epoch 215, batch 2, d_loss=0.042 g_loss=0.041 KID= 0.04707\n",
      "epoch 215, batch 3, d_loss=0.043 g_loss=-0.001 KID= 0.04707\n",
      "epoch 215, batch 4, d_loss=0.032 g_loss=-0.043 KID= 0.04707\n",
      "epoch 215, batch 5, d_loss=0.000 g_loss=-0.063 KID= 0.04707\n",
      "epoch 215, batch 6, d_loss=0.028 g_loss=-0.087 KID= 0.04707\n",
      "epoch 215, batch 7, d_loss=0.002 g_loss=-0.115 KID= 0.04707\n",
      "epoch 215, batch 8, d_loss=0.074 g_loss=-0.133 KID= 0.04707\n",
      "epoch 215, batch 9, d_loss=0.113 g_loss=-0.100 KID= 0.04707\n",
      "epoch 215, batch 10, d_loss=0.069 g_loss=-0.093 KID= 0.04707\n",
      "epoch 215, batch 11, d_loss=0.052 g_loss=-0.069 KID= 0.04707\n",
      "epoch 215, batch 12, d_loss=0.036 g_loss=-0.052 KID= 0.04707\n",
      "epoch 215, batch 13, d_loss=-0.011 g_loss=-0.050 KID= 0.04707\n",
      "epoch 215, batch 14, d_loss=0.024 g_loss=-0.056 KID= 0.04707\n",
      "epoch 215, batch 15, d_loss=0.028 g_loss=-0.060 KID= 0.04707\n",
      "epoch 215, batch 16, d_loss=-0.016 g_loss=0.025 KID= 0.04707\n",
      "epoch 215, batch 17, d_loss=0.005 g_loss=0.135 KID= 0.04707\n",
      "epoch 215, batch 18, d_loss=0.002 g_loss=0.115 KID= 0.04707\n",
      "epoch 215, batch 19, d_loss=0.015 g_loss=0.175 KID= 0.04707\n",
      "epoch 216, batch 0, d_loss=-0.035 g_loss=0.170 KID= 0.04707\n",
      "epoch 216, batch 1, d_loss=0.079 g_loss=0.162 KID= 0.04707\n",
      "epoch 216, batch 2, d_loss=0.201 g_loss=0.175 KID= 0.04707\n",
      "epoch 216, batch 3, d_loss=0.054 g_loss=0.171 KID= 0.04707\n",
      "epoch 216, batch 4, d_loss=0.167 g_loss=0.139 KID= 0.04707\n",
      "epoch 216, batch 5, d_loss=0.084 g_loss=0.118 KID= 0.04707\n",
      "epoch 216, batch 6, d_loss=-0.001 g_loss=0.077 KID= 0.04707\n",
      "epoch 216, batch 7, d_loss=0.023 g_loss=0.039 KID= 0.04707\n",
      "epoch 216, batch 8, d_loss=-0.011 g_loss=0.014 KID= 0.04707\n",
      "epoch 216, batch 9, d_loss=0.031 g_loss=-0.017 KID= 0.04707\n",
      "epoch 216, batch 10, d_loss=0.026 g_loss=-0.086 KID= 0.04707\n",
      "epoch 216, batch 11, d_loss=-0.020 g_loss=-0.138 KID= 0.04707\n",
      "epoch 216, batch 12, d_loss=0.034 g_loss=-0.150 KID= 0.04707\n",
      "epoch 216, batch 13, d_loss=0.062 g_loss=-0.102 KID= 0.04707\n",
      "epoch 216, batch 14, d_loss=-0.015 g_loss=-0.098 KID= 0.04707\n",
      "epoch 216, batch 15, d_loss=0.004 g_loss=-0.082 KID= 0.04707\n",
      "epoch 216, batch 16, d_loss=0.028 g_loss=-0.067 KID= 0.04707\n",
      "epoch 216, batch 17, d_loss=-0.024 g_loss=-0.140 KID= 0.04707\n",
      "epoch 216, batch 18, d_loss=0.052 g_loss=-0.155 KID= 0.04707\n",
      "epoch 216, batch 19, d_loss=0.052 g_loss=-0.103 KID= 0.04707\n",
      "epoch 217, batch 0, d_loss=-0.015 g_loss=-0.150 KID= 0.04707\n",
      "epoch 217, batch 1, d_loss=0.106 g_loss=-0.102 KID= 0.04707\n",
      "epoch 217, batch 2, d_loss=0.068 g_loss=-0.105 KID= 0.04707\n",
      "epoch 217, batch 3, d_loss=0.018 g_loss=-0.122 KID= 0.04707\n",
      "epoch 217, batch 4, d_loss=0.122 g_loss=-0.071 KID= 0.04707\n",
      "epoch 217, batch 5, d_loss=0.073 g_loss=-0.055 KID= 0.04707\n",
      "epoch 217, batch 6, d_loss=0.035 g_loss=-0.021 KID= 0.04707\n",
      "epoch 217, batch 7, d_loss=0.013 g_loss=-0.034 KID= 0.04707\n",
      "epoch 217, batch 8, d_loss=0.006 g_loss=-0.017 KID= 0.04707\n",
      "epoch 217, batch 9, d_loss=0.068 g_loss=0.014 KID= 0.04707\n",
      "epoch 217, batch 10, d_loss=0.055 g_loss=0.060 KID= 0.04707\n",
      "epoch 217, batch 11, d_loss=0.014 g_loss=0.108 KID= 0.04707\n",
      "epoch 217, batch 12, d_loss=0.149 g_loss=0.137 KID= 0.04707\n",
      "epoch 217, batch 13, d_loss=0.032 g_loss=0.196 KID= 0.04707\n",
      "epoch 217, batch 14, d_loss=0.034 g_loss=0.207 KID= 0.04707\n",
      "epoch 217, batch 15, d_loss=0.028 g_loss=0.204 KID= 0.04707\n",
      "epoch 217, batch 16, d_loss=0.002 g_loss=0.213 KID= 0.04707\n",
      "epoch 217, batch 17, d_loss=-0.030 g_loss=0.221 KID= 0.04707\n",
      "epoch 217, batch 18, d_loss=0.011 g_loss=0.195 KID= 0.04707\n",
      "epoch 217, batch 19, d_loss=0.042 g_loss=0.188 KID= 0.04707\n",
      "epoch 218, batch 0, d_loss=0.093 g_loss=0.190 KID= 0.04707\n",
      "epoch 218, batch 1, d_loss=0.052 g_loss=0.189 KID= 0.04707\n",
      "epoch 218, batch 2, d_loss=0.014 g_loss=0.199 KID= 0.04707\n",
      "epoch 218, batch 3, d_loss=0.050 g_loss=0.245 KID= 0.04707\n",
      "epoch 218, batch 4, d_loss=0.060 g_loss=0.266 KID= 0.04707\n",
      "epoch 218, batch 5, d_loss=0.017 g_loss=0.301 KID= 0.04707\n",
      "epoch 218, batch 6, d_loss=0.050 g_loss=0.392 KID= 0.04707\n",
      "epoch 218, batch 7, d_loss=0.029 g_loss=0.475 KID= 0.04707\n",
      "epoch 218, batch 8, d_loss=-0.015 g_loss=0.527 KID= 0.04707\n",
      "epoch 218, batch 9, d_loss=0.018 g_loss=0.547 KID= 0.04707\n",
      "epoch 218, batch 10, d_loss=-0.046 g_loss=0.505 KID= 0.04707\n",
      "epoch 218, batch 11, d_loss=0.048 g_loss=0.436 KID= 0.04707\n",
      "epoch 218, batch 12, d_loss=0.246 g_loss=0.421 KID= 0.04707\n",
      "epoch 218, batch 13, d_loss=0.112 g_loss=0.396 KID= 0.04707\n",
      "epoch 218, batch 14, d_loss=0.109 g_loss=0.328 KID= 0.04707\n",
      "epoch 218, batch 15, d_loss=0.059 g_loss=0.220 KID= 0.04707\n",
      "epoch 218, batch 16, d_loss=0.025 g_loss=0.188 KID= 0.04707\n",
      "epoch 218, batch 17, d_loss=-0.036 g_loss=0.169 KID= 0.04707\n",
      "epoch 218, batch 18, d_loss=-0.041 g_loss=0.173 KID= 0.04707\n",
      "epoch 218, batch 19, d_loss=0.036 g_loss=0.150 KID= 0.04707\n",
      "epoch 219, batch 0, d_loss=0.095 g_loss=0.085 KID= 0.04707\n",
      "epoch 219, batch 1, d_loss=0.046 g_loss=-0.004 KID= 0.04707\n",
      "epoch 219, batch 2, d_loss=0.033 g_loss=0.007 KID= 0.04707\n",
      "epoch 219, batch 3, d_loss=0.097 g_loss=0.044 KID= 0.04707\n",
      "epoch 219, batch 4, d_loss=0.098 g_loss=-0.003 KID= 0.04707\n",
      "epoch 219, batch 5, d_loss=0.012 g_loss=-0.085 KID= 0.04707\n",
      "epoch 219, batch 6, d_loss=0.152 g_loss=-0.083 KID= 0.04707\n",
      "epoch 219, batch 7, d_loss=0.028 g_loss=-0.099 KID= 0.04707\n",
      "epoch 219, batch 8, d_loss=0.020 g_loss=-0.086 KID= 0.04707\n",
      "epoch 219, batch 9, d_loss=0.039 g_loss=-0.038 KID= 0.04707\n",
      "epoch 219, batch 10, d_loss=-0.010 g_loss=-0.025 KID= 0.04707\n",
      "epoch 219, batch 11, d_loss=-0.036 g_loss=-0.006 KID= 0.04707\n",
      "epoch 219, batch 12, d_loss=0.069 g_loss=0.013 KID= 0.04707\n",
      "epoch 219, batch 13, d_loss=0.037 g_loss=0.013 KID= 0.04707\n",
      "epoch 219, batch 14, d_loss=0.025 g_loss=0.016 KID= 0.04707\n",
      "epoch 219, batch 15, d_loss=0.016 g_loss=-0.031 KID= 0.04707\n",
      "epoch 219, batch 16, d_loss=0.032 g_loss=-0.005 KID= 0.04707\n",
      "epoch 219, batch 17, d_loss=0.034 g_loss=0.031 KID= 0.04707\n",
      "epoch 219, batch 18, d_loss=0.031 g_loss=0.069 KID= 0.04707\n",
      "epoch 219, batch 19, d_loss=0.141 g_loss=0.129 KID= 0.04707\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 220, batch 0, d_loss=0.040 g_loss=0.143 KID= 0.05868\n",
      "epoch 220, batch 1, d_loss=0.090 g_loss=0.198 KID= 0.05868\n",
      "epoch 220, batch 2, d_loss=0.041 g_loss=0.231 KID= 0.05868\n",
      "epoch 220, batch 3, d_loss=-0.021 g_loss=0.240 KID= 0.05868\n",
      "epoch 220, batch 4, d_loss=0.018 g_loss=0.257 KID= 0.05868\n",
      "epoch 220, batch 5, d_loss=0.013 g_loss=0.263 KID= 0.05868\n",
      "epoch 220, batch 6, d_loss=0.048 g_loss=0.278 KID= 0.05868\n",
      "epoch 220, batch 7, d_loss=-0.014 g_loss=0.259 KID= 0.05868\n",
      "epoch 220, batch 8, d_loss=-0.028 g_loss=0.236 KID= 0.05868\n",
      "epoch 220, batch 9, d_loss=0.121 g_loss=0.156 KID= 0.05868\n",
      "epoch 220, batch 10, d_loss=0.157 g_loss=0.039 KID= 0.05868\n",
      "epoch 220, batch 11, d_loss=-0.023 g_loss=-0.063 KID= 0.05868\n",
      "epoch 220, batch 12, d_loss=0.193 g_loss=-0.104 KID= 0.05868\n",
      "epoch 220, batch 13, d_loss=0.103 g_loss=-0.116 KID= 0.05868\n",
      "epoch 220, batch 14, d_loss=0.164 g_loss=-0.142 KID= 0.05868\n",
      "epoch 220, batch 15, d_loss=0.013 g_loss=-0.214 KID= 0.05868\n",
      "epoch 220, batch 16, d_loss=0.069 g_loss=-0.234 KID= 0.05868\n",
      "epoch 220, batch 17, d_loss=-0.015 g_loss=-0.325 KID= 0.05868\n",
      "epoch 220, batch 18, d_loss=0.153 g_loss=-0.279 KID= 0.05868\n",
      "epoch 220, batch 19, d_loss=0.037 g_loss=-0.330 KID= 0.05868\n",
      "epoch 221, batch 0, d_loss=0.039 g_loss=-0.360 KID= 0.05868\n",
      "epoch 221, batch 1, d_loss=0.208 g_loss=-0.239 KID= 0.05868\n",
      "epoch 221, batch 2, d_loss=0.176 g_loss=-0.161 KID= 0.05868\n",
      "epoch 221, batch 3, d_loss=-0.003 g_loss=-0.112 KID= 0.05868\n",
      "epoch 221, batch 4, d_loss=0.069 g_loss=-0.034 KID= 0.05868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 221, batch 5, d_loss=-0.018 g_loss=0.107 KID= 0.05868\n",
      "epoch 221, batch 6, d_loss=0.073 g_loss=0.162 KID= 0.05868\n",
      "epoch 221, batch 7, d_loss=0.025 g_loss=0.200 KID= 0.05868\n",
      "epoch 221, batch 8, d_loss=-0.079 g_loss=0.339 KID= 0.05868\n",
      "epoch 221, batch 9, d_loss=0.331 g_loss=0.339 KID= 0.05868\n",
      "epoch 221, batch 10, d_loss=0.177 g_loss=0.323 KID= 0.05868\n",
      "epoch 221, batch 11, d_loss=0.043 g_loss=0.310 KID= 0.05868\n",
      "epoch 221, batch 12, d_loss=0.043 g_loss=0.258 KID= 0.05868\n",
      "epoch 221, batch 13, d_loss=0.058 g_loss=0.240 KID= 0.05868\n",
      "epoch 221, batch 14, d_loss=0.001 g_loss=0.196 KID= 0.05868\n",
      "epoch 221, batch 15, d_loss=-0.023 g_loss=0.076 KID= 0.05868\n",
      "epoch 221, batch 16, d_loss=0.092 g_loss=0.089 KID= 0.05868\n",
      "epoch 221, batch 17, d_loss=0.005 g_loss=0.084 KID= 0.05868\n",
      "epoch 221, batch 18, d_loss=0.123 g_loss=0.130 KID= 0.05868\n",
      "epoch 221, batch 19, d_loss=0.084 g_loss=0.177 KID= 0.05868\n",
      "epoch 222, batch 0, d_loss=0.030 g_loss=0.157 KID= 0.05868\n",
      "epoch 222, batch 1, d_loss=0.142 g_loss=0.147 KID= 0.05868\n",
      "epoch 222, batch 2, d_loss=0.132 g_loss=0.100 KID= 0.05868\n",
      "epoch 222, batch 3, d_loss=0.009 g_loss=0.053 KID= 0.05868\n",
      "epoch 222, batch 4, d_loss=0.076 g_loss=-0.006 KID= 0.05868\n",
      "epoch 222, batch 5, d_loss=0.054 g_loss=-0.048 KID= 0.05868\n",
      "epoch 222, batch 6, d_loss=-0.002 g_loss=-0.029 KID= 0.05868\n",
      "epoch 222, batch 7, d_loss=0.053 g_loss=0.013 KID= 0.05868\n",
      "epoch 222, batch 8, d_loss=0.008 g_loss=0.048 KID= 0.05868\n",
      "epoch 222, batch 9, d_loss=0.104 g_loss=0.020 KID= 0.05868\n",
      "epoch 222, batch 10, d_loss=0.133 g_loss=-0.032 KID= 0.05868\n",
      "epoch 222, batch 11, d_loss=0.045 g_loss=-0.020 KID= 0.05868\n",
      "epoch 222, batch 12, d_loss=0.109 g_loss=-0.018 KID= 0.05868\n",
      "epoch 222, batch 13, d_loss=0.050 g_loss=0.031 KID= 0.05868\n",
      "epoch 222, batch 14, d_loss=0.021 g_loss=0.072 KID= 0.05868\n",
      "epoch 222, batch 15, d_loss=0.021 g_loss=0.137 KID= 0.05868\n",
      "epoch 222, batch 16, d_loss=0.026 g_loss=0.214 KID= 0.05868\n",
      "epoch 222, batch 17, d_loss=-0.021 g_loss=0.222 KID= 0.05868\n",
      "epoch 222, batch 18, d_loss=0.012 g_loss=0.173 KID= 0.05868\n",
      "epoch 222, batch 19, d_loss=0.090 g_loss=0.154 KID= 0.05868\n",
      "epoch 223, batch 0, d_loss=0.075 g_loss=0.147 KID= 0.05868\n",
      "epoch 223, batch 1, d_loss=0.073 g_loss=0.083 KID= 0.05868\n",
      "epoch 223, batch 2, d_loss=0.090 g_loss=0.039 KID= 0.05868\n",
      "epoch 223, batch 3, d_loss=0.037 g_loss=0.075 KID= 0.05868\n",
      "epoch 223, batch 4, d_loss=0.056 g_loss=0.118 KID= 0.05868\n",
      "epoch 223, batch 5, d_loss=0.012 g_loss=0.097 KID= 0.05868\n",
      "epoch 223, batch 6, d_loss=0.044 g_loss=0.125 KID= 0.05868\n",
      "epoch 223, batch 7, d_loss=0.033 g_loss=0.129 KID= 0.05868\n",
      "epoch 223, batch 8, d_loss=-0.027 g_loss=0.124 KID= 0.05868\n",
      "epoch 223, batch 9, d_loss=0.146 g_loss=0.170 KID= 0.05868\n",
      "epoch 223, batch 10, d_loss=0.047 g_loss=0.197 KID= 0.05868\n",
      "epoch 223, batch 11, d_loss=0.008 g_loss=0.199 KID= 0.05868\n",
      "epoch 223, batch 12, d_loss=0.063 g_loss=0.178 KID= 0.05868\n",
      "epoch 223, batch 13, d_loss=0.078 g_loss=0.131 KID= 0.05868\n",
      "epoch 223, batch 14, d_loss=0.056 g_loss=0.066 KID= 0.05868\n",
      "epoch 223, batch 15, d_loss=0.031 g_loss=0.016 KID= 0.05868\n",
      "epoch 223, batch 16, d_loss=0.085 g_loss=-0.003 KID= 0.05868\n",
      "epoch 223, batch 17, d_loss=0.065 g_loss=-0.013 KID= 0.05868\n",
      "epoch 223, batch 18, d_loss=-0.006 g_loss=-0.002 KID= 0.05868\n",
      "epoch 223, batch 19, d_loss=0.091 g_loss=0.016 KID= 0.05868\n",
      "epoch 224, batch 0, d_loss=0.067 g_loss=0.093 KID= 0.05868\n",
      "epoch 224, batch 1, d_loss=0.009 g_loss=0.139 KID= 0.05868\n",
      "epoch 224, batch 2, d_loss=0.063 g_loss=0.083 KID= 0.05868\n",
      "epoch 224, batch 3, d_loss=-0.025 g_loss=0.137 KID= 0.05868\n",
      "epoch 224, batch 4, d_loss=0.056 g_loss=0.215 KID= 0.05868\n",
      "epoch 224, batch 5, d_loss=0.051 g_loss=0.298 KID= 0.05868\n",
      "epoch 224, batch 6, d_loss=-0.012 g_loss=0.386 KID= 0.05868\n",
      "epoch 224, batch 7, d_loss=-0.062 g_loss=0.404 KID= 0.05868\n",
      "epoch 224, batch 8, d_loss=-0.004 g_loss=0.348 KID= 0.05868\n",
      "epoch 224, batch 9, d_loss=0.049 g_loss=0.253 KID= 0.05868\n",
      "epoch 224, batch 10, d_loss=0.056 g_loss=0.192 KID= 0.05868\n",
      "epoch 224, batch 11, d_loss=0.063 g_loss=0.132 KID= 0.05868\n",
      "epoch 224, batch 12, d_loss=0.051 g_loss=0.073 KID= 0.05868\n",
      "epoch 224, batch 13, d_loss=0.005 g_loss=0.001 KID= 0.05868\n",
      "epoch 224, batch 14, d_loss=0.027 g_loss=0.017 KID= 0.05868\n",
      "epoch 224, batch 15, d_loss=0.005 g_loss=0.052 KID= 0.05868\n",
      "epoch 224, batch 16, d_loss=0.030 g_loss=0.101 KID= 0.05868\n",
      "epoch 224, batch 17, d_loss=-0.030 g_loss=0.112 KID= 0.05868\n",
      "epoch 224, batch 18, d_loss=0.028 g_loss=0.100 KID= 0.05868\n",
      "epoch 224, batch 19, d_loss=0.099 g_loss=0.091 KID= 0.05868\n",
      "epoch 225, batch 0, d_loss=0.057 g_loss=0.059 KID= 0.05868\n",
      "epoch 225, batch 1, d_loss=0.041 g_loss=0.027 KID= 0.05868\n",
      "epoch 225, batch 2, d_loss=0.079 g_loss=-0.098 KID= 0.05868\n",
      "epoch 225, batch 3, d_loss=0.057 g_loss=-0.150 KID= 0.05868\n",
      "epoch 225, batch 4, d_loss=0.022 g_loss=-0.106 KID= 0.05868\n",
      "epoch 225, batch 5, d_loss=-0.033 g_loss=-0.001 KID= 0.05868\n",
      "epoch 225, batch 6, d_loss=-0.006 g_loss=0.164 KID= 0.05868\n",
      "epoch 225, batch 7, d_loss=-0.019 g_loss=0.312 KID= 0.05868\n",
      "epoch 225, batch 8, d_loss=-0.039 g_loss=0.432 KID= 0.05868\n",
      "epoch 225, batch 9, d_loss=-0.075 g_loss=0.465 KID= 0.05868\n",
      "epoch 225, batch 10, d_loss=-0.019 g_loss=0.501 KID= 0.05868\n",
      "epoch 225, batch 11, d_loss=0.121 g_loss=0.481 KID= 0.05868\n",
      "epoch 225, batch 12, d_loss=0.202 g_loss=0.389 KID= 0.05868\n",
      "epoch 225, batch 13, d_loss=-0.028 g_loss=0.410 KID= 0.05868\n",
      "epoch 225, batch 14, d_loss=0.052 g_loss=0.356 KID= 0.05868\n",
      "epoch 225, batch 15, d_loss=0.046 g_loss=0.264 KID= 0.05868\n",
      "epoch 225, batch 16, d_loss=0.046 g_loss=0.164 KID= 0.05868\n",
      "epoch 225, batch 17, d_loss=0.008 g_loss=0.125 KID= 0.05868\n",
      "epoch 225, batch 18, d_loss=-0.031 g_loss=0.066 KID= 0.05868\n",
      "epoch 225, batch 19, d_loss=0.166 g_loss=0.044 KID= 0.05868\n",
      "epoch 226, batch 0, d_loss=0.095 g_loss=-0.020 KID= 0.05868\n",
      "epoch 226, batch 1, d_loss=-0.011 g_loss=-0.074 KID= 0.05868\n",
      "epoch 226, batch 2, d_loss=0.074 g_loss=-0.118 KID= 0.05868\n",
      "epoch 226, batch 3, d_loss=0.097 g_loss=-0.156 KID= 0.05868\n",
      "epoch 226, batch 4, d_loss=-0.003 g_loss=-0.237 KID= 0.05868\n",
      "epoch 226, batch 5, d_loss=0.126 g_loss=-0.241 KID= 0.05868\n",
      "epoch 226, batch 6, d_loss=0.083 g_loss=-0.211 KID= 0.05868\n",
      "epoch 226, batch 7, d_loss=0.142 g_loss=-0.161 KID= 0.05868\n",
      "epoch 226, batch 8, d_loss=0.046 g_loss=-0.134 KID= 0.05868\n",
      "epoch 226, batch 9, d_loss=0.028 g_loss=-0.176 KID= 0.05868\n",
      "epoch 226, batch 10, d_loss=0.011 g_loss=-0.222 KID= 0.05868\n",
      "epoch 226, batch 11, d_loss=0.045 g_loss=-0.233 KID= 0.05868\n",
      "epoch 226, batch 12, d_loss=0.044 g_loss=-0.270 KID= 0.05868\n",
      "epoch 226, batch 13, d_loss=-0.100 g_loss=-0.310 KID= 0.05868\n",
      "epoch 226, batch 14, d_loss=0.095 g_loss=-0.291 KID= 0.05868\n",
      "epoch 226, batch 15, d_loss=0.045 g_loss=-0.311 KID= 0.05868\n",
      "epoch 226, batch 16, d_loss=-0.005 g_loss=-0.336 KID= 0.05868\n",
      "epoch 226, batch 17, d_loss=0.011 g_loss=-0.311 KID= 0.05868\n",
      "epoch 226, batch 18, d_loss=0.108 g_loss=-0.204 KID= 0.05868\n",
      "epoch 226, batch 19, d_loss=0.089 g_loss=-0.156 KID= 0.05868\n",
      "epoch 227, batch 0, d_loss=0.106 g_loss=-0.077 KID= 0.05868\n",
      "epoch 227, batch 1, d_loss=0.070 g_loss=0.015 KID= 0.05868\n",
      "epoch 227, batch 2, d_loss=0.041 g_loss=0.048 KID= 0.05868\n",
      "epoch 227, batch 3, d_loss=0.048 g_loss=0.087 KID= 0.05868\n",
      "epoch 227, batch 4, d_loss=-0.020 g_loss=0.075 KID= 0.05868\n",
      "epoch 227, batch 5, d_loss=-0.002 g_loss=0.062 KID= 0.05868\n",
      "epoch 227, batch 6, d_loss=0.087 g_loss=0.100 KID= 0.05868\n",
      "epoch 227, batch 7, d_loss=0.095 g_loss=0.205 KID= 0.05868\n",
      "epoch 227, batch 8, d_loss=-0.019 g_loss=0.293 KID= 0.05868\n",
      "epoch 227, batch 9, d_loss=0.109 g_loss=0.328 KID= 0.05868\n",
      "epoch 227, batch 10, d_loss=0.065 g_loss=0.394 KID= 0.05868\n",
      "epoch 227, batch 11, d_loss=-0.033 g_loss=0.437 KID= 0.05868\n",
      "epoch 227, batch 12, d_loss=0.107 g_loss=0.414 KID= 0.05868\n",
      "epoch 227, batch 13, d_loss=0.089 g_loss=0.450 KID= 0.05868\n",
      "epoch 227, batch 14, d_loss=0.077 g_loss=0.458 KID= 0.05868\n",
      "epoch 227, batch 15, d_loss=0.054 g_loss=0.450 KID= 0.05868\n",
      "epoch 227, batch 16, d_loss=0.052 g_loss=0.418 KID= 0.05868\n",
      "epoch 227, batch 17, d_loss=0.005 g_loss=0.375 KID= 0.05868\n",
      "epoch 227, batch 18, d_loss=0.125 g_loss=0.389 KID= 0.05868\n",
      "epoch 227, batch 19, d_loss=0.107 g_loss=0.374 KID= 0.05868\n",
      "epoch 228, batch 0, d_loss=0.004 g_loss=0.358 KID= 0.05868\n",
      "epoch 228, batch 1, d_loss=0.087 g_loss=0.358 KID= 0.05868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 228, batch 2, d_loss=0.078 g_loss=0.311 KID= 0.05868\n",
      "epoch 228, batch 3, d_loss=-0.039 g_loss=0.259 KID= 0.05868\n",
      "epoch 228, batch 4, d_loss=-0.016 g_loss=0.199 KID= 0.05868\n",
      "epoch 228, batch 5, d_loss=-0.083 g_loss=0.107 KID= 0.05868\n",
      "epoch 228, batch 6, d_loss=-0.031 g_loss=0.049 KID= 0.05868\n",
      "epoch 228, batch 7, d_loss=0.090 g_loss=0.024 KID= 0.05868\n",
      "epoch 228, batch 8, d_loss=0.053 g_loss=0.039 KID= 0.05868\n",
      "epoch 228, batch 9, d_loss=0.026 g_loss=0.099 KID= 0.05868\n",
      "epoch 228, batch 10, d_loss=0.034 g_loss=0.163 KID= 0.05868\n",
      "epoch 228, batch 11, d_loss=0.027 g_loss=0.200 KID= 0.05868\n",
      "epoch 228, batch 12, d_loss=0.054 g_loss=0.152 KID= 0.05868\n",
      "epoch 228, batch 13, d_loss=-0.060 g_loss=0.138 KID= 0.05868\n",
      "epoch 228, batch 14, d_loss=0.040 g_loss=0.150 KID= 0.05868\n",
      "epoch 228, batch 15, d_loss=0.042 g_loss=0.110 KID= 0.05868\n",
      "epoch 228, batch 16, d_loss=0.085 g_loss=0.099 KID= 0.05868\n",
      "epoch 228, batch 17, d_loss=-0.013 g_loss=0.148 KID= 0.05868\n",
      "epoch 228, batch 18, d_loss=0.008 g_loss=0.163 KID= 0.05868\n",
      "epoch 228, batch 19, d_loss=0.079 g_loss=0.167 KID= 0.05868\n",
      "epoch 229, batch 0, d_loss=-0.001 g_loss=0.172 KID= 0.05868\n",
      "epoch 229, batch 1, d_loss=-0.042 g_loss=0.183 KID= 0.05868\n",
      "epoch 229, batch 2, d_loss=0.008 g_loss=0.145 KID= 0.05868\n",
      "epoch 229, batch 3, d_loss=0.084 g_loss=0.103 KID= 0.05868\n",
      "epoch 229, batch 4, d_loss=0.005 g_loss=0.049 KID= 0.05868\n",
      "epoch 229, batch 5, d_loss=0.096 g_loss=0.066 KID= 0.05868\n",
      "epoch 229, batch 6, d_loss=-0.002 g_loss=0.067 KID= 0.05868\n",
      "epoch 229, batch 7, d_loss=-0.038 g_loss=0.073 KID= 0.05868\n",
      "epoch 229, batch 8, d_loss=-0.020 g_loss=0.015 KID= 0.05868\n",
      "epoch 229, batch 9, d_loss=0.072 g_loss=0.015 KID= 0.05868\n",
      "epoch 229, batch 10, d_loss=0.027 g_loss=-0.044 KID= 0.05868\n",
      "epoch 229, batch 11, d_loss=0.112 g_loss=0.038 KID= 0.05868\n",
      "epoch 229, batch 12, d_loss=0.057 g_loss=0.031 KID= 0.05868\n",
      "epoch 229, batch 13, d_loss=0.022 g_loss=0.038 KID= 0.05868\n",
      "epoch 229, batch 14, d_loss=0.043 g_loss=0.088 KID= 0.05868\n",
      "epoch 229, batch 15, d_loss=-0.029 g_loss=0.076 KID= 0.05868\n",
      "epoch 229, batch 16, d_loss=-0.006 g_loss=0.040 KID= 0.05868\n",
      "epoch 229, batch 17, d_loss=0.069 g_loss=0.119 KID= 0.05868\n",
      "epoch 229, batch 18, d_loss=-0.003 g_loss=0.109 KID= 0.05868\n",
      "epoch 229, batch 19, d_loss=0.059 g_loss=0.102 KID= 0.05868\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 230, batch 0, d_loss=0.093 g_loss=0.089 KID= 0.04298\n",
      "epoch 230, batch 1, d_loss=0.016 g_loss=0.063 KID= 0.04298\n",
      "epoch 230, batch 2, d_loss=0.121 g_loss=0.046 KID= 0.04298\n",
      "epoch 230, batch 3, d_loss=0.045 g_loss=-0.004 KID= 0.04298\n",
      "epoch 230, batch 4, d_loss=0.045 g_loss=-0.050 KID= 0.04298\n",
      "epoch 230, batch 5, d_loss=0.102 g_loss=-0.132 KID= 0.04298\n",
      "epoch 230, batch 6, d_loss=0.147 g_loss=-0.172 KID= 0.04298\n",
      "epoch 230, batch 7, d_loss=0.092 g_loss=-0.150 KID= 0.04298\n",
      "epoch 230, batch 8, d_loss=0.041 g_loss=-0.098 KID= 0.04298\n",
      "epoch 230, batch 9, d_loss=0.070 g_loss=-0.031 KID= 0.04298\n",
      "epoch 230, batch 10, d_loss=0.025 g_loss=0.016 KID= 0.04298\n",
      "epoch 230, batch 11, d_loss=0.063 g_loss=0.048 KID= 0.04298\n",
      "epoch 230, batch 12, d_loss=-0.019 g_loss=0.036 KID= 0.04298\n",
      "epoch 230, batch 13, d_loss=0.096 g_loss=0.042 KID= 0.04298\n",
      "epoch 230, batch 14, d_loss=0.075 g_loss=0.042 KID= 0.04298\n",
      "epoch 230, batch 15, d_loss=0.015 g_loss=0.037 KID= 0.04298\n",
      "epoch 230, batch 16, d_loss=0.029 g_loss=0.094 KID= 0.04298\n",
      "epoch 230, batch 17, d_loss=0.041 g_loss=0.124 KID= 0.04298\n",
      "epoch 230, batch 18, d_loss=0.040 g_loss=0.183 KID= 0.04298\n",
      "epoch 230, batch 19, d_loss=0.038 g_loss=0.207 KID= 0.04298\n",
      "epoch 231, batch 0, d_loss=-0.029 g_loss=0.183 KID= 0.04298\n",
      "epoch 231, batch 1, d_loss=0.050 g_loss=0.194 KID= 0.04298\n",
      "epoch 231, batch 2, d_loss=0.111 g_loss=0.151 KID= 0.04298\n",
      "epoch 231, batch 3, d_loss=0.018 g_loss=0.123 KID= 0.04298\n",
      "epoch 231, batch 4, d_loss=0.037 g_loss=0.070 KID= 0.04298\n",
      "epoch 231, batch 5, d_loss=0.075 g_loss=0.074 KID= 0.04298\n",
      "epoch 231, batch 6, d_loss=0.024 g_loss=0.071 KID= 0.04298\n",
      "epoch 231, batch 7, d_loss=-0.005 g_loss=0.083 KID= 0.04298\n",
      "epoch 231, batch 8, d_loss=0.000 g_loss=0.048 KID= 0.04298\n",
      "epoch 231, batch 9, d_loss=0.114 g_loss=-0.004 KID= 0.04298\n",
      "epoch 231, batch 10, d_loss=0.094 g_loss=-0.055 KID= 0.04298\n",
      "epoch 231, batch 11, d_loss=-0.009 g_loss=-0.145 KID= 0.04298\n",
      "epoch 231, batch 12, d_loss=0.038 g_loss=-0.140 KID= 0.04298\n",
      "epoch 231, batch 13, d_loss=0.056 g_loss=-0.151 KID= 0.04298\n",
      "epoch 231, batch 14, d_loss=0.029 g_loss=-0.170 KID= 0.04298\n",
      "epoch 231, batch 15, d_loss=-0.009 g_loss=-0.159 KID= 0.04298\n",
      "epoch 231, batch 16, d_loss=0.041 g_loss=-0.122 KID= 0.04298\n",
      "epoch 231, batch 17, d_loss=0.034 g_loss=-0.057 KID= 0.04298\n",
      "epoch 231, batch 18, d_loss=-0.010 g_loss=0.015 KID= 0.04298\n",
      "epoch 231, batch 19, d_loss=0.072 g_loss=0.089 KID= 0.04298\n",
      "epoch 232, batch 0, d_loss=0.007 g_loss=0.126 KID= 0.04298\n",
      "epoch 232, batch 1, d_loss=0.045 g_loss=0.141 KID= 0.04298\n",
      "epoch 232, batch 2, d_loss=0.093 g_loss=0.152 KID= 0.04298\n",
      "epoch 232, batch 3, d_loss=0.003 g_loss=0.152 KID= 0.04298\n",
      "epoch 232, batch 4, d_loss=0.065 g_loss=0.157 KID= 0.04298\n",
      "epoch 232, batch 5, d_loss=0.053 g_loss=0.163 KID= 0.04298\n",
      "epoch 232, batch 6, d_loss=-0.011 g_loss=0.180 KID= 0.04298\n",
      "epoch 232, batch 7, d_loss=0.028 g_loss=0.179 KID= 0.04298\n",
      "epoch 232, batch 8, d_loss=0.035 g_loss=0.195 KID= 0.04298\n",
      "epoch 232, batch 9, d_loss=0.015 g_loss=0.176 KID= 0.04298\n",
      "epoch 232, batch 10, d_loss=0.140 g_loss=0.158 KID= 0.04298\n",
      "epoch 232, batch 11, d_loss=0.033 g_loss=0.111 KID= 0.04298\n",
      "epoch 232, batch 12, d_loss=0.012 g_loss=0.061 KID= 0.04298\n",
      "epoch 232, batch 13, d_loss=-0.007 g_loss=-0.017 KID= 0.04298\n",
      "epoch 232, batch 14, d_loss=-0.023 g_loss=-0.067 KID= 0.04298\n",
      "epoch 232, batch 15, d_loss=-0.018 g_loss=-0.101 KID= 0.04298\n",
      "epoch 232, batch 16, d_loss=0.041 g_loss=-0.121 KID= 0.04298\n",
      "epoch 232, batch 17, d_loss=0.042 g_loss=-0.071 KID= 0.04298\n",
      "epoch 232, batch 18, d_loss=-0.003 g_loss=-0.013 KID= 0.04298\n",
      "epoch 232, batch 19, d_loss=0.147 g_loss=0.124 KID= 0.04298\n",
      "epoch 233, batch 0, d_loss=0.057 g_loss=0.160 KID= 0.04298\n",
      "epoch 233, batch 1, d_loss=0.124 g_loss=0.204 KID= 0.04298\n",
      "epoch 233, batch 2, d_loss=0.131 g_loss=0.239 KID= 0.04298\n",
      "epoch 233, batch 3, d_loss=0.107 g_loss=0.267 KID= 0.04298\n",
      "epoch 233, batch 4, d_loss=0.094 g_loss=0.291 KID= 0.04298\n",
      "epoch 233, batch 5, d_loss=0.058 g_loss=0.308 KID= 0.04298\n",
      "epoch 233, batch 6, d_loss=0.059 g_loss=0.342 KID= 0.04298\n",
      "epoch 233, batch 7, d_loss=0.071 g_loss=0.357 KID= 0.04298\n",
      "epoch 233, batch 8, d_loss=0.048 g_loss=0.354 KID= 0.04298\n",
      "epoch 233, batch 9, d_loss=0.067 g_loss=0.323 KID= 0.04298\n",
      "epoch 233, batch 10, d_loss=0.072 g_loss=0.263 KID= 0.04298\n",
      "epoch 233, batch 11, d_loss=-0.015 g_loss=0.211 KID= 0.04298\n",
      "epoch 233, batch 12, d_loss=0.036 g_loss=0.114 KID= 0.04298\n",
      "epoch 233, batch 13, d_loss=-0.010 g_loss=0.035 KID= 0.04298\n",
      "epoch 233, batch 14, d_loss=0.045 g_loss=0.021 KID= 0.04298\n",
      "epoch 233, batch 15, d_loss=0.049 g_loss=0.030 KID= 0.04298\n",
      "epoch 233, batch 16, d_loss=0.051 g_loss=0.067 KID= 0.04298\n",
      "epoch 233, batch 17, d_loss=0.060 g_loss=0.093 KID= 0.04298\n",
      "epoch 233, batch 18, d_loss=0.086 g_loss=0.121 KID= 0.04298\n",
      "epoch 233, batch 19, d_loss=-0.011 g_loss=0.105 KID= 0.04298\n",
      "epoch 234, batch 0, d_loss=-0.008 g_loss=0.097 KID= 0.04298\n",
      "epoch 234, batch 1, d_loss=0.044 g_loss=0.119 KID= 0.04298\n",
      "epoch 234, batch 2, d_loss=0.036 g_loss=0.130 KID= 0.04298\n",
      "epoch 234, batch 3, d_loss=0.000 g_loss=0.179 KID= 0.04298\n",
      "epoch 234, batch 4, d_loss=-0.023 g_loss=0.267 KID= 0.04298\n",
      "epoch 234, batch 5, d_loss=0.034 g_loss=0.249 KID= 0.04298\n",
      "epoch 234, batch 6, d_loss=-0.038 g_loss=0.304 KID= 0.04298\n",
      "epoch 234, batch 7, d_loss=-0.072 g_loss=0.292 KID= 0.04298\n",
      "epoch 234, batch 8, d_loss=-0.079 g_loss=0.238 KID= 0.04298\n",
      "epoch 234, batch 9, d_loss=0.132 g_loss=0.182 KID= 0.04298\n",
      "epoch 234, batch 10, d_loss=0.130 g_loss=0.123 KID= 0.04298\n",
      "epoch 234, batch 11, d_loss=-0.003 g_loss=0.110 KID= 0.04298\n",
      "epoch 234, batch 12, d_loss=0.150 g_loss=0.135 KID= 0.04298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 234, batch 13, d_loss=0.093 g_loss=0.202 KID= 0.04298\n",
      "epoch 234, batch 14, d_loss=0.091 g_loss=0.309 KID= 0.04298\n",
      "epoch 234, batch 15, d_loss=-0.021 g_loss=0.351 KID= 0.04298\n",
      "epoch 234, batch 16, d_loss=0.008 g_loss=0.387 KID= 0.04298\n",
      "epoch 234, batch 17, d_loss=0.036 g_loss=0.379 KID= 0.04298\n",
      "epoch 234, batch 18, d_loss=0.083 g_loss=0.345 KID= 0.04298\n",
      "epoch 234, batch 19, d_loss=0.108 g_loss=0.241 KID= 0.04298\n",
      "epoch 235, batch 0, d_loss=-0.007 g_loss=0.135 KID= 0.04298\n",
      "epoch 235, batch 1, d_loss=0.189 g_loss=0.155 KID= 0.04298\n",
      "epoch 235, batch 2, d_loss=0.152 g_loss=0.136 KID= 0.04298\n",
      "epoch 235, batch 3, d_loss=0.031 g_loss=0.158 KID= 0.04298\n",
      "epoch 235, batch 4, d_loss=0.018 g_loss=0.232 KID= 0.04298\n",
      "epoch 235, batch 5, d_loss=0.031 g_loss=0.316 KID= 0.04298\n",
      "epoch 235, batch 6, d_loss=0.041 g_loss=0.524 KID= 0.04298\n",
      "epoch 235, batch 7, d_loss=0.003 g_loss=0.690 KID= 0.04298\n",
      "epoch 235, batch 8, d_loss=-0.024 g_loss=0.813 KID= 0.04298\n",
      "epoch 235, batch 9, d_loss=0.097 g_loss=0.704 KID= 0.04298\n",
      "epoch 235, batch 10, d_loss=0.059 g_loss=0.370 KID= 0.04298\n",
      "epoch 235, batch 11, d_loss=0.037 g_loss=0.075 KID= 0.04298\n",
      "epoch 235, batch 12, d_loss=-0.095 g_loss=-0.378 KID= 0.04298\n",
      "epoch 235, batch 13, d_loss=0.018 g_loss=-0.533 KID= 0.04298\n",
      "epoch 235, batch 14, d_loss=0.158 g_loss=-0.373 KID= 0.04298\n",
      "epoch 235, batch 15, d_loss=0.110 g_loss=-0.175 KID= 0.04298\n",
      "epoch 235, batch 16, d_loss=0.008 g_loss=0.160 KID= 0.04298\n",
      "epoch 235, batch 17, d_loss=-0.065 g_loss=0.391 KID= 0.04298\n",
      "epoch 235, batch 18, d_loss=-0.113 g_loss=0.563 KID= 0.04298\n",
      "epoch 235, batch 19, d_loss=-0.053 g_loss=0.633 KID= 0.04298\n",
      "epoch 236, batch 0, d_loss=-0.063 g_loss=0.580 KID= 0.04298\n",
      "epoch 236, batch 1, d_loss=-0.007 g_loss=0.406 KID= 0.04298\n",
      "epoch 236, batch 2, d_loss=0.097 g_loss=0.286 KID= 0.04298\n",
      "epoch 236, batch 3, d_loss=0.036 g_loss=0.177 KID= 0.04298\n",
      "epoch 236, batch 4, d_loss=0.032 g_loss=0.095 KID= 0.04298\n",
      "epoch 236, batch 5, d_loss=0.095 g_loss=0.073 KID= 0.04298\n",
      "epoch 236, batch 6, d_loss=0.074 g_loss=0.047 KID= 0.04298\n",
      "epoch 236, batch 7, d_loss=0.051 g_loss=0.022 KID= 0.04298\n",
      "epoch 236, batch 8, d_loss=0.095 g_loss=0.095 KID= 0.04298\n",
      "epoch 236, batch 9, d_loss=0.012 g_loss=0.137 KID= 0.04298\n",
      "epoch 236, batch 10, d_loss=0.042 g_loss=0.207 KID= 0.04298\n",
      "epoch 236, batch 11, d_loss=-0.027 g_loss=0.215 KID= 0.04298\n",
      "epoch 236, batch 12, d_loss=-0.083 g_loss=0.194 KID= 0.04298\n",
      "epoch 236, batch 13, d_loss=0.016 g_loss=0.157 KID= 0.04298\n",
      "epoch 236, batch 14, d_loss=0.017 g_loss=0.114 KID= 0.04298\n",
      "epoch 236, batch 15, d_loss=0.059 g_loss=0.099 KID= 0.04298\n",
      "epoch 236, batch 16, d_loss=0.012 g_loss=0.059 KID= 0.04298\n",
      "epoch 236, batch 17, d_loss=-0.030 g_loss=0.028 KID= 0.04298\n",
      "epoch 236, batch 18, d_loss=0.061 g_loss=-0.060 KID= 0.04298\n",
      "epoch 236, batch 19, d_loss=0.182 g_loss=-0.038 KID= 0.04298\n",
      "epoch 237, batch 0, d_loss=0.023 g_loss=-0.049 KID= 0.04298\n",
      "epoch 237, batch 1, d_loss=0.088 g_loss=-0.073 KID= 0.04298\n",
      "epoch 237, batch 2, d_loss=0.139 g_loss=-0.059 KID= 0.04298\n",
      "epoch 237, batch 3, d_loss=0.033 g_loss=-0.096 KID= 0.04298\n",
      "epoch 237, batch 4, d_loss=0.001 g_loss=-0.127 KID= 0.04298\n",
      "epoch 237, batch 5, d_loss=0.016 g_loss=-0.178 KID= 0.04298\n",
      "epoch 237, batch 6, d_loss=-0.027 g_loss=-0.258 KID= 0.04298\n",
      "epoch 237, batch 7, d_loss=0.048 g_loss=-0.255 KID= 0.04298\n",
      "epoch 237, batch 8, d_loss=-0.026 g_loss=-0.271 KID= 0.04298\n",
      "epoch 237, batch 9, d_loss=0.020 g_loss=-0.215 KID= 0.04298\n",
      "epoch 237, batch 10, d_loss=0.024 g_loss=-0.117 KID= 0.04298\n",
      "epoch 237, batch 11, d_loss=0.019 g_loss=-0.080 KID= 0.04298\n",
      "epoch 237, batch 12, d_loss=-0.036 g_loss=-0.005 KID= 0.04298\n",
      "epoch 237, batch 13, d_loss=0.028 g_loss=0.087 KID= 0.04298\n",
      "epoch 237, batch 14, d_loss=0.033 g_loss=0.246 KID= 0.04298\n",
      "epoch 237, batch 15, d_loss=-0.036 g_loss=0.265 KID= 0.04298\n",
      "epoch 237, batch 16, d_loss=0.016 g_loss=0.394 KID= 0.04298\n",
      "epoch 237, batch 17, d_loss=-0.013 g_loss=0.450 KID= 0.04298\n",
      "epoch 237, batch 18, d_loss=0.083 g_loss=0.456 KID= 0.04298\n",
      "epoch 237, batch 19, d_loss=0.094 g_loss=0.243 KID= 0.04298\n",
      "epoch 238, batch 0, d_loss=-0.004 g_loss=0.063 KID= 0.04298\n",
      "epoch 238, batch 1, d_loss=0.020 g_loss=-0.068 KID= 0.04298\n",
      "epoch 238, batch 2, d_loss=0.062 g_loss=-0.187 KID= 0.04298\n",
      "epoch 238, batch 3, d_loss=-0.004 g_loss=-0.350 KID= 0.04298\n",
      "epoch 238, batch 4, d_loss=0.089 g_loss=-0.382 KID= 0.04298\n",
      "epoch 238, batch 5, d_loss=0.103 g_loss=-0.421 KID= 0.04298\n",
      "epoch 238, batch 6, d_loss=0.021 g_loss=-0.371 KID= 0.04298\n",
      "epoch 238, batch 7, d_loss=0.105 g_loss=-0.192 KID= 0.04298\n",
      "epoch 238, batch 8, d_loss=0.097 g_loss=-0.111 KID= 0.04298\n",
      "epoch 238, batch 9, d_loss=0.144 g_loss=-0.059 KID= 0.04298\n",
      "epoch 238, batch 10, d_loss=0.154 g_loss=0.021 KID= 0.04298\n",
      "epoch 238, batch 11, d_loss=0.098 g_loss=0.022 KID= 0.04298\n",
      "epoch 238, batch 12, d_loss=0.051 g_loss=0.054 KID= 0.04298\n",
      "epoch 238, batch 13, d_loss=0.099 g_loss=0.102 KID= 0.04298\n",
      "epoch 238, batch 14, d_loss=0.068 g_loss=0.188 KID= 0.04298\n",
      "epoch 238, batch 15, d_loss=0.013 g_loss=0.247 KID= 0.04298\n",
      "epoch 238, batch 16, d_loss=0.082 g_loss=0.331 KID= 0.04298\n",
      "epoch 238, batch 17, d_loss=0.001 g_loss=0.408 KID= 0.04298\n",
      "epoch 238, batch 18, d_loss=0.025 g_loss=0.485 KID= 0.04298\n",
      "epoch 238, batch 19, d_loss=-0.018 g_loss=0.449 KID= 0.04298\n",
      "epoch 239, batch 0, d_loss=-0.057 g_loss=0.389 KID= 0.04298\n",
      "epoch 239, batch 1, d_loss=0.002 g_loss=0.355 KID= 0.04298\n",
      "epoch 239, batch 2, d_loss=0.100 g_loss=0.266 KID= 0.04298\n",
      "epoch 239, batch 3, d_loss=0.139 g_loss=0.185 KID= 0.04298\n",
      "epoch 239, batch 4, d_loss=0.058 g_loss=0.180 KID= 0.04298\n",
      "epoch 239, batch 5, d_loss=0.082 g_loss=0.175 KID= 0.04298\n",
      "epoch 239, batch 6, d_loss=0.050 g_loss=0.226 KID= 0.04298\n",
      "epoch 239, batch 7, d_loss=0.009 g_loss=0.241 KID= 0.04298\n",
      "epoch 239, batch 8, d_loss=-0.029 g_loss=0.284 KID= 0.04298\n",
      "epoch 239, batch 9, d_loss=0.100 g_loss=0.226 KID= 0.04298\n",
      "epoch 239, batch 10, d_loss=0.094 g_loss=0.149 KID= 0.04298\n",
      "epoch 239, batch 11, d_loss=0.056 g_loss=0.048 KID= 0.04298\n",
      "epoch 239, batch 12, d_loss=0.046 g_loss=-0.034 KID= 0.04298\n",
      "epoch 239, batch 13, d_loss=0.078 g_loss=-0.118 KID= 0.04298\n",
      "epoch 239, batch 14, d_loss=0.061 g_loss=-0.146 KID= 0.04298\n",
      "epoch 239, batch 15, d_loss=0.058 g_loss=-0.134 KID= 0.04298\n",
      "epoch 239, batch 16, d_loss=0.049 g_loss=-0.127 KID= 0.04298\n",
      "epoch 239, batch 17, d_loss=0.057 g_loss=-0.130 KID= 0.04298\n",
      "epoch 239, batch 18, d_loss=0.055 g_loss=-0.053 KID= 0.04298\n",
      "epoch 239, batch 19, d_loss=0.035 g_loss=-0.021 KID= 0.04298\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 240, batch 0, d_loss=-0.064 g_loss=-0.029 KID= 0.04932\n",
      "epoch 240, batch 1, d_loss=0.083 g_loss=-0.032 KID= 0.04932\n",
      "epoch 240, batch 2, d_loss=0.110 g_loss=-0.110 KID= 0.04932\n",
      "epoch 240, batch 3, d_loss=0.120 g_loss=-0.132 KID= 0.04932\n",
      "epoch 240, batch 4, d_loss=0.099 g_loss=-0.120 KID= 0.04932\n",
      "epoch 240, batch 5, d_loss=0.114 g_loss=-0.096 KID= 0.04932\n",
      "epoch 240, batch 6, d_loss=0.100 g_loss=-0.070 KID= 0.04932\n",
      "epoch 240, batch 7, d_loss=0.038 g_loss=-0.041 KID= 0.04932\n",
      "epoch 240, batch 8, d_loss=-0.010 g_loss=-0.044 KID= 0.04932\n",
      "epoch 240, batch 9, d_loss=0.086 g_loss=-0.042 KID= 0.04932\n",
      "epoch 240, batch 10, d_loss=0.093 g_loss=-0.054 KID= 0.04932\n",
      "epoch 240, batch 11, d_loss=0.068 g_loss=-0.038 KID= 0.04932\n",
      "epoch 240, batch 12, d_loss=0.060 g_loss=-0.002 KID= 0.04932\n",
      "epoch 240, batch 13, d_loss=0.044 g_loss=0.022 KID= 0.04932\n",
      "epoch 240, batch 14, d_loss=0.108 g_loss=0.132 KID= 0.04932\n",
      "epoch 240, batch 15, d_loss=0.068 g_loss=0.169 KID= 0.04932\n",
      "epoch 240, batch 16, d_loss=0.028 g_loss=0.212 KID= 0.04932\n",
      "epoch 240, batch 17, d_loss=0.071 g_loss=0.289 KID= 0.04932\n",
      "epoch 240, batch 18, d_loss=0.044 g_loss=0.404 KID= 0.04932\n",
      "epoch 240, batch 19, d_loss=0.033 g_loss=0.444 KID= 0.04932\n",
      "epoch 241, batch 0, d_loss=0.004 g_loss=0.461 KID= 0.04932\n",
      "epoch 241, batch 1, d_loss=0.043 g_loss=0.450 KID= 0.04932\n",
      "epoch 241, batch 2, d_loss=0.002 g_loss=0.355 KID= 0.04932\n",
      "epoch 241, batch 3, d_loss=0.062 g_loss=0.296 KID= 0.04932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 241, batch 4, d_loss=0.033 g_loss=0.282 KID= 0.04932\n",
      "epoch 241, batch 5, d_loss=0.058 g_loss=0.263 KID= 0.04932\n",
      "epoch 241, batch 6, d_loss=0.059 g_loss=0.255 KID= 0.04932\n",
      "epoch 241, batch 7, d_loss=0.020 g_loss=0.235 KID= 0.04932\n",
      "epoch 241, batch 8, d_loss=-0.060 g_loss=0.330 KID= 0.04932\n",
      "epoch 241, batch 9, d_loss=0.043 g_loss=0.356 KID= 0.04932\n",
      "epoch 241, batch 10, d_loss=-0.017 g_loss=0.329 KID= 0.04932\n",
      "epoch 241, batch 11, d_loss=-0.026 g_loss=0.248 KID= 0.04932\n",
      "epoch 241, batch 12, d_loss=0.162 g_loss=0.174 KID= 0.04932\n",
      "epoch 241, batch 13, d_loss=0.044 g_loss=0.199 KID= 0.04932\n",
      "epoch 241, batch 14, d_loss=0.066 g_loss=0.158 KID= 0.04932\n",
      "epoch 241, batch 15, d_loss=0.098 g_loss=0.077 KID= 0.04932\n",
      "epoch 241, batch 16, d_loss=0.028 g_loss=0.088 KID= 0.04932\n",
      "epoch 241, batch 17, d_loss=0.047 g_loss=0.086 KID= 0.04932\n",
      "epoch 241, batch 18, d_loss=0.047 g_loss=0.139 KID= 0.04932\n",
      "epoch 241, batch 19, d_loss=-0.005 g_loss=0.147 KID= 0.04932\n",
      "epoch 242, batch 0, d_loss=0.000 g_loss=0.175 KID= 0.04932\n",
      "epoch 242, batch 1, d_loss=0.113 g_loss=0.176 KID= 0.04932\n",
      "epoch 242, batch 2, d_loss=0.046 g_loss=0.176 KID= 0.04932\n",
      "epoch 242, batch 3, d_loss=0.093 g_loss=0.124 KID= 0.04932\n",
      "epoch 242, batch 4, d_loss=0.088 g_loss=0.083 KID= 0.04932\n",
      "epoch 242, batch 5, d_loss=0.047 g_loss=0.030 KID= 0.04932\n",
      "epoch 242, batch 6, d_loss=0.116 g_loss=-0.041 KID= 0.04932\n",
      "epoch 242, batch 7, d_loss=0.110 g_loss=-0.044 KID= 0.04932\n",
      "epoch 242, batch 8, d_loss=0.110 g_loss=0.031 KID= 0.04932\n",
      "epoch 242, batch 9, d_loss=0.065 g_loss=0.050 KID= 0.04932\n",
      "epoch 242, batch 10, d_loss=0.073 g_loss=0.079 KID= 0.04932\n",
      "epoch 242, batch 11, d_loss=0.035 g_loss=0.096 KID= 0.04932\n",
      "epoch 242, batch 12, d_loss=0.064 g_loss=0.083 KID= 0.04932\n",
      "epoch 242, batch 13, d_loss=-0.021 g_loss=0.057 KID= 0.04932\n",
      "epoch 242, batch 14, d_loss=-0.020 g_loss=0.031 KID= 0.04932\n",
      "epoch 242, batch 15, d_loss=-0.032 g_loss=-0.011 KID= 0.04932\n",
      "epoch 242, batch 16, d_loss=-0.040 g_loss=-0.069 KID= 0.04932\n",
      "epoch 242, batch 17, d_loss=0.035 g_loss=-0.143 KID= 0.04932\n",
      "epoch 242, batch 18, d_loss=-0.026 g_loss=-0.134 KID= 0.04932\n",
      "epoch 242, batch 19, d_loss=0.297 g_loss=-0.078 KID= 0.04932\n",
      "epoch 243, batch 0, d_loss=0.250 g_loss=-0.020 KID= 0.04932\n",
      "epoch 243, batch 1, d_loss=0.058 g_loss=-0.028 KID= 0.04932\n",
      "epoch 243, batch 2, d_loss=0.118 g_loss=-0.068 KID= 0.04932\n",
      "epoch 243, batch 3, d_loss=0.055 g_loss=-0.071 KID= 0.04932\n",
      "epoch 243, batch 4, d_loss=0.065 g_loss=-0.022 KID= 0.04932\n",
      "epoch 243, batch 5, d_loss=0.014 g_loss=-0.032 KID= 0.04932\n",
      "epoch 243, batch 6, d_loss=0.027 g_loss=-0.040 KID= 0.04932\n",
      "epoch 243, batch 7, d_loss=0.041 g_loss=-0.090 KID= 0.04932\n",
      "epoch 243, batch 8, d_loss=0.092 g_loss=-0.078 KID= 0.04932\n",
      "epoch 243, batch 9, d_loss=0.006 g_loss=-0.130 KID= 0.04932\n",
      "epoch 243, batch 10, d_loss=0.068 g_loss=-0.212 KID= 0.04932\n",
      "epoch 243, batch 11, d_loss=0.091 g_loss=-0.206 KID= 0.04932\n",
      "epoch 243, batch 12, d_loss=0.081 g_loss=-0.315 KID= 0.04932\n",
      "epoch 243, batch 13, d_loss=0.135 g_loss=-0.378 KID= 0.04932\n",
      "epoch 243, batch 14, d_loss=0.058 g_loss=-0.421 KID= 0.04932\n",
      "epoch 243, batch 15, d_loss=0.110 g_loss=-0.423 KID= 0.04932\n",
      "epoch 243, batch 16, d_loss=0.052 g_loss=-0.421 KID= 0.04932\n",
      "epoch 243, batch 17, d_loss=0.045 g_loss=-0.382 KID= 0.04932\n",
      "epoch 243, batch 18, d_loss=0.013 g_loss=-0.364 KID= 0.04932\n",
      "epoch 243, batch 19, d_loss=-0.004 g_loss=-0.371 KID= 0.04932\n",
      "epoch 244, batch 0, d_loss=-0.035 g_loss=-0.399 KID= 0.04932\n",
      "epoch 244, batch 1, d_loss=-0.061 g_loss=-0.443 KID= 0.04932\n",
      "epoch 244, batch 2, d_loss=0.032 g_loss=-0.421 KID= 0.04932\n",
      "epoch 244, batch 3, d_loss=-0.012 g_loss=-0.390 KID= 0.04932\n",
      "epoch 244, batch 4, d_loss=0.061 g_loss=-0.296 KID= 0.04932\n",
      "epoch 244, batch 5, d_loss=-0.026 g_loss=-0.323 KID= 0.04932\n",
      "epoch 244, batch 6, d_loss=0.019 g_loss=-0.448 KID= 0.04932\n",
      "epoch 244, batch 7, d_loss=0.096 g_loss=-0.427 KID= 0.04932\n",
      "epoch 244, batch 8, d_loss=0.076 g_loss=-0.294 KID= 0.04932\n",
      "epoch 244, batch 9, d_loss=-0.001 g_loss=-0.215 KID= 0.04932\n",
      "epoch 244, batch 10, d_loss=0.011 g_loss=-0.170 KID= 0.04932\n",
      "epoch 244, batch 11, d_loss=0.041 g_loss=-0.181 KID= 0.04932\n",
      "epoch 244, batch 12, d_loss=0.087 g_loss=-0.228 KID= 0.04932\n",
      "epoch 244, batch 13, d_loss=0.088 g_loss=-0.287 KID= 0.04932\n",
      "epoch 244, batch 14, d_loss=0.109 g_loss=-0.286 KID= 0.04932\n",
      "epoch 244, batch 15, d_loss=0.108 g_loss=-0.217 KID= 0.04932\n",
      "epoch 244, batch 16, d_loss=0.050 g_loss=-0.202 KID= 0.04932\n",
      "epoch 244, batch 17, d_loss=0.041 g_loss=-0.198 KID= 0.04932\n",
      "epoch 244, batch 18, d_loss=0.059 g_loss=-0.178 KID= 0.04932\n",
      "epoch 244, batch 19, d_loss=0.086 g_loss=-0.169 KID= 0.04932\n",
      "epoch 245, batch 0, d_loss=0.089 g_loss=-0.120 KID= 0.04932\n",
      "epoch 245, batch 1, d_loss=0.063 g_loss=-0.069 KID= 0.04932\n",
      "epoch 245, batch 2, d_loss=0.038 g_loss=-0.013 KID= 0.04932\n",
      "epoch 245, batch 3, d_loss=0.027 g_loss=0.047 KID= 0.04932\n",
      "epoch 245, batch 4, d_loss=0.019 g_loss=0.088 KID= 0.04932\n",
      "epoch 245, batch 5, d_loss=-0.007 g_loss=0.098 KID= 0.04932\n",
      "epoch 245, batch 6, d_loss=0.056 g_loss=0.035 KID= 0.04932\n",
      "epoch 245, batch 7, d_loss=0.339 g_loss=-0.024 KID= 0.04932\n",
      "epoch 245, batch 8, d_loss=0.226 g_loss=-0.047 KID= 0.04932\n",
      "epoch 245, batch 9, d_loss=0.235 g_loss=-0.017 KID= 0.04932\n",
      "epoch 245, batch 10, d_loss=0.216 g_loss=-0.040 KID= 0.04932\n",
      "epoch 245, batch 11, d_loss=0.104 g_loss=-0.136 KID= 0.04932\n",
      "epoch 245, batch 12, d_loss=0.109 g_loss=-0.203 KID= 0.04932\n",
      "epoch 245, batch 13, d_loss=0.262 g_loss=-0.114 KID= 0.04932\n",
      "epoch 245, batch 14, d_loss=0.073 g_loss=-0.007 KID= 0.04932\n",
      "epoch 245, batch 15, d_loss=0.017 g_loss=0.297 KID= 0.04932\n",
      "epoch 245, batch 16, d_loss=-0.052 g_loss=0.453 KID= 0.04932\n",
      "epoch 245, batch 17, d_loss=0.049 g_loss=0.260 KID= 0.04932\n",
      "epoch 245, batch 18, d_loss=0.175 g_loss=0.153 KID= 0.04932\n",
      "epoch 245, batch 19, d_loss=0.187 g_loss=-0.064 KID= 0.04932\n",
      "epoch 246, batch 0, d_loss=0.254 g_loss=-0.101 KID= 0.04932\n",
      "epoch 246, batch 1, d_loss=0.113 g_loss=-0.118 KID= 0.04932\n",
      "epoch 246, batch 2, d_loss=0.058 g_loss=-0.175 KID= 0.04932\n",
      "epoch 246, batch 3, d_loss=0.109 g_loss=-0.175 KID= 0.04932\n",
      "epoch 246, batch 4, d_loss=0.071 g_loss=-0.187 KID= 0.04932\n",
      "epoch 246, batch 5, d_loss=0.193 g_loss=-0.020 KID= 0.04932\n",
      "epoch 246, batch 6, d_loss=0.157 g_loss=0.122 KID= 0.04932\n",
      "epoch 246, batch 7, d_loss=0.083 g_loss=0.182 KID= 0.04932\n",
      "epoch 246, batch 8, d_loss=0.088 g_loss=0.211 KID= 0.04932\n",
      "epoch 246, batch 9, d_loss=0.113 g_loss=0.180 KID= 0.04932\n",
      "epoch 246, batch 10, d_loss=0.017 g_loss=0.147 KID= 0.04932\n",
      "epoch 246, batch 11, d_loss=0.024 g_loss=0.045 KID= 0.04932\n",
      "epoch 246, batch 12, d_loss=0.103 g_loss=-0.003 KID= 0.04932\n",
      "epoch 246, batch 13, d_loss=0.088 g_loss=-0.044 KID= 0.04932\n",
      "epoch 246, batch 14, d_loss=0.154 g_loss=-0.051 KID= 0.04932\n",
      "epoch 246, batch 15, d_loss=0.085 g_loss=-0.051 KID= 0.04932\n",
      "epoch 246, batch 16, d_loss=0.096 g_loss=-0.024 KID= 0.04932\n",
      "epoch 246, batch 17, d_loss=0.134 g_loss=0.018 KID= 0.04932\n",
      "epoch 246, batch 18, d_loss=0.076 g_loss=0.054 KID= 0.04932\n",
      "epoch 246, batch 19, d_loss=0.034 g_loss=0.059 KID= 0.04932\n",
      "epoch 247, batch 0, d_loss=0.114 g_loss=0.077 KID= 0.04932\n",
      "epoch 247, batch 1, d_loss=0.135 g_loss=0.112 KID= 0.04932\n",
      "epoch 247, batch 2, d_loss=0.116 g_loss=0.113 KID= 0.04932\n",
      "epoch 247, batch 3, d_loss=0.164 g_loss=0.119 KID= 0.04932\n",
      "epoch 247, batch 4, d_loss=0.108 g_loss=0.118 KID= 0.04932\n",
      "epoch 247, batch 5, d_loss=0.134 g_loss=0.148 KID= 0.04932\n",
      "epoch 247, batch 6, d_loss=0.110 g_loss=0.153 KID= 0.04932\n",
      "epoch 247, batch 7, d_loss=0.075 g_loss=0.154 KID= 0.04932\n",
      "epoch 247, batch 8, d_loss=0.118 g_loss=0.141 KID= 0.04932\n",
      "epoch 247, batch 9, d_loss=0.093 g_loss=0.112 KID= 0.04932\n",
      "epoch 247, batch 10, d_loss=0.059 g_loss=0.068 KID= 0.04932\n",
      "epoch 247, batch 11, d_loss=0.074 g_loss=0.020 KID= 0.04932\n",
      "epoch 247, batch 12, d_loss=0.070 g_loss=-0.033 KID= 0.04932\n",
      "epoch 247, batch 13, d_loss=0.060 g_loss=-0.076 KID= 0.04932\n",
      "epoch 247, batch 14, d_loss=0.119 g_loss=-0.060 KID= 0.04932\n",
      "epoch 247, batch 15, d_loss=0.143 g_loss=-0.016 KID= 0.04932\n",
      "epoch 247, batch 16, d_loss=0.077 g_loss=0.021 KID= 0.04932\n",
      "epoch 247, batch 17, d_loss=0.080 g_loss=0.077 KID= 0.04932\n",
      "epoch 247, batch 18, d_loss=0.098 g_loss=0.125 KID= 0.04932\n",
      "epoch 247, batch 19, d_loss=0.071 g_loss=0.114 KID= 0.04932\n",
      "epoch 248, batch 0, d_loss=0.094 g_loss=0.037 KID= 0.04932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 248, batch 1, d_loss=0.059 g_loss=-0.032 KID= 0.04932\n",
      "epoch 248, batch 2, d_loss=0.030 g_loss=-0.150 KID= 0.04932\n",
      "epoch 248, batch 3, d_loss=0.086 g_loss=-0.260 KID= 0.04932\n",
      "epoch 248, batch 4, d_loss=0.040 g_loss=-0.325 KID= 0.04932\n",
      "epoch 248, batch 5, d_loss=0.067 g_loss=-0.335 KID= 0.04932\n",
      "epoch 248, batch 6, d_loss=0.082 g_loss=-0.340 KID= 0.04932\n",
      "epoch 248, batch 7, d_loss=0.078 g_loss=-0.247 KID= 0.04932\n",
      "epoch 248, batch 8, d_loss=0.070 g_loss=-0.165 KID= 0.04932\n",
      "epoch 248, batch 9, d_loss=0.085 g_loss=-0.130 KID= 0.04932\n",
      "epoch 248, batch 10, d_loss=0.022 g_loss=-0.097 KID= 0.04932\n",
      "epoch 248, batch 11, d_loss=0.036 g_loss=-0.091 KID= 0.04932\n",
      "epoch 248, batch 12, d_loss=0.087 g_loss=-0.109 KID= 0.04932\n",
      "epoch 248, batch 13, d_loss=0.031 g_loss=-0.123 KID= 0.04932\n",
      "epoch 248, batch 14, d_loss=0.082 g_loss=-0.123 KID= 0.04932\n",
      "epoch 248, batch 15, d_loss=0.111 g_loss=-0.110 KID= 0.04932\n",
      "epoch 248, batch 16, d_loss=0.021 g_loss=-0.132 KID= 0.04932\n",
      "epoch 248, batch 17, d_loss=-0.008 g_loss=-0.202 KID= 0.04932\n",
      "epoch 248, batch 18, d_loss=0.049 g_loss=-0.203 KID= 0.04932\n",
      "epoch 248, batch 19, d_loss=0.053 g_loss=-0.163 KID= 0.04932\n",
      "epoch 249, batch 0, d_loss=0.133 g_loss=-0.115 KID= 0.04932\n",
      "epoch 249, batch 1, d_loss=0.116 g_loss=-0.142 KID= 0.04932\n",
      "epoch 249, batch 2, d_loss=0.037 g_loss=-0.245 KID= 0.04932\n",
      "epoch 249, batch 3, d_loss=0.108 g_loss=-0.324 KID= 0.04932\n",
      "epoch 249, batch 4, d_loss=0.118 g_loss=-0.397 KID= 0.04932\n",
      "epoch 249, batch 5, d_loss=0.088 g_loss=-0.356 KID= 0.04932\n",
      "epoch 249, batch 6, d_loss=0.066 g_loss=-0.256 KID= 0.04932\n",
      "epoch 249, batch 7, d_loss=0.006 g_loss=-0.178 KID= 0.04932\n",
      "epoch 249, batch 8, d_loss=-0.032 g_loss=-0.125 KID= 0.04932\n",
      "epoch 249, batch 9, d_loss=0.000 g_loss=-0.169 KID= 0.04932\n",
      "epoch 249, batch 10, d_loss=0.015 g_loss=-0.184 KID= 0.04932\n",
      "epoch 249, batch 11, d_loss=0.065 g_loss=-0.195 KID= 0.04932\n",
      "epoch 249, batch 12, d_loss=0.116 g_loss=-0.264 KID= 0.04932\n",
      "epoch 249, batch 13, d_loss=0.044 g_loss=-0.281 KID= 0.04932\n",
      "epoch 249, batch 14, d_loss=0.053 g_loss=-0.346 KID= 0.04932\n",
      "epoch 249, batch 15, d_loss=0.089 g_loss=-0.348 KID= 0.04932\n",
      "epoch 249, batch 16, d_loss=-0.011 g_loss=-0.385 KID= 0.04932\n",
      "epoch 249, batch 17, d_loss=0.037 g_loss=-0.396 KID= 0.04932\n",
      "epoch 249, batch 18, d_loss=0.184 g_loss=-0.298 KID= 0.04932\n",
      "epoch 249, batch 19, d_loss=0.098 g_loss=-0.246 KID= 0.04932\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 250, batch 0, d_loss=0.022 g_loss=-0.191 KID= 0.04022\n",
      "epoch 250, batch 1, d_loss=0.033 g_loss=-0.161 KID= 0.04022\n",
      "epoch 250, batch 2, d_loss=0.028 g_loss=-0.152 KID= 0.04022\n",
      "epoch 250, batch 3, d_loss=0.041 g_loss=-0.145 KID= 0.04022\n",
      "epoch 250, batch 4, d_loss=0.059 g_loss=-0.122 KID= 0.04022\n",
      "epoch 250, batch 5, d_loss=-0.021 g_loss=-0.124 KID= 0.04022\n",
      "epoch 250, batch 6, d_loss=0.112 g_loss=-0.138 KID= 0.04022\n",
      "epoch 250, batch 7, d_loss=0.096 g_loss=-0.138 KID= 0.04022\n",
      "epoch 250, batch 8, d_loss=0.063 g_loss=-0.166 KID= 0.04022\n",
      "epoch 250, batch 9, d_loss=0.108 g_loss=-0.204 KID= 0.04022\n",
      "epoch 250, batch 10, d_loss=0.061 g_loss=-0.239 KID= 0.04022\n",
      "epoch 250, batch 11, d_loss=0.091 g_loss=-0.248 KID= 0.04022\n",
      "epoch 250, batch 12, d_loss=0.058 g_loss=-0.237 KID= 0.04022\n",
      "epoch 250, batch 13, d_loss=0.000 g_loss=-0.223 KID= 0.04022\n",
      "epoch 250, batch 14, d_loss=0.006 g_loss=-0.180 KID= 0.04022\n",
      "epoch 250, batch 15, d_loss=0.021 g_loss=-0.029 KID= 0.04022\n",
      "epoch 250, batch 16, d_loss=-0.019 g_loss=0.086 KID= 0.04022\n",
      "epoch 250, batch 17, d_loss=-0.026 g_loss=0.146 KID= 0.04022\n",
      "epoch 250, batch 18, d_loss=-0.127 g_loss=0.141 KID= 0.04022\n",
      "epoch 250, batch 19, d_loss=0.082 g_loss=0.061 KID= 0.04022\n",
      "epoch 251, batch 0, d_loss=0.091 g_loss=0.004 KID= 0.04022\n",
      "epoch 251, batch 1, d_loss=0.036 g_loss=-0.070 KID= 0.04022\n",
      "epoch 251, batch 2, d_loss=0.015 g_loss=-0.195 KID= 0.04022\n",
      "epoch 251, batch 3, d_loss=0.121 g_loss=-0.282 KID= 0.04022\n",
      "epoch 251, batch 4, d_loss=0.044 g_loss=-0.278 KID= 0.04022\n",
      "epoch 251, batch 5, d_loss=0.084 g_loss=-0.177 KID= 0.04022\n",
      "epoch 251, batch 6, d_loss=0.013 g_loss=-0.041 KID= 0.04022\n",
      "epoch 251, batch 7, d_loss=0.043 g_loss=0.131 KID= 0.04022\n",
      "epoch 251, batch 8, d_loss=0.090 g_loss=0.087 KID= 0.04022\n",
      "epoch 251, batch 9, d_loss=0.088 g_loss=-0.038 KID= 0.04022\n",
      "epoch 251, batch 10, d_loss=0.030 g_loss=-0.127 KID= 0.04022\n",
      "epoch 251, batch 11, d_loss=0.052 g_loss=-0.182 KID= 0.04022\n",
      "epoch 251, batch 12, d_loss=-0.014 g_loss=-0.299 KID= 0.04022\n",
      "epoch 251, batch 13, d_loss=0.010 g_loss=-0.359 KID= 0.04022\n",
      "epoch 251, batch 14, d_loss=0.046 g_loss=-0.402 KID= 0.04022\n",
      "epoch 251, batch 15, d_loss=0.050 g_loss=-0.327 KID= 0.04022\n",
      "epoch 251, batch 16, d_loss=0.091 g_loss=-0.311 KID= 0.04022\n",
      "epoch 251, batch 17, d_loss=0.052 g_loss=-0.241 KID= 0.04022\n",
      "epoch 251, batch 18, d_loss=0.097 g_loss=-0.161 KID= 0.04022\n",
      "epoch 251, batch 19, d_loss=0.175 g_loss=-0.122 KID= 0.04022\n",
      "epoch 252, batch 0, d_loss=0.121 g_loss=-0.053 KID= 0.04022\n",
      "epoch 252, batch 1, d_loss=0.051 g_loss=-0.032 KID= 0.04022\n",
      "epoch 252, batch 2, d_loss=0.011 g_loss=-0.052 KID= 0.04022\n",
      "epoch 252, batch 3, d_loss=-0.004 g_loss=-0.081 KID= 0.04022\n",
      "epoch 252, batch 4, d_loss=-0.025 g_loss=-0.139 KID= 0.04022\n",
      "epoch 252, batch 5, d_loss=0.072 g_loss=-0.150 KID= 0.04022\n",
      "epoch 252, batch 6, d_loss=-0.004 g_loss=-0.172 KID= 0.04022\n",
      "epoch 252, batch 7, d_loss=-0.007 g_loss=-0.201 KID= 0.04022\n",
      "epoch 252, batch 8, d_loss=0.127 g_loss=-0.140 KID= 0.04022\n",
      "epoch 252, batch 9, d_loss=0.087 g_loss=-0.113 KID= 0.04022\n",
      "epoch 252, batch 10, d_loss=-0.008 g_loss=-0.126 KID= 0.04022\n",
      "epoch 252, batch 11, d_loss=0.148 g_loss=-0.123 KID= 0.04022\n",
      "epoch 252, batch 12, d_loss=0.083 g_loss=-0.134 KID= 0.04022\n",
      "epoch 252, batch 13, d_loss=0.055 g_loss=-0.195 KID= 0.04022\n",
      "epoch 252, batch 14, d_loss=0.113 g_loss=-0.182 KID= 0.04022\n",
      "epoch 252, batch 15, d_loss=0.022 g_loss=-0.159 KID= 0.04022\n",
      "epoch 252, batch 16, d_loss=0.022 g_loss=-0.125 KID= 0.04022\n",
      "epoch 252, batch 17, d_loss=0.039 g_loss=-0.055 KID= 0.04022\n",
      "epoch 252, batch 18, d_loss=0.061 g_loss=-0.045 KID= 0.04022\n",
      "epoch 252, batch 19, d_loss=0.047 g_loss=-0.070 KID= 0.04022\n",
      "epoch 253, batch 0, d_loss=0.071 g_loss=-0.056 KID= 0.04022\n",
      "epoch 253, batch 1, d_loss=0.013 g_loss=-0.051 KID= 0.04022\n",
      "epoch 253, batch 2, d_loss=-0.004 g_loss=-0.097 KID= 0.04022\n",
      "epoch 253, batch 3, d_loss=0.011 g_loss=-0.125 KID= 0.04022\n",
      "epoch 253, batch 4, d_loss=-0.068 g_loss=-0.122 KID= 0.04022\n",
      "epoch 253, batch 5, d_loss=0.033 g_loss=-0.134 KID= 0.04022\n",
      "epoch 253, batch 6, d_loss=-0.017 g_loss=-0.223 KID= 0.04022\n",
      "epoch 253, batch 7, d_loss=-0.000 g_loss=-0.265 KID= 0.04022\n",
      "epoch 253, batch 8, d_loss=0.231 g_loss=-0.280 KID= 0.04022\n",
      "epoch 253, batch 9, d_loss=0.173 g_loss=-0.256 KID= 0.04022\n",
      "epoch 253, batch 10, d_loss=0.056 g_loss=-0.312 KID= 0.04022\n",
      "epoch 253, batch 11, d_loss=0.090 g_loss=-0.322 KID= 0.04022\n",
      "epoch 253, batch 12, d_loss=0.037 g_loss=-0.363 KID= 0.04022\n",
      "epoch 253, batch 13, d_loss=0.096 g_loss=-0.341 KID= 0.04022\n",
      "epoch 253, batch 14, d_loss=0.089 g_loss=-0.341 KID= 0.04022\n",
      "epoch 253, batch 15, d_loss=0.082 g_loss=-0.299 KID= 0.04022\n",
      "epoch 253, batch 16, d_loss=0.078 g_loss=-0.255 KID= 0.04022\n",
      "epoch 253, batch 17, d_loss=0.094 g_loss=-0.201 KID= 0.04022\n",
      "epoch 253, batch 18, d_loss=0.073 g_loss=-0.181 KID= 0.04022\n",
      "epoch 253, batch 19, d_loss=0.019 g_loss=-0.173 KID= 0.04022\n",
      "epoch 254, batch 0, d_loss=0.009 g_loss=-0.173 KID= 0.04022\n",
      "epoch 254, batch 1, d_loss=0.006 g_loss=-0.174 KID= 0.04022\n",
      "epoch 254, batch 2, d_loss=-0.034 g_loss=-0.253 KID= 0.04022\n",
      "epoch 254, batch 3, d_loss=-0.054 g_loss=-0.308 KID= 0.04022\n",
      "epoch 254, batch 4, d_loss=0.077 g_loss=-0.305 KID= 0.04022\n",
      "epoch 254, batch 5, d_loss=0.105 g_loss=-0.273 KID= 0.04022\n",
      "epoch 254, batch 6, d_loss=0.057 g_loss=-0.274 KID= 0.04022\n",
      "epoch 254, batch 7, d_loss=0.045 g_loss=-0.228 KID= 0.04022\n",
      "epoch 254, batch 8, d_loss=0.161 g_loss=-0.132 KID= 0.04022\n",
      "epoch 254, batch 9, d_loss=0.093 g_loss=-0.088 KID= 0.04022\n",
      "epoch 254, batch 10, d_loss=-0.012 g_loss=-0.042 KID= 0.04022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 254, batch 11, d_loss=-0.016 g_loss=0.008 KID= 0.04022\n",
      "epoch 254, batch 12, d_loss=-0.044 g_loss=0.005 KID= 0.04022\n",
      "epoch 254, batch 13, d_loss=0.030 g_loss=-0.009 KID= 0.04022\n",
      "epoch 254, batch 14, d_loss=-0.013 g_loss=-0.057 KID= 0.04022\n",
      "epoch 254, batch 15, d_loss=-0.011 g_loss=-0.027 KID= 0.04022\n",
      "epoch 254, batch 16, d_loss=0.081 g_loss=-0.049 KID= 0.04022\n",
      "epoch 254, batch 17, d_loss=0.063 g_loss=-0.080 KID= 0.04022\n",
      "epoch 254, batch 18, d_loss=0.011 g_loss=-0.138 KID= 0.04022\n",
      "epoch 254, batch 19, d_loss=0.105 g_loss=-0.168 KID= 0.04022\n",
      "epoch 255, batch 0, d_loss=0.103 g_loss=-0.238 KID= 0.04022\n",
      "epoch 255, batch 1, d_loss=0.110 g_loss=-0.289 KID= 0.04022\n",
      "epoch 255, batch 2, d_loss=0.028 g_loss=-0.320 KID= 0.04022\n",
      "epoch 255, batch 3, d_loss=-0.009 g_loss=-0.370 KID= 0.04022\n",
      "epoch 255, batch 4, d_loss=-0.007 g_loss=-0.374 KID= 0.04022\n",
      "epoch 255, batch 5, d_loss=0.014 g_loss=-0.296 KID= 0.04022\n",
      "epoch 255, batch 6, d_loss=0.006 g_loss=-0.233 KID= 0.04022\n",
      "epoch 255, batch 7, d_loss=0.004 g_loss=-0.203 KID= 0.04022\n",
      "epoch 255, batch 8, d_loss=0.212 g_loss=-0.098 KID= 0.04022\n",
      "epoch 255, batch 9, d_loss=0.126 g_loss=-0.055 KID= 0.04022\n",
      "epoch 255, batch 10, d_loss=0.041 g_loss=0.005 KID= 0.04022\n",
      "epoch 255, batch 11, d_loss=0.019 g_loss=-0.007 KID= 0.04022\n",
      "epoch 255, batch 12, d_loss=0.017 g_loss=-0.022 KID= 0.04022\n",
      "epoch 255, batch 13, d_loss=0.008 g_loss=-0.049 KID= 0.04022\n",
      "epoch 255, batch 14, d_loss=-0.017 g_loss=-0.061 KID= 0.04022\n",
      "epoch 255, batch 15, d_loss=0.012 g_loss=-0.039 KID= 0.04022\n",
      "epoch 255, batch 16, d_loss=-0.025 g_loss=-0.066 KID= 0.04022\n",
      "epoch 255, batch 17, d_loss=0.001 g_loss=-0.117 KID= 0.04022\n",
      "epoch 255, batch 18, d_loss=-0.045 g_loss=-0.125 KID= 0.04022\n",
      "epoch 255, batch 19, d_loss=0.014 g_loss=-0.119 KID= 0.04022\n",
      "epoch 256, batch 0, d_loss=0.067 g_loss=-0.084 KID= 0.04022\n",
      "epoch 256, batch 1, d_loss=0.077 g_loss=-0.104 KID= 0.04022\n",
      "epoch 256, batch 2, d_loss=0.002 g_loss=-0.108 KID= 0.04022\n",
      "epoch 256, batch 3, d_loss=0.040 g_loss=-0.105 KID= 0.04022\n",
      "epoch 256, batch 4, d_loss=0.048 g_loss=-0.080 KID= 0.04022\n",
      "epoch 256, batch 5, d_loss=0.007 g_loss=-0.025 KID= 0.04022\n",
      "epoch 256, batch 6, d_loss=0.018 g_loss=0.020 KID= 0.04022\n",
      "epoch 256, batch 7, d_loss=-0.036 g_loss=0.042 KID= 0.04022\n",
      "epoch 256, batch 8, d_loss=0.149 g_loss=0.094 KID= 0.04022\n",
      "epoch 256, batch 9, d_loss=0.119 g_loss=0.096 KID= 0.04022\n",
      "epoch 256, batch 10, d_loss=-0.006 g_loss=0.056 KID= 0.04022\n",
      "epoch 256, batch 11, d_loss=0.101 g_loss=0.026 KID= 0.04022\n",
      "epoch 256, batch 12, d_loss=0.009 g_loss=-0.043 KID= 0.04022\n",
      "epoch 256, batch 13, d_loss=0.046 g_loss=-0.080 KID= 0.04022\n",
      "epoch 256, batch 14, d_loss=0.009 g_loss=-0.110 KID= 0.04022\n",
      "epoch 256, batch 15, d_loss=0.065 g_loss=-0.018 KID= 0.04022\n",
      "epoch 256, batch 16, d_loss=0.018 g_loss=0.003 KID= 0.04022\n",
      "epoch 256, batch 17, d_loss=-0.022 g_loss=-0.007 KID= 0.04022\n",
      "epoch 256, batch 18, d_loss=-0.018 g_loss=-0.017 KID= 0.04022\n",
      "epoch 256, batch 19, d_loss=-0.029 g_loss=-0.049 KID= 0.04022\n",
      "epoch 257, batch 0, d_loss=0.012 g_loss=-0.126 KID= 0.04022\n",
      "epoch 257, batch 1, d_loss=0.079 g_loss=-0.197 KID= 0.04022\n",
      "epoch 257, batch 2, d_loss=0.048 g_loss=-0.262 KID= 0.04022\n",
      "epoch 257, batch 3, d_loss=0.024 g_loss=-0.330 KID= 0.04022\n",
      "epoch 257, batch 4, d_loss=0.066 g_loss=-0.339 KID= 0.04022\n",
      "epoch 257, batch 5, d_loss=0.068 g_loss=-0.249 KID= 0.04022\n",
      "epoch 257, batch 6, d_loss=0.015 g_loss=-0.181 KID= 0.04022\n",
      "epoch 257, batch 7, d_loss=0.031 g_loss=-0.095 KID= 0.04022\n",
      "epoch 257, batch 8, d_loss=0.077 g_loss=0.004 KID= 0.04022\n",
      "epoch 257, batch 9, d_loss=0.029 g_loss=0.004 KID= 0.04022\n",
      "epoch 257, batch 10, d_loss=0.113 g_loss=0.009 KID= 0.04022\n",
      "epoch 257, batch 11, d_loss=0.065 g_loss=-0.023 KID= 0.04022\n",
      "epoch 257, batch 12, d_loss=0.026 g_loss=-0.065 KID= 0.04022\n",
      "epoch 257, batch 13, d_loss=0.024 g_loss=-0.095 KID= 0.04022\n",
      "epoch 257, batch 14, d_loss=0.004 g_loss=-0.116 KID= 0.04022\n",
      "epoch 257, batch 15, d_loss=0.032 g_loss=-0.133 KID= 0.04022\n",
      "epoch 257, batch 16, d_loss=0.017 g_loss=-0.094 KID= 0.04022\n",
      "epoch 257, batch 17, d_loss=-0.043 g_loss=0.060 KID= 0.04022\n",
      "epoch 257, batch 18, d_loss=0.145 g_loss=0.131 KID= 0.04022\n",
      "epoch 257, batch 19, d_loss=0.137 g_loss=0.060 KID= 0.04022\n",
      "epoch 258, batch 0, d_loss=0.037 g_loss=-0.009 KID= 0.04022\n",
      "epoch 258, batch 1, d_loss=0.047 g_loss=-0.057 KID= 0.04022\n",
      "epoch 258, batch 2, d_loss=0.031 g_loss=-0.127 KID= 0.04022\n",
      "epoch 258, batch 3, d_loss=0.044 g_loss=-0.164 KID= 0.04022\n",
      "epoch 258, batch 4, d_loss=-0.007 g_loss=-0.167 KID= 0.04022\n",
      "epoch 258, batch 5, d_loss=0.021 g_loss=0.025 KID= 0.04022\n",
      "epoch 258, batch 6, d_loss=0.008 g_loss=0.129 KID= 0.04022\n",
      "epoch 258, batch 7, d_loss=0.007 g_loss=0.216 KID= 0.04022\n",
      "epoch 258, batch 8, d_loss=-0.051 g_loss=0.266 KID= 0.04022\n",
      "epoch 258, batch 9, d_loss=0.007 g_loss=0.187 KID= 0.04022\n",
      "epoch 258, batch 10, d_loss=0.004 g_loss=0.097 KID= 0.04022\n",
      "epoch 258, batch 11, d_loss=0.158 g_loss=0.025 KID= 0.04022\n",
      "epoch 258, batch 12, d_loss=0.000 g_loss=-0.146 KID= 0.04022\n",
      "epoch 258, batch 13, d_loss=0.035 g_loss=-0.303 KID= 0.04022\n",
      "epoch 258, batch 14, d_loss=0.013 g_loss=-0.317 KID= 0.04022\n",
      "epoch 258, batch 15, d_loss=0.038 g_loss=-0.224 KID= 0.04022\n",
      "epoch 258, batch 16, d_loss=-0.004 g_loss=-0.157 KID= 0.04022\n",
      "epoch 258, batch 17, d_loss=-0.040 g_loss=-0.083 KID= 0.04022\n",
      "epoch 258, batch 18, d_loss=0.071 g_loss=0.002 KID= 0.04022\n",
      "epoch 258, batch 19, d_loss=0.050 g_loss=-0.019 KID= 0.04022\n",
      "epoch 259, batch 0, d_loss=-0.008 g_loss=-0.054 KID= 0.04022\n",
      "epoch 259, batch 1, d_loss=-0.057 g_loss=-0.055 KID= 0.04022\n",
      "epoch 259, batch 2, d_loss=0.062 g_loss=-0.071 KID= 0.04022\n",
      "epoch 259, batch 3, d_loss=-0.018 g_loss=-0.155 KID= 0.04022\n",
      "epoch 259, batch 4, d_loss=-0.037 g_loss=-0.237 KID= 0.04022\n",
      "epoch 259, batch 5, d_loss=0.169 g_loss=-0.240 KID= 0.04022\n",
      "epoch 259, batch 6, d_loss=0.109 g_loss=-0.288 KID= 0.04022\n",
      "epoch 259, batch 7, d_loss=0.062 g_loss=-0.255 KID= 0.04022\n",
      "epoch 259, batch 8, d_loss=0.024 g_loss=-0.142 KID= 0.04022\n",
      "epoch 259, batch 9, d_loss=-0.025 g_loss=-0.048 KID= 0.04022\n",
      "epoch 259, batch 10, d_loss=-0.092 g_loss=0.017 KID= 0.04022\n",
      "epoch 259, batch 11, d_loss=0.048 g_loss=0.021 KID= 0.04022\n",
      "epoch 259, batch 12, d_loss=-0.025 g_loss=-0.044 KID= 0.04022\n",
      "epoch 259, batch 13, d_loss=0.056 g_loss=-0.088 KID= 0.04022\n",
      "epoch 259, batch 14, d_loss=0.028 g_loss=-0.092 KID= 0.04022\n",
      "epoch 259, batch 15, d_loss=-0.027 g_loss=-0.092 KID= 0.04022\n",
      "epoch 259, batch 16, d_loss=0.076 g_loss=-0.087 KID= 0.04022\n",
      "epoch 259, batch 17, d_loss=-0.026 g_loss=-0.007 KID= 0.04022\n",
      "epoch 259, batch 18, d_loss=0.041 g_loss=0.057 KID= 0.04022\n",
      "epoch 259, batch 19, d_loss=0.051 g_loss=0.055 KID= 0.04022\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 260, batch 0, d_loss=0.087 g_loss=0.034 KID= 0.03563\n",
      "epoch 260, batch 1, d_loss=0.088 g_loss=-0.022 KID= 0.03563\n",
      "epoch 260, batch 2, d_loss=-0.002 g_loss=-0.113 KID= 0.03563\n",
      "epoch 260, batch 3, d_loss=0.043 g_loss=-0.203 KID= 0.03563\n",
      "epoch 260, batch 4, d_loss=-0.008 g_loss=-0.190 KID= 0.03563\n",
      "epoch 260, batch 5, d_loss=0.075 g_loss=-0.136 KID= 0.03563\n",
      "epoch 260, batch 6, d_loss=-0.019 g_loss=-0.081 KID= 0.03563\n",
      "epoch 260, batch 7, d_loss=0.006 g_loss=0.148 KID= 0.03563\n",
      "epoch 260, batch 8, d_loss=0.014 g_loss=0.335 KID= 0.03563\n",
      "epoch 260, batch 9, d_loss=-0.036 g_loss=0.555 KID= 0.03563\n",
      "epoch 260, batch 10, d_loss=0.033 g_loss=0.788 KID= 0.03563\n",
      "epoch 260, batch 11, d_loss=0.112 g_loss=0.711 KID= 0.03563\n",
      "epoch 260, batch 12, d_loss=0.051 g_loss=0.505 KID= 0.03563\n",
      "epoch 260, batch 13, d_loss=0.095 g_loss=0.259 KID= 0.03563\n",
      "epoch 260, batch 14, d_loss=0.030 g_loss=0.025 KID= 0.03563\n",
      "epoch 260, batch 15, d_loss=-0.030 g_loss=-0.223 KID= 0.03563\n",
      "epoch 260, batch 16, d_loss=-0.097 g_loss=-0.478 KID= 0.03563\n",
      "epoch 260, batch 17, d_loss=-0.056 g_loss=-0.399 KID= 0.03563\n",
      "epoch 260, batch 18, d_loss=0.018 g_loss=-0.300 KID= 0.03563\n",
      "epoch 260, batch 19, d_loss=0.045 g_loss=-0.367 KID= 0.03563\n",
      "epoch 261, batch 0, d_loss=0.018 g_loss=-0.307 KID= 0.03563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 261, batch 1, d_loss=0.121 g_loss=-0.248 KID= 0.03563\n",
      "epoch 261, batch 2, d_loss=0.088 g_loss=-0.320 KID= 0.03563\n",
      "epoch 261, batch 3, d_loss=-0.004 g_loss=-0.350 KID= 0.03563\n",
      "epoch 261, batch 4, d_loss=-0.003 g_loss=-0.318 KID= 0.03563\n",
      "epoch 261, batch 5, d_loss=0.015 g_loss=-0.380 KID= 0.03563\n",
      "epoch 261, batch 6, d_loss=0.020 g_loss=-0.354 KID= 0.03563\n",
      "epoch 261, batch 7, d_loss=0.016 g_loss=-0.020 KID= 0.03563\n",
      "epoch 261, batch 8, d_loss=0.032 g_loss=0.184 KID= 0.03563\n",
      "epoch 261, batch 9, d_loss=0.024 g_loss=0.208 KID= 0.03563\n",
      "epoch 261, batch 10, d_loss=0.011 g_loss=0.214 KID= 0.03563\n",
      "epoch 261, batch 11, d_loss=0.031 g_loss=0.127 KID= 0.03563\n",
      "epoch 261, batch 12, d_loss=0.012 g_loss=0.005 KID= 0.03563\n",
      "epoch 261, batch 13, d_loss=-0.007 g_loss=-0.171 KID= 0.03563\n",
      "epoch 261, batch 14, d_loss=0.020 g_loss=-0.278 KID= 0.03563\n",
      "epoch 261, batch 15, d_loss=0.054 g_loss=-0.077 KID= 0.03563\n",
      "epoch 261, batch 16, d_loss=-0.033 g_loss=0.077 KID= 0.03563\n",
      "epoch 261, batch 17, d_loss=-0.046 g_loss=0.265 KID= 0.03563\n",
      "epoch 261, batch 18, d_loss=0.072 g_loss=0.375 KID= 0.03563\n",
      "epoch 261, batch 19, d_loss=-0.003 g_loss=0.360 KID= 0.03563\n",
      "epoch 262, batch 0, d_loss=0.025 g_loss=0.315 KID= 0.03563\n",
      "epoch 262, batch 1, d_loss=0.167 g_loss=0.178 KID= 0.03563\n",
      "epoch 262, batch 2, d_loss=0.055 g_loss=0.057 KID= 0.03563\n",
      "epoch 262, batch 3, d_loss=0.050 g_loss=0.003 KID= 0.03563\n",
      "epoch 262, batch 4, d_loss=-0.032 g_loss=-0.085 KID= 0.03563\n",
      "epoch 262, batch 5, d_loss=-0.066 g_loss=-0.193 KID= 0.03563\n",
      "epoch 262, batch 6, d_loss=-0.055 g_loss=-0.201 KID= 0.03563\n",
      "epoch 262, batch 7, d_loss=-0.001 g_loss=-0.187 KID= 0.03563\n",
      "epoch 262, batch 8, d_loss=-0.072 g_loss=-0.145 KID= 0.03563\n",
      "epoch 262, batch 9, d_loss=0.051 g_loss=-0.056 KID= 0.03563\n",
      "epoch 262, batch 10, d_loss=-0.032 g_loss=0.045 KID= 0.03563\n",
      "epoch 262, batch 11, d_loss=0.038 g_loss=0.146 KID= 0.03563\n",
      "epoch 262, batch 12, d_loss=-0.009 g_loss=0.211 KID= 0.03563\n",
      "epoch 262, batch 13, d_loss=-0.047 g_loss=0.316 KID= 0.03563\n",
      "epoch 262, batch 14, d_loss=-0.015 g_loss=0.367 KID= 0.03563\n",
      "epoch 262, batch 15, d_loss=0.102 g_loss=0.392 KID= 0.03563\n",
      "epoch 262, batch 16, d_loss=0.051 g_loss=0.369 KID= 0.03563\n",
      "epoch 262, batch 17, d_loss=0.013 g_loss=0.402 KID= 0.03563\n",
      "epoch 262, batch 18, d_loss=0.093 g_loss=0.397 KID= 0.03563\n",
      "epoch 262, batch 19, d_loss=0.036 g_loss=0.368 KID= 0.03563\n",
      "epoch 263, batch 0, d_loss=0.107 g_loss=0.334 KID= 0.03563\n",
      "epoch 263, batch 1, d_loss=0.159 g_loss=0.283 KID= 0.03563\n",
      "epoch 263, batch 2, d_loss=0.032 g_loss=0.308 KID= 0.03563\n",
      "epoch 263, batch 3, d_loss=0.043 g_loss=0.350 KID= 0.03563\n",
      "epoch 263, batch 4, d_loss=-0.001 g_loss=0.352 KID= 0.03563\n",
      "epoch 263, batch 5, d_loss=-0.023 g_loss=0.361 KID= 0.03563\n",
      "epoch 263, batch 6, d_loss=-0.029 g_loss=0.359 KID= 0.03563\n",
      "epoch 263, batch 7, d_loss=0.024 g_loss=0.311 KID= 0.03563\n",
      "epoch 263, batch 8, d_loss=0.056 g_loss=0.326 KID= 0.03563\n",
      "epoch 263, batch 9, d_loss=0.016 g_loss=0.347 KID= 0.03563\n",
      "epoch 263, batch 10, d_loss=0.044 g_loss=0.350 KID= 0.03563\n",
      "epoch 263, batch 11, d_loss=0.068 g_loss=0.283 KID= 0.03563\n",
      "epoch 263, batch 12, d_loss=-0.020 g_loss=0.240 KID= 0.03563\n",
      "epoch 263, batch 13, d_loss=-0.027 g_loss=0.214 KID= 0.03563\n",
      "epoch 263, batch 14, d_loss=-0.051 g_loss=0.157 KID= 0.03563\n",
      "epoch 263, batch 15, d_loss=0.064 g_loss=0.132 KID= 0.03563\n",
      "epoch 263, batch 16, d_loss=0.012 g_loss=0.047 KID= 0.03563\n",
      "epoch 263, batch 17, d_loss=-0.073 g_loss=0.001 KID= 0.03563\n",
      "epoch 263, batch 18, d_loss=0.088 g_loss=0.074 KID= 0.03563\n",
      "epoch 263, batch 19, d_loss=0.040 g_loss=0.005 KID= 0.03563\n",
      "epoch 264, batch 0, d_loss=-0.024 g_loss=-0.121 KID= 0.03563\n",
      "epoch 264, batch 1, d_loss=0.010 g_loss=-0.265 KID= 0.03563\n",
      "epoch 264, batch 2, d_loss=-0.026 g_loss=-0.417 KID= 0.03563\n",
      "epoch 264, batch 3, d_loss=-0.003 g_loss=-0.511 KID= 0.03563\n",
      "epoch 264, batch 4, d_loss=0.058 g_loss=-0.453 KID= 0.03563\n",
      "epoch 264, batch 5, d_loss=0.050 g_loss=-0.324 KID= 0.03563\n",
      "epoch 264, batch 6, d_loss=-0.033 g_loss=-0.238 KID= 0.03563\n",
      "epoch 264, batch 7, d_loss=-0.070 g_loss=-0.146 KID= 0.03563\n",
      "epoch 264, batch 8, d_loss=0.064 g_loss=-0.045 KID= 0.03563\n",
      "epoch 264, batch 9, d_loss=0.002 g_loss=-0.026 KID= 0.03563\n",
      "epoch 264, batch 10, d_loss=-0.030 g_loss=-0.074 KID= 0.03563\n",
      "epoch 264, batch 11, d_loss=0.048 g_loss=-0.198 KID= 0.03563\n",
      "epoch 264, batch 12, d_loss=0.003 g_loss=-0.294 KID= 0.03563\n",
      "epoch 264, batch 13, d_loss=0.000 g_loss=-0.308 KID= 0.03563\n",
      "epoch 264, batch 14, d_loss=-0.030 g_loss=-0.288 KID= 0.03563\n",
      "epoch 264, batch 15, d_loss=0.024 g_loss=-0.269 KID= 0.03563\n",
      "epoch 264, batch 16, d_loss=0.025 g_loss=-0.319 KID= 0.03563\n",
      "epoch 264, batch 17, d_loss=0.002 g_loss=-0.363 KID= 0.03563\n",
      "epoch 264, batch 18, d_loss=0.006 g_loss=-0.311 KID= 0.03563\n",
      "epoch 264, batch 19, d_loss=-0.048 g_loss=-0.308 KID= 0.03563\n",
      "epoch 265, batch 0, d_loss=0.043 g_loss=-0.280 KID= 0.03563\n",
      "epoch 265, batch 1, d_loss=0.088 g_loss=-0.283 KID= 0.03563\n",
      "epoch 265, batch 2, d_loss=-0.036 g_loss=-0.278 KID= 0.03563\n",
      "epoch 265, batch 3, d_loss=0.018 g_loss=-0.261 KID= 0.03563\n",
      "epoch 265, batch 4, d_loss=0.051 g_loss=-0.225 KID= 0.03563\n",
      "epoch 265, batch 5, d_loss=-0.046 g_loss=-0.246 KID= 0.03563\n",
      "epoch 265, batch 6, d_loss=-0.063 g_loss=-0.271 KID= 0.03563\n",
      "epoch 265, batch 7, d_loss=-0.092 g_loss=-0.324 KID= 0.03563\n",
      "epoch 265, batch 8, d_loss=0.081 g_loss=-0.277 KID= 0.03563\n",
      "epoch 265, batch 9, d_loss=0.026 g_loss=-0.279 KID= 0.03563\n",
      "epoch 265, batch 10, d_loss=-0.062 g_loss=-0.295 KID= 0.03563\n",
      "epoch 265, batch 11, d_loss=0.061 g_loss=-0.317 KID= 0.03563\n",
      "epoch 265, batch 12, d_loss=0.088 g_loss=-0.298 KID= 0.03563\n",
      "epoch 265, batch 13, d_loss=0.075 g_loss=-0.281 KID= 0.03563\n",
      "epoch 265, batch 14, d_loss=0.031 g_loss=-0.220 KID= 0.03563\n",
      "epoch 265, batch 15, d_loss=0.055 g_loss=-0.110 KID= 0.03563\n",
      "epoch 265, batch 16, d_loss=-0.001 g_loss=-0.075 KID= 0.03563\n",
      "epoch 265, batch 17, d_loss=-0.013 g_loss=-0.047 KID= 0.03563\n",
      "epoch 265, batch 18, d_loss=-0.023 g_loss=0.058 KID= 0.03563\n",
      "epoch 265, batch 19, d_loss=0.018 g_loss=0.140 KID= 0.03563\n",
      "epoch 266, batch 0, d_loss=0.036 g_loss=0.205 KID= 0.03563\n",
      "epoch 266, batch 1, d_loss=0.012 g_loss=0.224 KID= 0.03563\n",
      "epoch 266, batch 2, d_loss=-0.063 g_loss=0.210 KID= 0.03563\n",
      "epoch 266, batch 3, d_loss=0.033 g_loss=0.193 KID= 0.03563\n",
      "epoch 266, batch 4, d_loss=0.037 g_loss=0.188 KID= 0.03563\n",
      "epoch 266, batch 5, d_loss=0.044 g_loss=0.170 KID= 0.03563\n",
      "epoch 266, batch 6, d_loss=0.048 g_loss=0.057 KID= 0.03563\n",
      "epoch 266, batch 7, d_loss=-0.056 g_loss=-0.015 KID= 0.03563\n",
      "epoch 266, batch 8, d_loss=0.080 g_loss=-0.080 KID= 0.03563\n",
      "epoch 266, batch 9, d_loss=-0.002 g_loss=-0.194 KID= 0.03563\n",
      "epoch 266, batch 10, d_loss=-0.041 g_loss=-0.227 KID= 0.03563\n",
      "epoch 266, batch 11, d_loss=0.023 g_loss=-0.223 KID= 0.03563\n",
      "epoch 266, batch 12, d_loss=0.034 g_loss=-0.192 KID= 0.03563\n",
      "epoch 266, batch 13, d_loss=-0.010 g_loss=-0.251 KID= 0.03563\n",
      "epoch 266, batch 14, d_loss=-0.004 g_loss=-0.268 KID= 0.03563\n",
      "epoch 266, batch 15, d_loss=0.036 g_loss=-0.321 KID= 0.03563\n",
      "epoch 266, batch 16, d_loss=0.011 g_loss=-0.394 KID= 0.03563\n",
      "epoch 266, batch 17, d_loss=-0.018 g_loss=-0.390 KID= 0.03563\n",
      "epoch 266, batch 18, d_loss=-0.027 g_loss=-0.358 KID= 0.03563\n",
      "epoch 266, batch 19, d_loss=-0.048 g_loss=-0.312 KID= 0.03563\n",
      "epoch 267, batch 0, d_loss=0.046 g_loss=-0.314 KID= 0.03563\n",
      "epoch 267, batch 1, d_loss=0.088 g_loss=-0.430 KID= 0.03563\n",
      "epoch 267, batch 2, d_loss=-0.036 g_loss=-0.578 KID= 0.03563\n",
      "epoch 267, batch 3, d_loss=0.067 g_loss=-0.634 KID= 0.03563\n",
      "epoch 267, batch 4, d_loss=0.094 g_loss=-0.767 KID= 0.03563\n",
      "epoch 267, batch 5, d_loss=0.045 g_loss=-0.691 KID= 0.03563\n",
      "epoch 267, batch 6, d_loss=0.043 g_loss=-0.502 KID= 0.03563\n",
      "epoch 267, batch 7, d_loss=0.053 g_loss=-0.316 KID= 0.03563\n",
      "epoch 267, batch 8, d_loss=0.031 g_loss=-0.169 KID= 0.03563\n",
      "epoch 267, batch 9, d_loss=-0.028 g_loss=-0.047 KID= 0.03563\n",
      "epoch 267, batch 10, d_loss=0.002 g_loss=0.023 KID= 0.03563\n",
      "epoch 267, batch 11, d_loss=0.058 g_loss=-0.003 KID= 0.03563\n",
      "epoch 267, batch 12, d_loss=0.009 g_loss=-0.034 KID= 0.03563\n",
      "epoch 267, batch 13, d_loss=-0.036 g_loss=-0.087 KID= 0.03563\n",
      "epoch 267, batch 14, d_loss=-0.072 g_loss=-0.243 KID= 0.03563\n",
      "epoch 267, batch 15, d_loss=-0.015 g_loss=-0.362 KID= 0.03563\n",
      "epoch 267, batch 16, d_loss=0.034 g_loss=-0.375 KID= 0.03563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 267, batch 17, d_loss=-0.017 g_loss=-0.298 KID= 0.03563\n",
      "epoch 267, batch 18, d_loss=0.135 g_loss=-0.138 KID= 0.03563\n",
      "epoch 267, batch 19, d_loss=0.077 g_loss=-0.093 KID= 0.03563\n",
      "epoch 268, batch 0, d_loss=0.022 g_loss=-0.112 KID= 0.03563\n",
      "epoch 268, batch 1, d_loss=0.045 g_loss=-0.167 KID= 0.03563\n",
      "epoch 268, batch 2, d_loss=-0.051 g_loss=-0.183 KID= 0.03563\n",
      "epoch 268, batch 3, d_loss=0.018 g_loss=-0.219 KID= 0.03563\n",
      "epoch 268, batch 4, d_loss=-0.007 g_loss=-0.306 KID= 0.03563\n",
      "epoch 268, batch 5, d_loss=-0.026 g_loss=-0.357 KID= 0.03563\n",
      "epoch 268, batch 6, d_loss=-0.011 g_loss=-0.382 KID= 0.03563\n",
      "epoch 268, batch 7, d_loss=0.038 g_loss=-0.421 KID= 0.03563\n",
      "epoch 268, batch 8, d_loss=-0.003 g_loss=-0.494 KID= 0.03563\n",
      "epoch 268, batch 9, d_loss=0.039 g_loss=-0.511 KID= 0.03563\n",
      "epoch 268, batch 10, d_loss=0.043 g_loss=-0.578 KID= 0.03563\n",
      "epoch 268, batch 11, d_loss=0.057 g_loss=-0.538 KID= 0.03563\n",
      "epoch 268, batch 12, d_loss=-0.020 g_loss=-0.485 KID= 0.03563\n",
      "epoch 268, batch 13, d_loss=0.002 g_loss=-0.446 KID= 0.03563\n",
      "epoch 268, batch 14, d_loss=-0.049 g_loss=-0.436 KID= 0.03563\n",
      "epoch 268, batch 15, d_loss=0.047 g_loss=-0.328 KID= 0.03563\n",
      "epoch 268, batch 16, d_loss=0.013 g_loss=-0.240 KID= 0.03563\n",
      "epoch 268, batch 17, d_loss=-0.032 g_loss=-0.150 KID= 0.03563\n",
      "epoch 268, batch 18, d_loss=0.067 g_loss=-0.016 KID= 0.03563\n",
      "epoch 268, batch 19, d_loss=0.042 g_loss=0.052 KID= 0.03563\n",
      "epoch 269, batch 0, d_loss=0.002 g_loss=0.033 KID= 0.03563\n",
      "epoch 269, batch 1, d_loss=0.071 g_loss=0.006 KID= 0.03563\n",
      "epoch 269, batch 2, d_loss=0.030 g_loss=-0.040 KID= 0.03563\n",
      "epoch 269, batch 3, d_loss=0.006 g_loss=-0.049 KID= 0.03563\n",
      "epoch 269, batch 4, d_loss=0.005 g_loss=-0.055 KID= 0.03563\n",
      "epoch 269, batch 5, d_loss=-0.037 g_loss=-0.028 KID= 0.03563\n",
      "epoch 269, batch 6, d_loss=-0.056 g_loss=0.024 KID= 0.03563\n",
      "epoch 269, batch 7, d_loss=-0.012 g_loss=0.051 KID= 0.03563\n",
      "epoch 269, batch 8, d_loss=0.030 g_loss=0.085 KID= 0.03563\n",
      "epoch 269, batch 9, d_loss=-0.033 g_loss=0.123 KID= 0.03563\n",
      "epoch 269, batch 10, d_loss=0.055 g_loss=0.068 KID= 0.03563\n",
      "epoch 269, batch 11, d_loss=0.150 g_loss=-0.036 KID= 0.03563\n",
      "epoch 269, batch 12, d_loss=0.123 g_loss=-0.123 KID= 0.03563\n",
      "epoch 269, batch 13, d_loss=0.037 g_loss=-0.212 KID= 0.03563\n",
      "epoch 269, batch 14, d_loss=0.037 g_loss=-0.320 KID= 0.03563\n",
      "epoch 269, batch 15, d_loss=0.032 g_loss=-0.353 KID= 0.03563\n",
      "epoch 269, batch 16, d_loss=0.021 g_loss=-0.320 KID= 0.03563\n",
      "epoch 269, batch 17, d_loss=-0.081 g_loss=-0.271 KID= 0.03563\n",
      "epoch 269, batch 18, d_loss=-0.057 g_loss=-0.236 KID= 0.03563\n",
      "epoch 269, batch 19, d_loss=-0.059 g_loss=-0.257 KID= 0.03563\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 270, batch 0, d_loss=-0.015 g_loss=-0.276 KID= 0.03987\n",
      "epoch 270, batch 1, d_loss=0.060 g_loss=-0.357 KID= 0.03987\n",
      "epoch 270, batch 2, d_loss=-0.115 g_loss=-0.524 KID= 0.03987\n",
      "epoch 270, batch 3, d_loss=0.047 g_loss=-0.660 KID= 0.03987\n",
      "epoch 270, batch 4, d_loss=0.034 g_loss=-0.865 KID= 0.03987\n",
      "epoch 270, batch 5, d_loss=-0.054 g_loss=-1.065 KID= 0.03987\n",
      "epoch 270, batch 6, d_loss=0.047 g_loss=-1.030 KID= 0.03987\n",
      "epoch 270, batch 7, d_loss=0.108 g_loss=-0.841 KID= 0.03987\n",
      "epoch 270, batch 8, d_loss=0.016 g_loss=-0.713 KID= 0.03987\n",
      "epoch 270, batch 9, d_loss=0.013 g_loss=-0.597 KID= 0.03987\n",
      "epoch 270, batch 10, d_loss=0.022 g_loss=-0.500 KID= 0.03987\n",
      "epoch 270, batch 11, d_loss=0.032 g_loss=-0.431 KID= 0.03987\n",
      "epoch 270, batch 12, d_loss=0.022 g_loss=-0.306 KID= 0.03987\n",
      "epoch 270, batch 13, d_loss=-0.011 g_loss=-0.248 KID= 0.03987\n",
      "epoch 270, batch 14, d_loss=-0.019 g_loss=-0.201 KID= 0.03987\n",
      "epoch 270, batch 15, d_loss=0.075 g_loss=-0.080 KID= 0.03987\n",
      "epoch 270, batch 16, d_loss=0.039 g_loss=0.029 KID= 0.03987\n",
      "epoch 270, batch 17, d_loss=-0.047 g_loss=0.137 KID= 0.03987\n",
      "epoch 270, batch 18, d_loss=0.073 g_loss=0.374 KID= 0.03987\n",
      "epoch 270, batch 19, d_loss=0.030 g_loss=0.500 KID= 0.03987\n",
      "epoch 271, batch 0, d_loss=0.041 g_loss=0.426 KID= 0.03987\n",
      "epoch 271, batch 1, d_loss=0.107 g_loss=0.286 KID= 0.03987\n",
      "epoch 271, batch 2, d_loss=0.027 g_loss=0.213 KID= 0.03987\n",
      "epoch 271, batch 3, d_loss=-0.033 g_loss=0.103 KID= 0.03987\n",
      "epoch 271, batch 4, d_loss=-0.063 g_loss=-0.025 KID= 0.03987\n",
      "epoch 271, batch 5, d_loss=-0.026 g_loss=-0.070 KID= 0.03987\n",
      "epoch 271, batch 6, d_loss=0.000 g_loss=-0.085 KID= 0.03987\n",
      "epoch 271, batch 7, d_loss=-0.048 g_loss=-0.191 KID= 0.03987\n",
      "epoch 271, batch 8, d_loss=-0.010 g_loss=-0.273 KID= 0.03987\n",
      "epoch 271, batch 9, d_loss=0.027 g_loss=-0.393 KID= 0.03987\n",
      "epoch 271, batch 10, d_loss=-0.009 g_loss=-0.515 KID= 0.03987\n",
      "epoch 271, batch 11, d_loss=0.053 g_loss=-0.659 KID= 0.03987\n",
      "epoch 271, batch 12, d_loss=-0.010 g_loss=-0.721 KID= 0.03987\n",
      "epoch 271, batch 13, d_loss=0.025 g_loss=-0.738 KID= 0.03987\n",
      "epoch 271, batch 14, d_loss=0.037 g_loss=-0.708 KID= 0.03987\n",
      "epoch 271, batch 15, d_loss=-0.041 g_loss=-0.560 KID= 0.03987\n",
      "epoch 271, batch 16, d_loss=-0.132 g_loss=-0.363 KID= 0.03987\n",
      "epoch 271, batch 17, d_loss=-0.082 g_loss=-0.251 KID= 0.03987\n",
      "epoch 271, batch 18, d_loss=0.015 g_loss=-0.088 KID= 0.03987\n",
      "epoch 271, batch 19, d_loss=-0.031 g_loss=0.012 KID= 0.03987\n",
      "epoch 272, batch 0, d_loss=0.044 g_loss=0.035 KID= 0.03987\n",
      "epoch 272, batch 1, d_loss=0.179 g_loss=0.032 KID= 0.03987\n",
      "epoch 272, batch 2, d_loss=-0.015 g_loss=0.064 KID= 0.03987\n",
      "epoch 272, batch 3, d_loss=-0.010 g_loss=0.139 KID= 0.03987\n",
      "epoch 272, batch 4, d_loss=-0.031 g_loss=0.105 KID= 0.03987\n",
      "epoch 272, batch 5, d_loss=0.073 g_loss=0.029 KID= 0.03987\n",
      "epoch 272, batch 6, d_loss=0.116 g_loss=-0.030 KID= 0.03987\n",
      "epoch 272, batch 7, d_loss=-0.004 g_loss=-0.048 KID= 0.03987\n",
      "epoch 272, batch 8, d_loss=-0.007 g_loss=-0.032 KID= 0.03987\n",
      "epoch 272, batch 9, d_loss=0.033 g_loss=-0.037 KID= 0.03987\n",
      "epoch 272, batch 10, d_loss=-0.029 g_loss=-0.017 KID= 0.03987\n",
      "epoch 272, batch 11, d_loss=-0.070 g_loss=0.035 KID= 0.03987\n",
      "epoch 272, batch 12, d_loss=-0.043 g_loss=0.111 KID= 0.03987\n",
      "epoch 272, batch 13, d_loss=-0.075 g_loss=0.183 KID= 0.03987\n",
      "epoch 272, batch 14, d_loss=-0.057 g_loss=0.180 KID= 0.03987\n",
      "epoch 272, batch 15, d_loss=-0.017 g_loss=0.161 KID= 0.03987\n",
      "epoch 272, batch 16, d_loss=-0.034 g_loss=0.096 KID= 0.03987\n",
      "epoch 272, batch 17, d_loss=-0.016 g_loss=0.020 KID= 0.03987\n",
      "epoch 272, batch 18, d_loss=0.061 g_loss=0.020 KID= 0.03987\n",
      "epoch 272, batch 19, d_loss=-0.002 g_loss=-0.054 KID= 0.03987\n",
      "epoch 273, batch 0, d_loss=0.130 g_loss=-0.074 KID= 0.03987\n",
      "epoch 273, batch 1, d_loss=0.166 g_loss=-0.073 KID= 0.03987\n",
      "epoch 273, batch 2, d_loss=0.022 g_loss=-0.124 KID= 0.03987\n",
      "epoch 273, batch 3, d_loss=0.069 g_loss=-0.115 KID= 0.03987\n",
      "epoch 273, batch 4, d_loss=0.071 g_loss=-0.137 KID= 0.03987\n",
      "epoch 273, batch 5, d_loss=0.029 g_loss=-0.134 KID= 0.03987\n",
      "epoch 273, batch 6, d_loss=0.098 g_loss=-0.114 KID= 0.03987\n",
      "epoch 273, batch 7, d_loss=0.037 g_loss=-0.092 KID= 0.03987\n",
      "epoch 273, batch 8, d_loss=-0.032 g_loss=-0.052 KID= 0.03987\n",
      "epoch 273, batch 9, d_loss=0.012 g_loss=-0.060 KID= 0.03987\n",
      "epoch 273, batch 10, d_loss=-0.006 g_loss=-0.101 KID= 0.03987\n",
      "epoch 273, batch 11, d_loss=-0.060 g_loss=-0.107 KID= 0.03987\n",
      "epoch 273, batch 12, d_loss=0.012 g_loss=-0.126 KID= 0.03987\n",
      "epoch 273, batch 13, d_loss=-0.034 g_loss=-0.157 KID= 0.03987\n",
      "epoch 273, batch 14, d_loss=-0.048 g_loss=-0.210 KID= 0.03987\n",
      "epoch 273, batch 15, d_loss=0.003 g_loss=-0.244 KID= 0.03987\n",
      "epoch 273, batch 16, d_loss=-0.008 g_loss=-0.247 KID= 0.03987\n",
      "epoch 273, batch 17, d_loss=-0.042 g_loss=-0.238 KID= 0.03987\n",
      "epoch 273, batch 18, d_loss=0.057 g_loss=-0.171 KID= 0.03987\n",
      "epoch 273, batch 19, d_loss=-0.042 g_loss=-0.175 KID= 0.03987\n",
      "epoch 274, batch 0, d_loss=0.006 g_loss=-0.169 KID= 0.03987\n",
      "epoch 274, batch 1, d_loss=0.084 g_loss=-0.122 KID= 0.03987\n",
      "epoch 274, batch 2, d_loss=-0.075 g_loss=-0.116 KID= 0.03987\n",
      "epoch 274, batch 3, d_loss=0.000 g_loss=-0.098 KID= 0.03987\n",
      "epoch 274, batch 4, d_loss=0.038 g_loss=-0.068 KID= 0.03987\n",
      "epoch 274, batch 5, d_loss=-0.027 g_loss=-0.070 KID= 0.03987\n",
      "epoch 274, batch 6, d_loss=0.028 g_loss=-0.068 KID= 0.03987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 274, batch 7, d_loss=0.045 g_loss=-0.037 KID= 0.03987\n",
      "epoch 274, batch 8, d_loss=0.005 g_loss=-0.013 KID= 0.03987\n",
      "epoch 274, batch 9, d_loss=0.044 g_loss=-0.049 KID= 0.03987\n",
      "epoch 274, batch 10, d_loss=0.036 g_loss=-0.035 KID= 0.03987\n",
      "epoch 274, batch 11, d_loss=-0.017 g_loss=0.041 KID= 0.03987\n",
      "epoch 274, batch 12, d_loss=0.022 g_loss=0.093 KID= 0.03987\n",
      "epoch 274, batch 13, d_loss=-0.067 g_loss=0.158 KID= 0.03987\n",
      "epoch 274, batch 14, d_loss=-0.060 g_loss=0.250 KID= 0.03987\n",
      "epoch 274, batch 15, d_loss=0.032 g_loss=0.331 KID= 0.03987\n",
      "epoch 274, batch 16, d_loss=0.050 g_loss=0.300 KID= 0.03987\n",
      "epoch 274, batch 17, d_loss=-0.076 g_loss=0.333 KID= 0.03987\n",
      "epoch 274, batch 18, d_loss=0.049 g_loss=0.294 KID= 0.03987\n",
      "epoch 274, batch 19, d_loss=0.001 g_loss=0.205 KID= 0.03987\n",
      "epoch 275, batch 0, d_loss=0.029 g_loss=0.108 KID= 0.03987\n",
      "epoch 275, batch 1, d_loss=0.037 g_loss=0.003 KID= 0.03987\n",
      "epoch 275, batch 2, d_loss=-0.087 g_loss=-0.125 KID= 0.03987\n",
      "epoch 275, batch 3, d_loss=0.030 g_loss=-0.228 KID= 0.03987\n",
      "epoch 275, batch 4, d_loss=0.061 g_loss=-0.289 KID= 0.03987\n",
      "epoch 275, batch 5, d_loss=-0.061 g_loss=-0.244 KID= 0.03987\n",
      "epoch 275, batch 6, d_loss=-0.096 g_loss=-0.213 KID= 0.03987\n",
      "epoch 275, batch 7, d_loss=-0.065 g_loss=-0.259 KID= 0.03987\n",
      "epoch 275, batch 8, d_loss=0.021 g_loss=-0.209 KID= 0.03987\n",
      "epoch 275, batch 9, d_loss=0.038 g_loss=-0.219 KID= 0.03987\n",
      "epoch 275, batch 10, d_loss=0.096 g_loss=-0.246 KID= 0.03987\n",
      "epoch 275, batch 11, d_loss=0.023 g_loss=-0.286 KID= 0.03987\n",
      "epoch 275, batch 12, d_loss=-0.016 g_loss=-0.372 KID= 0.03987\n",
      "epoch 275, batch 13, d_loss=-0.047 g_loss=-0.426 KID= 0.03987\n",
      "epoch 275, batch 14, d_loss=-0.095 g_loss=-0.513 KID= 0.03987\n",
      "epoch 275, batch 15, d_loss=0.020 g_loss=-0.429 KID= 0.03987\n",
      "epoch 275, batch 16, d_loss=0.006 g_loss=-0.366 KID= 0.03987\n",
      "epoch 275, batch 17, d_loss=-0.076 g_loss=-0.256 KID= 0.03987\n",
      "epoch 275, batch 18, d_loss=0.071 g_loss=-0.150 KID= 0.03987\n",
      "epoch 275, batch 19, d_loss=0.047 g_loss=-0.192 KID= 0.03987\n",
      "epoch 276, batch 0, d_loss=-0.032 g_loss=-0.145 KID= 0.03987\n",
      "epoch 276, batch 1, d_loss=-0.001 g_loss=-0.080 KID= 0.03987\n",
      "epoch 276, batch 2, d_loss=-0.011 g_loss=-0.021 KID= 0.03987\n",
      "epoch 276, batch 3, d_loss=-0.045 g_loss=0.050 KID= 0.03987\n",
      "epoch 276, batch 4, d_loss=0.068 g_loss=0.084 KID= 0.03987\n",
      "epoch 276, batch 5, d_loss=0.049 g_loss=0.062 KID= 0.03987\n",
      "epoch 276, batch 6, d_loss=0.009 g_loss=0.118 KID= 0.03987\n",
      "epoch 276, batch 7, d_loss=0.000 g_loss=0.152 KID= 0.03987\n",
      "epoch 276, batch 8, d_loss=0.016 g_loss=0.224 KID= 0.03987\n",
      "epoch 276, batch 9, d_loss=-0.106 g_loss=0.244 KID= 0.03987\n",
      "epoch 276, batch 10, d_loss=-0.008 g_loss=0.202 KID= 0.03987\n",
      "epoch 276, batch 11, d_loss=0.015 g_loss=0.111 KID= 0.03987\n",
      "epoch 276, batch 12, d_loss=0.063 g_loss=0.065 KID= 0.03987\n",
      "epoch 276, batch 13, d_loss=0.084 g_loss=0.033 KID= 0.03987\n",
      "epoch 276, batch 14, d_loss=-0.063 g_loss=-0.052 KID= 0.03987\n",
      "epoch 276, batch 15, d_loss=-0.030 g_loss=-0.178 KID= 0.03987\n",
      "epoch 276, batch 16, d_loss=0.053 g_loss=-0.204 KID= 0.03987\n",
      "epoch 276, batch 17, d_loss=0.019 g_loss=-0.131 KID= 0.03987\n",
      "epoch 276, batch 18, d_loss=-0.037 g_loss=-0.041 KID= 0.03987\n",
      "epoch 276, batch 19, d_loss=-0.065 g_loss=-0.005 KID= 0.03987\n",
      "epoch 277, batch 0, d_loss=-0.022 g_loss=-0.046 KID= 0.03987\n",
      "epoch 277, batch 1, d_loss=-0.043 g_loss=-0.082 KID= 0.03987\n",
      "epoch 277, batch 2, d_loss=-0.090 g_loss=-0.183 KID= 0.03987\n",
      "epoch 277, batch 3, d_loss=-0.069 g_loss=-0.318 KID= 0.03987\n",
      "epoch 277, batch 4, d_loss=0.029 g_loss=-0.483 KID= 0.03987\n",
      "epoch 277, batch 5, d_loss=0.080 g_loss=-0.608 KID= 0.03987\n",
      "epoch 277, batch 6, d_loss=0.042 g_loss=-0.614 KID= 0.03987\n",
      "epoch 277, batch 7, d_loss=0.018 g_loss=-0.594 KID= 0.03987\n",
      "epoch 277, batch 8, d_loss=0.080 g_loss=-0.475 KID= 0.03987\n",
      "epoch 277, batch 9, d_loss=-0.056 g_loss=-0.418 KID= 0.03987\n",
      "epoch 277, batch 10, d_loss=-0.051 g_loss=-0.307 KID= 0.03987\n",
      "epoch 277, batch 11, d_loss=-0.037 g_loss=-0.284 KID= 0.03987\n",
      "epoch 277, batch 12, d_loss=0.030 g_loss=-0.249 KID= 0.03987\n",
      "epoch 277, batch 13, d_loss=-0.040 g_loss=-0.277 KID= 0.03987\n",
      "epoch 277, batch 14, d_loss=-0.017 g_loss=-0.296 KID= 0.03987\n",
      "epoch 277, batch 15, d_loss=-0.034 g_loss=-0.246 KID= 0.03987\n",
      "epoch 277, batch 16, d_loss=0.036 g_loss=-0.251 KID= 0.03987\n",
      "epoch 277, batch 17, d_loss=0.048 g_loss=-0.239 KID= 0.03987\n",
      "epoch 277, batch 18, d_loss=0.058 g_loss=-0.237 KID= 0.03987\n",
      "epoch 277, batch 19, d_loss=0.021 g_loss=-0.269 KID= 0.03987\n",
      "epoch 278, batch 0, d_loss=0.000 g_loss=-0.338 KID= 0.03987\n",
      "epoch 278, batch 1, d_loss=0.046 g_loss=-0.334 KID= 0.03987\n",
      "epoch 278, batch 2, d_loss=0.014 g_loss=-0.434 KID= 0.03987\n",
      "epoch 278, batch 3, d_loss=-0.055 g_loss=-0.469 KID= 0.03987\n",
      "epoch 278, batch 4, d_loss=0.014 g_loss=-0.449 KID= 0.03987\n",
      "epoch 278, batch 5, d_loss=-0.059 g_loss=-0.464 KID= 0.03987\n",
      "epoch 278, batch 6, d_loss=-0.025 g_loss=-0.434 KID= 0.03987\n",
      "epoch 278, batch 7, d_loss=-0.072 g_loss=-0.380 KID= 0.03987\n",
      "epoch 278, batch 8, d_loss=-0.040 g_loss=-0.330 KID= 0.03987\n",
      "epoch 278, batch 9, d_loss=-0.115 g_loss=-0.336 KID= 0.03987\n",
      "epoch 278, batch 10, d_loss=-0.005 g_loss=-0.337 KID= 0.03987\n",
      "epoch 278, batch 11, d_loss=0.045 g_loss=-0.383 KID= 0.03987\n",
      "epoch 278, batch 12, d_loss=0.031 g_loss=-0.398 KID= 0.03987\n",
      "epoch 278, batch 13, d_loss=0.060 g_loss=-0.429 KID= 0.03987\n",
      "epoch 278, batch 14, d_loss=0.063 g_loss=-0.427 KID= 0.03987\n",
      "epoch 278, batch 15, d_loss=0.033 g_loss=-0.405 KID= 0.03987\n",
      "epoch 278, batch 16, d_loss=0.000 g_loss=-0.431 KID= 0.03987\n",
      "epoch 278, batch 17, d_loss=-0.064 g_loss=-0.433 KID= 0.03987\n",
      "epoch 278, batch 18, d_loss=-0.027 g_loss=-0.416 KID= 0.03987\n",
      "epoch 278, batch 19, d_loss=-0.057 g_loss=-0.461 KID= 0.03987\n",
      "epoch 279, batch 0, d_loss=-0.013 g_loss=-0.502 KID= 0.03987\n",
      "epoch 279, batch 1, d_loss=0.031 g_loss=-0.484 KID= 0.03987\n",
      "epoch 279, batch 2, d_loss=0.026 g_loss=-0.524 KID= 0.03987\n",
      "epoch 279, batch 3, d_loss=-0.022 g_loss=-0.518 KID= 0.03987\n",
      "epoch 279, batch 4, d_loss=0.031 g_loss=-0.472 KID= 0.03987\n",
      "epoch 279, batch 5, d_loss=-0.029 g_loss=-0.435 KID= 0.03987\n",
      "epoch 279, batch 6, d_loss=0.073 g_loss=-0.406 KID= 0.03987\n",
      "epoch 279, batch 7, d_loss=-0.028 g_loss=-0.389 KID= 0.03987\n",
      "epoch 279, batch 8, d_loss=0.005 g_loss=-0.369 KID= 0.03987\n",
      "epoch 279, batch 9, d_loss=-0.017 g_loss=-0.344 KID= 0.03987\n",
      "epoch 279, batch 10, d_loss=-0.050 g_loss=-0.287 KID= 0.03987\n",
      "epoch 279, batch 11, d_loss=-0.030 g_loss=-0.303 KID= 0.03987\n",
      "epoch 279, batch 12, d_loss=-0.006 g_loss=-0.304 KID= 0.03987\n",
      "epoch 279, batch 13, d_loss=-0.018 g_loss=-0.320 KID= 0.03987\n",
      "epoch 279, batch 14, d_loss=0.026 g_loss=-0.280 KID= 0.03987\n",
      "epoch 279, batch 15, d_loss=0.071 g_loss=-0.200 KID= 0.03987\n",
      "epoch 279, batch 16, d_loss=-0.010 g_loss=-0.126 KID= 0.03987\n",
      "epoch 279, batch 17, d_loss=-0.044 g_loss=-0.039 KID= 0.03987\n",
      "epoch 279, batch 18, d_loss=-0.028 g_loss=-0.021 KID= 0.03987\n",
      "epoch 279, batch 19, d_loss=-0.045 g_loss=0.005 KID= 0.03987\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 280, batch 0, d_loss=-0.012 g_loss=0.026 KID= 0.02573\n",
      "epoch 280, batch 1, d_loss=0.040 g_loss=0.024 KID= 0.02573\n",
      "epoch 280, batch 2, d_loss=-0.024 g_loss=0.074 KID= 0.02573\n",
      "epoch 280, batch 3, d_loss=-0.095 g_loss=0.086 KID= 0.02573\n",
      "epoch 280, batch 4, d_loss=-0.021 g_loss=0.024 KID= 0.02573\n",
      "epoch 280, batch 5, d_loss=-0.065 g_loss=-0.125 KID= 0.02573\n",
      "epoch 280, batch 6, d_loss=0.007 g_loss=-0.236 KID= 0.02573\n",
      "epoch 280, batch 7, d_loss=0.089 g_loss=-0.333 KID= 0.02573\n",
      "epoch 280, batch 8, d_loss=0.075 g_loss=-0.401 KID= 0.02573\n",
      "epoch 280, batch 9, d_loss=0.013 g_loss=-0.445 KID= 0.02573\n",
      "epoch 280, batch 10, d_loss=0.004 g_loss=-0.479 KID= 0.02573\n",
      "epoch 280, batch 11, d_loss=-0.019 g_loss=-0.497 KID= 0.02573\n",
      "epoch 280, batch 12, d_loss=-0.035 g_loss=-0.418 KID= 0.02573\n",
      "epoch 280, batch 13, d_loss=-0.034 g_loss=-0.335 KID= 0.02573\n",
      "epoch 280, batch 14, d_loss=-0.046 g_loss=-0.291 KID= 0.02573\n",
      "epoch 280, batch 15, d_loss=-0.037 g_loss=-0.241 KID= 0.02573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 280, batch 16, d_loss=-0.081 g_loss=-0.254 KID= 0.02573\n",
      "epoch 280, batch 17, d_loss=-0.070 g_loss=-0.196 KID= 0.02573\n",
      "epoch 280, batch 18, d_loss=0.083 g_loss=-0.072 KID= 0.02573\n",
      "epoch 280, batch 19, d_loss=-0.010 g_loss=-0.030 KID= 0.02573\n",
      "epoch 281, batch 0, d_loss=0.051 g_loss=0.015 KID= 0.02573\n",
      "epoch 281, batch 1, d_loss=0.090 g_loss=0.155 KID= 0.02573\n",
      "epoch 281, batch 2, d_loss=0.004 g_loss=0.239 KID= 0.02573\n",
      "epoch 281, batch 3, d_loss=0.017 g_loss=0.272 KID= 0.02573\n",
      "epoch 281, batch 4, d_loss=-0.011 g_loss=0.279 KID= 0.02573\n",
      "epoch 281, batch 5, d_loss=-0.069 g_loss=0.309 KID= 0.02573\n",
      "epoch 281, batch 6, d_loss=0.002 g_loss=0.350 KID= 0.02573\n",
      "epoch 281, batch 7, d_loss=0.009 g_loss=0.388 KID= 0.02573\n",
      "epoch 281, batch 8, d_loss=0.003 g_loss=0.409 KID= 0.02573\n",
      "epoch 281, batch 9, d_loss=0.009 g_loss=0.420 KID= 0.02573\n",
      "epoch 281, batch 10, d_loss=0.008 g_loss=0.369 KID= 0.02573\n",
      "epoch 281, batch 11, d_loss=-0.018 g_loss=0.246 KID= 0.02573\n",
      "epoch 281, batch 12, d_loss=0.012 g_loss=0.086 KID= 0.02573\n",
      "epoch 281, batch 13, d_loss=-0.018 g_loss=-0.007 KID= 0.02573\n",
      "epoch 281, batch 14, d_loss=0.001 g_loss=-0.142 KID= 0.02573\n",
      "epoch 281, batch 15, d_loss=-0.002 g_loss=-0.200 KID= 0.02573\n",
      "epoch 281, batch 16, d_loss=-0.070 g_loss=-0.188 KID= 0.02573\n",
      "epoch 281, batch 17, d_loss=-0.093 g_loss=-0.169 KID= 0.02573\n",
      "epoch 281, batch 18, d_loss=-0.036 g_loss=-0.310 KID= 0.02573\n",
      "epoch 281, batch 19, d_loss=-0.101 g_loss=-0.458 KID= 0.02573\n",
      "epoch 282, batch 0, d_loss=-0.063 g_loss=-0.573 KID= 0.02573\n",
      "epoch 282, batch 1, d_loss=0.085 g_loss=-0.600 KID= 0.02573\n",
      "epoch 282, batch 2, d_loss=0.057 g_loss=-0.640 KID= 0.02573\n",
      "epoch 282, batch 3, d_loss=0.020 g_loss=-0.529 KID= 0.02573\n",
      "epoch 282, batch 4, d_loss=0.050 g_loss=-0.379 KID= 0.02573\n",
      "epoch 282, batch 5, d_loss=-0.007 g_loss=-0.190 KID= 0.02573\n",
      "epoch 282, batch 6, d_loss=0.054 g_loss=-0.056 KID= 0.02573\n",
      "epoch 282, batch 7, d_loss=-0.004 g_loss=0.066 KID= 0.02573\n",
      "epoch 282, batch 8, d_loss=-0.003 g_loss=0.182 KID= 0.02573\n",
      "epoch 282, batch 9, d_loss=-0.067 g_loss=0.240 KID= 0.02573\n",
      "epoch 282, batch 10, d_loss=-0.039 g_loss=0.211 KID= 0.02573\n",
      "epoch 282, batch 11, d_loss=-0.046 g_loss=0.154 KID= 0.02573\n",
      "epoch 282, batch 12, d_loss=0.001 g_loss=0.105 KID= 0.02573\n",
      "epoch 282, batch 13, d_loss=0.008 g_loss=-0.001 KID= 0.02573\n",
      "epoch 282, batch 14, d_loss=0.003 g_loss=-0.092 KID= 0.02573\n",
      "epoch 282, batch 15, d_loss=0.012 g_loss=-0.142 KID= 0.02573\n",
      "epoch 282, batch 16, d_loss=0.039 g_loss=-0.180 KID= 0.02573\n",
      "epoch 282, batch 17, d_loss=-0.017 g_loss=-0.182 KID= 0.02573\n",
      "epoch 282, batch 18, d_loss=0.037 g_loss=-0.180 KID= 0.02573\n",
      "epoch 282, batch 19, d_loss=-0.038 g_loss=-0.176 KID= 0.02573\n",
      "epoch 283, batch 0, d_loss=-0.058 g_loss=-0.152 KID= 0.02573\n",
      "epoch 283, batch 1, d_loss=0.028 g_loss=-0.195 KID= 0.02573\n",
      "epoch 283, batch 2, d_loss=-0.053 g_loss=-0.202 KID= 0.02573\n",
      "epoch 283, batch 3, d_loss=-0.073 g_loss=-0.147 KID= 0.02573\n",
      "epoch 283, batch 4, d_loss=0.032 g_loss=-0.122 KID= 0.02573\n",
      "epoch 283, batch 5, d_loss=-0.017 g_loss=-0.070 KID= 0.02573\n",
      "epoch 283, batch 6, d_loss=-0.052 g_loss=-0.036 KID= 0.02573\n",
      "epoch 283, batch 7, d_loss=-0.108 g_loss=-0.035 KID= 0.02573\n",
      "epoch 283, batch 8, d_loss=0.062 g_loss=-0.017 KID= 0.02573\n",
      "epoch 283, batch 9, d_loss=0.022 g_loss=-0.073 KID= 0.02573\n",
      "epoch 283, batch 10, d_loss=0.042 g_loss=-0.109 KID= 0.02573\n",
      "epoch 283, batch 11, d_loss=0.006 g_loss=-0.112 KID= 0.02573\n",
      "epoch 283, batch 12, d_loss=0.036 g_loss=-0.124 KID= 0.02573\n",
      "epoch 283, batch 13, d_loss=0.055 g_loss=-0.112 KID= 0.02573\n",
      "epoch 283, batch 14, d_loss=-0.047 g_loss=-0.093 KID= 0.02573\n",
      "epoch 283, batch 15, d_loss=-0.010 g_loss=-0.045 KID= 0.02573\n",
      "epoch 283, batch 16, d_loss=0.009 g_loss=-0.029 KID= 0.02573\n",
      "epoch 283, batch 17, d_loss=-0.040 g_loss=-0.017 KID= 0.02573\n",
      "epoch 283, batch 18, d_loss=-0.062 g_loss=-0.043 KID= 0.02573\n",
      "epoch 283, batch 19, d_loss=-0.054 g_loss=-0.087 KID= 0.02573\n",
      "epoch 284, batch 0, d_loss=-0.094 g_loss=-0.130 KID= 0.02573\n",
      "epoch 284, batch 1, d_loss=-0.011 g_loss=-0.205 KID= 0.02573\n",
      "epoch 284, batch 2, d_loss=-0.032 g_loss=-0.304 KID= 0.02573\n",
      "epoch 284, batch 3, d_loss=-0.043 g_loss=-0.345 KID= 0.02573\n",
      "epoch 284, batch 4, d_loss=0.021 g_loss=-0.335 KID= 0.02573\n",
      "epoch 284, batch 5, d_loss=-0.057 g_loss=-0.387 KID= 0.02573\n",
      "epoch 284, batch 6, d_loss=-0.038 g_loss=-0.391 KID= 0.02573\n",
      "epoch 284, batch 7, d_loss=-0.019 g_loss=-0.368 KID= 0.02573\n",
      "epoch 284, batch 8, d_loss=0.041 g_loss=-0.356 KID= 0.02573\n",
      "epoch 284, batch 9, d_loss=0.017 g_loss=-0.354 KID= 0.02573\n",
      "epoch 284, batch 10, d_loss=0.043 g_loss=-0.331 KID= 0.02573\n",
      "epoch 284, batch 11, d_loss=0.018 g_loss=-0.350 KID= 0.02573\n",
      "epoch 284, batch 12, d_loss=0.045 g_loss=-0.380 KID= 0.02573\n",
      "epoch 284, batch 13, d_loss=-0.034 g_loss=-0.446 KID= 0.02573\n",
      "epoch 284, batch 14, d_loss=-0.051 g_loss=-0.489 KID= 0.02573\n",
      "epoch 284, batch 15, d_loss=-0.075 g_loss=-0.442 KID= 0.02573\n",
      "epoch 284, batch 16, d_loss=-0.046 g_loss=-0.370 KID= 0.02573\n",
      "epoch 284, batch 17, d_loss=0.012 g_loss=-0.234 KID= 0.02573\n",
      "epoch 284, batch 18, d_loss=0.057 g_loss=-0.130 KID= 0.02573\n",
      "epoch 284, batch 19, d_loss=0.001 g_loss=-0.129 KID= 0.02573\n",
      "epoch 285, batch 0, d_loss=0.006 g_loss=-0.074 KID= 0.02573\n",
      "epoch 285, batch 1, d_loss=0.076 g_loss=-0.106 KID= 0.02573\n",
      "epoch 285, batch 2, d_loss=-0.025 g_loss=-0.142 KID= 0.02573\n",
      "epoch 285, batch 3, d_loss=-0.058 g_loss=-0.146 KID= 0.02573\n",
      "epoch 285, batch 4, d_loss=-0.035 g_loss=-0.147 KID= 0.02573\n",
      "epoch 285, batch 5, d_loss=-0.028 g_loss=-0.083 KID= 0.02573\n",
      "epoch 285, batch 6, d_loss=-0.085 g_loss=-0.013 KID= 0.02573\n",
      "epoch 285, batch 7, d_loss=-0.107 g_loss=0.055 KID= 0.02573\n",
      "epoch 285, batch 8, d_loss=0.011 g_loss=0.082 KID= 0.02573\n",
      "epoch 285, batch 9, d_loss=0.020 g_loss=0.023 KID= 0.02573\n",
      "epoch 285, batch 10, d_loss=0.038 g_loss=-0.010 KID= 0.02573\n",
      "epoch 285, batch 11, d_loss=0.053 g_loss=-0.057 KID= 0.02573\n",
      "epoch 285, batch 12, d_loss=-0.014 g_loss=-0.086 KID= 0.02573\n",
      "epoch 285, batch 13, d_loss=-0.042 g_loss=-0.143 KID= 0.02573\n",
      "epoch 285, batch 14, d_loss=-0.073 g_loss=-0.164 KID= 0.02573\n",
      "epoch 285, batch 15, d_loss=-0.093 g_loss=-0.110 KID= 0.02573\n",
      "epoch 285, batch 16, d_loss=-0.069 g_loss=-0.047 KID= 0.02573\n",
      "epoch 285, batch 17, d_loss=-0.056 g_loss=0.105 KID= 0.02573\n",
      "epoch 285, batch 18, d_loss=-0.021 g_loss=0.237 KID= 0.02573\n",
      "epoch 285, batch 19, d_loss=0.001 g_loss=0.237 KID= 0.02573\n",
      "epoch 286, batch 0, d_loss=0.046 g_loss=0.184 KID= 0.02573\n",
      "epoch 286, batch 1, d_loss=0.035 g_loss=0.009 KID= 0.02573\n",
      "epoch 286, batch 2, d_loss=-0.030 g_loss=-0.066 KID= 0.02573\n",
      "epoch 286, batch 3, d_loss=-0.015 g_loss=-0.135 KID= 0.02573\n",
      "epoch 286, batch 4, d_loss=0.026 g_loss=-0.177 KID= 0.02573\n",
      "epoch 286, batch 5, d_loss=-0.000 g_loss=-0.193 KID= 0.02573\n",
      "epoch 286, batch 6, d_loss=-0.037 g_loss=-0.141 KID= 0.02573\n",
      "epoch 286, batch 7, d_loss=-0.035 g_loss=-0.113 KID= 0.02573\n",
      "epoch 286, batch 8, d_loss=-0.079 g_loss=-0.181 KID= 0.02573\n",
      "epoch 286, batch 9, d_loss=-0.082 g_loss=-0.349 KID= 0.02573\n",
      "epoch 286, batch 10, d_loss=-0.097 g_loss=-0.528 KID= 0.02573\n",
      "epoch 286, batch 11, d_loss=0.049 g_loss=-0.607 KID= 0.02573\n",
      "epoch 286, batch 12, d_loss=-0.043 g_loss=-0.576 KID= 0.02573\n",
      "epoch 286, batch 13, d_loss=-0.055 g_loss=-0.500 KID= 0.02573\n",
      "epoch 286, batch 14, d_loss=-0.030 g_loss=-0.431 KID= 0.02573\n",
      "epoch 286, batch 15, d_loss=-0.033 g_loss=-0.275 KID= 0.02573\n",
      "epoch 286, batch 16, d_loss=-0.021 g_loss=-0.103 KID= 0.02573\n",
      "epoch 286, batch 17, d_loss=0.003 g_loss=0.050 KID= 0.02573\n",
      "epoch 286, batch 18, d_loss=0.025 g_loss=0.122 KID= 0.02573\n",
      "epoch 286, batch 19, d_loss=-0.025 g_loss=0.112 KID= 0.02573\n",
      "epoch 287, batch 0, d_loss=0.000 g_loss=0.090 KID= 0.02573\n",
      "epoch 287, batch 1, d_loss=-0.001 g_loss=-0.012 KID= 0.02573\n",
      "epoch 287, batch 2, d_loss=-0.058 g_loss=-0.017 KID= 0.02573\n",
      "epoch 287, batch 3, d_loss=-0.018 g_loss=-0.011 KID= 0.02573\n",
      "epoch 287, batch 4, d_loss=-0.041 g_loss=0.009 KID= 0.02573\n",
      "epoch 287, batch 5, d_loss=-0.017 g_loss=0.056 KID= 0.02573\n",
      "epoch 287, batch 6, d_loss=-0.022 g_loss=0.143 KID= 0.02573\n",
      "epoch 287, batch 7, d_loss=-0.046 g_loss=0.311 KID= 0.02573\n",
      "epoch 287, batch 8, d_loss=-0.000 g_loss=0.410 KID= 0.02573\n",
      "epoch 287, batch 9, d_loss=0.003 g_loss=0.400 KID= 0.02573\n",
      "epoch 287, batch 10, d_loss=-0.011 g_loss=0.266 KID= 0.02573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 287, batch 11, d_loss=0.123 g_loss=0.084 KID= 0.02573\n",
      "epoch 287, batch 12, d_loss=0.016 g_loss=-0.098 KID= 0.02573\n",
      "epoch 287, batch 13, d_loss=-0.018 g_loss=-0.257 KID= 0.02573\n",
      "epoch 287, batch 14, d_loss=-0.008 g_loss=-0.379 KID= 0.02573\n",
      "epoch 287, batch 15, d_loss=-0.017 g_loss=-0.472 KID= 0.02573\n",
      "epoch 287, batch 16, d_loss=-0.001 g_loss=-0.525 KID= 0.02573\n",
      "epoch 287, batch 17, d_loss=0.030 g_loss=-0.429 KID= 0.02573\n",
      "epoch 287, batch 18, d_loss=0.011 g_loss=-0.333 KID= 0.02573\n",
      "epoch 287, batch 19, d_loss=-0.051 g_loss=-0.293 KID= 0.02573\n",
      "epoch 288, batch 0, d_loss=0.005 g_loss=-0.253 KID= 0.02573\n",
      "epoch 288, batch 1, d_loss=-0.148 g_loss=-0.289 KID= 0.02573\n",
      "epoch 288, batch 2, d_loss=-0.074 g_loss=-0.273 KID= 0.02573\n",
      "epoch 288, batch 3, d_loss=-0.072 g_loss=-0.331 KID= 0.02573\n",
      "epoch 288, batch 4, d_loss=-0.004 g_loss=-0.349 KID= 0.02573\n",
      "epoch 288, batch 5, d_loss=-0.006 g_loss=-0.329 KID= 0.02573\n",
      "epoch 288, batch 6, d_loss=-0.034 g_loss=-0.341 KID= 0.02573\n",
      "epoch 288, batch 7, d_loss=-0.027 g_loss=-0.267 KID= 0.02573\n",
      "epoch 288, batch 8, d_loss=-0.095 g_loss=-0.259 KID= 0.02573\n",
      "epoch 288, batch 9, d_loss=-0.075 g_loss=-0.247 KID= 0.02573\n",
      "epoch 288, batch 10, d_loss=-0.034 g_loss=-0.231 KID= 0.02573\n",
      "epoch 288, batch 11, d_loss=0.104 g_loss=-0.116 KID= 0.02573\n",
      "epoch 288, batch 12, d_loss=-0.052 g_loss=-0.050 KID= 0.02573\n",
      "epoch 288, batch 13, d_loss=0.053 g_loss=-0.007 KID= 0.02573\n",
      "epoch 288, batch 14, d_loss=0.015 g_loss=0.031 KID= 0.02573\n",
      "epoch 288, batch 15, d_loss=-0.003 g_loss=0.052 KID= 0.02573\n",
      "epoch 288, batch 16, d_loss=-0.009 g_loss=0.054 KID= 0.02573\n",
      "epoch 288, batch 17, d_loss=-0.004 g_loss=0.112 KID= 0.02573\n",
      "epoch 288, batch 18, d_loss=0.022 g_loss=0.132 KID= 0.02573\n",
      "epoch 288, batch 19, d_loss=-0.054 g_loss=0.157 KID= 0.02573\n",
      "epoch 289, batch 0, d_loss=0.043 g_loss=0.132 KID= 0.02573\n",
      "epoch 289, batch 1, d_loss=0.026 g_loss=0.095 KID= 0.02573\n",
      "epoch 289, batch 2, d_loss=0.045 g_loss=0.016 KID= 0.02573\n",
      "epoch 289, batch 3, d_loss=-0.043 g_loss=-0.049 KID= 0.02573\n",
      "epoch 289, batch 4, d_loss=-0.012 g_loss=-0.131 KID= 0.02573\n",
      "epoch 289, batch 5, d_loss=-0.056 g_loss=-0.247 KID= 0.02573\n",
      "epoch 289, batch 6, d_loss=-0.029 g_loss=-0.337 KID= 0.02573\n",
      "epoch 289, batch 7, d_loss=-0.020 g_loss=-0.397 KID= 0.02573\n",
      "epoch 289, batch 8, d_loss=0.037 g_loss=-0.406 KID= 0.02573\n",
      "epoch 289, batch 9, d_loss=0.024 g_loss=-0.425 KID= 0.02573\n",
      "epoch 289, batch 10, d_loss=-0.081 g_loss=-0.472 KID= 0.02573\n",
      "epoch 289, batch 11, d_loss=-0.026 g_loss=-0.421 KID= 0.02573\n",
      "epoch 289, batch 12, d_loss=-0.031 g_loss=-0.437 KID= 0.02573\n",
      "epoch 289, batch 13, d_loss=0.010 g_loss=-0.385 KID= 0.02573\n",
      "epoch 289, batch 14, d_loss=-0.003 g_loss=-0.365 KID= 0.02573\n",
      "epoch 289, batch 15, d_loss=-0.035 g_loss=-0.328 KID= 0.02573\n",
      "epoch 289, batch 16, d_loss=-0.054 g_loss=-0.276 KID= 0.02573\n",
      "epoch 289, batch 17, d_loss=0.036 g_loss=-0.162 KID= 0.02573\n",
      "epoch 289, batch 18, d_loss=-0.029 g_loss=-0.040 KID= 0.02573\n",
      "epoch 289, batch 19, d_loss=-0.087 g_loss=0.027 KID= 0.02573\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 290, batch 0, d_loss=0.027 g_loss=0.069 KID= 0.03510\n",
      "epoch 290, batch 1, d_loss=-0.025 g_loss=-0.004 KID= 0.03510\n",
      "epoch 290, batch 2, d_loss=-0.008 g_loss=-0.106 KID= 0.03510\n",
      "epoch 290, batch 3, d_loss=-0.030 g_loss=-0.181 KID= 0.03510\n",
      "epoch 290, batch 4, d_loss=-0.023 g_loss=-0.309 KID= 0.03510\n",
      "epoch 290, batch 5, d_loss=-0.059 g_loss=-0.488 KID= 0.03510\n",
      "epoch 290, batch 6, d_loss=-0.077 g_loss=-0.626 KID= 0.03510\n",
      "epoch 290, batch 7, d_loss=-0.023 g_loss=-0.669 KID= 0.03510\n",
      "epoch 290, batch 8, d_loss=-0.050 g_loss=-0.725 KID= 0.03510\n",
      "epoch 290, batch 9, d_loss=-0.040 g_loss=-0.849 KID= 0.03510\n",
      "epoch 290, batch 10, d_loss=-0.054 g_loss=-0.890 KID= 0.03510\n",
      "epoch 290, batch 11, d_loss=0.085 g_loss=-0.904 KID= 0.03510\n",
      "epoch 290, batch 12, d_loss=0.036 g_loss=-0.891 KID= 0.03510\n",
      "epoch 290, batch 13, d_loss=0.027 g_loss=-0.780 KID= 0.03510\n",
      "epoch 290, batch 14, d_loss=-0.022 g_loss=-0.624 KID= 0.03510\n",
      "epoch 290, batch 15, d_loss=-0.053 g_loss=-0.524 KID= 0.03510\n",
      "epoch 290, batch 16, d_loss=-0.074 g_loss=-0.542 KID= 0.03510\n",
      "epoch 290, batch 17, d_loss=0.000 g_loss=-0.579 KID= 0.03510\n",
      "epoch 290, batch 18, d_loss=-0.063 g_loss=-0.664 KID= 0.03510\n",
      "epoch 290, batch 19, d_loss=-0.030 g_loss=-0.696 KID= 0.03510\n",
      "epoch 291, batch 0, d_loss=0.024 g_loss=-0.684 KID= 0.03510\n",
      "epoch 291, batch 1, d_loss=-0.021 g_loss=-0.656 KID= 0.03510\n",
      "epoch 291, batch 2, d_loss=-0.002 g_loss=-0.619 KID= 0.03510\n",
      "epoch 291, batch 3, d_loss=0.001 g_loss=-0.507 KID= 0.03510\n",
      "epoch 291, batch 4, d_loss=-0.000 g_loss=-0.371 KID= 0.03510\n",
      "epoch 291, batch 5, d_loss=-0.093 g_loss=-0.255 KID= 0.03510\n",
      "epoch 291, batch 6, d_loss=-0.126 g_loss=-0.129 KID= 0.03510\n",
      "epoch 291, batch 7, d_loss=-0.002 g_loss=-0.016 KID= 0.03510\n",
      "epoch 291, batch 8, d_loss=0.035 g_loss=0.048 KID= 0.03510\n",
      "epoch 291, batch 9, d_loss=-0.055 g_loss=0.019 KID= 0.03510\n",
      "epoch 291, batch 10, d_loss=-0.057 g_loss=0.037 KID= 0.03510\n",
      "epoch 291, batch 11, d_loss=0.028 g_loss=0.019 KID= 0.03510\n",
      "epoch 291, batch 12, d_loss=-0.038 g_loss=-0.039 KID= 0.03510\n",
      "epoch 291, batch 13, d_loss=-0.036 g_loss=-0.027 KID= 0.03510\n",
      "epoch 291, batch 14, d_loss=0.004 g_loss=0.011 KID= 0.03510\n",
      "epoch 291, batch 15, d_loss=-0.019 g_loss=0.046 KID= 0.03510\n",
      "epoch 291, batch 16, d_loss=0.055 g_loss=0.092 KID= 0.03510\n",
      "epoch 291, batch 17, d_loss=0.043 g_loss=0.127 KID= 0.03510\n",
      "epoch 291, batch 18, d_loss=-0.047 g_loss=0.171 KID= 0.03510\n",
      "epoch 291, batch 19, d_loss=-0.038 g_loss=0.182 KID= 0.03510\n",
      "epoch 292, batch 0, d_loss=-0.034 g_loss=0.151 KID= 0.03510\n",
      "epoch 292, batch 1, d_loss=-0.056 g_loss=0.115 KID= 0.03510\n",
      "epoch 292, batch 2, d_loss=-0.103 g_loss=0.035 KID= 0.03510\n",
      "epoch 292, batch 3, d_loss=-0.009 g_loss=-0.066 KID= 0.03510\n",
      "epoch 292, batch 4, d_loss=-0.043 g_loss=-0.068 KID= 0.03510\n",
      "epoch 292, batch 5, d_loss=0.056 g_loss=-0.123 KID= 0.03510\n",
      "epoch 292, batch 6, d_loss=-0.051 g_loss=-0.156 KID= 0.03510\n",
      "epoch 292, batch 7, d_loss=0.054 g_loss=-0.177 KID= 0.03510\n",
      "epoch 292, batch 8, d_loss=0.045 g_loss=-0.257 KID= 0.03510\n",
      "epoch 292, batch 9, d_loss=-0.011 g_loss=-0.340 KID= 0.03510\n",
      "epoch 292, batch 10, d_loss=-0.001 g_loss=-0.430 KID= 0.03510\n",
      "epoch 292, batch 11, d_loss=0.010 g_loss=-0.509 KID= 0.03510\n",
      "epoch 292, batch 12, d_loss=0.004 g_loss=-0.461 KID= 0.03510\n",
      "epoch 292, batch 13, d_loss=-0.031 g_loss=-0.365 KID= 0.03510\n",
      "epoch 292, batch 14, d_loss=-0.059 g_loss=-0.303 KID= 0.03510\n",
      "epoch 292, batch 15, d_loss=-0.132 g_loss=-0.284 KID= 0.03510\n",
      "epoch 292, batch 16, d_loss=-0.079 g_loss=-0.307 KID= 0.03510\n",
      "epoch 292, batch 17, d_loss=-0.039 g_loss=-0.274 KID= 0.03510\n",
      "epoch 292, batch 18, d_loss=-0.006 g_loss=-0.226 KID= 0.03510\n",
      "epoch 292, batch 19, d_loss=0.035 g_loss=-0.194 KID= 0.03510\n",
      "epoch 293, batch 0, d_loss=0.062 g_loss=-0.199 KID= 0.03510\n",
      "epoch 293, batch 1, d_loss=0.020 g_loss=-0.216 KID= 0.03510\n",
      "epoch 293, batch 2, d_loss=-0.032 g_loss=-0.238 KID= 0.03510\n",
      "epoch 293, batch 3, d_loss=0.017 g_loss=-0.167 KID= 0.03510\n",
      "epoch 293, batch 4, d_loss=-0.009 g_loss=-0.133 KID= 0.03510\n",
      "epoch 293, batch 5, d_loss=-0.007 g_loss=-0.080 KID= 0.03510\n",
      "epoch 293, batch 6, d_loss=0.008 g_loss=-0.073 KID= 0.03510\n",
      "epoch 293, batch 7, d_loss=-0.012 g_loss=0.040 KID= 0.03510\n",
      "epoch 293, batch 8, d_loss=-0.038 g_loss=0.125 KID= 0.03510\n",
      "epoch 293, batch 9, d_loss=-0.015 g_loss=0.166 KID= 0.03510\n",
      "epoch 293, batch 10, d_loss=-0.016 g_loss=0.171 KID= 0.03510\n",
      "epoch 293, batch 11, d_loss=-0.029 g_loss=0.099 KID= 0.03510\n",
      "epoch 293, batch 12, d_loss=0.022 g_loss=0.043 KID= 0.03510\n",
      "epoch 293, batch 13, d_loss=-0.024 g_loss=0.023 KID= 0.03510\n",
      "epoch 293, batch 14, d_loss=-0.042 g_loss=0.020 KID= 0.03510\n",
      "epoch 293, batch 15, d_loss=-0.039 g_loss=0.029 KID= 0.03510\n",
      "epoch 293, batch 16, d_loss=-0.085 g_loss=-0.001 KID= 0.03510\n",
      "epoch 293, batch 17, d_loss=0.052 g_loss=0.020 KID= 0.03510\n",
      "epoch 293, batch 18, d_loss=0.042 g_loss=0.075 KID= 0.03510\n",
      "epoch 293, batch 19, d_loss=0.002 g_loss=0.083 KID= 0.03510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 294, batch 0, d_loss=-0.049 g_loss=0.095 KID= 0.03510\n",
      "epoch 294, batch 1, d_loss=-0.010 g_loss=0.029 KID= 0.03510\n",
      "epoch 294, batch 2, d_loss=-0.051 g_loss=0.001 KID= 0.03510\n",
      "epoch 294, batch 3, d_loss=-0.075 g_loss=-0.024 KID= 0.03510\n",
      "epoch 294, batch 4, d_loss=-0.024 g_loss=-0.048 KID= 0.03510\n",
      "epoch 294, batch 5, d_loss=-0.097 g_loss=-0.108 KID= 0.03510\n",
      "epoch 294, batch 6, d_loss=-0.011 g_loss=-0.154 KID= 0.03510\n",
      "epoch 294, batch 7, d_loss=0.063 g_loss=-0.149 KID= 0.03510\n",
      "epoch 294, batch 8, d_loss=-0.021 g_loss=-0.200 KID= 0.03510\n",
      "epoch 294, batch 9, d_loss=-0.035 g_loss=-0.212 KID= 0.03510\n",
      "epoch 294, batch 10, d_loss=-0.007 g_loss=-0.218 KID= 0.03510\n",
      "epoch 294, batch 11, d_loss=-0.036 g_loss=-0.251 KID= 0.03510\n",
      "epoch 294, batch 12, d_loss=-0.010 g_loss=-0.240 KID= 0.03510\n",
      "epoch 294, batch 13, d_loss=-0.019 g_loss=-0.205 KID= 0.03510\n",
      "epoch 294, batch 14, d_loss=0.030 g_loss=-0.106 KID= 0.03510\n",
      "epoch 294, batch 15, d_loss=-0.006 g_loss=-0.083 KID= 0.03510\n",
      "epoch 294, batch 16, d_loss=-0.072 g_loss=-0.138 KID= 0.03510\n",
      "epoch 294, batch 17, d_loss=0.050 g_loss=-0.162 KID= 0.03510\n",
      "epoch 294, batch 18, d_loss=-0.016 g_loss=-0.224 KID= 0.03510\n",
      "epoch 294, batch 19, d_loss=-0.049 g_loss=-0.307 KID= 0.03510\n",
      "epoch 295, batch 0, d_loss=-0.023 g_loss=-0.323 KID= 0.03510\n",
      "epoch 295, batch 1, d_loss=-0.081 g_loss=-0.378 KID= 0.03510\n",
      "epoch 295, batch 2, d_loss=-0.061 g_loss=-0.435 KID= 0.03510\n",
      "epoch 295, batch 3, d_loss=-0.102 g_loss=-0.526 KID= 0.03510\n",
      "epoch 295, batch 4, d_loss=-0.105 g_loss=-0.574 KID= 0.03510\n",
      "epoch 295, batch 5, d_loss=-0.069 g_loss=-0.690 KID= 0.03510\n",
      "epoch 295, batch 6, d_loss=0.082 g_loss=-0.675 KID= 0.03510\n",
      "epoch 295, batch 7, d_loss=-0.014 g_loss=-0.713 KID= 0.03510\n",
      "epoch 295, batch 8, d_loss=0.053 g_loss=-0.561 KID= 0.03510\n",
      "epoch 295, batch 9, d_loss=0.082 g_loss=-0.471 KID= 0.03510\n",
      "epoch 295, batch 10, d_loss=0.015 g_loss=-0.324 KID= 0.03510\n",
      "epoch 295, batch 11, d_loss=-0.032 g_loss=-0.213 KID= 0.03510\n",
      "epoch 295, batch 12, d_loss=-0.035 g_loss=-0.094 KID= 0.03510\n",
      "epoch 295, batch 13, d_loss=-0.036 g_loss=0.069 KID= 0.03510\n",
      "epoch 295, batch 14, d_loss=-0.004 g_loss=0.182 KID= 0.03510\n",
      "epoch 295, batch 15, d_loss=-0.036 g_loss=0.323 KID= 0.03510\n",
      "epoch 295, batch 16, d_loss=-0.078 g_loss=0.400 KID= 0.03510\n",
      "epoch 295, batch 17, d_loss=0.068 g_loss=0.320 KID= 0.03510\n",
      "epoch 295, batch 18, d_loss=0.007 g_loss=0.202 KID= 0.03510\n",
      "epoch 295, batch 19, d_loss=-0.033 g_loss=0.056 KID= 0.03510\n",
      "epoch 296, batch 0, d_loss=-0.005 g_loss=-0.098 KID= 0.03510\n",
      "epoch 296, batch 1, d_loss=0.015 g_loss=-0.187 KID= 0.03510\n",
      "epoch 296, batch 2, d_loss=-0.015 g_loss=-0.263 KID= 0.03510\n",
      "epoch 296, batch 3, d_loss=-0.035 g_loss=-0.268 KID= 0.03510\n",
      "epoch 296, batch 4, d_loss=0.029 g_loss=-0.193 KID= 0.03510\n",
      "epoch 296, batch 5, d_loss=-0.026 g_loss=-0.112 KID= 0.03510\n",
      "epoch 296, batch 6, d_loss=-0.048 g_loss=-0.075 KID= 0.03510\n",
      "epoch 296, batch 7, d_loss=-0.021 g_loss=-0.015 KID= 0.03510\n",
      "epoch 296, batch 8, d_loss=-0.033 g_loss=0.002 KID= 0.03510\n",
      "epoch 296, batch 9, d_loss=-0.006 g_loss=-0.121 KID= 0.03510\n",
      "epoch 296, batch 10, d_loss=-0.005 g_loss=-0.295 KID= 0.03510\n",
      "epoch 296, batch 11, d_loss=-0.051 g_loss=-0.521 KID= 0.03510\n",
      "epoch 296, batch 12, d_loss=-0.052 g_loss=-0.737 KID= 0.03510\n",
      "epoch 296, batch 13, d_loss=0.004 g_loss=-0.893 KID= 0.03510\n",
      "epoch 296, batch 14, d_loss=-0.024 g_loss=-0.880 KID= 0.03510\n",
      "epoch 296, batch 15, d_loss=-0.047 g_loss=-0.819 KID= 0.03510\n",
      "epoch 296, batch 16, d_loss=-0.053 g_loss=-0.734 KID= 0.03510\n",
      "epoch 296, batch 17, d_loss=0.024 g_loss=-0.643 KID= 0.03510\n",
      "epoch 296, batch 18, d_loss=-0.077 g_loss=-0.537 KID= 0.03510\n",
      "epoch 296, batch 19, d_loss=-0.091 g_loss=-0.458 KID= 0.03510\n",
      "epoch 297, batch 0, d_loss=-0.043 g_loss=-0.438 KID= 0.03510\n",
      "epoch 297, batch 1, d_loss=-0.035 g_loss=-0.364 KID= 0.03510\n",
      "epoch 297, batch 2, d_loss=0.017 g_loss=-0.319 KID= 0.03510\n",
      "epoch 297, batch 3, d_loss=-0.058 g_loss=-0.276 KID= 0.03510\n",
      "epoch 297, batch 4, d_loss=-0.015 g_loss=-0.181 KID= 0.03510\n",
      "epoch 297, batch 5, d_loss=0.044 g_loss=-0.159 KID= 0.03510\n",
      "epoch 297, batch 6, d_loss=-0.012 g_loss=-0.200 KID= 0.03510\n",
      "epoch 297, batch 7, d_loss=0.072 g_loss=-0.239 KID= 0.03510\n",
      "epoch 297, batch 8, d_loss=0.024 g_loss=-0.287 KID= 0.03510\n",
      "epoch 297, batch 9, d_loss=-0.008 g_loss=-0.362 KID= 0.03510\n",
      "epoch 297, batch 10, d_loss=0.018 g_loss=-0.397 KID= 0.03510\n",
      "epoch 297, batch 11, d_loss=-0.006 g_loss=-0.393 KID= 0.03510\n",
      "epoch 297, batch 12, d_loss=-0.056 g_loss=-0.319 KID= 0.03510\n",
      "epoch 297, batch 13, d_loss=-0.057 g_loss=-0.190 KID= 0.03510\n",
      "epoch 297, batch 14, d_loss=-0.008 g_loss=-0.088 KID= 0.03510\n",
      "epoch 297, batch 15, d_loss=-0.064 g_loss=-0.001 KID= 0.03510\n",
      "epoch 297, batch 16, d_loss=-0.002 g_loss=0.043 KID= 0.03510\n",
      "epoch 297, batch 17, d_loss=0.040 g_loss=0.102 KID= 0.03510\n",
      "epoch 297, batch 18, d_loss=-0.014 g_loss=0.123 KID= 0.03510\n",
      "epoch 297, batch 19, d_loss=-0.058 g_loss=0.036 KID= 0.03510\n",
      "epoch 298, batch 0, d_loss=-0.018 g_loss=-0.113 KID= 0.03510\n",
      "epoch 298, batch 1, d_loss=-0.077 g_loss=-0.284 KID= 0.03510\n",
      "epoch 298, batch 2, d_loss=-0.060 g_loss=-0.450 KID= 0.03510\n",
      "epoch 298, batch 3, d_loss=-0.081 g_loss=-0.670 KID= 0.03510\n",
      "epoch 298, batch 4, d_loss=0.011 g_loss=-0.621 KID= 0.03510\n",
      "epoch 298, batch 5, d_loss=0.024 g_loss=-0.646 KID= 0.03510\n",
      "epoch 298, batch 6, d_loss=0.002 g_loss=-0.592 KID= 0.03510\n",
      "epoch 298, batch 7, d_loss=0.034 g_loss=-0.493 KID= 0.03510\n",
      "epoch 298, batch 8, d_loss=0.044 g_loss=-0.396 KID= 0.03510\n",
      "epoch 298, batch 9, d_loss=0.041 g_loss=-0.275 KID= 0.03510\n",
      "epoch 298, batch 10, d_loss=0.030 g_loss=-0.267 KID= 0.03510\n",
      "epoch 298, batch 11, d_loss=0.017 g_loss=-0.287 KID= 0.03510\n",
      "epoch 298, batch 12, d_loss=-0.050 g_loss=-0.265 KID= 0.03510\n",
      "epoch 298, batch 13, d_loss=-0.076 g_loss=-0.289 KID= 0.03510\n",
      "epoch 298, batch 14, d_loss=-0.055 g_loss=-0.355 KID= 0.03510\n",
      "epoch 298, batch 15, d_loss=-0.117 g_loss=-0.457 KID= 0.03510\n",
      "epoch 298, batch 16, d_loss=-0.098 g_loss=-0.608 KID= 0.03510\n",
      "epoch 298, batch 17, d_loss=0.086 g_loss=-0.606 KID= 0.03510\n",
      "epoch 298, batch 18, d_loss=0.049 g_loss=-0.593 KID= 0.03510\n",
      "epoch 298, batch 19, d_loss=0.012 g_loss=-0.552 KID= 0.03510\n",
      "epoch 299, batch 0, d_loss=0.065 g_loss=-0.526 KID= 0.03510\n",
      "epoch 299, batch 1, d_loss=-0.140 g_loss=-0.557 KID= 0.03510\n",
      "epoch 299, batch 2, d_loss=-0.024 g_loss=-0.541 KID= 0.03510\n",
      "epoch 299, batch 3, d_loss=-0.058 g_loss=-0.551 KID= 0.03510\n",
      "epoch 299, batch 4, d_loss=-0.016 g_loss=-0.315 KID= 0.03510\n",
      "epoch 299, batch 5, d_loss=-0.047 g_loss=-0.115 KID= 0.03510\n",
      "epoch 299, batch 6, d_loss=-0.033 g_loss=0.105 KID= 0.03510\n",
      "epoch 299, batch 7, d_loss=0.009 g_loss=0.242 KID= 0.03510\n",
      "epoch 299, batch 8, d_loss=0.032 g_loss=0.306 KID= 0.03510\n",
      "epoch 299, batch 9, d_loss=0.018 g_loss=0.389 KID= 0.03510\n",
      "epoch 299, batch 10, d_loss=-0.021 g_loss=0.329 KID= 0.03510\n",
      "epoch 299, batch 11, d_loss=-0.002 g_loss=0.267 KID= 0.03510\n",
      "epoch 299, batch 12, d_loss=-0.024 g_loss=0.316 KID= 0.03510\n",
      "epoch 299, batch 13, d_loss=-0.041 g_loss=0.364 KID= 0.03510\n",
      "epoch 299, batch 14, d_loss=0.028 g_loss=0.433 KID= 0.03510\n",
      "epoch 299, batch 15, d_loss=-0.081 g_loss=0.515 KID= 0.03510\n",
      "epoch 299, batch 16, d_loss=-0.101 g_loss=0.557 KID= 0.03510\n",
      "epoch 299, batch 17, d_loss=0.001 g_loss=0.536 KID= 0.03510\n",
      "epoch 299, batch 18, d_loss=-0.002 g_loss=0.404 KID= 0.03510\n",
      "epoch 299, batch 19, d_loss=-0.011 g_loss=0.156 KID= 0.03510\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 300, batch 0, d_loss=0.011 g_loss=-0.214 KID= 0.04520\n",
      "epoch 300, batch 1, d_loss=-0.106 g_loss=-0.525 KID= 0.04520\n",
      "epoch 300, batch 2, d_loss=-0.061 g_loss=-0.733 KID= 0.04520\n",
      "epoch 300, batch 3, d_loss=-0.050 g_loss=-0.905 KID= 0.04520\n",
      "epoch 300, batch 4, d_loss=-0.092 g_loss=-0.908 KID= 0.04520\n",
      "epoch 300, batch 5, d_loss=-0.029 g_loss=-0.931 KID= 0.04520\n",
      "epoch 300, batch 6, d_loss=-0.025 g_loss=-0.999 KID= 0.04520\n",
      "epoch 300, batch 7, d_loss=0.024 g_loss=-0.971 KID= 0.04520\n",
      "epoch 300, batch 8, d_loss=0.011 g_loss=-0.949 KID= 0.04520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 300, batch 9, d_loss=0.024 g_loss=-0.886 KID= 0.04520\n",
      "epoch 300, batch 10, d_loss=0.008 g_loss=-0.824 KID= 0.04520\n",
      "epoch 300, batch 11, d_loss=-0.036 g_loss=-0.797 KID= 0.04520\n",
      "epoch 300, batch 12, d_loss=-0.051 g_loss=-0.679 KID= 0.04520\n",
      "epoch 300, batch 13, d_loss=-0.069 g_loss=-0.481 KID= 0.04520\n",
      "epoch 300, batch 14, d_loss=0.052 g_loss=-0.115 KID= 0.04520\n",
      "epoch 300, batch 15, d_loss=-0.056 g_loss=0.085 KID= 0.04520\n",
      "epoch 300, batch 16, d_loss=-0.072 g_loss=0.169 KID= 0.04520\n",
      "epoch 300, batch 17, d_loss=-0.001 g_loss=0.323 KID= 0.04520\n",
      "epoch 300, batch 18, d_loss=-0.020 g_loss=0.460 KID= 0.04520\n",
      "epoch 300, batch 19, d_loss=0.021 g_loss=0.466 KID= 0.04520\n",
      "epoch 301, batch 0, d_loss=0.050 g_loss=0.449 KID= 0.04520\n",
      "epoch 301, batch 1, d_loss=-0.019 g_loss=0.450 KID= 0.04520\n",
      "epoch 301, batch 2, d_loss=-0.003 g_loss=0.409 KID= 0.04520\n",
      "epoch 301, batch 3, d_loss=-0.044 g_loss=0.356 KID= 0.04520\n",
      "epoch 301, batch 4, d_loss=-0.071 g_loss=0.397 KID= 0.04520\n",
      "epoch 301, batch 5, d_loss=-0.055 g_loss=0.359 KID= 0.04520\n",
      "epoch 301, batch 6, d_loss=0.028 g_loss=0.213 KID= 0.04520\n",
      "epoch 301, batch 7, d_loss=-0.015 g_loss=0.143 KID= 0.04520\n",
      "epoch 301, batch 8, d_loss=0.048 g_loss=0.046 KID= 0.04520\n",
      "epoch 301, batch 9, d_loss=0.038 g_loss=-0.089 KID= 0.04520\n",
      "epoch 301, batch 10, d_loss=0.070 g_loss=-0.194 KID= 0.04520\n",
      "epoch 301, batch 11, d_loss=-0.073 g_loss=-0.312 KID= 0.04520\n",
      "epoch 301, batch 12, d_loss=-0.001 g_loss=-0.316 KID= 0.04520\n",
      "epoch 301, batch 13, d_loss=-0.050 g_loss=-0.349 KID= 0.04520\n",
      "epoch 301, batch 14, d_loss=-0.028 g_loss=-0.312 KID= 0.04520\n",
      "epoch 301, batch 15, d_loss=-0.099 g_loss=-0.275 KID= 0.04520\n",
      "epoch 301, batch 16, d_loss=-0.111 g_loss=-0.291 KID= 0.04520\n",
      "epoch 301, batch 17, d_loss=-0.008 g_loss=-0.275 KID= 0.04520\n",
      "epoch 301, batch 18, d_loss=-0.042 g_loss=-0.289 KID= 0.04520\n",
      "epoch 301, batch 19, d_loss=-0.063 g_loss=-0.353 KID= 0.04520\n",
      "epoch 302, batch 0, d_loss=-0.027 g_loss=-0.430 KID= 0.04520\n",
      "epoch 302, batch 1, d_loss=-0.020 g_loss=-0.475 KID= 0.04520\n",
      "epoch 302, batch 2, d_loss=-0.024 g_loss=-0.459 KID= 0.04520\n",
      "epoch 302, batch 3, d_loss=-0.045 g_loss=-0.448 KID= 0.04520\n",
      "epoch 302, batch 4, d_loss=0.032 g_loss=-0.304 KID= 0.04520\n",
      "epoch 302, batch 5, d_loss=-0.015 g_loss=-0.276 KID= 0.04520\n",
      "epoch 302, batch 6, d_loss=-0.076 g_loss=-0.236 KID= 0.04520\n",
      "epoch 302, batch 7, d_loss=-0.019 g_loss=-0.085 KID= 0.04520\n",
      "epoch 302, batch 8, d_loss=-0.009 g_loss=0.015 KID= 0.04520\n",
      "epoch 302, batch 9, d_loss=-0.015 g_loss=-0.039 KID= 0.04520\n",
      "epoch 302, batch 10, d_loss=0.010 g_loss=-0.144 KID= 0.04520\n",
      "epoch 302, batch 11, d_loss=-0.047 g_loss=-0.189 KID= 0.04520\n",
      "epoch 302, batch 12, d_loss=-0.019 g_loss=-0.230 KID= 0.04520\n",
      "epoch 302, batch 13, d_loss=-0.024 g_loss=-0.301 KID= 0.04520\n",
      "epoch 302, batch 14, d_loss=-0.040 g_loss=-0.300 KID= 0.04520\n",
      "epoch 302, batch 15, d_loss=-0.071 g_loss=-0.318 KID= 0.04520\n",
      "epoch 302, batch 16, d_loss=-0.061 g_loss=-0.348 KID= 0.04520\n",
      "epoch 302, batch 17, d_loss=-0.014 g_loss=-0.347 KID= 0.04520\n",
      "epoch 302, batch 18, d_loss=0.005 g_loss=-0.275 KID= 0.04520\n",
      "epoch 302, batch 19, d_loss=-0.064 g_loss=-0.281 KID= 0.04520\n",
      "epoch 303, batch 0, d_loss=0.062 g_loss=-0.302 KID= 0.04520\n",
      "epoch 303, batch 1, d_loss=-0.100 g_loss=-0.358 KID= 0.04520\n",
      "epoch 303, batch 2, d_loss=0.018 g_loss=-0.378 KID= 0.04520\n",
      "epoch 303, batch 3, d_loss=-0.027 g_loss=-0.430 KID= 0.04520\n",
      "epoch 303, batch 4, d_loss=0.054 g_loss=-0.414 KID= 0.04520\n",
      "epoch 303, batch 5, d_loss=0.019 g_loss=-0.435 KID= 0.04520\n",
      "epoch 303, batch 6, d_loss=0.011 g_loss=-0.451 KID= 0.04520\n",
      "epoch 303, batch 7, d_loss=0.012 g_loss=-0.403 KID= 0.04520\n",
      "epoch 303, batch 8, d_loss=-0.013 g_loss=-0.326 KID= 0.04520\n",
      "epoch 303, batch 9, d_loss=-0.063 g_loss=-0.334 KID= 0.04520\n",
      "epoch 303, batch 10, d_loss=-0.058 g_loss=-0.369 KID= 0.04520\n",
      "epoch 303, batch 11, d_loss=-0.043 g_loss=-0.372 KID= 0.04520\n",
      "epoch 303, batch 12, d_loss=-0.057 g_loss=-0.336 KID= 0.04520\n",
      "epoch 303, batch 13, d_loss=-0.053 g_loss=-0.302 KID= 0.04520\n",
      "epoch 303, batch 14, d_loss=0.003 g_loss=-0.258 KID= 0.04520\n",
      "epoch 303, batch 15, d_loss=-0.047 g_loss=-0.262 KID= 0.04520\n",
      "epoch 303, batch 16, d_loss=-0.030 g_loss=-0.284 KID= 0.04520\n",
      "epoch 303, batch 17, d_loss=-0.034 g_loss=-0.291 KID= 0.04520\n",
      "epoch 303, batch 18, d_loss=-0.074 g_loss=-0.282 KID= 0.04520\n",
      "epoch 303, batch 19, d_loss=0.051 g_loss=-0.281 KID= 0.04520\n",
      "epoch 304, batch 0, d_loss=0.017 g_loss=-0.323 KID= 0.04520\n",
      "epoch 304, batch 1, d_loss=-0.091 g_loss=-0.408 KID= 0.04520\n",
      "epoch 304, batch 2, d_loss=-0.046 g_loss=-0.526 KID= 0.04520\n",
      "epoch 304, batch 3, d_loss=-0.032 g_loss=-0.610 KID= 0.04520\n",
      "epoch 304, batch 4, d_loss=-0.106 g_loss=-0.746 KID= 0.04520\n",
      "epoch 304, batch 5, d_loss=-0.052 g_loss=-0.726 KID= 0.04520\n",
      "epoch 304, batch 6, d_loss=-0.001 g_loss=-0.610 KID= 0.04520\n",
      "epoch 304, batch 7, d_loss=0.038 g_loss=-0.351 KID= 0.04520\n",
      "epoch 304, batch 8, d_loss=0.008 g_loss=-0.103 KID= 0.04520\n",
      "epoch 304, batch 9, d_loss=-0.074 g_loss=-0.010 KID= 0.04520\n",
      "epoch 304, batch 10, d_loss=0.055 g_loss=0.048 KID= 0.04520\n",
      "epoch 304, batch 11, d_loss=0.019 g_loss=0.037 KID= 0.04520\n",
      "epoch 304, batch 12, d_loss=0.038 g_loss=0.126 KID= 0.04520\n",
      "epoch 304, batch 13, d_loss=0.011 g_loss=0.193 KID= 0.04520\n",
      "epoch 304, batch 14, d_loss=0.060 g_loss=0.325 KID= 0.04520\n",
      "epoch 304, batch 15, d_loss=-0.041 g_loss=0.427 KID= 0.04520\n",
      "epoch 304, batch 16, d_loss=-0.066 g_loss=0.547 KID= 0.04520\n",
      "epoch 304, batch 17, d_loss=0.002 g_loss=0.696 KID= 0.04520\n",
      "epoch 304, batch 18, d_loss=-0.016 g_loss=0.866 KID= 0.04520\n",
      "epoch 304, batch 19, d_loss=0.012 g_loss=0.763 KID= 0.04520\n",
      "epoch 305, batch 0, d_loss=0.004 g_loss=0.643 KID= 0.04520\n",
      "epoch 305, batch 1, d_loss=-0.130 g_loss=0.528 KID= 0.04520\n",
      "epoch 305, batch 2, d_loss=-0.025 g_loss=0.405 KID= 0.04520\n",
      "epoch 305, batch 3, d_loss=-0.021 g_loss=0.266 KID= 0.04520\n",
      "epoch 305, batch 4, d_loss=-0.053 g_loss=0.193 KID= 0.04520\n",
      "epoch 305, batch 5, d_loss=-0.009 g_loss=0.086 KID= 0.04520\n",
      "epoch 305, batch 6, d_loss=-0.018 g_loss=-0.071 KID= 0.04520\n",
      "epoch 305, batch 7, d_loss=-0.044 g_loss=-0.163 KID= 0.04520\n",
      "epoch 305, batch 8, d_loss=-0.006 g_loss=-0.247 KID= 0.04520\n",
      "epoch 305, batch 9, d_loss=-0.024 g_loss=-0.401 KID= 0.04520\n",
      "epoch 305, batch 10, d_loss=0.001 g_loss=-0.575 KID= 0.04520\n",
      "epoch 305, batch 11, d_loss=-0.058 g_loss=-0.781 KID= 0.04520\n",
      "epoch 305, batch 12, d_loss=-0.103 g_loss=-1.019 KID= 0.04520\n",
      "epoch 305, batch 13, d_loss=-0.062 g_loss=-1.136 KID= 0.04520\n",
      "epoch 305, batch 14, d_loss=0.062 g_loss=-1.167 KID= 0.04520\n",
      "epoch 305, batch 15, d_loss=-0.031 g_loss=-1.013 KID= 0.04520\n",
      "epoch 305, batch 16, d_loss=-0.107 g_loss=-0.872 KID= 0.04520\n",
      "epoch 305, batch 17, d_loss=0.069 g_loss=-0.609 KID= 0.04520\n",
      "epoch 305, batch 18, d_loss=-0.057 g_loss=-0.407 KID= 0.04520\n",
      "epoch 305, batch 19, d_loss=-0.074 g_loss=-0.281 KID= 0.04520\n",
      "epoch 306, batch 0, d_loss=-0.018 g_loss=-0.219 KID= 0.04520\n",
      "epoch 306, batch 1, d_loss=-0.088 g_loss=-0.137 KID= 0.04520\n",
      "epoch 306, batch 2, d_loss=-0.043 g_loss=-0.070 KID= 0.04520\n",
      "epoch 306, batch 3, d_loss=-0.046 g_loss=-0.006 KID= 0.04520\n",
      "epoch 306, batch 4, d_loss=-0.054 g_loss=0.095 KID= 0.04520\n",
      "epoch 306, batch 5, d_loss=-0.079 g_loss=0.168 KID= 0.04520\n",
      "epoch 306, batch 6, d_loss=0.025 g_loss=0.192 KID= 0.04520\n",
      "epoch 306, batch 7, d_loss=-0.026 g_loss=0.246 KID= 0.04520\n",
      "epoch 306, batch 8, d_loss=-0.026 g_loss=0.286 KID= 0.04520\n",
      "epoch 306, batch 9, d_loss=0.026 g_loss=0.245 KID= 0.04520\n",
      "epoch 306, batch 10, d_loss=0.090 g_loss=0.207 KID= 0.04520\n",
      "epoch 306, batch 11, d_loss=0.001 g_loss=0.175 KID= 0.04520\n",
      "epoch 306, batch 12, d_loss=-0.047 g_loss=0.151 KID= 0.04520\n",
      "epoch 306, batch 13, d_loss=-0.064 g_loss=0.172 KID= 0.04520\n",
      "epoch 306, batch 14, d_loss=-0.041 g_loss=0.150 KID= 0.04520\n",
      "epoch 306, batch 15, d_loss=-0.093 g_loss=0.151 KID= 0.04520\n",
      "epoch 306, batch 16, d_loss=-0.190 g_loss=0.129 KID= 0.04520\n",
      "epoch 306, batch 17, d_loss=-0.017 g_loss=0.136 KID= 0.04520\n",
      "epoch 306, batch 18, d_loss=0.009 g_loss=0.069 KID= 0.04520\n",
      "epoch 306, batch 19, d_loss=-0.032 g_loss=-0.054 KID= 0.04520\n",
      "epoch 307, batch 0, d_loss=0.020 g_loss=-0.176 KID= 0.04520\n",
      "epoch 307, batch 1, d_loss=0.058 g_loss=-0.347 KID= 0.04520\n",
      "epoch 307, batch 2, d_loss=-0.006 g_loss=-0.440 KID= 0.04520\n",
      "epoch 307, batch 3, d_loss=-0.073 g_loss=-0.513 KID= 0.04520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 307, batch 4, d_loss=-0.060 g_loss=-0.598 KID= 0.04520\n",
      "epoch 307, batch 5, d_loss=-0.101 g_loss=-0.784 KID= 0.04520\n",
      "epoch 307, batch 6, d_loss=-0.052 g_loss=-0.926 KID= 0.04520\n",
      "epoch 307, batch 7, d_loss=0.044 g_loss=-0.965 KID= 0.04520\n",
      "epoch 307, batch 8, d_loss=-0.053 g_loss=-0.952 KID= 0.04520\n",
      "epoch 307, batch 9, d_loss=0.055 g_loss=-0.826 KID= 0.04520\n",
      "epoch 307, batch 10, d_loss=0.082 g_loss=-0.729 KID= 0.04520\n",
      "epoch 307, batch 11, d_loss=-0.099 g_loss=-0.714 KID= 0.04520\n",
      "epoch 307, batch 12, d_loss=-0.006 g_loss=-0.644 KID= 0.04520\n",
      "epoch 307, batch 13, d_loss=0.014 g_loss=-0.538 KID= 0.04520\n",
      "epoch 307, batch 14, d_loss=-0.057 g_loss=-0.402 KID= 0.04520\n",
      "epoch 307, batch 15, d_loss=-0.087 g_loss=-0.326 KID= 0.04520\n",
      "epoch 307, batch 16, d_loss=-0.115 g_loss=-0.242 KID= 0.04520\n",
      "epoch 307, batch 17, d_loss=-0.025 g_loss=-0.184 KID= 0.04520\n",
      "epoch 307, batch 18, d_loss=-0.022 g_loss=-0.107 KID= 0.04520\n",
      "epoch 307, batch 19, d_loss=-0.094 g_loss=-0.122 KID= 0.04520\n",
      "epoch 308, batch 0, d_loss=0.028 g_loss=-0.125 KID= 0.04520\n",
      "epoch 308, batch 1, d_loss=-0.037 g_loss=-0.191 KID= 0.04520\n",
      "epoch 308, batch 2, d_loss=0.012 g_loss=-0.284 KID= 0.04520\n",
      "epoch 308, batch 3, d_loss=-0.023 g_loss=-0.352 KID= 0.04520\n",
      "epoch 308, batch 4, d_loss=0.023 g_loss=-0.418 KID= 0.04520\n",
      "epoch 308, batch 5, d_loss=-0.014 g_loss=-0.426 KID= 0.04520\n",
      "epoch 308, batch 6, d_loss=-0.074 g_loss=-0.373 KID= 0.04520\n",
      "epoch 308, batch 7, d_loss=-0.023 g_loss=-0.231 KID= 0.04520\n",
      "epoch 308, batch 8, d_loss=-0.006 g_loss=-0.156 KID= 0.04520\n",
      "epoch 308, batch 9, d_loss=0.002 g_loss=-0.102 KID= 0.04520\n",
      "epoch 308, batch 10, d_loss=-0.053 g_loss=-0.037 KID= 0.04520\n",
      "epoch 308, batch 11, d_loss=0.003 g_loss=-0.045 KID= 0.04520\n",
      "epoch 308, batch 12, d_loss=-0.041 g_loss=-0.078 KID= 0.04520\n",
      "epoch 308, batch 13, d_loss=-0.052 g_loss=-0.141 KID= 0.04520\n",
      "epoch 308, batch 14, d_loss=0.024 g_loss=-0.212 KID= 0.04520\n",
      "epoch 308, batch 15, d_loss=-0.026 g_loss=-0.336 KID= 0.04520\n",
      "epoch 308, batch 16, d_loss=-0.071 g_loss=-0.473 KID= 0.04520\n",
      "epoch 308, batch 17, d_loss=-0.025 g_loss=-0.601 KID= 0.04520\n",
      "epoch 308, batch 18, d_loss=-0.096 g_loss=-0.836 KID= 0.04520\n",
      "epoch 308, batch 19, d_loss=-0.051 g_loss=-1.004 KID= 0.04520\n",
      "epoch 309, batch 0, d_loss=0.193 g_loss=-0.938 KID= 0.04520\n",
      "epoch 309, batch 1, d_loss=-0.053 g_loss=-0.997 KID= 0.04520\n",
      "epoch 309, batch 2, d_loss=0.058 g_loss=-0.974 KID= 0.04520\n",
      "epoch 309, batch 3, d_loss=-0.011 g_loss=-0.954 KID= 0.04520\n",
      "epoch 309, batch 4, d_loss=-0.060 g_loss=-0.997 KID= 0.04520\n",
      "epoch 309, batch 5, d_loss=-0.080 g_loss=-1.053 KID= 0.04520\n",
      "epoch 309, batch 6, d_loss=-0.008 g_loss=-0.945 KID= 0.04520\n",
      "epoch 309, batch 7, d_loss=0.031 g_loss=-0.691 KID= 0.04520\n",
      "epoch 309, batch 8, d_loss=-0.039 g_loss=-0.465 KID= 0.04520\n",
      "epoch 309, batch 9, d_loss=-0.091 g_loss=-0.269 KID= 0.04520\n",
      "epoch 309, batch 10, d_loss=-0.007 g_loss=-0.184 KID= 0.04520\n",
      "epoch 309, batch 11, d_loss=-0.120 g_loss=-0.165 KID= 0.04520\n",
      "epoch 309, batch 12, d_loss=-0.022 g_loss=-0.198 KID= 0.04520\n",
      "epoch 309, batch 13, d_loss=-0.017 g_loss=-0.155 KID= 0.04520\n",
      "epoch 309, batch 14, d_loss=0.020 g_loss=-0.079 KID= 0.04520\n",
      "epoch 309, batch 15, d_loss=-0.047 g_loss=-0.020 KID= 0.04520\n",
      "epoch 309, batch 16, d_loss=-0.074 g_loss=-0.012 KID= 0.04520\n",
      "epoch 309, batch 17, d_loss=-0.056 g_loss=-0.016 KID= 0.04520\n",
      "epoch 309, batch 18, d_loss=-0.036 g_loss=-0.033 KID= 0.04520\n",
      "epoch 309, batch 19, d_loss=-0.015 g_loss=-0.072 KID= 0.04520\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 310, batch 0, d_loss=0.009 g_loss=-0.096 KID= 0.02858\n",
      "epoch 310, batch 1, d_loss=-0.058 g_loss=-0.090 KID= 0.02858\n",
      "epoch 310, batch 2, d_loss=0.004 g_loss=-0.132 KID= 0.02858\n",
      "epoch 310, batch 3, d_loss=-0.019 g_loss=-0.095 KID= 0.02858\n",
      "epoch 310, batch 4, d_loss=-0.058 g_loss=-0.044 KID= 0.02858\n",
      "epoch 310, batch 5, d_loss=-0.049 g_loss=-0.031 KID= 0.02858\n",
      "epoch 310, batch 6, d_loss=-0.064 g_loss=0.080 KID= 0.02858\n",
      "epoch 310, batch 7, d_loss=-0.033 g_loss=0.125 KID= 0.02858\n",
      "epoch 310, batch 8, d_loss=-0.081 g_loss=0.096 KID= 0.02858\n",
      "epoch 310, batch 9, d_loss=-0.051 g_loss=0.137 KID= 0.02858\n",
      "epoch 310, batch 10, d_loss=0.019 g_loss=0.174 KID= 0.02858\n",
      "epoch 310, batch 11, d_loss=0.024 g_loss=0.147 KID= 0.02858\n",
      "epoch 310, batch 12, d_loss=-0.004 g_loss=0.173 KID= 0.02858\n",
      "epoch 310, batch 13, d_loss=-0.007 g_loss=0.186 KID= 0.02858\n",
      "epoch 310, batch 14, d_loss=-0.012 g_loss=0.239 KID= 0.02858\n",
      "epoch 310, batch 15, d_loss=-0.055 g_loss=0.218 KID= 0.02858\n",
      "epoch 310, batch 16, d_loss=-0.054 g_loss=0.200 KID= 0.02858\n",
      "epoch 310, batch 17, d_loss=0.016 g_loss=0.131 KID= 0.02858\n",
      "epoch 310, batch 18, d_loss=-0.029 g_loss=-0.025 KID= 0.02858\n",
      "epoch 310, batch 19, d_loss=0.006 g_loss=-0.129 KID= 0.02858\n",
      "epoch 311, batch 0, d_loss=0.058 g_loss=-0.223 KID= 0.02858\n",
      "epoch 311, batch 1, d_loss=-0.116 g_loss=-0.318 KID= 0.02858\n",
      "epoch 311, batch 2, d_loss=-0.008 g_loss=-0.408 KID= 0.02858\n",
      "epoch 311, batch 3, d_loss=-0.008 g_loss=-0.491 KID= 0.02858\n",
      "epoch 311, batch 4, d_loss=-0.085 g_loss=-0.536 KID= 0.02858\n",
      "epoch 311, batch 5, d_loss=-0.130 g_loss=-0.584 KID= 0.02858\n",
      "epoch 311, batch 6, d_loss=-0.047 g_loss=-0.649 KID= 0.02858\n",
      "epoch 311, batch 7, d_loss=0.028 g_loss=-0.703 KID= 0.02858\n",
      "epoch 311, batch 8, d_loss=0.005 g_loss=-0.801 KID= 0.02858\n",
      "epoch 311, batch 9, d_loss=-0.008 g_loss=-0.808 KID= 0.02858\n",
      "epoch 311, batch 10, d_loss=0.003 g_loss=-0.793 KID= 0.02858\n",
      "epoch 311, batch 11, d_loss=-0.035 g_loss=-0.800 KID= 0.02858\n",
      "epoch 311, batch 12, d_loss=-0.044 g_loss=-0.737 KID= 0.02858\n",
      "epoch 311, batch 13, d_loss=-0.047 g_loss=-0.826 KID= 0.02858\n",
      "epoch 311, batch 14, d_loss=0.005 g_loss=-0.796 KID= 0.02858\n",
      "epoch 311, batch 15, d_loss=-0.018 g_loss=-0.851 KID= 0.02858\n",
      "epoch 311, batch 16, d_loss=-0.033 g_loss=-0.801 KID= 0.02858\n",
      "epoch 311, batch 17, d_loss=0.100 g_loss=-0.510 KID= 0.02858\n",
      "epoch 311, batch 18, d_loss=-0.023 g_loss=-0.370 KID= 0.02858\n",
      "epoch 311, batch 19, d_loss=-0.038 g_loss=-0.310 KID= 0.02858\n",
      "epoch 312, batch 0, d_loss=-0.003 g_loss=-0.275 KID= 0.02858\n",
      "epoch 312, batch 1, d_loss=-0.006 g_loss=-0.288 KID= 0.02858\n",
      "epoch 312, batch 2, d_loss=-0.032 g_loss=-0.314 KID= 0.02858\n",
      "epoch 312, batch 3, d_loss=-0.059 g_loss=-0.307 KID= 0.02858\n",
      "epoch 312, batch 4, d_loss=-0.024 g_loss=-0.281 KID= 0.02858\n",
      "epoch 312, batch 5, d_loss=-0.031 g_loss=-0.233 KID= 0.02858\n",
      "epoch 312, batch 6, d_loss=-0.053 g_loss=-0.249 KID= 0.02858\n",
      "epoch 312, batch 7, d_loss=-0.053 g_loss=-0.221 KID= 0.02858\n",
      "epoch 312, batch 8, d_loss=-0.039 g_loss=-0.222 KID= 0.02858\n",
      "epoch 312, batch 9, d_loss=-0.012 g_loss=-0.219 KID= 0.02858\n",
      "epoch 312, batch 10, d_loss=0.047 g_loss=-0.246 KID= 0.02858\n",
      "epoch 312, batch 11, d_loss=-0.038 g_loss=-0.293 KID= 0.02858\n",
      "epoch 312, batch 12, d_loss=0.020 g_loss=-0.290 KID= 0.02858\n",
      "epoch 312, batch 13, d_loss=0.005 g_loss=-0.321 KID= 0.02858\n",
      "epoch 312, batch 14, d_loss=-0.050 g_loss=-0.302 KID= 0.02858\n",
      "epoch 312, batch 15, d_loss=-0.099 g_loss=-0.297 KID= 0.02858\n",
      "epoch 312, batch 16, d_loss=-0.142 g_loss=-0.335 KID= 0.02858\n",
      "epoch 312, batch 17, d_loss=0.001 g_loss=-0.300 KID= 0.02858\n",
      "epoch 312, batch 18, d_loss=-0.055 g_loss=-0.339 KID= 0.02858\n",
      "epoch 312, batch 19, d_loss=0.012 g_loss=-0.389 KID= 0.02858\n",
      "epoch 313, batch 0, d_loss=-0.019 g_loss=-0.456 KID= 0.02858\n",
      "epoch 313, batch 1, d_loss=0.011 g_loss=-0.497 KID= 0.02858\n",
      "epoch 313, batch 2, d_loss=-0.029 g_loss=-0.468 KID= 0.02858\n",
      "epoch 313, batch 3, d_loss=-0.056 g_loss=-0.455 KID= 0.02858\n",
      "epoch 313, batch 4, d_loss=-0.050 g_loss=-0.371 KID= 0.02858\n",
      "epoch 313, batch 5, d_loss=-0.123 g_loss=-0.330 KID= 0.02858\n",
      "epoch 313, batch 6, d_loss=-0.077 g_loss=-0.357 KID= 0.02858\n",
      "epoch 313, batch 7, d_loss=-0.060 g_loss=-0.428 KID= 0.02858\n",
      "epoch 313, batch 8, d_loss=-0.043 g_loss=-0.517 KID= 0.02858\n",
      "epoch 313, batch 9, d_loss=-0.028 g_loss=-0.584 KID= 0.02858\n",
      "epoch 313, batch 10, d_loss=0.097 g_loss=-0.645 KID= 0.02858\n",
      "epoch 313, batch 11, d_loss=-0.066 g_loss=-0.710 KID= 0.02858\n",
      "epoch 313, batch 12, d_loss=0.029 g_loss=-0.621 KID= 0.02858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 313, batch 13, d_loss=0.049 g_loss=-0.569 KID= 0.02858\n",
      "epoch 313, batch 14, d_loss=-0.044 g_loss=-0.466 KID= 0.02858\n",
      "epoch 313, batch 15, d_loss=-0.028 g_loss=-0.355 KID= 0.02858\n",
      "epoch 313, batch 16, d_loss=-0.086 g_loss=-0.325 KID= 0.02858\n",
      "epoch 313, batch 17, d_loss=-0.031 g_loss=-0.263 KID= 0.02858\n",
      "epoch 313, batch 18, d_loss=0.004 g_loss=-0.249 KID= 0.02858\n",
      "epoch 313, batch 19, d_loss=-0.025 g_loss=-0.291 KID= 0.02858\n",
      "epoch 314, batch 0, d_loss=-0.063 g_loss=-0.381 KID= 0.02858\n",
      "epoch 314, batch 1, d_loss=-0.018 g_loss=-0.400 KID= 0.02858\n",
      "epoch 314, batch 2, d_loss=-0.051 g_loss=-0.381 KID= 0.02858\n",
      "epoch 314, batch 3, d_loss=-0.096 g_loss=-0.323 KID= 0.02858\n",
      "epoch 314, batch 4, d_loss=-0.029 g_loss=-0.200 KID= 0.02858\n",
      "epoch 314, batch 5, d_loss=-0.091 g_loss=-0.096 KID= 0.02858\n",
      "epoch 314, batch 6, d_loss=-0.081 g_loss=-0.065 KID= 0.02858\n",
      "epoch 314, batch 7, d_loss=-0.047 g_loss=-0.029 KID= 0.02858\n",
      "epoch 314, batch 8, d_loss=-0.104 g_loss=-0.077 KID= 0.02858\n",
      "epoch 314, batch 9, d_loss=-0.022 g_loss=-0.215 KID= 0.02858\n",
      "epoch 314, batch 10, d_loss=0.063 g_loss=-0.304 KID= 0.02858\n",
      "epoch 314, batch 11, d_loss=-0.089 g_loss=-0.395 KID= 0.02858\n",
      "epoch 314, batch 12, d_loss=0.036 g_loss=-0.453 KID= 0.02858\n",
      "epoch 314, batch 13, d_loss=0.049 g_loss=-0.518 KID= 0.02858\n",
      "epoch 314, batch 14, d_loss=-0.044 g_loss=-0.443 KID= 0.02858\n",
      "epoch 314, batch 15, d_loss=-0.068 g_loss=-0.323 KID= 0.02858\n",
      "epoch 314, batch 16, d_loss=-0.101 g_loss=-0.243 KID= 0.02858\n",
      "epoch 314, batch 17, d_loss=-0.067 g_loss=-0.129 KID= 0.02858\n",
      "epoch 314, batch 18, d_loss=-0.002 g_loss=-0.065 KID= 0.02858\n",
      "epoch 314, batch 19, d_loss=-0.035 g_loss=-0.122 KID= 0.02858\n",
      "epoch 315, batch 0, d_loss=-0.025 g_loss=-0.205 KID= 0.02858\n",
      "epoch 315, batch 1, d_loss=-0.022 g_loss=-0.336 KID= 0.02858\n",
      "epoch 315, batch 2, d_loss=-0.054 g_loss=-0.431 KID= 0.02858\n",
      "epoch 315, batch 3, d_loss=-0.079 g_loss=-0.413 KID= 0.02858\n",
      "epoch 315, batch 4, d_loss=-0.044 g_loss=-0.362 KID= 0.02858\n",
      "epoch 315, batch 5, d_loss=-0.080 g_loss=-0.270 KID= 0.02858\n",
      "epoch 315, batch 6, d_loss=-0.135 g_loss=-0.123 KID= 0.02858\n",
      "epoch 315, batch 7, d_loss=0.016 g_loss=0.005 KID= 0.02858\n",
      "epoch 315, batch 8, d_loss=0.002 g_loss=0.025 KID= 0.02858\n",
      "epoch 315, batch 9, d_loss=-0.082 g_loss=-0.032 KID= 0.02858\n",
      "epoch 315, batch 10, d_loss=0.030 g_loss=-0.092 KID= 0.02858\n",
      "epoch 315, batch 11, d_loss=0.012 g_loss=-0.222 KID= 0.02858\n",
      "epoch 315, batch 12, d_loss=0.016 g_loss=-0.344 KID= 0.02858\n",
      "epoch 315, batch 13, d_loss=-0.012 g_loss=-0.300 KID= 0.02858\n",
      "epoch 315, batch 14, d_loss=-0.034 g_loss=-0.200 KID= 0.02858\n",
      "epoch 315, batch 15, d_loss=-0.062 g_loss=-0.132 KID= 0.02858\n",
      "epoch 315, batch 16, d_loss=0.004 g_loss=-0.095 KID= 0.02858\n",
      "epoch 315, batch 17, d_loss=-0.008 g_loss=-0.088 KID= 0.02858\n",
      "epoch 315, batch 18, d_loss=0.005 g_loss=-0.133 KID= 0.02858\n",
      "epoch 315, batch 19, d_loss=-0.043 g_loss=-0.234 KID= 0.02858\n",
      "epoch 316, batch 0, d_loss=-0.078 g_loss=-0.352 KID= 0.02858\n",
      "epoch 316, batch 1, d_loss=-0.048 g_loss=-0.432 KID= 0.02858\n",
      "epoch 316, batch 2, d_loss=-0.061 g_loss=-0.470 KID= 0.02858\n",
      "epoch 316, batch 3, d_loss=-0.033 g_loss=-0.367 KID= 0.02858\n",
      "epoch 316, batch 4, d_loss=-0.034 g_loss=-0.227 KID= 0.02858\n",
      "epoch 316, batch 5, d_loss=-0.016 g_loss=-0.113 KID= 0.02858\n",
      "epoch 316, batch 6, d_loss=-0.133 g_loss=-0.054 KID= 0.02858\n",
      "epoch 316, batch 7, d_loss=-0.106 g_loss=-0.039 KID= 0.02858\n",
      "epoch 316, batch 8, d_loss=-0.095 g_loss=-0.021 KID= 0.02858\n",
      "epoch 316, batch 9, d_loss=-0.011 g_loss=-0.077 KID= 0.02858\n",
      "epoch 316, batch 10, d_loss=-0.014 g_loss=-0.146 KID= 0.02858\n",
      "epoch 316, batch 11, d_loss=-0.080 g_loss=-0.137 KID= 0.02858\n",
      "epoch 316, batch 12, d_loss=-0.053 g_loss=-0.110 KID= 0.02858\n",
      "epoch 316, batch 13, d_loss=-0.055 g_loss=-0.108 KID= 0.02858\n",
      "epoch 316, batch 14, d_loss=-0.048 g_loss=-0.124 KID= 0.02858\n",
      "epoch 316, batch 15, d_loss=-0.092 g_loss=-0.231 KID= 0.02858\n",
      "epoch 316, batch 16, d_loss=-0.019 g_loss=-0.270 KID= 0.02858\n",
      "epoch 316, batch 17, d_loss=0.077 g_loss=-0.149 KID= 0.02858\n",
      "epoch 316, batch 18, d_loss=-0.034 g_loss=-0.061 KID= 0.02858\n",
      "epoch 316, batch 19, d_loss=0.015 g_loss=-0.039 KID= 0.02858\n",
      "epoch 317, batch 0, d_loss=-0.029 g_loss=-0.063 KID= 0.02858\n",
      "epoch 317, batch 1, d_loss=-0.096 g_loss=-0.103 KID= 0.02858\n",
      "epoch 317, batch 2, d_loss=-0.072 g_loss=-0.153 KID= 0.02858\n",
      "epoch 317, batch 3, d_loss=-0.071 g_loss=-0.206 KID= 0.02858\n",
      "epoch 317, batch 4, d_loss=-0.084 g_loss=-0.242 KID= 0.02858\n",
      "epoch 317, batch 5, d_loss=0.016 g_loss=-0.293 KID= 0.02858\n",
      "epoch 317, batch 6, d_loss=-0.061 g_loss=-0.303 KID= 0.02858\n",
      "epoch 317, batch 7, d_loss=-0.000 g_loss=-0.228 KID= 0.02858\n",
      "epoch 317, batch 8, d_loss=-0.010 g_loss=-0.229 KID= 0.02858\n",
      "epoch 317, batch 9, d_loss=0.004 g_loss=-0.355 KID= 0.02858\n",
      "epoch 317, batch 10, d_loss=-0.074 g_loss=-0.470 KID= 0.02858\n",
      "epoch 317, batch 11, d_loss=-0.062 g_loss=-0.649 KID= 0.02858\n",
      "epoch 317, batch 12, d_loss=-0.032 g_loss=-0.713 KID= 0.02858\n",
      "epoch 317, batch 13, d_loss=-0.025 g_loss=-0.622 KID= 0.02858\n",
      "epoch 317, batch 14, d_loss=-0.055 g_loss=-0.462 KID= 0.02858\n",
      "epoch 317, batch 15, d_loss=-0.091 g_loss=-0.390 KID= 0.02858\n",
      "epoch 317, batch 16, d_loss=-0.070 g_loss=-0.314 KID= 0.02858\n",
      "epoch 317, batch 17, d_loss=-0.010 g_loss=-0.163 KID= 0.02858\n",
      "epoch 317, batch 18, d_loss=0.009 g_loss=-0.066 KID= 0.02858\n",
      "epoch 317, batch 19, d_loss=-0.029 g_loss=-0.035 KID= 0.02858\n",
      "epoch 318, batch 0, d_loss=-0.028 g_loss=-0.026 KID= 0.02858\n",
      "epoch 318, batch 1, d_loss=-0.039 g_loss=-0.004 KID= 0.02858\n",
      "epoch 318, batch 2, d_loss=-0.072 g_loss=-0.008 KID= 0.02858\n",
      "epoch 318, batch 3, d_loss=-0.055 g_loss=0.074 KID= 0.02858\n",
      "epoch 318, batch 4, d_loss=-0.069 g_loss=0.097 KID= 0.02858\n",
      "epoch 318, batch 5, d_loss=-0.028 g_loss=0.114 KID= 0.02858\n",
      "epoch 318, batch 6, d_loss=-0.076 g_loss=0.146 KID= 0.02858\n",
      "epoch 318, batch 7, d_loss=0.042 g_loss=0.239 KID= 0.02858\n",
      "epoch 318, batch 8, d_loss=-0.034 g_loss=0.261 KID= 0.02858\n",
      "epoch 318, batch 9, d_loss=-0.043 g_loss=0.260 KID= 0.02858\n",
      "epoch 318, batch 10, d_loss=-0.072 g_loss=0.252 KID= 0.02858\n",
      "epoch 318, batch 11, d_loss=-0.079 g_loss=0.182 KID= 0.02858\n",
      "epoch 318, batch 12, d_loss=-0.040 g_loss=0.103 KID= 0.02858\n",
      "epoch 318, batch 13, d_loss=-0.049 g_loss=0.077 KID= 0.02858\n",
      "epoch 318, batch 14, d_loss=-0.065 g_loss=0.053 KID= 0.02858\n",
      "epoch 318, batch 15, d_loss=-0.028 g_loss=-0.030 KID= 0.02858\n",
      "epoch 318, batch 16, d_loss=-0.030 g_loss=-0.097 KID= 0.02858\n",
      "epoch 318, batch 17, d_loss=-0.044 g_loss=-0.144 KID= 0.02858\n",
      "epoch 318, batch 18, d_loss=-0.040 g_loss=-0.191 KID= 0.02858\n",
      "epoch 318, batch 19, d_loss=-0.007 g_loss=-0.220 KID= 0.02858\n",
      "epoch 319, batch 0, d_loss=0.035 g_loss=-0.300 KID= 0.02858\n",
      "epoch 319, batch 1, d_loss=-0.022 g_loss=-0.312 KID= 0.02858\n",
      "epoch 319, batch 2, d_loss=-0.045 g_loss=-0.340 KID= 0.02858\n",
      "epoch 319, batch 3, d_loss=-0.047 g_loss=-0.345 KID= 0.02858\n",
      "epoch 319, batch 4, d_loss=-0.005 g_loss=-0.362 KID= 0.02858\n",
      "epoch 319, batch 5, d_loss=0.012 g_loss=-0.429 KID= 0.02858\n",
      "epoch 319, batch 6, d_loss=-0.044 g_loss=-0.409 KID= 0.02858\n",
      "epoch 319, batch 7, d_loss=0.005 g_loss=-0.381 KID= 0.02858\n",
      "epoch 319, batch 8, d_loss=-0.003 g_loss=-0.352 KID= 0.02858\n",
      "epoch 319, batch 9, d_loss=0.001 g_loss=-0.388 KID= 0.02858\n",
      "epoch 319, batch 10, d_loss=-0.002 g_loss=-0.415 KID= 0.02858\n",
      "epoch 319, batch 11, d_loss=0.038 g_loss=-0.422 KID= 0.02858\n",
      "epoch 319, batch 12, d_loss=-0.059 g_loss=-0.426 KID= 0.02858\n",
      "epoch 319, batch 13, d_loss=-0.040 g_loss=-0.376 KID= 0.02858\n",
      "epoch 319, batch 14, d_loss=-0.097 g_loss=-0.303 KID= 0.02858\n",
      "epoch 319, batch 15, d_loss=-0.085 g_loss=-0.316 KID= 0.02858\n",
      "epoch 319, batch 16, d_loss=-0.077 g_loss=-0.350 KID= 0.02858\n",
      "epoch 319, batch 17, d_loss=-0.039 g_loss=-0.313 KID= 0.02858\n",
      "epoch 319, batch 18, d_loss=-0.080 g_loss=-0.288 KID= 0.02858\n",
      "epoch 319, batch 19, d_loss=-0.052 g_loss=-0.336 KID= 0.02858\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 320, batch 0, d_loss=-0.016 g_loss=-0.316 KID= 0.01945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 320, batch 1, d_loss=-0.098 g_loss=-0.245 KID= 0.01945\n",
      "epoch 320, batch 2, d_loss=-0.053 g_loss=-0.170 KID= 0.01945\n",
      "epoch 320, batch 3, d_loss=-0.023 g_loss=-0.043 KID= 0.01945\n",
      "epoch 320, batch 4, d_loss=-0.093 g_loss=0.048 KID= 0.01945\n",
      "epoch 320, batch 5, d_loss=-0.017 g_loss=0.045 KID= 0.01945\n",
      "epoch 320, batch 6, d_loss=-0.013 g_loss=0.043 KID= 0.01945\n",
      "epoch 320, batch 7, d_loss=-0.005 g_loss=0.077 KID= 0.01945\n",
      "epoch 320, batch 8, d_loss=-0.010 g_loss=0.068 KID= 0.01945\n",
      "epoch 320, batch 9, d_loss=-0.020 g_loss=-0.001 KID= 0.01945\n",
      "epoch 320, batch 10, d_loss=-0.048 g_loss=-0.080 KID= 0.01945\n",
      "epoch 320, batch 11, d_loss=-0.062 g_loss=-0.139 KID= 0.01945\n",
      "epoch 320, batch 12, d_loss=-0.126 g_loss=-0.161 KID= 0.01945\n",
      "epoch 320, batch 13, d_loss=-0.069 g_loss=-0.098 KID= 0.01945\n",
      "epoch 320, batch 14, d_loss=-0.067 g_loss=-0.139 KID= 0.01945\n",
      "epoch 320, batch 15, d_loss=-0.084 g_loss=-0.151 KID= 0.01945\n",
      "epoch 320, batch 16, d_loss=-0.051 g_loss=-0.183 KID= 0.01945\n",
      "epoch 320, batch 17, d_loss=0.042 g_loss=-0.149 KID= 0.01945\n",
      "epoch 320, batch 18, d_loss=0.001 g_loss=-0.045 KID= 0.01945\n",
      "epoch 320, batch 19, d_loss=-0.028 g_loss=-0.093 KID= 0.01945\n",
      "epoch 321, batch 0, d_loss=-0.023 g_loss=-0.140 KID= 0.01945\n",
      "epoch 321, batch 1, d_loss=-0.025 g_loss=-0.171 KID= 0.01945\n",
      "epoch 321, batch 2, d_loss=-0.043 g_loss=-0.247 KID= 0.01945\n",
      "epoch 321, batch 3, d_loss=-0.095 g_loss=-0.233 KID= 0.01945\n",
      "epoch 321, batch 4, d_loss=-0.094 g_loss=-0.269 KID= 0.01945\n",
      "epoch 321, batch 5, d_loss=-0.023 g_loss=-0.428 KID= 0.01945\n",
      "epoch 321, batch 6, d_loss=-0.056 g_loss=-0.549 KID= 0.01945\n",
      "epoch 321, batch 7, d_loss=-0.031 g_loss=-0.560 KID= 0.01945\n",
      "epoch 321, batch 8, d_loss=-0.079 g_loss=-0.627 KID= 0.01945\n",
      "epoch 321, batch 9, d_loss=-0.053 g_loss=-0.692 KID= 0.01945\n",
      "epoch 321, batch 10, d_loss=-0.018 g_loss=-0.758 KID= 0.01945\n",
      "epoch 321, batch 11, d_loss=-0.041 g_loss=-0.733 KID= 0.01945\n",
      "epoch 321, batch 12, d_loss=-0.038 g_loss=-0.713 KID= 0.01945\n",
      "epoch 321, batch 13, d_loss=0.020 g_loss=-0.601 KID= 0.01945\n",
      "epoch 321, batch 14, d_loss=-0.050 g_loss=-0.481 KID= 0.01945\n",
      "epoch 321, batch 15, d_loss=-0.085 g_loss=-0.399 KID= 0.01945\n",
      "epoch 321, batch 16, d_loss=-0.033 g_loss=-0.335 KID= 0.01945\n",
      "epoch 321, batch 17, d_loss=-0.003 g_loss=-0.242 KID= 0.01945\n",
      "epoch 321, batch 18, d_loss=-0.077 g_loss=-0.202 KID= 0.01945\n",
      "epoch 321, batch 19, d_loss=-0.049 g_loss=-0.210 KID= 0.01945\n",
      "epoch 322, batch 0, d_loss=-0.015 g_loss=-0.160 KID= 0.01945\n",
      "epoch 322, batch 1, d_loss=-0.109 g_loss=-0.152 KID= 0.01945\n",
      "epoch 322, batch 2, d_loss=-0.105 g_loss=-0.118 KID= 0.01945\n",
      "epoch 322, batch 3, d_loss=-0.075 g_loss=-0.126 KID= 0.01945\n",
      "epoch 322, batch 4, d_loss=-0.088 g_loss=-0.104 KID= 0.01945\n",
      "epoch 322, batch 5, d_loss=-0.021 g_loss=-0.151 KID= 0.01945\n",
      "epoch 322, batch 6, d_loss=-0.085 g_loss=-0.198 KID= 0.01945\n",
      "epoch 322, batch 7, d_loss=-0.001 g_loss=-0.192 KID= 0.01945\n",
      "epoch 322, batch 8, d_loss=-0.005 g_loss=-0.200 KID= 0.01945\n",
      "epoch 322, batch 9, d_loss=-0.014 g_loss=-0.251 KID= 0.01945\n",
      "epoch 322, batch 10, d_loss=-0.041 g_loss=-0.304 KID= 0.01945\n",
      "epoch 322, batch 11, d_loss=-0.056 g_loss=-0.322 KID= 0.01945\n",
      "epoch 322, batch 12, d_loss=-0.093 g_loss=-0.333 KID= 0.01945\n",
      "epoch 322, batch 13, d_loss=-0.059 g_loss=-0.287 KID= 0.01945\n",
      "epoch 322, batch 14, d_loss=-0.095 g_loss=-0.225 KID= 0.01945\n",
      "epoch 322, batch 15, d_loss=-0.072 g_loss=-0.249 KID= 0.01945\n",
      "epoch 322, batch 16, d_loss=-0.043 g_loss=-0.267 KID= 0.01945\n",
      "epoch 322, batch 17, d_loss=-0.008 g_loss=-0.187 KID= 0.01945\n",
      "epoch 322, batch 18, d_loss=-0.042 g_loss=-0.145 KID= 0.01945\n",
      "epoch 322, batch 19, d_loss=-0.004 g_loss=-0.163 KID= 0.01945\n",
      "epoch 323, batch 0, d_loss=-0.016 g_loss=-0.175 KID= 0.01945\n",
      "epoch 323, batch 1, d_loss=-0.067 g_loss=-0.165 KID= 0.01945\n",
      "epoch 323, batch 2, d_loss=-0.060 g_loss=-0.138 KID= 0.01945\n",
      "epoch 323, batch 3, d_loss=-0.023 g_loss=-0.137 KID= 0.01945\n",
      "epoch 323, batch 4, d_loss=-0.053 g_loss=-0.106 KID= 0.01945\n",
      "epoch 323, batch 5, d_loss=-0.064 g_loss=-0.109 KID= 0.01945\n",
      "epoch 323, batch 6, d_loss=-0.041 g_loss=-0.161 KID= 0.01945\n",
      "epoch 323, batch 7, d_loss=0.044 g_loss=-0.171 KID= 0.01945\n",
      "epoch 323, batch 8, d_loss=-0.059 g_loss=-0.197 KID= 0.01945\n",
      "epoch 323, batch 9, d_loss=-0.084 g_loss=-0.272 KID= 0.01945\n",
      "epoch 323, batch 10, d_loss=-0.067 g_loss=-0.361 KID= 0.01945\n",
      "epoch 323, batch 11, d_loss=-0.022 g_loss=-0.420 KID= 0.01945\n",
      "epoch 323, batch 12, d_loss=-0.052 g_loss=-0.498 KID= 0.01945\n",
      "epoch 323, batch 13, d_loss=-0.040 g_loss=-0.437 KID= 0.01945\n",
      "epoch 323, batch 14, d_loss=-0.081 g_loss=-0.432 KID= 0.01945\n",
      "epoch 323, batch 15, d_loss=-0.042 g_loss=-0.470 KID= 0.01945\n",
      "epoch 323, batch 16, d_loss=-0.127 g_loss=-0.568 KID= 0.01945\n",
      "epoch 323, batch 17, d_loss=-0.008 g_loss=-0.567 KID= 0.01945\n",
      "epoch 323, batch 18, d_loss=-0.041 g_loss=-0.606 KID= 0.01945\n",
      "epoch 323, batch 19, d_loss=-0.042 g_loss=-0.623 KID= 0.01945\n",
      "epoch 324, batch 0, d_loss=0.008 g_loss=-0.639 KID= 0.01945\n",
      "epoch 324, batch 1, d_loss=-0.061 g_loss=-0.660 KID= 0.01945\n",
      "epoch 324, batch 2, d_loss=-0.053 g_loss=-0.653 KID= 0.01945\n",
      "epoch 324, batch 3, d_loss=-0.020 g_loss=-0.632 KID= 0.01945\n",
      "epoch 324, batch 4, d_loss=-0.049 g_loss=-0.537 KID= 0.01945\n",
      "epoch 324, batch 5, d_loss=-0.090 g_loss=-0.487 KID= 0.01945\n",
      "epoch 324, batch 6, d_loss=-0.061 g_loss=-0.431 KID= 0.01945\n",
      "epoch 324, batch 7, d_loss=-0.067 g_loss=-0.359 KID= 0.01945\n",
      "epoch 324, batch 8, d_loss=-0.089 g_loss=-0.322 KID= 0.01945\n",
      "epoch 324, batch 9, d_loss=0.015 g_loss=-0.363 KID= 0.01945\n",
      "epoch 324, batch 10, d_loss=-0.052 g_loss=-0.409 KID= 0.01945\n",
      "epoch 324, batch 11, d_loss=-0.071 g_loss=-0.428 KID= 0.01945\n",
      "epoch 324, batch 12, d_loss=-0.093 g_loss=-0.480 KID= 0.01945\n",
      "epoch 324, batch 13, d_loss=-0.038 g_loss=-0.453 KID= 0.01945\n",
      "epoch 324, batch 14, d_loss=-0.018 g_loss=-0.406 KID= 0.01945\n",
      "epoch 324, batch 15, d_loss=-0.078 g_loss=-0.344 KID= 0.01945\n",
      "epoch 324, batch 16, d_loss=-0.097 g_loss=-0.301 KID= 0.01945\n",
      "epoch 324, batch 17, d_loss=-0.010 g_loss=-0.203 KID= 0.01945\n",
      "epoch 324, batch 18, d_loss=-0.074 g_loss=-0.178 KID= 0.01945\n",
      "epoch 324, batch 19, d_loss=-0.093 g_loss=-0.270 KID= 0.01945\n",
      "epoch 325, batch 0, d_loss=-0.013 g_loss=-0.385 KID= 0.01945\n",
      "epoch 325, batch 1, d_loss=-0.056 g_loss=-0.530 KID= 0.01945\n",
      "epoch 325, batch 2, d_loss=-0.060 g_loss=-0.640 KID= 0.01945\n",
      "epoch 325, batch 3, d_loss=-0.024 g_loss=-0.684 KID= 0.01945\n",
      "epoch 325, batch 4, d_loss=-0.091 g_loss=-0.654 KID= 0.01945\n",
      "epoch 325, batch 5, d_loss=-0.004 g_loss=-0.640 KID= 0.01945\n",
      "epoch 325, batch 6, d_loss=-0.045 g_loss=-0.652 KID= 0.01945\n",
      "epoch 325, batch 7, d_loss=0.050 g_loss=-0.401 KID= 0.01945\n",
      "epoch 325, batch 8, d_loss=-0.064 g_loss=-0.245 KID= 0.01945\n",
      "epoch 325, batch 9, d_loss=-0.036 g_loss=-0.154 KID= 0.01945\n",
      "epoch 325, batch 10, d_loss=-0.082 g_loss=-0.030 KID= 0.01945\n",
      "epoch 325, batch 11, d_loss=-0.075 g_loss=0.018 KID= 0.01945\n",
      "epoch 325, batch 12, d_loss=-0.046 g_loss=0.022 KID= 0.01945\n",
      "epoch 325, batch 13, d_loss=-0.100 g_loss=0.105 KID= 0.01945\n",
      "epoch 325, batch 14, d_loss=-0.133 g_loss=0.186 KID= 0.01945\n",
      "epoch 325, batch 15, d_loss=-0.056 g_loss=0.193 KID= 0.01945\n",
      "epoch 325, batch 16, d_loss=-0.139 g_loss=0.159 KID= 0.01945\n",
      "epoch 325, batch 17, d_loss=0.015 g_loss=0.090 KID= 0.01945\n",
      "epoch 325, batch 18, d_loss=-0.015 g_loss=-0.014 KID= 0.01945\n",
      "epoch 325, batch 19, d_loss=-0.085 g_loss=-0.071 KID= 0.01945\n",
      "epoch 326, batch 0, d_loss=-0.015 g_loss=-0.171 KID= 0.01945\n",
      "epoch 326, batch 1, d_loss=-0.022 g_loss=-0.302 KID= 0.01945\n",
      "epoch 326, batch 2, d_loss=-0.043 g_loss=-0.302 KID= 0.01945\n",
      "epoch 326, batch 3, d_loss=0.050 g_loss=-0.270 KID= 0.01945\n",
      "epoch 326, batch 4, d_loss=-0.035 g_loss=-0.198 KID= 0.01945\n",
      "epoch 326, batch 5, d_loss=-0.048 g_loss=-0.186 KID= 0.01945\n",
      "epoch 326, batch 6, d_loss=-0.142 g_loss=-0.216 KID= 0.01945\n",
      "epoch 326, batch 7, d_loss=-0.056 g_loss=-0.222 KID= 0.01945\n",
      "epoch 326, batch 8, d_loss=-0.113 g_loss=-0.243 KID= 0.01945\n",
      "epoch 326, batch 9, d_loss=-0.126 g_loss=-0.254 KID= 0.01945\n",
      "epoch 326, batch 10, d_loss=-0.077 g_loss=-0.347 KID= 0.01945\n",
      "epoch 326, batch 11, d_loss=-0.043 g_loss=-0.402 KID= 0.01945\n",
      "epoch 326, batch 12, d_loss=-0.009 g_loss=-0.490 KID= 0.01945\n",
      "epoch 326, batch 13, d_loss=-0.042 g_loss=-0.529 KID= 0.01945\n",
      "epoch 326, batch 14, d_loss=-0.041 g_loss=-0.498 KID= 0.01945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 326, batch 15, d_loss=-0.058 g_loss=-0.440 KID= 0.01945\n",
      "epoch 326, batch 16, d_loss=-0.023 g_loss=-0.361 KID= 0.01945\n",
      "epoch 326, batch 17, d_loss=-0.049 g_loss=-0.207 KID= 0.01945\n",
      "epoch 326, batch 18, d_loss=-0.023 g_loss=-0.175 KID= 0.01945\n",
      "epoch 326, batch 19, d_loss=-0.005 g_loss=-0.201 KID= 0.01945\n",
      "epoch 327, batch 0, d_loss=-0.002 g_loss=-0.281 KID= 0.01945\n",
      "epoch 327, batch 1, d_loss=-0.038 g_loss=-0.418 KID= 0.01945\n",
      "epoch 327, batch 2, d_loss=-0.080 g_loss=-0.471 KID= 0.01945\n",
      "epoch 327, batch 3, d_loss=-0.032 g_loss=-0.457 KID= 0.01945\n",
      "epoch 327, batch 4, d_loss=-0.089 g_loss=-0.456 KID= 0.01945\n",
      "epoch 327, batch 5, d_loss=-0.045 g_loss=-0.436 KID= 0.01945\n",
      "epoch 327, batch 6, d_loss=-0.095 g_loss=-0.417 KID= 0.01945\n",
      "epoch 327, batch 7, d_loss=-0.058 g_loss=-0.390 KID= 0.01945\n",
      "epoch 327, batch 8, d_loss=-0.091 g_loss=-0.423 KID= 0.01945\n",
      "epoch 327, batch 9, d_loss=-0.079 g_loss=-0.535 KID= 0.01945\n",
      "epoch 327, batch 10, d_loss=-0.034 g_loss=-0.692 KID= 0.01945\n",
      "epoch 327, batch 11, d_loss=-0.110 g_loss=-0.767 KID= 0.01945\n",
      "epoch 327, batch 12, d_loss=-0.019 g_loss=-0.715 KID= 0.01945\n",
      "epoch 327, batch 13, d_loss=-0.060 g_loss=-0.640 KID= 0.01945\n",
      "epoch 327, batch 14, d_loss=-0.064 g_loss=-0.535 KID= 0.01945\n",
      "epoch 327, batch 15, d_loss=-0.022 g_loss=-0.451 KID= 0.01945\n",
      "epoch 327, batch 16, d_loss=0.001 g_loss=-0.396 KID= 0.01945\n",
      "epoch 327, batch 17, d_loss=-0.024 g_loss=-0.249 KID= 0.01945\n",
      "epoch 327, batch 18, d_loss=-0.029 g_loss=-0.173 KID= 0.01945\n",
      "epoch 327, batch 19, d_loss=-0.014 g_loss=-0.124 KID= 0.01945\n",
      "epoch 328, batch 0, d_loss=-0.024 g_loss=-0.095 KID= 0.01945\n",
      "epoch 328, batch 1, d_loss=-0.043 g_loss=-0.120 KID= 0.01945\n",
      "epoch 328, batch 2, d_loss=-0.120 g_loss=-0.142 KID= 0.01945\n",
      "epoch 328, batch 3, d_loss=-0.058 g_loss=-0.158 KID= 0.01945\n",
      "epoch 328, batch 4, d_loss=-0.076 g_loss=-0.169 KID= 0.01945\n",
      "epoch 328, batch 5, d_loss=-0.105 g_loss=-0.117 KID= 0.01945\n",
      "epoch 328, batch 6, d_loss=-0.041 g_loss=-0.093 KID= 0.01945\n",
      "epoch 328, batch 7, d_loss=0.033 g_loss=0.077 KID= 0.01945\n",
      "epoch 328, batch 8, d_loss=-0.073 g_loss=0.248 KID= 0.01945\n",
      "epoch 328, batch 9, d_loss=-0.093 g_loss=0.351 KID= 0.01945\n",
      "epoch 328, batch 10, d_loss=-0.063 g_loss=0.445 KID= 0.01945\n",
      "epoch 328, batch 11, d_loss=-0.092 g_loss=0.429 KID= 0.01945\n",
      "epoch 328, batch 12, d_loss=-0.086 g_loss=0.395 KID= 0.01945\n",
      "epoch 328, batch 13, d_loss=-0.054 g_loss=0.406 KID= 0.01945\n",
      "epoch 328, batch 14, d_loss=-0.040 g_loss=0.457 KID= 0.01945\n",
      "epoch 328, batch 15, d_loss=0.050 g_loss=0.460 KID= 0.01945\n",
      "epoch 328, batch 16, d_loss=-0.078 g_loss=0.650 KID= 0.01945\n",
      "epoch 328, batch 17, d_loss=-0.128 g_loss=0.852 KID= 0.01945\n",
      "epoch 328, batch 18, d_loss=-0.081 g_loss=0.860 KID= 0.01945\n",
      "epoch 328, batch 19, d_loss=-0.121 g_loss=0.749 KID= 0.01945\n",
      "epoch 329, batch 0, d_loss=-0.005 g_loss=0.332 KID= 0.01945\n",
      "epoch 329, batch 1, d_loss=-0.049 g_loss=-0.116 KID= 0.01945\n",
      "epoch 329, batch 2, d_loss=-0.053 g_loss=-0.476 KID= 0.01945\n",
      "epoch 329, batch 3, d_loss=-0.036 g_loss=-0.756 KID= 0.01945\n",
      "epoch 329, batch 4, d_loss=-0.010 g_loss=-1.018 KID= 0.01945\n",
      "epoch 329, batch 5, d_loss=-0.059 g_loss=-1.171 KID= 0.01945\n",
      "epoch 329, batch 6, d_loss=-0.047 g_loss=-1.139 KID= 0.01945\n",
      "epoch 329, batch 7, d_loss=0.065 g_loss=-1.139 KID= 0.01945\n",
      "epoch 329, batch 8, d_loss=-0.055 g_loss=-1.307 KID= 0.01945\n",
      "epoch 329, batch 9, d_loss=-0.016 g_loss=-1.415 KID= 0.01945\n",
      "epoch 329, batch 10, d_loss=0.026 g_loss=-1.476 KID= 0.01945\n",
      "epoch 329, batch 11, d_loss=-0.073 g_loss=-1.422 KID= 0.01945\n",
      "epoch 329, batch 12, d_loss=-0.125 g_loss=-1.436 KID= 0.01945\n",
      "epoch 329, batch 13, d_loss=-0.016 g_loss=-1.383 KID= 0.01945\n",
      "epoch 329, batch 14, d_loss=-0.076 g_loss=-1.121 KID= 0.01945\n",
      "epoch 329, batch 15, d_loss=-0.068 g_loss=-0.796 KID= 0.01945\n",
      "epoch 329, batch 16, d_loss=-0.016 g_loss=-0.512 KID= 0.01945\n",
      "epoch 329, batch 17, d_loss=-0.146 g_loss=-0.378 KID= 0.01945\n",
      "epoch 329, batch 18, d_loss=-0.068 g_loss=-0.272 KID= 0.01945\n",
      "epoch 329, batch 19, d_loss=-0.095 g_loss=-0.220 KID= 0.01945\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 330, batch 0, d_loss=-0.057 g_loss=0.052 KID= 0.02649\n",
      "epoch 330, batch 1, d_loss=-0.106 g_loss=0.304 KID= 0.02649\n",
      "epoch 330, batch 2, d_loss=-0.057 g_loss=0.386 KID= 0.02649\n",
      "epoch 330, batch 3, d_loss=-0.037 g_loss=0.405 KID= 0.02649\n",
      "epoch 330, batch 4, d_loss=-0.022 g_loss=0.395 KID= 0.02649\n",
      "epoch 330, batch 5, d_loss=0.010 g_loss=0.335 KID= 0.02649\n",
      "epoch 330, batch 6, d_loss=-0.046 g_loss=0.202 KID= 0.02649\n",
      "epoch 330, batch 7, d_loss=0.057 g_loss=0.083 KID= 0.02649\n",
      "epoch 330, batch 8, d_loss=-0.070 g_loss=0.013 KID= 0.02649\n",
      "epoch 330, batch 9, d_loss=-0.105 g_loss=-0.041 KID= 0.02649\n",
      "epoch 330, batch 10, d_loss=-0.044 g_loss=-0.017 KID= 0.02649\n",
      "epoch 330, batch 11, d_loss=-0.081 g_loss=-0.014 KID= 0.02649\n",
      "epoch 330, batch 12, d_loss=-0.124 g_loss=0.004 KID= 0.02649\n",
      "epoch 330, batch 13, d_loss=-0.097 g_loss=0.027 KID= 0.02649\n",
      "epoch 330, batch 14, d_loss=-0.119 g_loss=0.060 KID= 0.02649\n",
      "epoch 330, batch 15, d_loss=-0.093 g_loss=0.029 KID= 0.02649\n",
      "epoch 330, batch 16, d_loss=0.146 g_loss=-0.123 KID= 0.02649\n",
      "epoch 330, batch 17, d_loss=-0.033 g_loss=-0.220 KID= 0.02649\n",
      "epoch 330, batch 18, d_loss=-0.034 g_loss=-0.320 KID= 0.02649\n",
      "epoch 330, batch 19, d_loss=-0.073 g_loss=-0.427 KID= 0.02649\n",
      "epoch 331, batch 0, d_loss=-0.045 g_loss=-0.465 KID= 0.02649\n",
      "epoch 331, batch 1, d_loss=-0.129 g_loss=-0.426 KID= 0.02649\n",
      "epoch 331, batch 2, d_loss=-0.083 g_loss=-0.369 KID= 0.02649\n",
      "epoch 331, batch 3, d_loss=-0.066 g_loss=-0.310 KID= 0.02649\n",
      "epoch 331, batch 4, d_loss=-0.112 g_loss=-0.223 KID= 0.02649\n",
      "epoch 331, batch 5, d_loss=-0.085 g_loss=-0.192 KID= 0.02649\n",
      "epoch 331, batch 6, d_loss=-0.118 g_loss=-0.104 KID= 0.02649\n",
      "epoch 331, batch 7, d_loss=0.054 g_loss=-0.156 KID= 0.02649\n",
      "epoch 331, batch 8, d_loss=0.042 g_loss=-0.257 KID= 0.02649\n",
      "epoch 331, batch 9, d_loss=0.000 g_loss=-0.411 KID= 0.02649\n",
      "epoch 331, batch 10, d_loss=-0.093 g_loss=-0.500 KID= 0.02649\n",
      "epoch 331, batch 11, d_loss=-0.057 g_loss=-0.608 KID= 0.02649\n",
      "epoch 331, batch 12, d_loss=-0.080 g_loss=-0.681 KID= 0.02649\n",
      "epoch 331, batch 13, d_loss=-0.024 g_loss=-0.716 KID= 0.02649\n",
      "epoch 331, batch 14, d_loss=-0.116 g_loss=-0.741 KID= 0.02649\n",
      "epoch 331, batch 15, d_loss=-0.065 g_loss=-0.727 KID= 0.02649\n",
      "epoch 331, batch 16, d_loss=0.024 g_loss=-0.766 KID= 0.02649\n",
      "epoch 331, batch 17, d_loss=-0.049 g_loss=-0.746 KID= 0.02649\n",
      "epoch 331, batch 18, d_loss=-0.010 g_loss=-0.703 KID= 0.02649\n",
      "epoch 331, batch 19, d_loss=0.014 g_loss=-0.655 KID= 0.02649\n",
      "epoch 332, batch 0, d_loss=-0.002 g_loss=-0.520 KID= 0.02649\n",
      "epoch 332, batch 1, d_loss=-0.055 g_loss=-0.408 KID= 0.02649\n",
      "epoch 332, batch 2, d_loss=-0.021 g_loss=-0.288 KID= 0.02649\n",
      "epoch 332, batch 3, d_loss=-0.036 g_loss=-0.183 KID= 0.02649\n",
      "epoch 332, batch 4, d_loss=-0.056 g_loss=-0.092 KID= 0.02649\n",
      "epoch 332, batch 5, d_loss=-0.090 g_loss=-0.026 KID= 0.02649\n",
      "epoch 332, batch 6, d_loss=-0.039 g_loss=0.025 KID= 0.02649\n",
      "epoch 332, batch 7, d_loss=-0.012 g_loss=0.063 KID= 0.02649\n",
      "epoch 332, batch 8, d_loss=-0.033 g_loss=0.030 KID= 0.02649\n",
      "epoch 332, batch 9, d_loss=0.005 g_loss=-0.031 KID= 0.02649\n",
      "epoch 332, batch 10, d_loss=-0.046 g_loss=-0.046 KID= 0.02649\n",
      "epoch 332, batch 11, d_loss=-0.019 g_loss=-0.063 KID= 0.02649\n",
      "epoch 332, batch 12, d_loss=-0.074 g_loss=-0.045 KID= 0.02649\n",
      "epoch 332, batch 13, d_loss=-0.044 g_loss=-0.047 KID= 0.02649\n",
      "epoch 332, batch 14, d_loss=-0.123 g_loss=-0.126 KID= 0.02649\n",
      "epoch 332, batch 15, d_loss=-0.137 g_loss=-0.211 KID= 0.02649\n",
      "epoch 332, batch 16, d_loss=-0.035 g_loss=-0.362 KID= 0.02649\n",
      "epoch 332, batch 17, d_loss=-0.046 g_loss=-0.490 KID= 0.02649\n",
      "epoch 332, batch 18, d_loss=-0.017 g_loss=-0.562 KID= 0.02649\n",
      "epoch 332, batch 19, d_loss=-0.068 g_loss=-0.619 KID= 0.02649\n",
      "epoch 333, batch 0, d_loss=0.043 g_loss=-0.627 KID= 0.02649\n",
      "epoch 333, batch 1, d_loss=-0.092 g_loss=-0.670 KID= 0.02649\n",
      "epoch 333, batch 2, d_loss=-0.054 g_loss=-0.650 KID= 0.02649\n",
      "epoch 333, batch 3, d_loss=-0.086 g_loss=-0.671 KID= 0.02649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 333, batch 4, d_loss=-0.079 g_loss=-0.728 KID= 0.02649\n",
      "epoch 333, batch 5, d_loss=-0.090 g_loss=-0.741 KID= 0.02649\n",
      "epoch 333, batch 6, d_loss=-0.065 g_loss=-0.607 KID= 0.02649\n",
      "epoch 333, batch 7, d_loss=-0.062 g_loss=-0.523 KID= 0.02649\n",
      "epoch 333, batch 8, d_loss=-0.124 g_loss=-0.512 KID= 0.02649\n",
      "epoch 333, batch 9, d_loss=-0.142 g_loss=-0.478 KID= 0.02649\n",
      "epoch 333, batch 10, d_loss=-0.101 g_loss=-0.455 KID= 0.02649\n",
      "epoch 333, batch 11, d_loss=-0.088 g_loss=-0.482 KID= 0.02649\n",
      "epoch 333, batch 12, d_loss=-0.058 g_loss=-0.408 KID= 0.02649\n",
      "epoch 333, batch 13, d_loss=0.005 g_loss=-0.312 KID= 0.02649\n",
      "epoch 333, batch 14, d_loss=-0.009 g_loss=-0.194 KID= 0.02649\n",
      "epoch 333, batch 15, d_loss=-0.076 g_loss=-0.113 KID= 0.02649\n",
      "epoch 333, batch 16, d_loss=0.007 g_loss=-0.022 KID= 0.02649\n",
      "epoch 333, batch 17, d_loss=-0.007 g_loss=-0.056 KID= 0.02649\n",
      "epoch 333, batch 18, d_loss=-0.043 g_loss=-0.170 KID= 0.02649\n",
      "epoch 333, batch 19, d_loss=-0.102 g_loss=-0.304 KID= 0.02649\n",
      "epoch 334, batch 0, d_loss=-0.036 g_loss=-0.418 KID= 0.02649\n",
      "epoch 334, batch 1, d_loss=-0.064 g_loss=-0.490 KID= 0.02649\n",
      "epoch 334, batch 2, d_loss=-0.084 g_loss=-0.514 KID= 0.02649\n",
      "epoch 334, batch 3, d_loss=-0.059 g_loss=-0.481 KID= 0.02649\n",
      "epoch 334, batch 4, d_loss=-0.093 g_loss=-0.507 KID= 0.02649\n",
      "epoch 334, batch 5, d_loss=-0.069 g_loss=-0.489 KID= 0.02649\n",
      "epoch 334, batch 6, d_loss=0.021 g_loss=-0.363 KID= 0.02649\n",
      "epoch 334, batch 7, d_loss=-0.047 g_loss=-0.331 KID= 0.02649\n",
      "epoch 334, batch 8, d_loss=-0.055 g_loss=-0.356 KID= 0.02649\n",
      "epoch 334, batch 9, d_loss=-0.057 g_loss=-0.361 KID= 0.02649\n",
      "epoch 334, batch 10, d_loss=-0.097 g_loss=-0.351 KID= 0.02649\n",
      "epoch 334, batch 11, d_loss=-0.045 g_loss=-0.368 KID= 0.02649\n",
      "epoch 334, batch 12, d_loss=-0.065 g_loss=-0.386 KID= 0.02649\n",
      "epoch 334, batch 13, d_loss=-0.016 g_loss=-0.279 KID= 0.02649\n",
      "epoch 334, batch 14, d_loss=-0.041 g_loss=-0.263 KID= 0.02649\n",
      "epoch 334, batch 15, d_loss=-0.078 g_loss=-0.239 KID= 0.02649\n",
      "epoch 334, batch 16, d_loss=-0.034 g_loss=-0.177 KID= 0.02649\n",
      "epoch 334, batch 17, d_loss=-0.028 g_loss=-0.169 KID= 0.02649\n",
      "epoch 334, batch 18, d_loss=-0.066 g_loss=-0.201 KID= 0.02649\n",
      "epoch 334, batch 19, d_loss=-0.082 g_loss=-0.266 KID= 0.02649\n",
      "epoch 335, batch 0, d_loss=-0.070 g_loss=-0.377 KID= 0.02649\n",
      "epoch 335, batch 1, d_loss=-0.117 g_loss=-0.511 KID= 0.02649\n",
      "epoch 335, batch 2, d_loss=-0.056 g_loss=-0.618 KID= 0.02649\n",
      "epoch 335, batch 3, d_loss=-0.042 g_loss=-0.626 KID= 0.02649\n",
      "epoch 335, batch 4, d_loss=-0.056 g_loss=-0.651 KID= 0.02649\n",
      "epoch 335, batch 5, d_loss=-0.065 g_loss=-0.549 KID= 0.02649\n",
      "epoch 335, batch 6, d_loss=0.035 g_loss=-0.429 KID= 0.02649\n",
      "epoch 335, batch 7, d_loss=-0.101 g_loss=-0.359 KID= 0.02649\n",
      "epoch 335, batch 8, d_loss=-0.079 g_loss=-0.317 KID= 0.02649\n",
      "epoch 335, batch 9, d_loss=-0.094 g_loss=-0.368 KID= 0.02649\n",
      "epoch 335, batch 10, d_loss=-0.086 g_loss=-0.426 KID= 0.02649\n",
      "epoch 335, batch 11, d_loss=-0.006 g_loss=-0.443 KID= 0.02649\n",
      "epoch 335, batch 12, d_loss=-0.074 g_loss=-0.483 KID= 0.02649\n",
      "epoch 335, batch 13, d_loss=-0.063 g_loss=-0.411 KID= 0.02649\n",
      "epoch 335, batch 14, d_loss=-0.067 g_loss=-0.415 KID= 0.02649\n",
      "epoch 335, batch 15, d_loss=-0.079 g_loss=-0.407 KID= 0.02649\n",
      "epoch 335, batch 16, d_loss=0.021 g_loss=-0.327 KID= 0.02649\n",
      "epoch 335, batch 17, d_loss=0.030 g_loss=-0.311 KID= 0.02649\n",
      "epoch 335, batch 18, d_loss=-0.081 g_loss=-0.330 KID= 0.02649\n",
      "epoch 335, batch 19, d_loss=-0.009 g_loss=-0.383 KID= 0.02649\n",
      "epoch 336, batch 0, d_loss=-0.015 g_loss=-0.478 KID= 0.02649\n",
      "epoch 336, batch 1, d_loss=-0.079 g_loss=-0.526 KID= 0.02649\n",
      "epoch 336, batch 2, d_loss=-0.092 g_loss=-0.542 KID= 0.02649\n",
      "epoch 336, batch 3, d_loss=-0.042 g_loss=-0.525 KID= 0.02649\n",
      "epoch 336, batch 4, d_loss=-0.162 g_loss=-0.547 KID= 0.02649\n",
      "epoch 336, batch 5, d_loss=-0.057 g_loss=-0.520 KID= 0.02649\n",
      "epoch 336, batch 6, d_loss=-0.058 g_loss=-0.495 KID= 0.02649\n",
      "epoch 336, batch 7, d_loss=-0.099 g_loss=-0.456 KID= 0.02649\n",
      "epoch 336, batch 8, d_loss=0.013 g_loss=-0.379 KID= 0.02649\n",
      "epoch 336, batch 9, d_loss=0.002 g_loss=-0.312 KID= 0.02649\n",
      "epoch 336, batch 10, d_loss=-0.142 g_loss=-0.316 KID= 0.02649\n",
      "epoch 336, batch 11, d_loss=-0.046 g_loss=-0.313 KID= 0.02649\n",
      "epoch 336, batch 12, d_loss=-0.069 g_loss=-0.284 KID= 0.02649\n",
      "epoch 336, batch 13, d_loss=-0.088 g_loss=-0.209 KID= 0.02649\n",
      "epoch 336, batch 14, d_loss=0.052 g_loss=-0.153 KID= 0.02649\n",
      "epoch 336, batch 15, d_loss=-0.066 g_loss=-0.099 KID= 0.02649\n",
      "epoch 336, batch 16, d_loss=-0.047 g_loss=-0.022 KID= 0.02649\n",
      "epoch 336, batch 17, d_loss=0.046 g_loss=0.059 KID= 0.02649\n",
      "epoch 336, batch 18, d_loss=-0.049 g_loss=0.101 KID= 0.02649\n",
      "epoch 336, batch 19, d_loss=-0.041 g_loss=0.167 KID= 0.02649\n",
      "epoch 337, batch 0, d_loss=-0.051 g_loss=0.242 KID= 0.02649\n",
      "epoch 337, batch 1, d_loss=-0.053 g_loss=0.341 KID= 0.02649\n",
      "epoch 337, batch 2, d_loss=-0.124 g_loss=0.484 KID= 0.02649\n",
      "epoch 337, batch 3, d_loss=-0.109 g_loss=0.485 KID= 0.02649\n",
      "epoch 337, batch 4, d_loss=-0.149 g_loss=0.438 KID= 0.02649\n",
      "epoch 337, batch 5, d_loss=-0.048 g_loss=0.234 KID= 0.02649\n",
      "epoch 337, batch 6, d_loss=0.025 g_loss=0.115 KID= 0.02649\n",
      "epoch 337, batch 7, d_loss=-0.049 g_loss=-0.023 KID= 0.02649\n",
      "epoch 337, batch 8, d_loss=-0.025 g_loss=-0.267 KID= 0.02649\n",
      "epoch 337, batch 9, d_loss=-0.069 g_loss=-0.471 KID= 0.02649\n",
      "epoch 337, batch 10, d_loss=-0.111 g_loss=-0.697 KID= 0.02649\n",
      "epoch 337, batch 11, d_loss=-0.077 g_loss=-0.947 KID= 0.02649\n",
      "epoch 337, batch 12, d_loss=-0.049 g_loss=-1.276 KID= 0.02649\n",
      "epoch 337, batch 13, d_loss=-0.084 g_loss=-1.461 KID= 0.02649\n",
      "epoch 337, batch 14, d_loss=-0.098 g_loss=-1.792 KID= 0.02649\n",
      "epoch 337, batch 15, d_loss=-0.118 g_loss=-2.131 KID= 0.02649\n",
      "epoch 337, batch 16, d_loss=0.227 g_loss=-1.534 KID= 0.02649\n",
      "epoch 337, batch 17, d_loss=0.114 g_loss=-1.183 KID= 0.02649\n",
      "epoch 337, batch 18, d_loss=-0.044 g_loss=-0.903 KID= 0.02649\n",
      "epoch 337, batch 19, d_loss=-0.011 g_loss=-0.661 KID= 0.02649\n",
      "epoch 338, batch 0, d_loss=-0.111 g_loss=-0.502 KID= 0.02649\n",
      "epoch 338, batch 1, d_loss=-0.127 g_loss=-0.434 KID= 0.02649\n",
      "epoch 338, batch 2, d_loss=-0.117 g_loss=-0.366 KID= 0.02649\n",
      "epoch 338, batch 3, d_loss=-0.095 g_loss=-0.273 KID= 0.02649\n",
      "epoch 338, batch 4, d_loss=-0.162 g_loss=-0.205 KID= 0.02649\n",
      "epoch 338, batch 5, d_loss=-0.090 g_loss=-0.167 KID= 0.02649\n",
      "epoch 338, batch 6, d_loss=-0.072 g_loss=-0.052 KID= 0.02649\n",
      "epoch 338, batch 7, d_loss=-0.090 g_loss=0.063 KID= 0.02649\n",
      "epoch 338, batch 8, d_loss=0.021 g_loss=0.020 KID= 0.02649\n",
      "epoch 338, batch 9, d_loss=-0.002 g_loss=0.024 KID= 0.02649\n",
      "epoch 338, batch 10, d_loss=0.009 g_loss=-0.014 KID= 0.02649\n",
      "epoch 338, batch 11, d_loss=0.049 g_loss=-0.027 KID= 0.02649\n",
      "epoch 338, batch 12, d_loss=-0.034 g_loss=-0.025 KID= 0.02649\n",
      "epoch 338, batch 13, d_loss=-0.088 g_loss=0.025 KID= 0.02649\n",
      "epoch 338, batch 14, d_loss=-0.075 g_loss=0.043 KID= 0.02649\n",
      "epoch 338, batch 15, d_loss=-0.136 g_loss=0.099 KID= 0.02649\n",
      "epoch 338, batch 16, d_loss=-0.082 g_loss=0.119 KID= 0.02649\n",
      "epoch 338, batch 17, d_loss=-0.050 g_loss=0.046 KID= 0.02649\n",
      "epoch 338, batch 18, d_loss=-0.134 g_loss=-0.009 KID= 0.02649\n",
      "epoch 338, batch 19, d_loss=0.014 g_loss=-0.167 KID= 0.02649\n",
      "epoch 339, batch 0, d_loss=-0.043 g_loss=-0.312 KID= 0.02649\n",
      "epoch 339, batch 1, d_loss=0.004 g_loss=-0.357 KID= 0.02649\n",
      "epoch 339, batch 2, d_loss=-0.004 g_loss=-0.365 KID= 0.02649\n",
      "epoch 339, batch 3, d_loss=-0.053 g_loss=-0.264 KID= 0.02649\n",
      "epoch 339, batch 4, d_loss=-0.097 g_loss=-0.206 KID= 0.02649\n",
      "epoch 339, batch 5, d_loss=-0.189 g_loss=-0.201 KID= 0.02649\n",
      "epoch 339, batch 6, d_loss=-0.135 g_loss=-0.158 KID= 0.02649\n",
      "epoch 339, batch 7, d_loss=-0.088 g_loss=-0.118 KID= 0.02649\n",
      "epoch 339, batch 8, d_loss=-0.046 g_loss=-0.211 KID= 0.02649\n",
      "epoch 339, batch 9, d_loss=-0.114 g_loss=-0.285 KID= 0.02649\n",
      "epoch 339, batch 10, d_loss=-0.047 g_loss=-0.401 KID= 0.02649\n",
      "epoch 339, batch 11, d_loss=0.030 g_loss=-0.561 KID= 0.02649\n",
      "epoch 339, batch 12, d_loss=-0.073 g_loss=-0.669 KID= 0.02649\n",
      "epoch 339, batch 13, d_loss=0.095 g_loss=-0.624 KID= 0.02649\n",
      "epoch 339, batch 14, d_loss=-0.012 g_loss=-0.680 KID= 0.02649\n",
      "epoch 339, batch 15, d_loss=-0.023 g_loss=-0.591 KID= 0.02649\n",
      "epoch 339, batch 16, d_loss=0.059 g_loss=-0.448 KID= 0.02649\n",
      "epoch 339, batch 17, d_loss=-0.069 g_loss=-0.336 KID= 0.02649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 339, batch 18, d_loss=-0.212 g_loss=-0.237 KID= 0.02649\n",
      "epoch 339, batch 19, d_loss=-0.125 g_loss=-0.135 KID= 0.02649\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 340, batch 0, d_loss=-0.135 g_loss=-0.059 KID= 0.02248\n",
      "epoch 340, batch 1, d_loss=-0.151 g_loss=-0.021 KID= 0.02248\n",
      "epoch 340, batch 2, d_loss=0.014 g_loss=-0.055 KID= 0.02248\n",
      "epoch 340, batch 3, d_loss=0.043 g_loss=-0.148 KID= 0.02248\n",
      "epoch 340, batch 4, d_loss=0.060 g_loss=-0.204 KID= 0.02248\n",
      "epoch 340, batch 5, d_loss=-0.028 g_loss=-0.307 KID= 0.02248\n",
      "epoch 340, batch 6, d_loss=0.125 g_loss=-0.215 KID= 0.02248\n",
      "epoch 340, batch 7, d_loss=0.035 g_loss=-0.099 KID= 0.02248\n",
      "epoch 340, batch 8, d_loss=-0.017 g_loss=-0.039 KID= 0.02248\n",
      "epoch 340, batch 9, d_loss=-0.007 g_loss=-0.011 KID= 0.02248\n",
      "epoch 340, batch 10, d_loss=-0.065 g_loss=0.059 KID= 0.02248\n",
      "epoch 340, batch 11, d_loss=-0.057 g_loss=0.040 KID= 0.02248\n",
      "epoch 340, batch 12, d_loss=-0.149 g_loss=0.097 KID= 0.02248\n",
      "epoch 340, batch 13, d_loss=-0.091 g_loss=0.044 KID= 0.02248\n",
      "epoch 340, batch 14, d_loss=-0.190 g_loss=0.002 KID= 0.02248\n",
      "epoch 340, batch 15, d_loss=-0.018 g_loss=-0.183 KID= 0.02248\n",
      "epoch 340, batch 16, d_loss=-0.089 g_loss=-0.273 KID= 0.02248\n",
      "epoch 340, batch 17, d_loss=-0.101 g_loss=-0.368 KID= 0.02248\n",
      "epoch 340, batch 18, d_loss=0.014 g_loss=-0.474 KID= 0.02248\n",
      "epoch 340, batch 19, d_loss=-0.026 g_loss=-0.596 KID= 0.02248\n",
      "epoch 341, batch 0, d_loss=-0.089 g_loss=-0.669 KID= 0.02248\n",
      "epoch 341, batch 1, d_loss=-0.115 g_loss=-0.677 KID= 0.02248\n",
      "epoch 341, batch 2, d_loss=-0.056 g_loss=-0.618 KID= 0.02248\n",
      "epoch 341, batch 3, d_loss=-0.077 g_loss=-0.550 KID= 0.02248\n",
      "epoch 341, batch 4, d_loss=-0.027 g_loss=-0.521 KID= 0.02248\n",
      "epoch 341, batch 5, d_loss=-0.152 g_loss=-0.495 KID= 0.02248\n",
      "epoch 341, batch 6, d_loss=-0.039 g_loss=-0.331 KID= 0.02248\n",
      "epoch 341, batch 7, d_loss=-0.053 g_loss=-0.280 KID= 0.02248\n",
      "epoch 341, batch 8, d_loss=-0.131 g_loss=-0.302 KID= 0.02248\n",
      "epoch 341, batch 9, d_loss=-0.054 g_loss=-0.359 KID= 0.02248\n",
      "epoch 341, batch 10, d_loss=-0.075 g_loss=-0.472 KID= 0.02248\n",
      "epoch 341, batch 11, d_loss=0.007 g_loss=-0.541 KID= 0.02248\n",
      "epoch 341, batch 12, d_loss=0.015 g_loss=-0.595 KID= 0.02248\n",
      "epoch 341, batch 13, d_loss=0.056 g_loss=-0.530 KID= 0.02248\n",
      "epoch 341, batch 14, d_loss=-0.079 g_loss=-0.477 KID= 0.02248\n",
      "epoch 341, batch 15, d_loss=-0.058 g_loss=-0.374 KID= 0.02248\n",
      "epoch 341, batch 16, d_loss=0.008 g_loss=-0.252 KID= 0.02248\n",
      "epoch 341, batch 17, d_loss=-0.058 g_loss=-0.144 KID= 0.02248\n",
      "epoch 341, batch 18, d_loss=-0.068 g_loss=-0.146 KID= 0.02248\n",
      "epoch 341, batch 19, d_loss=-0.046 g_loss=-0.217 KID= 0.02248\n",
      "epoch 342, batch 0, d_loss=-0.082 g_loss=-0.346 KID= 0.02248\n",
      "epoch 342, batch 1, d_loss=-0.039 g_loss=-0.543 KID= 0.02248\n",
      "epoch 342, batch 2, d_loss=-0.077 g_loss=-0.710 KID= 0.02248\n",
      "epoch 342, batch 3, d_loss=-0.054 g_loss=-0.726 KID= 0.02248\n",
      "epoch 342, batch 4, d_loss=-0.082 g_loss=-0.728 KID= 0.02248\n",
      "epoch 342, batch 5, d_loss=-0.045 g_loss=-0.774 KID= 0.02248\n",
      "epoch 342, batch 6, d_loss=-0.053 g_loss=-0.653 KID= 0.02248\n",
      "epoch 342, batch 7, d_loss=-0.046 g_loss=-0.565 KID= 0.02248\n",
      "epoch 342, batch 8, d_loss=-0.094 g_loss=-0.556 KID= 0.02248\n",
      "epoch 342, batch 9, d_loss=-0.032 g_loss=-0.530 KID= 0.02248\n",
      "epoch 342, batch 10, d_loss=-0.141 g_loss=-0.543 KID= 0.02248\n",
      "epoch 342, batch 11, d_loss=-0.044 g_loss=-0.535 KID= 0.02248\n",
      "epoch 342, batch 12, d_loss=-0.093 g_loss=-0.559 KID= 0.02248\n",
      "epoch 342, batch 13, d_loss=-0.085 g_loss=-0.592 KID= 0.02248\n",
      "epoch 342, batch 14, d_loss=-0.037 g_loss=-0.711 KID= 0.02248\n",
      "epoch 342, batch 15, d_loss=-0.072 g_loss=-0.836 KID= 0.02248\n",
      "epoch 342, batch 16, d_loss=0.002 g_loss=-0.773 KID= 0.02248\n",
      "epoch 342, batch 17, d_loss=-0.040 g_loss=-0.709 KID= 0.02248\n",
      "epoch 342, batch 18, d_loss=-0.025 g_loss=-0.592 KID= 0.02248\n",
      "epoch 342, batch 19, d_loss=-0.055 g_loss=-0.465 KID= 0.02248\n",
      "epoch 343, batch 0, d_loss=-0.067 g_loss=-0.330 KID= 0.02248\n",
      "epoch 343, batch 1, d_loss=-0.097 g_loss=-0.239 KID= 0.02248\n",
      "epoch 343, batch 2, d_loss=-0.121 g_loss=-0.229 KID= 0.02248\n",
      "epoch 343, batch 3, d_loss=-0.052 g_loss=-0.209 KID= 0.02248\n",
      "epoch 343, batch 4, d_loss=-0.165 g_loss=-0.245 KID= 0.02248\n",
      "epoch 343, batch 5, d_loss=-0.074 g_loss=-0.370 KID= 0.02248\n",
      "epoch 343, batch 6, d_loss=-0.014 g_loss=-0.363 KID= 0.02248\n",
      "epoch 343, batch 7, d_loss=0.009 g_loss=-0.301 KID= 0.02248\n",
      "epoch 343, batch 8, d_loss=0.025 g_loss=-0.380 KID= 0.02248\n",
      "epoch 343, batch 9, d_loss=0.037 g_loss=-0.333 KID= 0.02248\n",
      "epoch 343, batch 10, d_loss=-0.083 g_loss=-0.283 KID= 0.02248\n",
      "epoch 343, batch 11, d_loss=-0.013 g_loss=-0.256 KID= 0.02248\n",
      "epoch 343, batch 12, d_loss=-0.041 g_loss=-0.226 KID= 0.02248\n",
      "epoch 343, batch 13, d_loss=-0.066 g_loss=-0.156 KID= 0.02248\n",
      "epoch 343, batch 14, d_loss=-0.091 g_loss=-0.139 KID= 0.02248\n",
      "epoch 343, batch 15, d_loss=-0.124 g_loss=-0.127 KID= 0.02248\n",
      "epoch 343, batch 16, d_loss=-0.112 g_loss=-0.081 KID= 0.02248\n",
      "epoch 343, batch 17, d_loss=-0.120 g_loss=-0.047 KID= 0.02248\n",
      "epoch 343, batch 18, d_loss=-0.127 g_loss=-0.103 KID= 0.02248\n",
      "epoch 343, batch 19, d_loss=0.005 g_loss=-0.286 KID= 0.02248\n",
      "epoch 344, batch 0, d_loss=-0.043 g_loss=-0.478 KID= 0.02248\n",
      "epoch 344, batch 1, d_loss=-0.059 g_loss=-0.522 KID= 0.02248\n",
      "epoch 344, batch 2, d_loss=-0.039 g_loss=-0.598 KID= 0.02248\n",
      "epoch 344, batch 3, d_loss=0.016 g_loss=-0.499 KID= 0.02248\n",
      "epoch 344, batch 4, d_loss=-0.093 g_loss=-0.432 KID= 0.02248\n",
      "epoch 344, batch 5, d_loss=-0.087 g_loss=-0.356 KID= 0.02248\n",
      "epoch 344, batch 6, d_loss=-0.047 g_loss=-0.201 KID= 0.02248\n",
      "epoch 344, batch 7, d_loss=-0.046 g_loss=-0.092 KID= 0.02248\n",
      "epoch 344, batch 8, d_loss=0.002 g_loss=-0.073 KID= 0.02248\n",
      "epoch 344, batch 9, d_loss=-0.063 g_loss=-0.086 KID= 0.02248\n",
      "epoch 344, batch 10, d_loss=-0.086 g_loss=-0.117 KID= 0.02248\n",
      "epoch 344, batch 11, d_loss=-0.037 g_loss=-0.169 KID= 0.02248\n",
      "epoch 344, batch 12, d_loss=-0.057 g_loss=-0.309 KID= 0.02248\n",
      "epoch 344, batch 13, d_loss=-0.059 g_loss=-0.383 KID= 0.02248\n",
      "epoch 344, batch 14, d_loss=-0.071 g_loss=-0.410 KID= 0.02248\n",
      "epoch 344, batch 15, d_loss=-0.118 g_loss=-0.474 KID= 0.02248\n",
      "epoch 344, batch 16, d_loss=-0.002 g_loss=-0.405 KID= 0.02248\n",
      "epoch 344, batch 17, d_loss=-0.067 g_loss=-0.341 KID= 0.02248\n",
      "epoch 344, batch 18, d_loss=-0.112 g_loss=-0.318 KID= 0.02248\n",
      "epoch 344, batch 19, d_loss=-0.045 g_loss=-0.383 KID= 0.02248\n",
      "epoch 345, batch 0, d_loss=-0.095 g_loss=-0.415 KID= 0.02248\n",
      "epoch 345, batch 1, d_loss=-0.066 g_loss=-0.386 KID= 0.02248\n",
      "epoch 345, batch 2, d_loss=-0.130 g_loss=-0.390 KID= 0.02248\n",
      "epoch 345, batch 3, d_loss=-0.014 g_loss=-0.328 KID= 0.02248\n",
      "epoch 345, batch 4, d_loss=-0.076 g_loss=-0.286 KID= 0.02248\n",
      "epoch 345, batch 5, d_loss=-0.077 g_loss=-0.276 KID= 0.02248\n",
      "epoch 345, batch 6, d_loss=-0.064 g_loss=-0.221 KID= 0.02248\n",
      "epoch 345, batch 7, d_loss=-0.055 g_loss=-0.193 KID= 0.02248\n",
      "epoch 345, batch 8, d_loss=-0.058 g_loss=-0.222 KID= 0.02248\n",
      "epoch 345, batch 9, d_loss=0.018 g_loss=-0.286 KID= 0.02248\n",
      "epoch 345, batch 10, d_loss=-0.061 g_loss=-0.339 KID= 0.02248\n",
      "epoch 345, batch 11, d_loss=-0.007 g_loss=-0.388 KID= 0.02248\n",
      "epoch 345, batch 12, d_loss=-0.053 g_loss=-0.435 KID= 0.02248\n",
      "epoch 345, batch 13, d_loss=-0.080 g_loss=-0.478 KID= 0.02248\n",
      "epoch 345, batch 14, d_loss=-0.122 g_loss=-0.534 KID= 0.02248\n",
      "epoch 345, batch 15, d_loss=-0.116 g_loss=-0.611 KID= 0.02248\n",
      "epoch 345, batch 16, d_loss=-0.044 g_loss=-0.640 KID= 0.02248\n",
      "epoch 345, batch 17, d_loss=-0.062 g_loss=-0.678 KID= 0.02248\n",
      "epoch 345, batch 18, d_loss=-0.051 g_loss=-0.730 KID= 0.02248\n",
      "epoch 345, batch 19, d_loss=-0.002 g_loss=-0.767 KID= 0.02248\n",
      "epoch 346, batch 0, d_loss=-0.097 g_loss=-0.792 KID= 0.02248\n",
      "epoch 346, batch 1, d_loss=-0.074 g_loss=-0.835 KID= 0.02248\n",
      "epoch 346, batch 2, d_loss=-0.097 g_loss=-0.807 KID= 0.02248\n",
      "epoch 346, batch 3, d_loss=-0.033 g_loss=-0.740 KID= 0.02248\n",
      "epoch 346, batch 4, d_loss=-0.129 g_loss=-0.687 KID= 0.02248\n",
      "epoch 346, batch 5, d_loss=-0.055 g_loss=-0.574 KID= 0.02248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 346, batch 6, d_loss=-0.039 g_loss=-0.498 KID= 0.02248\n",
      "epoch 346, batch 7, d_loss=-0.066 g_loss=-0.457 KID= 0.02248\n",
      "epoch 346, batch 8, d_loss=-0.060 g_loss=-0.423 KID= 0.02248\n",
      "epoch 346, batch 9, d_loss=-0.046 g_loss=-0.369 KID= 0.02248\n",
      "epoch 346, batch 10, d_loss=-0.096 g_loss=-0.363 KID= 0.02248\n",
      "epoch 346, batch 11, d_loss=-0.106 g_loss=-0.279 KID= 0.02248\n",
      "epoch 346, batch 12, d_loss=-0.117 g_loss=-0.145 KID= 0.02248\n",
      "epoch 346, batch 13, d_loss=-0.055 g_loss=-0.078 KID= 0.02248\n",
      "epoch 346, batch 14, d_loss=-0.105 g_loss=-0.105 KID= 0.02248\n",
      "epoch 346, batch 15, d_loss=-0.114 g_loss=-0.140 KID= 0.02248\n",
      "epoch 346, batch 16, d_loss=0.004 g_loss=-0.114 KID= 0.02248\n",
      "epoch 346, batch 17, d_loss=-0.006 g_loss=-0.144 KID= 0.02248\n",
      "epoch 346, batch 18, d_loss=-0.041 g_loss=-0.182 KID= 0.02248\n",
      "epoch 346, batch 19, d_loss=-0.071 g_loss=-0.217 KID= 0.02248\n",
      "epoch 347, batch 0, d_loss=-0.109 g_loss=-0.256 KID= 0.02248\n",
      "epoch 347, batch 1, d_loss=-0.070 g_loss=-0.267 KID= 0.02248\n",
      "epoch 347, batch 2, d_loss=-0.069 g_loss=-0.315 KID= 0.02248\n",
      "epoch 347, batch 3, d_loss=-0.062 g_loss=-0.280 KID= 0.02248\n",
      "epoch 347, batch 4, d_loss=-0.113 g_loss=-0.261 KID= 0.02248\n",
      "epoch 347, batch 5, d_loss=-0.114 g_loss=-0.261 KID= 0.02248\n",
      "epoch 347, batch 6, d_loss=-0.006 g_loss=-0.205 KID= 0.02248\n",
      "epoch 347, batch 7, d_loss=-0.058 g_loss=-0.183 KID= 0.02248\n",
      "epoch 347, batch 8, d_loss=-0.141 g_loss=-0.189 KID= 0.02248\n",
      "epoch 347, batch 9, d_loss=-0.027 g_loss=-0.194 KID= 0.02248\n",
      "epoch 347, batch 10, d_loss=-0.030 g_loss=-0.228 KID= 0.02248\n",
      "epoch 347, batch 11, d_loss=-0.085 g_loss=-0.234 KID= 0.02248\n",
      "epoch 347, batch 12, d_loss=-0.119 g_loss=-0.203 KID= 0.02248\n",
      "epoch 347, batch 13, d_loss=-0.014 g_loss=-0.235 KID= 0.02248\n",
      "epoch 347, batch 14, d_loss=-0.102 g_loss=-0.287 KID= 0.02248\n",
      "epoch 347, batch 15, d_loss=-0.144 g_loss=-0.318 KID= 0.02248\n",
      "epoch 347, batch 16, d_loss=-0.076 g_loss=-0.277 KID= 0.02248\n",
      "epoch 347, batch 17, d_loss=-0.091 g_loss=-0.279 KID= 0.02248\n",
      "epoch 347, batch 18, d_loss=-0.000 g_loss=-0.330 KID= 0.02248\n",
      "epoch 347, batch 19, d_loss=-0.053 g_loss=-0.397 KID= 0.02248\n",
      "epoch 348, batch 0, d_loss=-0.114 g_loss=-0.479 KID= 0.02248\n",
      "epoch 348, batch 1, d_loss=0.005 g_loss=-0.460 KID= 0.02248\n",
      "epoch 348, batch 2, d_loss=-0.017 g_loss=-0.437 KID= 0.02248\n",
      "epoch 348, batch 3, d_loss=-0.073 g_loss=-0.423 KID= 0.02248\n",
      "epoch 348, batch 4, d_loss=-0.091 g_loss=-0.506 KID= 0.02248\n",
      "epoch 348, batch 5, d_loss=-0.118 g_loss=-0.573 KID= 0.02248\n",
      "epoch 348, batch 6, d_loss=-0.071 g_loss=-0.588 KID= 0.02248\n",
      "epoch 348, batch 7, d_loss=-0.090 g_loss=-0.649 KID= 0.02248\n",
      "epoch 348, batch 8, d_loss=-0.087 g_loss=-0.638 KID= 0.02248\n",
      "epoch 348, batch 9, d_loss=0.011 g_loss=-0.593 KID= 0.02248\n",
      "epoch 348, batch 10, d_loss=-0.085 g_loss=-0.573 KID= 0.02248\n",
      "epoch 348, batch 11, d_loss=-0.093 g_loss=-0.497 KID= 0.02248\n",
      "epoch 348, batch 12, d_loss=-0.102 g_loss=-0.481 KID= 0.02248\n",
      "epoch 348, batch 13, d_loss=-0.042 g_loss=-0.393 KID= 0.02248\n",
      "epoch 348, batch 14, d_loss=-0.094 g_loss=-0.403 KID= 0.02248\n",
      "epoch 348, batch 15, d_loss=-0.104 g_loss=-0.371 KID= 0.02248\n",
      "epoch 348, batch 16, d_loss=-0.037 g_loss=-0.279 KID= 0.02248\n",
      "epoch 348, batch 17, d_loss=-0.060 g_loss=-0.167 KID= 0.02248\n",
      "epoch 348, batch 18, d_loss=-0.072 g_loss=-0.183 KID= 0.02248\n",
      "epoch 348, batch 19, d_loss=-0.019 g_loss=-0.273 KID= 0.02248\n",
      "epoch 349, batch 0, d_loss=-0.113 g_loss=-0.322 KID= 0.02248\n",
      "epoch 349, batch 1, d_loss=-0.038 g_loss=-0.318 KID= 0.02248\n",
      "epoch 349, batch 2, d_loss=-0.033 g_loss=-0.294 KID= 0.02248\n",
      "epoch 349, batch 3, d_loss=-0.046 g_loss=-0.171 KID= 0.02248\n",
      "epoch 349, batch 4, d_loss=-0.094 g_loss=-0.114 KID= 0.02248\n",
      "epoch 349, batch 5, d_loss=-0.146 g_loss=-0.083 KID= 0.02248\n",
      "epoch 349, batch 6, d_loss=-0.081 g_loss=-0.092 KID= 0.02248\n",
      "epoch 349, batch 7, d_loss=0.001 g_loss=-0.205 KID= 0.02248\n",
      "epoch 349, batch 8, d_loss=-0.049 g_loss=-0.291 KID= 0.02248\n",
      "epoch 349, batch 9, d_loss=-0.031 g_loss=-0.298 KID= 0.02248\n",
      "epoch 349, batch 10, d_loss=-0.104 g_loss=-0.344 KID= 0.02248\n",
      "epoch 349, batch 11, d_loss=-0.139 g_loss=-0.363 KID= 0.02248\n",
      "epoch 349, batch 12, d_loss=-0.177 g_loss=-0.421 KID= 0.02248\n",
      "epoch 349, batch 13, d_loss=-0.097 g_loss=-0.443 KID= 0.02248\n",
      "epoch 349, batch 14, d_loss=-0.160 g_loss=-0.480 KID= 0.02248\n",
      "epoch 349, batch 15, d_loss=-0.071 g_loss=-0.419 KID= 0.02248\n",
      "epoch 349, batch 16, d_loss=-0.009 g_loss=-0.320 KID= 0.02248\n",
      "epoch 349, batch 17, d_loss=-0.065 g_loss=-0.225 KID= 0.02248\n",
      "epoch 349, batch 18, d_loss=0.006 g_loss=-0.187 KID= 0.02248\n",
      "epoch 349, batch 19, d_loss=-0.038 g_loss=-0.242 KID= 0.02248\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 350, batch 0, d_loss=-0.111 g_loss=-0.266 KID= 0.02230\n",
      "epoch 350, batch 1, d_loss=-0.027 g_loss=-0.306 KID= 0.02230\n",
      "epoch 350, batch 2, d_loss=-0.001 g_loss=-0.370 KID= 0.02230\n",
      "epoch 350, batch 3, d_loss=-0.017 g_loss=-0.322 KID= 0.02230\n",
      "epoch 350, batch 4, d_loss=-0.103 g_loss=-0.342 KID= 0.02230\n",
      "epoch 350, batch 5, d_loss=-0.117 g_loss=-0.446 KID= 0.02230\n",
      "epoch 350, batch 6, d_loss=-0.086 g_loss=-0.515 KID= 0.02230\n",
      "epoch 350, batch 7, d_loss=-0.072 g_loss=-0.633 KID= 0.02230\n",
      "epoch 350, batch 8, d_loss=-0.084 g_loss=-0.826 KID= 0.02230\n",
      "epoch 350, batch 9, d_loss=-0.009 g_loss=-0.915 KID= 0.02230\n",
      "epoch 350, batch 10, d_loss=-0.072 g_loss=-0.942 KID= 0.02230\n",
      "epoch 350, batch 11, d_loss=-0.113 g_loss=-0.930 KID= 0.02230\n",
      "epoch 350, batch 12, d_loss=-0.133 g_loss=-0.869 KID= 0.02230\n",
      "epoch 350, batch 13, d_loss=-0.113 g_loss=-0.800 KID= 0.02230\n",
      "epoch 350, batch 14, d_loss=-0.087 g_loss=-0.755 KID= 0.02230\n",
      "epoch 350, batch 15, d_loss=-0.129 g_loss=-0.691 KID= 0.02230\n",
      "epoch 350, batch 16, d_loss=-0.027 g_loss=-0.517 KID= 0.02230\n",
      "epoch 350, batch 17, d_loss=-0.033 g_loss=-0.337 KID= 0.02230\n",
      "epoch 350, batch 18, d_loss=-0.097 g_loss=-0.202 KID= 0.02230\n",
      "epoch 350, batch 19, d_loss=-0.041 g_loss=-0.139 KID= 0.02230\n",
      "epoch 351, batch 0, d_loss=-0.123 g_loss=-0.160 KID= 0.02230\n",
      "epoch 351, batch 1, d_loss=-0.069 g_loss=-0.204 KID= 0.02230\n",
      "epoch 351, batch 2, d_loss=-0.064 g_loss=-0.280 KID= 0.02230\n",
      "epoch 351, batch 3, d_loss=-0.038 g_loss=-0.266 KID= 0.02230\n",
      "epoch 351, batch 4, d_loss=-0.090 g_loss=-0.219 KID= 0.02230\n",
      "epoch 351, batch 5, d_loss=-0.127 g_loss=-0.144 KID= 0.02230\n",
      "epoch 351, batch 6, d_loss=-0.025 g_loss=-0.039 KID= 0.02230\n",
      "epoch 351, batch 7, d_loss=-0.069 g_loss=0.008 KID= 0.02230\n",
      "epoch 351, batch 8, d_loss=-0.017 g_loss=-0.030 KID= 0.02230\n",
      "epoch 351, batch 9, d_loss=-0.020 g_loss=-0.170 KID= 0.02230\n",
      "epoch 351, batch 10, d_loss=-0.042 g_loss=-0.302 KID= 0.02230\n",
      "epoch 351, batch 11, d_loss=0.007 g_loss=-0.414 KID= 0.02230\n",
      "epoch 351, batch 12, d_loss=-0.074 g_loss=-0.497 KID= 0.02230\n",
      "epoch 351, batch 13, d_loss=-0.067 g_loss=-0.484 KID= 0.02230\n",
      "epoch 351, batch 14, d_loss=-0.173 g_loss=-0.471 KID= 0.02230\n",
      "epoch 351, batch 15, d_loss=-0.137 g_loss=-0.462 KID= 0.02230\n",
      "epoch 351, batch 16, d_loss=-0.060 g_loss=-0.389 KID= 0.02230\n",
      "epoch 351, batch 17, d_loss=-0.118 g_loss=-0.370 KID= 0.02230\n",
      "epoch 351, batch 18, d_loss=-0.048 g_loss=-0.350 KID= 0.02230\n",
      "epoch 351, batch 19, d_loss=0.099 g_loss=-0.309 KID= 0.02230\n",
      "epoch 352, batch 0, d_loss=-0.055 g_loss=-0.308 KID= 0.02230\n",
      "epoch 352, batch 1, d_loss=0.018 g_loss=-0.229 KID= 0.02230\n",
      "epoch 352, batch 2, d_loss=0.003 g_loss=-0.057 KID= 0.02230\n",
      "epoch 352, batch 3, d_loss=-0.083 g_loss=0.092 KID= 0.02230\n",
      "epoch 352, batch 4, d_loss=-0.109 g_loss=0.189 KID= 0.02230\n",
      "epoch 352, batch 5, d_loss=-0.162 g_loss=0.231 KID= 0.02230\n",
      "epoch 352, batch 6, d_loss=-0.122 g_loss=0.292 KID= 0.02230\n",
      "epoch 352, batch 7, d_loss=-0.030 g_loss=0.317 KID= 0.02230\n",
      "epoch 352, batch 8, d_loss=-0.073 g_loss=0.207 KID= 0.02230\n",
      "epoch 352, batch 9, d_loss=-0.065 g_loss=0.058 KID= 0.02230\n",
      "epoch 352, batch 10, d_loss=-0.015 g_loss=-0.134 KID= 0.02230\n",
      "epoch 352, batch 11, d_loss=-0.127 g_loss=-0.285 KID= 0.02230\n",
      "epoch 352, batch 12, d_loss=-0.167 g_loss=-0.430 KID= 0.02230\n",
      "epoch 352, batch 13, d_loss=-0.095 g_loss=-0.559 KID= 0.02230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 352, batch 14, d_loss=-0.097 g_loss=-0.655 KID= 0.02230\n",
      "epoch 352, batch 15, d_loss=-0.096 g_loss=-0.762 KID= 0.02230\n",
      "epoch 352, batch 16, d_loss=0.002 g_loss=-0.713 KID= 0.02230\n",
      "epoch 352, batch 17, d_loss=-0.110 g_loss=-0.794 KID= 0.02230\n",
      "epoch 352, batch 18, d_loss=-0.118 g_loss=-0.886 KID= 0.02230\n",
      "epoch 352, batch 19, d_loss=-0.003 g_loss=-0.892 KID= 0.02230\n",
      "epoch 353, batch 0, d_loss=-0.130 g_loss=-0.890 KID= 0.02230\n",
      "epoch 353, batch 1, d_loss=-0.020 g_loss=-0.708 KID= 0.02230\n",
      "epoch 353, batch 2, d_loss=-0.058 g_loss=-0.553 KID= 0.02230\n",
      "epoch 353, batch 3, d_loss=-0.077 g_loss=-0.490 KID= 0.02230\n",
      "epoch 353, batch 4, d_loss=-0.083 g_loss=-0.489 KID= 0.02230\n",
      "epoch 353, batch 5, d_loss=-0.090 g_loss=-0.494 KID= 0.02230\n",
      "epoch 353, batch 6, d_loss=-0.076 g_loss=-0.493 KID= 0.02230\n",
      "epoch 353, batch 7, d_loss=-0.129 g_loss=-0.592 KID= 0.02230\n",
      "epoch 353, batch 8, d_loss=-0.044 g_loss=-0.667 KID= 0.02230\n",
      "epoch 353, batch 9, d_loss=0.041 g_loss=-0.620 KID= 0.02230\n",
      "epoch 353, batch 10, d_loss=-0.117 g_loss=-0.633 KID= 0.02230\n",
      "epoch 353, batch 11, d_loss=-0.062 g_loss=-0.588 KID= 0.02230\n",
      "epoch 353, batch 12, d_loss=-0.092 g_loss=-0.467 KID= 0.02230\n",
      "epoch 353, batch 13, d_loss=-0.109 g_loss=-0.347 KID= 0.02230\n",
      "epoch 353, batch 14, d_loss=-0.137 g_loss=-0.279 KID= 0.02230\n",
      "epoch 353, batch 15, d_loss=-0.140 g_loss=-0.217 KID= 0.02230\n",
      "epoch 353, batch 16, d_loss=-0.089 g_loss=-0.094 KID= 0.02230\n",
      "epoch 353, batch 17, d_loss=-0.059 g_loss=-0.056 KID= 0.02230\n",
      "epoch 353, batch 18, d_loss=-0.020 g_loss=-0.128 KID= 0.02230\n",
      "epoch 353, batch 19, d_loss=-0.050 g_loss=-0.208 KID= 0.02230\n",
      "epoch 354, batch 0, d_loss=-0.091 g_loss=-0.315 KID= 0.02230\n",
      "epoch 354, batch 1, d_loss=-0.046 g_loss=-0.369 KID= 0.02230\n",
      "epoch 354, batch 2, d_loss=-0.056 g_loss=-0.374 KID= 0.02230\n",
      "epoch 354, batch 3, d_loss=-0.105 g_loss=-0.404 KID= 0.02230\n",
      "epoch 354, batch 4, d_loss=-0.123 g_loss=-0.482 KID= 0.02230\n",
      "epoch 354, batch 5, d_loss=-0.101 g_loss=-0.552 KID= 0.02230\n",
      "epoch 354, batch 6, d_loss=0.009 g_loss=-0.472 KID= 0.02230\n",
      "epoch 354, batch 7, d_loss=-0.071 g_loss=-0.433 KID= 0.02230\n",
      "epoch 354, batch 8, d_loss=-0.100 g_loss=-0.416 KID= 0.02230\n",
      "epoch 354, batch 9, d_loss=-0.025 g_loss=-0.342 KID= 0.02230\n",
      "epoch 354, batch 10, d_loss=-0.122 g_loss=-0.389 KID= 0.02230\n",
      "epoch 354, batch 11, d_loss=-0.071 g_loss=-0.356 KID= 0.02230\n",
      "epoch 354, batch 12, d_loss=-0.115 g_loss=-0.294 KID= 0.02230\n",
      "epoch 354, batch 13, d_loss=-0.067 g_loss=-0.278 KID= 0.02230\n",
      "epoch 354, batch 14, d_loss=-0.065 g_loss=-0.340 KID= 0.02230\n",
      "epoch 354, batch 15, d_loss=-0.093 g_loss=-0.413 KID= 0.02230\n",
      "epoch 354, batch 16, d_loss=-0.044 g_loss=-0.377 KID= 0.02230\n",
      "epoch 354, batch 17, d_loss=-0.054 g_loss=-0.414 KID= 0.02230\n",
      "epoch 354, batch 18, d_loss=-0.116 g_loss=-0.523 KID= 0.02230\n",
      "epoch 354, batch 19, d_loss=-0.049 g_loss=-0.537 KID= 0.02230\n",
      "epoch 355, batch 0, d_loss=-0.094 g_loss=-0.562 KID= 0.02230\n",
      "epoch 355, batch 1, d_loss=-0.053 g_loss=-0.573 KID= 0.02230\n",
      "epoch 355, batch 2, d_loss=-0.068 g_loss=-0.500 KID= 0.02230\n",
      "epoch 355, batch 3, d_loss=-0.114 g_loss=-0.482 KID= 0.02230\n",
      "epoch 355, batch 4, d_loss=-0.105 g_loss=-0.486 KID= 0.02230\n",
      "epoch 355, batch 5, d_loss=-0.105 g_loss=-0.493 KID= 0.02230\n",
      "epoch 355, batch 6, d_loss=0.008 g_loss=-0.373 KID= 0.02230\n",
      "epoch 355, batch 7, d_loss=-0.109 g_loss=-0.325 KID= 0.02230\n",
      "epoch 355, batch 8, d_loss=-0.098 g_loss=-0.310 KID= 0.02230\n",
      "epoch 355, batch 9, d_loss=-0.080 g_loss=-0.315 KID= 0.02230\n",
      "epoch 355, batch 10, d_loss=-0.156 g_loss=-0.372 KID= 0.02230\n",
      "epoch 355, batch 11, d_loss=-0.114 g_loss=-0.384 KID= 0.02230\n",
      "epoch 355, batch 12, d_loss=-0.113 g_loss=-0.354 KID= 0.02230\n",
      "epoch 355, batch 13, d_loss=-0.070 g_loss=-0.331 KID= 0.02230\n",
      "epoch 355, batch 14, d_loss=-0.084 g_loss=-0.356 KID= 0.02230\n",
      "epoch 355, batch 15, d_loss=-0.114 g_loss=-0.341 KID= 0.02230\n",
      "epoch 355, batch 16, d_loss=-0.071 g_loss=-0.220 KID= 0.02230\n",
      "epoch 355, batch 17, d_loss=-0.073 g_loss=-0.183 KID= 0.02230\n",
      "epoch 355, batch 18, d_loss=0.008 g_loss=-0.221 KID= 0.02230\n",
      "epoch 355, batch 19, d_loss=-0.044 g_loss=-0.280 KID= 0.02230\n",
      "epoch 356, batch 0, d_loss=-0.076 g_loss=-0.351 KID= 0.02230\n",
      "epoch 356, batch 1, d_loss=-0.079 g_loss=-0.398 KID= 0.02230\n",
      "epoch 356, batch 2, d_loss=-0.061 g_loss=-0.418 KID= 0.02230\n",
      "epoch 356, batch 3, d_loss=-0.057 g_loss=-0.395 KID= 0.02230\n",
      "epoch 356, batch 4, d_loss=-0.110 g_loss=-0.364 KID= 0.02230\n",
      "epoch 356, batch 5, d_loss=-0.094 g_loss=-0.272 KID= 0.02230\n",
      "epoch 356, batch 6, d_loss=-0.073 g_loss=-0.125 KID= 0.02230\n",
      "epoch 356, batch 7, d_loss=-0.107 g_loss=-0.053 KID= 0.02230\n",
      "epoch 356, batch 8, d_loss=-0.084 g_loss=-0.072 KID= 0.02230\n",
      "epoch 356, batch 9, d_loss=-0.066 g_loss=-0.064 KID= 0.02230\n",
      "epoch 356, batch 10, d_loss=-0.085 g_loss=-0.082 KID= 0.02230\n",
      "epoch 356, batch 11, d_loss=-0.066 g_loss=-0.063 KID= 0.02230\n",
      "epoch 356, batch 12, d_loss=-0.044 g_loss=-0.031 KID= 0.02230\n",
      "epoch 356, batch 13, d_loss=-0.070 g_loss=-0.037 KID= 0.02230\n",
      "epoch 356, batch 14, d_loss=-0.042 g_loss=-0.183 KID= 0.02230\n",
      "epoch 356, batch 15, d_loss=-0.119 g_loss=-0.312 KID= 0.02230\n",
      "epoch 356, batch 16, d_loss=-0.072 g_loss=-0.363 KID= 0.02230\n",
      "epoch 356, batch 17, d_loss=-0.068 g_loss=-0.434 KID= 0.02230\n",
      "epoch 356, batch 18, d_loss=-0.122 g_loss=-0.472 KID= 0.02230\n",
      "epoch 356, batch 19, d_loss=-0.071 g_loss=-0.539 KID= 0.02230\n",
      "epoch 357, batch 0, d_loss=-0.088 g_loss=-0.567 KID= 0.02230\n",
      "epoch 357, batch 1, d_loss=-0.050 g_loss=-0.645 KID= 0.02230\n",
      "epoch 357, batch 2, d_loss=-0.098 g_loss=-0.688 KID= 0.02230\n",
      "epoch 357, batch 3, d_loss=-0.045 g_loss=-0.669 KID= 0.02230\n",
      "epoch 357, batch 4, d_loss=-0.100 g_loss=-0.700 KID= 0.02230\n",
      "epoch 357, batch 5, d_loss=-0.067 g_loss=-0.643 KID= 0.02230\n",
      "epoch 357, batch 6, d_loss=-0.098 g_loss=-0.592 KID= 0.02230\n",
      "epoch 357, batch 7, d_loss=-0.115 g_loss=-0.609 KID= 0.02230\n",
      "epoch 357, batch 8, d_loss=-0.046 g_loss=-0.634 KID= 0.02230\n",
      "epoch 357, batch 9, d_loss=-0.013 g_loss=-0.595 KID= 0.02230\n",
      "epoch 357, batch 10, d_loss=-0.124 g_loss=-0.599 KID= 0.02230\n",
      "epoch 357, batch 11, d_loss=-0.071 g_loss=-0.537 KID= 0.02230\n",
      "epoch 357, batch 12, d_loss=-0.073 g_loss=-0.446 KID= 0.02230\n",
      "epoch 357, batch 13, d_loss=-0.141 g_loss=-0.418 KID= 0.02230\n",
      "epoch 357, batch 14, d_loss=-0.093 g_loss=-0.481 KID= 0.02230\n",
      "epoch 357, batch 15, d_loss=-0.100 g_loss=-0.511 KID= 0.02230\n",
      "epoch 357, batch 16, d_loss=-0.024 g_loss=-0.462 KID= 0.02230\n",
      "epoch 357, batch 17, d_loss=-0.023 g_loss=-0.409 KID= 0.02230\n",
      "epoch 357, batch 18, d_loss=-0.117 g_loss=-0.377 KID= 0.02230\n",
      "epoch 357, batch 19, d_loss=-0.090 g_loss=-0.313 KID= 0.02230\n",
      "epoch 358, batch 0, d_loss=-0.058 g_loss=-0.311 KID= 0.02230\n",
      "epoch 358, batch 1, d_loss=-0.086 g_loss=-0.284 KID= 0.02230\n",
      "epoch 358, batch 2, d_loss=-0.073 g_loss=-0.216 KID= 0.02230\n",
      "epoch 358, batch 3, d_loss=-0.045 g_loss=-0.189 KID= 0.02230\n",
      "epoch 358, batch 4, d_loss=-0.077 g_loss=-0.161 KID= 0.02230\n",
      "epoch 358, batch 5, d_loss=-0.087 g_loss=-0.139 KID= 0.02230\n",
      "epoch 358, batch 6, d_loss=-0.080 g_loss=-0.016 KID= 0.02230\n",
      "epoch 358, batch 7, d_loss=-0.119 g_loss=0.020 KID= 0.02230\n",
      "epoch 358, batch 8, d_loss=-0.042 g_loss=-0.014 KID= 0.02230\n",
      "epoch 358, batch 9, d_loss=-0.023 g_loss=-0.072 KID= 0.02230\n",
      "epoch 358, batch 10, d_loss=-0.092 g_loss=-0.144 KID= 0.02230\n",
      "epoch 358, batch 11, d_loss=-0.051 g_loss=-0.238 KID= 0.02230\n",
      "epoch 358, batch 12, d_loss=-0.025 g_loss=-0.232 KID= 0.02230\n",
      "epoch 358, batch 13, d_loss=-0.074 g_loss=-0.237 KID= 0.02230\n",
      "epoch 358, batch 14, d_loss=-0.092 g_loss=-0.302 KID= 0.02230\n",
      "epoch 358, batch 15, d_loss=-0.169 g_loss=-0.324 KID= 0.02230\n",
      "epoch 358, batch 16, d_loss=-0.101 g_loss=-0.314 KID= 0.02230\n",
      "epoch 358, batch 17, d_loss=-0.085 g_loss=-0.391 KID= 0.02230\n",
      "epoch 358, batch 18, d_loss=-0.038 g_loss=-0.558 KID= 0.02230\n",
      "epoch 358, batch 19, d_loss=-0.023 g_loss=-0.604 KID= 0.02230\n",
      "epoch 359, batch 0, d_loss=-0.066 g_loss=-0.671 KID= 0.02230\n",
      "epoch 359, batch 1, d_loss=-0.064 g_loss=-0.802 KID= 0.02230\n",
      "epoch 359, batch 2, d_loss=-0.071 g_loss=-0.832 KID= 0.02230\n",
      "epoch 359, batch 3, d_loss=-0.073 g_loss=-0.779 KID= 0.02230\n",
      "epoch 359, batch 4, d_loss=-0.088 g_loss=-0.700 KID= 0.02230\n",
      "epoch 359, batch 5, d_loss=-0.118 g_loss=-0.586 KID= 0.02230\n",
      "epoch 359, batch 6, d_loss=-0.045 g_loss=-0.358 KID= 0.02230\n",
      "epoch 359, batch 7, d_loss=-0.068 g_loss=-0.234 KID= 0.02230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 359, batch 8, d_loss=-0.087 g_loss=-0.247 KID= 0.02230\n",
      "epoch 359, batch 9, d_loss=-0.078 g_loss=-0.204 KID= 0.02230\n",
      "epoch 359, batch 10, d_loss=-0.097 g_loss=-0.059 KID= 0.02230\n",
      "epoch 359, batch 11, d_loss=-0.105 g_loss=0.070 KID= 0.02230\n",
      "epoch 359, batch 12, d_loss=-0.114 g_loss=0.207 KID= 0.02230\n",
      "epoch 359, batch 13, d_loss=-0.091 g_loss=0.246 KID= 0.02230\n",
      "epoch 359, batch 14, d_loss=-0.061 g_loss=0.142 KID= 0.02230\n",
      "epoch 359, batch 15, d_loss=-0.034 g_loss=0.125 KID= 0.02230\n",
      "epoch 359, batch 16, d_loss=-0.001 g_loss=0.183 KID= 0.02230\n",
      "epoch 359, batch 17, d_loss=-0.137 g_loss=0.216 KID= 0.02230\n",
      "epoch 359, batch 18, d_loss=-0.137 g_loss=0.248 KID= 0.02230\n",
      "epoch 359, batch 19, d_loss=-0.129 g_loss=0.294 KID= 0.02230\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 360, batch 0, d_loss=-0.117 g_loss=0.282 KID= 0.01605\n",
      "epoch 360, batch 1, d_loss=-0.056 g_loss=0.248 KID= 0.01605\n",
      "epoch 360, batch 2, d_loss=-0.028 g_loss=0.288 KID= 0.01605\n",
      "epoch 360, batch 3, d_loss=0.012 g_loss=0.259 KID= 0.01605\n",
      "epoch 360, batch 4, d_loss=-0.107 g_loss=0.174 KID= 0.01605\n",
      "epoch 360, batch 5, d_loss=-0.132 g_loss=0.116 KID= 0.01605\n",
      "epoch 360, batch 6, d_loss=-0.023 g_loss=0.018 KID= 0.01605\n",
      "epoch 360, batch 7, d_loss=-0.078 g_loss=-0.026 KID= 0.01605\n",
      "epoch 360, batch 8, d_loss=-0.110 g_loss=-0.093 KID= 0.01605\n",
      "epoch 360, batch 9, d_loss=-0.055 g_loss=-0.232 KID= 0.01605\n",
      "epoch 360, batch 10, d_loss=-0.112 g_loss=-0.427 KID= 0.01605\n",
      "epoch 360, batch 11, d_loss=-0.094 g_loss=-0.624 KID= 0.01605\n",
      "epoch 360, batch 12, d_loss=-0.106 g_loss=-0.767 KID= 0.01605\n",
      "epoch 360, batch 13, d_loss=-0.160 g_loss=-0.818 KID= 0.01605\n",
      "epoch 360, batch 14, d_loss=-0.153 g_loss=-0.966 KID= 0.01605\n",
      "epoch 360, batch 15, d_loss=-0.113 g_loss=-0.999 KID= 0.01605\n",
      "epoch 360, batch 16, d_loss=-0.051 g_loss=-0.839 KID= 0.01605\n",
      "epoch 360, batch 17, d_loss=-0.002 g_loss=-0.703 KID= 0.01605\n",
      "epoch 360, batch 18, d_loss=-0.001 g_loss=-0.637 KID= 0.01605\n",
      "epoch 360, batch 19, d_loss=-0.010 g_loss=-0.503 KID= 0.01605\n",
      "epoch 361, batch 0, d_loss=-0.054 g_loss=-0.517 KID= 0.01605\n",
      "epoch 361, batch 1, d_loss=-0.102 g_loss=-0.472 KID= 0.01605\n",
      "epoch 361, batch 2, d_loss=-0.155 g_loss=-0.471 KID= 0.01605\n",
      "epoch 361, batch 3, d_loss=-0.107 g_loss=-0.442 KID= 0.01605\n",
      "epoch 361, batch 4, d_loss=-0.103 g_loss=-0.509 KID= 0.01605\n",
      "epoch 361, batch 5, d_loss=-0.128 g_loss=-0.520 KID= 0.01605\n",
      "epoch 361, batch 6, d_loss=-0.012 g_loss=-0.376 KID= 0.01605\n",
      "epoch 361, batch 7, d_loss=-0.153 g_loss=-0.297 KID= 0.01605\n",
      "epoch 361, batch 8, d_loss=-0.143 g_loss=-0.264 KID= 0.01605\n",
      "epoch 361, batch 9, d_loss=-0.086 g_loss=-0.305 KID= 0.01605\n",
      "epoch 361, batch 10, d_loss=-0.084 g_loss=-0.420 KID= 0.01605\n",
      "epoch 361, batch 11, d_loss=-0.058 g_loss=-0.352 KID= 0.01605\n",
      "epoch 361, batch 12, d_loss=0.006 g_loss=-0.243 KID= 0.01605\n",
      "epoch 361, batch 13, d_loss=-0.113 g_loss=-0.061 KID= 0.01605\n",
      "epoch 361, batch 14, d_loss=-0.132 g_loss=-0.003 KID= 0.01605\n",
      "epoch 361, batch 15, d_loss=-0.110 g_loss=0.031 KID= 0.01605\n",
      "epoch 361, batch 16, d_loss=-0.142 g_loss=0.033 KID= 0.01605\n",
      "epoch 361, batch 17, d_loss=-0.093 g_loss=0.056 KID= 0.01605\n",
      "epoch 361, batch 18, d_loss=-0.073 g_loss=0.015 KID= 0.01605\n",
      "epoch 361, batch 19, d_loss=-0.063 g_loss=-0.104 KID= 0.01605\n",
      "epoch 362, batch 0, d_loss=-0.062 g_loss=-0.203 KID= 0.01605\n",
      "epoch 362, batch 1, d_loss=-0.080 g_loss=-0.294 KID= 0.01605\n",
      "epoch 362, batch 2, d_loss=-0.114 g_loss=-0.383 KID= 0.01605\n",
      "epoch 362, batch 3, d_loss=-0.083 g_loss=-0.400 KID= 0.01605\n",
      "epoch 362, batch 4, d_loss=-0.095 g_loss=-0.520 KID= 0.01605\n",
      "epoch 362, batch 5, d_loss=-0.054 g_loss=-0.554 KID= 0.01605\n",
      "epoch 362, batch 6, d_loss=0.053 g_loss=-0.411 KID= 0.01605\n",
      "epoch 362, batch 7, d_loss=-0.076 g_loss=-0.356 KID= 0.01605\n",
      "epoch 362, batch 8, d_loss=-0.061 g_loss=-0.320 KID= 0.01605\n",
      "epoch 362, batch 9, d_loss=-0.091 g_loss=-0.279 KID= 0.01605\n",
      "epoch 362, batch 10, d_loss=-0.103 g_loss=-0.305 KID= 0.01605\n",
      "epoch 362, batch 11, d_loss=-0.074 g_loss=-0.236 KID= 0.01605\n",
      "epoch 362, batch 12, d_loss=-0.019 g_loss=-0.152 KID= 0.01605\n",
      "epoch 362, batch 13, d_loss=-0.092 g_loss=-0.085 KID= 0.01605\n",
      "epoch 362, batch 14, d_loss=-0.087 g_loss=-0.172 KID= 0.01605\n",
      "epoch 362, batch 15, d_loss=-0.116 g_loss=-0.267 KID= 0.01605\n",
      "epoch 362, batch 16, d_loss=-0.110 g_loss=-0.372 KID= 0.01605\n",
      "epoch 362, batch 17, d_loss=-0.128 g_loss=-0.493 KID= 0.01605\n",
      "epoch 362, batch 18, d_loss=-0.139 g_loss=-0.575 KID= 0.01605\n",
      "epoch 362, batch 19, d_loss=-0.057 g_loss=-0.636 KID= 0.01605\n",
      "epoch 363, batch 0, d_loss=-0.092 g_loss=-0.701 KID= 0.01605\n",
      "epoch 363, batch 1, d_loss=-0.067 g_loss=-0.656 KID= 0.01605\n",
      "epoch 363, batch 2, d_loss=-0.065 g_loss=-0.612 KID= 0.01605\n",
      "epoch 363, batch 3, d_loss=-0.068 g_loss=-0.462 KID= 0.01605\n",
      "epoch 363, batch 4, d_loss=-0.088 g_loss=-0.449 KID= 0.01605\n",
      "epoch 363, batch 5, d_loss=-0.089 g_loss=-0.358 KID= 0.01605\n",
      "epoch 363, batch 6, d_loss=-0.129 g_loss=-0.213 KID= 0.01605\n",
      "epoch 363, batch 7, d_loss=-0.164 g_loss=-0.143 KID= 0.01605\n",
      "epoch 363, batch 8, d_loss=-0.058 g_loss=-0.155 KID= 0.01605\n",
      "epoch 363, batch 9, d_loss=-0.061 g_loss=-0.261 KID= 0.01605\n",
      "epoch 363, batch 10, d_loss=-0.058 g_loss=-0.331 KID= 0.01605\n",
      "epoch 363, batch 11, d_loss=-0.074 g_loss=-0.474 KID= 0.01605\n",
      "epoch 363, batch 12, d_loss=-0.030 g_loss=-0.467 KID= 0.01605\n",
      "epoch 363, batch 13, d_loss=-0.054 g_loss=-0.396 KID= 0.01605\n",
      "epoch 363, batch 14, d_loss=-0.091 g_loss=-0.416 KID= 0.01605\n",
      "epoch 363, batch 15, d_loss=-0.088 g_loss=-0.376 KID= 0.01605\n",
      "epoch 363, batch 16, d_loss=-0.047 g_loss=-0.296 KID= 0.01605\n",
      "epoch 363, batch 17, d_loss=-0.090 g_loss=-0.267 KID= 0.01605\n",
      "epoch 363, batch 18, d_loss=-0.086 g_loss=-0.229 KID= 0.01605\n",
      "epoch 363, batch 19, d_loss=-0.069 g_loss=-0.197 KID= 0.01605\n",
      "epoch 364, batch 0, d_loss=-0.094 g_loss=-0.112 KID= 0.01605\n",
      "epoch 364, batch 1, d_loss=-0.095 g_loss=-0.026 KID= 0.01605\n",
      "epoch 364, batch 2, d_loss=-0.112 g_loss=0.104 KID= 0.01605\n",
      "epoch 364, batch 3, d_loss=-0.179 g_loss=0.199 KID= 0.01605\n",
      "epoch 364, batch 4, d_loss=-0.124 g_loss=0.290 KID= 0.01605\n",
      "epoch 364, batch 5, d_loss=-0.119 g_loss=0.334 KID= 0.01605\n",
      "epoch 364, batch 6, d_loss=-0.119 g_loss=0.260 KID= 0.01605\n",
      "epoch 364, batch 7, d_loss=-0.074 g_loss=0.096 KID= 0.01605\n",
      "epoch 364, batch 8, d_loss=-0.027 g_loss=-0.099 KID= 0.01605\n",
      "epoch 364, batch 9, d_loss=-0.005 g_loss=-0.309 KID= 0.01605\n",
      "epoch 364, batch 10, d_loss=-0.088 g_loss=-0.504 KID= 0.01605\n",
      "epoch 364, batch 11, d_loss=-0.114 g_loss=-0.653 KID= 0.01605\n",
      "epoch 364, batch 12, d_loss=-0.067 g_loss=-0.750 KID= 0.01605\n",
      "epoch 364, batch 13, d_loss=-0.071 g_loss=-0.778 KID= 0.01605\n",
      "epoch 364, batch 14, d_loss=-0.112 g_loss=-0.820 KID= 0.01605\n",
      "epoch 364, batch 15, d_loss=-0.158 g_loss=-0.824 KID= 0.01605\n",
      "epoch 364, batch 16, d_loss=-0.032 g_loss=-0.732 KID= 0.01605\n",
      "epoch 364, batch 17, d_loss=-0.033 g_loss=-0.741 KID= 0.01605\n",
      "epoch 364, batch 18, d_loss=-0.048 g_loss=-0.616 KID= 0.01605\n",
      "epoch 364, batch 19, d_loss=-0.092 g_loss=-0.560 KID= 0.01605\n",
      "epoch 365, batch 0, d_loss=-0.084 g_loss=-0.499 KID= 0.01605\n",
      "epoch 365, batch 1, d_loss=-0.091 g_loss=-0.387 KID= 0.01605\n",
      "epoch 365, batch 2, d_loss=-0.107 g_loss=-0.327 KID= 0.01605\n",
      "epoch 365, batch 3, d_loss=-0.169 g_loss=-0.321 KID= 0.01605\n",
      "epoch 365, batch 4, d_loss=-0.127 g_loss=-0.339 KID= 0.01605\n",
      "epoch 365, batch 5, d_loss=-0.042 g_loss=-0.330 KID= 0.01605\n",
      "epoch 365, batch 6, d_loss=-0.031 g_loss=-0.272 KID= 0.01605\n",
      "epoch 365, batch 7, d_loss=-0.097 g_loss=-0.171 KID= 0.01605\n",
      "epoch 365, batch 8, d_loss=-0.100 g_loss=-0.144 KID= 0.01605\n",
      "epoch 365, batch 9, d_loss=-0.056 g_loss=-0.097 KID= 0.01605\n",
      "epoch 365, batch 10, d_loss=-0.163 g_loss=-0.115 KID= 0.01605\n",
      "epoch 365, batch 11, d_loss=-0.116 g_loss=-0.142 KID= 0.01605\n",
      "epoch 365, batch 12, d_loss=-0.098 g_loss=-0.165 KID= 0.01605\n",
      "epoch 365, batch 13, d_loss=-0.054 g_loss=-0.182 KID= 0.01605\n",
      "epoch 365, batch 14, d_loss=-0.027 g_loss=-0.187 KID= 0.01605\n",
      "epoch 365, batch 15, d_loss=-0.116 g_loss=-0.169 KID= 0.01605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 365, batch 16, d_loss=-0.031 g_loss=-0.104 KID= 0.01605\n",
      "epoch 365, batch 17, d_loss=-0.071 g_loss=-0.134 KID= 0.01605\n",
      "epoch 365, batch 18, d_loss=-0.059 g_loss=-0.193 KID= 0.01605\n",
      "epoch 365, batch 19, d_loss=-0.122 g_loss=-0.243 KID= 0.01605\n",
      "epoch 366, batch 0, d_loss=-0.086 g_loss=-0.286 KID= 0.01605\n",
      "epoch 366, batch 1, d_loss=-0.143 g_loss=-0.327 KID= 0.01605\n",
      "epoch 366, batch 2, d_loss=-0.115 g_loss=-0.322 KID= 0.01605\n",
      "epoch 366, batch 3, d_loss=-0.146 g_loss=-0.328 KID= 0.01605\n",
      "epoch 366, batch 4, d_loss=-0.090 g_loss=-0.308 KID= 0.01605\n",
      "epoch 366, batch 5, d_loss=-0.099 g_loss=-0.329 KID= 0.01605\n",
      "epoch 366, batch 6, d_loss=-0.043 g_loss=-0.348 KID= 0.01605\n",
      "epoch 366, batch 7, d_loss=-0.096 g_loss=-0.411 KID= 0.01605\n",
      "epoch 366, batch 8, d_loss=-0.081 g_loss=-0.534 KID= 0.01605\n",
      "epoch 366, batch 9, d_loss=-0.048 g_loss=-0.693 KID= 0.01605\n",
      "epoch 366, batch 10, d_loss=-0.100 g_loss=-0.840 KID= 0.01605\n",
      "epoch 366, batch 11, d_loss=-0.108 g_loss=-0.957 KID= 0.01605\n",
      "epoch 366, batch 12, d_loss=-0.095 g_loss=-1.037 KID= 0.01605\n",
      "epoch 366, batch 13, d_loss=-0.133 g_loss=-1.041 KID= 0.01605\n",
      "epoch 366, batch 14, d_loss=-0.140 g_loss=-1.130 KID= 0.01605\n",
      "epoch 366, batch 15, d_loss=-0.040 g_loss=-0.931 KID= 0.01605\n",
      "epoch 366, batch 16, d_loss=0.031 g_loss=-0.736 KID= 0.01605\n",
      "epoch 366, batch 17, d_loss=-0.079 g_loss=-0.612 KID= 0.01605\n",
      "epoch 366, batch 18, d_loss=-0.060 g_loss=-0.620 KID= 0.01605\n",
      "epoch 366, batch 19, d_loss=-0.102 g_loss=-0.602 KID= 0.01605\n",
      "epoch 367, batch 0, d_loss=-0.103 g_loss=-0.549 KID= 0.01605\n",
      "epoch 367, batch 1, d_loss=-0.137 g_loss=-0.498 KID= 0.01605\n",
      "epoch 367, batch 2, d_loss=-0.075 g_loss=-0.385 KID= 0.01605\n",
      "epoch 367, batch 3, d_loss=-0.149 g_loss=-0.289 KID= 0.01605\n",
      "epoch 367, batch 4, d_loss=-0.115 g_loss=-0.191 KID= 0.01605\n",
      "epoch 367, batch 5, d_loss=-0.137 g_loss=-0.148 KID= 0.01605\n",
      "epoch 367, batch 6, d_loss=-0.027 g_loss=-0.161 KID= 0.01605\n",
      "epoch 367, batch 7, d_loss=-0.109 g_loss=-0.141 KID= 0.01605\n",
      "epoch 367, batch 8, d_loss=-0.102 g_loss=-0.175 KID= 0.01605\n",
      "epoch 367, batch 9, d_loss=0.027 g_loss=-0.202 KID= 0.01605\n",
      "epoch 367, batch 10, d_loss=-0.089 g_loss=-0.242 KID= 0.01605\n",
      "epoch 367, batch 11, d_loss=-0.070 g_loss=-0.245 KID= 0.01605\n",
      "epoch 367, batch 12, d_loss=-0.107 g_loss=-0.227 KID= 0.01605\n",
      "epoch 367, batch 13, d_loss=-0.148 g_loss=-0.166 KID= 0.01605\n",
      "epoch 367, batch 14, d_loss=-0.100 g_loss=-0.110 KID= 0.01605\n",
      "epoch 367, batch 15, d_loss=-0.121 g_loss=-0.149 KID= 0.01605\n",
      "epoch 367, batch 16, d_loss=-0.104 g_loss=-0.232 KID= 0.01605\n",
      "epoch 367, batch 17, d_loss=-0.158 g_loss=-0.327 KID= 0.01605\n",
      "epoch 367, batch 18, d_loss=-0.134 g_loss=-0.419 KID= 0.01605\n",
      "epoch 367, batch 19, d_loss=-0.115 g_loss=-0.508 KID= 0.01605\n",
      "epoch 368, batch 0, d_loss=-0.150 g_loss=-0.518 KID= 0.01605\n",
      "epoch 368, batch 1, d_loss=-0.096 g_loss=-0.513 KID= 0.01605\n",
      "epoch 368, batch 2, d_loss=-0.022 g_loss=-0.550 KID= 0.01605\n",
      "epoch 368, batch 3, d_loss=-0.039 g_loss=-0.506 KID= 0.01605\n",
      "epoch 368, batch 4, d_loss=-0.086 g_loss=-0.533 KID= 0.01605\n",
      "epoch 368, batch 5, d_loss=-0.097 g_loss=-0.490 KID= 0.01605\n",
      "epoch 368, batch 6, d_loss=-0.047 g_loss=-0.422 KID= 0.01605\n",
      "epoch 368, batch 7, d_loss=-0.100 g_loss=-0.381 KID= 0.01605\n",
      "epoch 368, batch 8, d_loss=-0.112 g_loss=-0.387 KID= 0.01605\n",
      "epoch 368, batch 9, d_loss=-0.111 g_loss=-0.361 KID= 0.01605\n",
      "epoch 368, batch 10, d_loss=-0.067 g_loss=-0.407 KID= 0.01605\n",
      "epoch 368, batch 11, d_loss=-0.122 g_loss=-0.440 KID= 0.01605\n",
      "epoch 368, batch 12, d_loss=-0.069 g_loss=-0.451 KID= 0.01605\n",
      "epoch 368, batch 13, d_loss=-0.112 g_loss=-0.462 KID= 0.01605\n",
      "epoch 368, batch 14, d_loss=-0.050 g_loss=-0.395 KID= 0.01605\n",
      "epoch 368, batch 15, d_loss=-0.028 g_loss=-0.288 KID= 0.01605\n",
      "epoch 368, batch 16, d_loss=-0.080 g_loss=-0.061 KID= 0.01605\n",
      "epoch 368, batch 17, d_loss=-0.150 g_loss=0.134 KID= 0.01605\n",
      "epoch 368, batch 18, d_loss=-0.143 g_loss=0.177 KID= 0.01605\n",
      "epoch 368, batch 19, d_loss=-0.098 g_loss=0.218 KID= 0.01605\n",
      "epoch 369, batch 0, d_loss=-0.115 g_loss=0.237 KID= 0.01605\n",
      "epoch 369, batch 1, d_loss=-0.086 g_loss=0.174 KID= 0.01605\n",
      "epoch 369, batch 2, d_loss=-0.086 g_loss=0.209 KID= 0.01605\n",
      "epoch 369, batch 3, d_loss=-0.054 g_loss=0.216 KID= 0.01605\n",
      "epoch 369, batch 4, d_loss=-0.103 g_loss=0.122 KID= 0.01605\n",
      "epoch 369, batch 5, d_loss=-0.161 g_loss=0.036 KID= 0.01605\n",
      "epoch 369, batch 6, d_loss=-0.039 g_loss=-0.034 KID= 0.01605\n",
      "epoch 369, batch 7, d_loss=-0.146 g_loss=-0.081 KID= 0.01605\n",
      "epoch 369, batch 8, d_loss=-0.081 g_loss=-0.189 KID= 0.01605\n",
      "epoch 369, batch 9, d_loss=0.014 g_loss=-0.285 KID= 0.01605\n",
      "epoch 369, batch 10, d_loss=-0.095 g_loss=-0.329 KID= 0.01605\n",
      "epoch 369, batch 11, d_loss=-0.125 g_loss=-0.338 KID= 0.01605\n",
      "epoch 369, batch 12, d_loss=-0.083 g_loss=-0.326 KID= 0.01605\n",
      "epoch 369, batch 13, d_loss=-0.178 g_loss=-0.256 KID= 0.01605\n",
      "epoch 369, batch 14, d_loss=-0.105 g_loss=-0.197 KID= 0.01605\n",
      "epoch 369, batch 15, d_loss=-0.140 g_loss=-0.200 KID= 0.01605\n",
      "epoch 369, batch 16, d_loss=-0.076 g_loss=-0.103 KID= 0.01605\n",
      "epoch 369, batch 17, d_loss=-0.088 g_loss=-0.147 KID= 0.01605\n",
      "epoch 369, batch 18, d_loss=-0.050 g_loss=-0.235 KID= 0.01605\n",
      "epoch 369, batch 19, d_loss=-0.078 g_loss=-0.216 KID= 0.01605\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 370, batch 0, d_loss=-0.081 g_loss=-0.307 KID= 0.01856\n",
      "epoch 370, batch 1, d_loss=-0.041 g_loss=-0.516 KID= 0.01856\n",
      "epoch 370, batch 2, d_loss=-0.012 g_loss=-0.584 KID= 0.01856\n",
      "epoch 370, batch 3, d_loss=-0.031 g_loss=-0.574 KID= 0.01856\n",
      "epoch 370, batch 4, d_loss=-0.099 g_loss=-0.582 KID= 0.01856\n",
      "epoch 370, batch 5, d_loss=-0.186 g_loss=-0.575 KID= 0.01856\n",
      "epoch 370, batch 6, d_loss=-0.140 g_loss=-0.524 KID= 0.01856\n",
      "epoch 370, batch 7, d_loss=-0.125 g_loss=-0.540 KID= 0.01856\n",
      "epoch 370, batch 8, d_loss=-0.130 g_loss=-0.593 KID= 0.01856\n",
      "epoch 370, batch 9, d_loss=-0.013 g_loss=-0.475 KID= 0.01856\n",
      "epoch 370, batch 10, d_loss=-0.077 g_loss=-0.380 KID= 0.01856\n",
      "epoch 370, batch 11, d_loss=-0.088 g_loss=-0.317 KID= 0.01856\n",
      "epoch 370, batch 12, d_loss=-0.049 g_loss=-0.188 KID= 0.01856\n",
      "epoch 370, batch 13, d_loss=-0.112 g_loss=-0.076 KID= 0.01856\n",
      "epoch 370, batch 14, d_loss=-0.108 g_loss=-0.037 KID= 0.01856\n",
      "epoch 370, batch 15, d_loss=-0.023 g_loss=-0.058 KID= 0.01856\n",
      "epoch 370, batch 16, d_loss=-0.079 g_loss=-0.014 KID= 0.01856\n",
      "epoch 370, batch 17, d_loss=-0.112 g_loss=-0.030 KID= 0.01856\n",
      "epoch 370, batch 18, d_loss=-0.130 g_loss=-0.059 KID= 0.01856\n",
      "epoch 370, batch 19, d_loss=-0.166 g_loss=-0.072 KID= 0.01856\n",
      "epoch 371, batch 0, d_loss=-0.211 g_loss=-0.098 KID= 0.01856\n",
      "epoch 371, batch 1, d_loss=-0.053 g_loss=-0.133 KID= 0.01856\n",
      "epoch 371, batch 2, d_loss=-0.028 g_loss=-0.162 KID= 0.01856\n",
      "epoch 371, batch 3, d_loss=0.007 g_loss=-0.172 KID= 0.01856\n",
      "epoch 371, batch 4, d_loss=-0.025 g_loss=-0.100 KID= 0.01856\n",
      "epoch 371, batch 5, d_loss=-0.116 g_loss=-0.012 KID= 0.01856\n",
      "epoch 371, batch 6, d_loss=-0.104 g_loss=0.083 KID= 0.01856\n",
      "epoch 371, batch 7, d_loss=-0.114 g_loss=0.132 KID= 0.01856\n",
      "epoch 371, batch 8, d_loss=-0.089 g_loss=0.158 KID= 0.01856\n",
      "epoch 371, batch 9, d_loss=-0.083 g_loss=0.103 KID= 0.01856\n",
      "epoch 371, batch 10, d_loss=-0.061 g_loss=0.024 KID= 0.01856\n",
      "epoch 371, batch 11, d_loss=-0.161 g_loss=-0.016 KID= 0.01856\n",
      "epoch 371, batch 12, d_loss=-0.082 g_loss=-0.055 KID= 0.01856\n",
      "epoch 371, batch 13, d_loss=-0.158 g_loss=-0.042 KID= 0.01856\n",
      "epoch 371, batch 14, d_loss=-0.167 g_loss=-0.040 KID= 0.01856\n",
      "epoch 371, batch 15, d_loss=-0.133 g_loss=-0.055 KID= 0.01856\n",
      "epoch 371, batch 16, d_loss=-0.069 g_loss=-0.168 KID= 0.01856\n",
      "epoch 371, batch 17, d_loss=-0.116 g_loss=-0.279 KID= 0.01856\n",
      "epoch 371, batch 18, d_loss=-0.137 g_loss=-0.422 KID= 0.01856\n",
      "epoch 371, batch 19, d_loss=-0.050 g_loss=-0.548 KID= 0.01856\n",
      "epoch 372, batch 0, d_loss=-0.115 g_loss=-0.640 KID= 0.01856\n",
      "epoch 372, batch 1, d_loss=-0.039 g_loss=-0.638 KID= 0.01856\n",
      "epoch 372, batch 2, d_loss=-0.100 g_loss=-0.623 KID= 0.01856\n",
      "epoch 372, batch 3, d_loss=-0.115 g_loss=-0.523 KID= 0.01856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 372, batch 4, d_loss=-0.081 g_loss=-0.518 KID= 0.01856\n",
      "epoch 372, batch 5, d_loss=-0.081 g_loss=-0.519 KID= 0.01856\n",
      "epoch 372, batch 6, d_loss=-0.149 g_loss=-0.488 KID= 0.01856\n",
      "epoch 372, batch 7, d_loss=-0.090 g_loss=-0.520 KID= 0.01856\n",
      "epoch 372, batch 8, d_loss=-0.057 g_loss=-0.544 KID= 0.01856\n",
      "epoch 372, batch 9, d_loss=-0.103 g_loss=-0.561 KID= 0.01856\n",
      "epoch 372, batch 10, d_loss=-0.071 g_loss=-0.563 KID= 0.01856\n",
      "epoch 372, batch 11, d_loss=-0.135 g_loss=-0.598 KID= 0.01856\n",
      "epoch 372, batch 12, d_loss=-0.079 g_loss=-0.610 KID= 0.01856\n",
      "epoch 372, batch 13, d_loss=-0.103 g_loss=-0.593 KID= 0.01856\n",
      "epoch 372, batch 14, d_loss=-0.116 g_loss=-0.667 KID= 0.01856\n",
      "epoch 372, batch 15, d_loss=-0.132 g_loss=-0.756 KID= 0.01856\n",
      "epoch 372, batch 16, d_loss=0.033 g_loss=-0.553 KID= 0.01856\n",
      "epoch 372, batch 17, d_loss=-0.101 g_loss=-0.469 KID= 0.01856\n",
      "epoch 372, batch 18, d_loss=-0.064 g_loss=-0.452 KID= 0.01856\n",
      "epoch 372, batch 19, d_loss=-0.065 g_loss=-0.424 KID= 0.01856\n",
      "epoch 373, batch 0, d_loss=-0.138 g_loss=-0.404 KID= 0.01856\n",
      "epoch 373, batch 1, d_loss=-0.084 g_loss=-0.425 KID= 0.01856\n",
      "epoch 373, batch 2, d_loss=-0.111 g_loss=-0.424 KID= 0.01856\n",
      "epoch 373, batch 3, d_loss=-0.148 g_loss=-0.392 KID= 0.01856\n",
      "epoch 373, batch 4, d_loss=-0.132 g_loss=-0.404 KID= 0.01856\n",
      "epoch 373, batch 5, d_loss=-0.080 g_loss=-0.437 KID= 0.01856\n",
      "epoch 373, batch 6, d_loss=-0.133 g_loss=-0.426 KID= 0.01856\n",
      "epoch 373, batch 7, d_loss=-0.081 g_loss=-0.456 KID= 0.01856\n",
      "epoch 373, batch 8, d_loss=-0.088 g_loss=-0.519 KID= 0.01856\n",
      "epoch 373, batch 9, d_loss=-0.079 g_loss=-0.536 KID= 0.01856\n",
      "epoch 373, batch 10, d_loss=-0.050 g_loss=-0.562 KID= 0.01856\n",
      "epoch 373, batch 11, d_loss=-0.115 g_loss=-0.557 KID= 0.01856\n",
      "epoch 373, batch 12, d_loss=-0.065 g_loss=-0.451 KID= 0.01856\n",
      "epoch 373, batch 13, d_loss=-0.105 g_loss=-0.361 KID= 0.01856\n",
      "epoch 373, batch 14, d_loss=-0.131 g_loss=-0.351 KID= 0.01856\n",
      "epoch 373, batch 15, d_loss=-0.114 g_loss=-0.278 KID= 0.01856\n",
      "epoch 373, batch 16, d_loss=-0.081 g_loss=-0.206 KID= 0.01856\n",
      "epoch 373, batch 17, d_loss=-0.154 g_loss=-0.247 KID= 0.01856\n",
      "epoch 373, batch 18, d_loss=-0.118 g_loss=-0.307 KID= 0.01856\n",
      "epoch 373, batch 19, d_loss=-0.135 g_loss=-0.410 KID= 0.01856\n",
      "epoch 374, batch 0, d_loss=-0.153 g_loss=-0.467 KID= 0.01856\n",
      "epoch 374, batch 1, d_loss=-0.121 g_loss=-0.527 KID= 0.01856\n",
      "epoch 374, batch 2, d_loss=-0.115 g_loss=-0.582 KID= 0.01856\n",
      "epoch 374, batch 3, d_loss=-0.126 g_loss=-0.532 KID= 0.01856\n",
      "epoch 374, batch 4, d_loss=-0.123 g_loss=-0.559 KID= 0.01856\n",
      "epoch 374, batch 5, d_loss=-0.020 g_loss=-0.513 KID= 0.01856\n",
      "epoch 374, batch 6, d_loss=-0.082 g_loss=-0.481 KID= 0.01856\n",
      "epoch 374, batch 7, d_loss=-0.075 g_loss=-0.539 KID= 0.01856\n",
      "epoch 374, batch 8, d_loss=-0.127 g_loss=-0.556 KID= 0.01856\n",
      "epoch 374, batch 9, d_loss=-0.081 g_loss=-0.545 KID= 0.01856\n",
      "epoch 374, batch 10, d_loss=-0.153 g_loss=-0.512 KID= 0.01856\n",
      "epoch 374, batch 11, d_loss=-0.148 g_loss=-0.491 KID= 0.01856\n",
      "epoch 374, batch 12, d_loss=-0.089 g_loss=-0.519 KID= 0.01856\n",
      "epoch 374, batch 13, d_loss=-0.084 g_loss=-0.430 KID= 0.01856\n",
      "epoch 374, batch 14, d_loss=-0.154 g_loss=-0.482 KID= 0.01856\n",
      "epoch 374, batch 15, d_loss=-0.060 g_loss=-0.376 KID= 0.01856\n",
      "epoch 374, batch 16, d_loss=-0.052 g_loss=-0.228 KID= 0.01856\n",
      "epoch 374, batch 17, d_loss=-0.131 g_loss=-0.172 KID= 0.01856\n",
      "epoch 374, batch 18, d_loss=-0.129 g_loss=-0.209 KID= 0.01856\n",
      "epoch 374, batch 19, d_loss=-0.118 g_loss=-0.247 KID= 0.01856\n",
      "epoch 375, batch 0, d_loss=-0.148 g_loss=-0.369 KID= 0.01856\n",
      "epoch 375, batch 1, d_loss=-0.116 g_loss=-0.463 KID= 0.01856\n",
      "epoch 375, batch 2, d_loss=-0.028 g_loss=-0.486 KID= 0.01856\n",
      "epoch 375, batch 3, d_loss=-0.118 g_loss=-0.455 KID= 0.01856\n",
      "epoch 375, batch 4, d_loss=-0.091 g_loss=-0.502 KID= 0.01856\n",
      "epoch 375, batch 5, d_loss=-0.109 g_loss=-0.587 KID= 0.01856\n",
      "epoch 375, batch 6, d_loss=-0.110 g_loss=-0.607 KID= 0.01856\n",
      "epoch 375, batch 7, d_loss=-0.119 g_loss=-0.668 KID= 0.01856\n",
      "epoch 375, batch 8, d_loss=-0.154 g_loss=-0.730 KID= 0.01856\n",
      "epoch 375, batch 9, d_loss=-0.129 g_loss=-0.640 KID= 0.01856\n",
      "epoch 375, batch 10, d_loss=-0.132 g_loss=-0.526 KID= 0.01856\n",
      "epoch 375, batch 11, d_loss=-0.104 g_loss=-0.480 KID= 0.01856\n",
      "epoch 375, batch 12, d_loss=-0.049 g_loss=-0.276 KID= 0.01856\n",
      "epoch 375, batch 13, d_loss=-0.080 g_loss=-0.065 KID= 0.01856\n",
      "epoch 375, batch 14, d_loss=-0.116 g_loss=0.072 KID= 0.01856\n",
      "epoch 375, batch 15, d_loss=-0.096 g_loss=0.198 KID= 0.01856\n",
      "epoch 375, batch 16, d_loss=-0.105 g_loss=0.272 KID= 0.01856\n",
      "epoch 375, batch 17, d_loss=-0.122 g_loss=0.170 KID= 0.01856\n",
      "epoch 375, batch 18, d_loss=-0.090 g_loss=0.053 KID= 0.01856\n",
      "epoch 375, batch 19, d_loss=-0.095 g_loss=-0.060 KID= 0.01856\n",
      "epoch 376, batch 0, d_loss=-0.077 g_loss=-0.243 KID= 0.01856\n",
      "epoch 376, batch 1, d_loss=-0.123 g_loss=-0.317 KID= 0.01856\n",
      "epoch 376, batch 2, d_loss=-0.089 g_loss=-0.317 KID= 0.01856\n",
      "epoch 376, batch 3, d_loss=-0.155 g_loss=-0.267 KID= 0.01856\n",
      "epoch 376, batch 4, d_loss=-0.146 g_loss=-0.286 KID= 0.01856\n",
      "epoch 376, batch 5, d_loss=-0.103 g_loss=-0.278 KID= 0.01856\n",
      "epoch 376, batch 6, d_loss=-0.097 g_loss=-0.289 KID= 0.01856\n",
      "epoch 376, batch 7, d_loss=-0.091 g_loss=-0.451 KID= 0.01856\n",
      "epoch 376, batch 8, d_loss=-0.104 g_loss=-0.555 KID= 0.01856\n",
      "epoch 376, batch 9, d_loss=-0.070 g_loss=-0.536 KID= 0.01856\n",
      "epoch 376, batch 10, d_loss=-0.119 g_loss=-0.555 KID= 0.01856\n",
      "epoch 376, batch 11, d_loss=-0.073 g_loss=-0.604 KID= 0.01856\n",
      "epoch 376, batch 12, d_loss=-0.026 g_loss=-0.572 KID= 0.01856\n",
      "epoch 376, batch 13, d_loss=-0.066 g_loss=-0.417 KID= 0.01856\n",
      "epoch 376, batch 14, d_loss=-0.156 g_loss=-0.247 KID= 0.01856\n",
      "epoch 376, batch 15, d_loss=-0.136 g_loss=-0.032 KID= 0.01856\n",
      "epoch 376, batch 16, d_loss=-0.139 g_loss=0.173 KID= 0.01856\n",
      "epoch 376, batch 17, d_loss=-0.081 g_loss=0.113 KID= 0.01856\n",
      "epoch 376, batch 18, d_loss=-0.089 g_loss=-0.020 KID= 0.01856\n",
      "epoch 376, batch 19, d_loss=-0.108 g_loss=-0.034 KID= 0.01856\n",
      "epoch 377, batch 0, d_loss=-0.068 g_loss=-0.056 KID= 0.01856\n",
      "epoch 377, batch 1, d_loss=-0.185 g_loss=-0.132 KID= 0.01856\n",
      "epoch 377, batch 2, d_loss=-0.121 g_loss=-0.223 KID= 0.01856\n",
      "epoch 377, batch 3, d_loss=-0.111 g_loss=-0.329 KID= 0.01856\n",
      "epoch 377, batch 4, d_loss=-0.086 g_loss=-0.479 KID= 0.01856\n",
      "epoch 377, batch 5, d_loss=0.036 g_loss=-0.505 KID= 0.01856\n",
      "epoch 377, batch 6, d_loss=-0.027 g_loss=-0.542 KID= 0.01856\n",
      "epoch 377, batch 7, d_loss=-0.134 g_loss=-0.575 KID= 0.01856\n",
      "epoch 377, batch 8, d_loss=-0.159 g_loss=-0.669 KID= 0.01856\n",
      "epoch 377, batch 9, d_loss=-0.135 g_loss=-0.668 KID= 0.01856\n",
      "epoch 377, batch 10, d_loss=-0.188 g_loss=-0.647 KID= 0.01856\n",
      "epoch 377, batch 11, d_loss=-0.142 g_loss=-0.602 KID= 0.01856\n",
      "epoch 377, batch 12, d_loss=-0.069 g_loss=-0.522 KID= 0.01856\n",
      "epoch 377, batch 13, d_loss=-0.105 g_loss=-0.494 KID= 0.01856\n",
      "epoch 377, batch 14, d_loss=-0.079 g_loss=-0.474 KID= 0.01856\n",
      "epoch 377, batch 15, d_loss=-0.089 g_loss=-0.373 KID= 0.01856\n",
      "epoch 377, batch 16, d_loss=-0.116 g_loss=-0.287 KID= 0.01856\n",
      "epoch 377, batch 17, d_loss=-0.087 g_loss=-0.320 KID= 0.01856\n",
      "epoch 377, batch 18, d_loss=-0.049 g_loss=-0.375 KID= 0.01856\n",
      "epoch 377, batch 19, d_loss=-0.091 g_loss=-0.380 KID= 0.01856\n",
      "epoch 378, batch 0, d_loss=-0.142 g_loss=-0.430 KID= 0.01856\n",
      "epoch 378, batch 1, d_loss=-0.140 g_loss=-0.445 KID= 0.01856\n",
      "epoch 378, batch 2, d_loss=-0.114 g_loss=-0.399 KID= 0.01856\n",
      "epoch 378, batch 3, d_loss=-0.166 g_loss=-0.315 KID= 0.01856\n",
      "epoch 378, batch 4, d_loss=-0.184 g_loss=-0.263 KID= 0.01856\n",
      "epoch 378, batch 5, d_loss=-0.040 g_loss=-0.195 KID= 0.01856\n",
      "epoch 378, batch 6, d_loss=-0.048 g_loss=-0.148 KID= 0.01856\n",
      "epoch 378, batch 7, d_loss=-0.086 g_loss=-0.274 KID= 0.01856\n",
      "epoch 378, batch 8, d_loss=-0.122 g_loss=-0.416 KID= 0.01856\n",
      "epoch 378, batch 9, d_loss=-0.064 g_loss=-0.478 KID= 0.01856\n",
      "epoch 378, batch 10, d_loss=-0.121 g_loss=-0.553 KID= 0.01856\n",
      "epoch 378, batch 11, d_loss=-0.135 g_loss=-0.556 KID= 0.01856\n",
      "epoch 378, batch 12, d_loss=-0.101 g_loss=-0.529 KID= 0.01856\n",
      "epoch 378, batch 13, d_loss=-0.114 g_loss=-0.484 KID= 0.01856\n",
      "epoch 378, batch 14, d_loss=-0.128 g_loss=-0.420 KID= 0.01856\n",
      "epoch 378, batch 15, d_loss=-0.104 g_loss=-0.322 KID= 0.01856\n",
      "epoch 378, batch 16, d_loss=-0.152 g_loss=-0.153 KID= 0.01856\n",
      "epoch 378, batch 17, d_loss=-0.108 g_loss=-0.103 KID= 0.01856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 378, batch 18, d_loss=-0.091 g_loss=-0.080 KID= 0.01856\n",
      "epoch 378, batch 19, d_loss=-0.129 g_loss=-0.076 KID= 0.01856\n",
      "epoch 379, batch 0, d_loss=-0.094 g_loss=-0.150 KID= 0.01856\n",
      "epoch 379, batch 1, d_loss=-0.084 g_loss=-0.266 KID= 0.01856\n",
      "epoch 379, batch 2, d_loss=-0.061 g_loss=-0.325 KID= 0.01856\n",
      "epoch 379, batch 3, d_loss=-0.109 g_loss=-0.341 KID= 0.01856\n",
      "epoch 379, batch 4, d_loss=-0.183 g_loss=-0.401 KID= 0.01856\n",
      "epoch 379, batch 5, d_loss=-0.066 g_loss=-0.437 KID= 0.01856\n",
      "epoch 379, batch 6, d_loss=-0.091 g_loss=-0.447 KID= 0.01856\n",
      "epoch 379, batch 7, d_loss=-0.123 g_loss=-0.566 KID= 0.01856\n",
      "epoch 379, batch 8, d_loss=-0.176 g_loss=-0.711 KID= 0.01856\n",
      "epoch 379, batch 9, d_loss=-0.135 g_loss=-0.773 KID= 0.01856\n",
      "epoch 379, batch 10, d_loss=-0.122 g_loss=-0.827 KID= 0.01856\n",
      "epoch 379, batch 11, d_loss=-0.112 g_loss=-0.930 KID= 0.01856\n",
      "epoch 379, batch 12, d_loss=-0.006 g_loss=-0.765 KID= 0.01856\n",
      "epoch 379, batch 13, d_loss=-0.066 g_loss=-0.609 KID= 0.01856\n",
      "epoch 379, batch 14, d_loss=-0.072 g_loss=-0.439 KID= 0.01856\n",
      "epoch 379, batch 15, d_loss=-0.098 g_loss=-0.190 KID= 0.01856\n",
      "epoch 379, batch 16, d_loss=-0.116 g_loss=0.049 KID= 0.01856\n",
      "epoch 379, batch 17, d_loss=-0.147 g_loss=0.123 KID= 0.01856\n",
      "epoch 379, batch 18, d_loss=-0.103 g_loss=0.094 KID= 0.01856\n",
      "epoch 379, batch 19, d_loss=-0.129 g_loss=0.072 KID= 0.01856\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 380, batch 0, d_loss=-0.136 g_loss=0.123 KID= 0.01909\n",
      "epoch 380, batch 1, d_loss=-0.132 g_loss=0.164 KID= 0.01909\n",
      "epoch 380, batch 2, d_loss=-0.097 g_loss=0.182 KID= 0.01909\n",
      "epoch 380, batch 3, d_loss=-0.132 g_loss=0.218 KID= 0.01909\n",
      "epoch 380, batch 4, d_loss=-0.128 g_loss=0.226 KID= 0.01909\n",
      "epoch 380, batch 5, d_loss=-0.034 g_loss=0.144 KID= 0.01909\n",
      "epoch 380, batch 6, d_loss=-0.136 g_loss=0.219 KID= 0.01909\n",
      "epoch 380, batch 7, d_loss=-0.117 g_loss=0.148 KID= 0.01909\n",
      "epoch 380, batch 8, d_loss=-0.110 g_loss=0.129 KID= 0.01909\n",
      "epoch 380, batch 9, d_loss=-0.167 g_loss=0.121 KID= 0.01909\n",
      "epoch 380, batch 10, d_loss=-0.080 g_loss=0.044 KID= 0.01909\n",
      "epoch 380, batch 11, d_loss=-0.059 g_loss=-0.038 KID= 0.01909\n",
      "epoch 380, batch 12, d_loss=-0.065 g_loss=-0.152 KID= 0.01909\n",
      "epoch 380, batch 13, d_loss=-0.110 g_loss=-0.204 KID= 0.01909\n",
      "epoch 380, batch 14, d_loss=-0.152 g_loss=-0.292 KID= 0.01909\n",
      "epoch 380, batch 15, d_loss=-0.079 g_loss=-0.399 KID= 0.01909\n",
      "epoch 380, batch 16, d_loss=-0.098 g_loss=-0.450 KID= 0.01909\n",
      "epoch 380, batch 17, d_loss=-0.136 g_loss=-0.585 KID= 0.01909\n",
      "epoch 380, batch 18, d_loss=-0.105 g_loss=-0.721 KID= 0.01909\n",
      "epoch 380, batch 19, d_loss=-0.100 g_loss=-0.771 KID= 0.01909\n",
      "epoch 381, batch 0, d_loss=-0.141 g_loss=-0.761 KID= 0.01909\n",
      "epoch 381, batch 1, d_loss=-0.177 g_loss=-0.725 KID= 0.01909\n",
      "epoch 381, batch 2, d_loss=-0.094 g_loss=-0.706 KID= 0.01909\n",
      "epoch 381, batch 3, d_loss=-0.153 g_loss=-0.626 KID= 0.01909\n",
      "epoch 381, batch 4, d_loss=-0.174 g_loss=-0.504 KID= 0.01909\n",
      "epoch 381, batch 5, d_loss=-0.036 g_loss=-0.428 KID= 0.01909\n",
      "epoch 381, batch 6, d_loss=-0.109 g_loss=-0.341 KID= 0.01909\n",
      "epoch 381, batch 7, d_loss=-0.114 g_loss=-0.340 KID= 0.01909\n",
      "epoch 381, batch 8, d_loss=-0.099 g_loss=-0.365 KID= 0.01909\n",
      "epoch 381, batch 9, d_loss=-0.078 g_loss=-0.339 KID= 0.01909\n",
      "epoch 381, batch 10, d_loss=-0.082 g_loss=-0.341 KID= 0.01909\n",
      "epoch 381, batch 11, d_loss=-0.082 g_loss=-0.363 KID= 0.01909\n",
      "epoch 381, batch 12, d_loss=-0.127 g_loss=-0.316 KID= 0.01909\n",
      "epoch 381, batch 13, d_loss=-0.091 g_loss=-0.316 KID= 0.01909\n",
      "epoch 381, batch 14, d_loss=-0.148 g_loss=-0.353 KID= 0.01909\n",
      "epoch 381, batch 15, d_loss=-0.069 g_loss=-0.332 KID= 0.01909\n",
      "epoch 381, batch 16, d_loss=-0.067 g_loss=-0.306 KID= 0.01909\n",
      "epoch 381, batch 17, d_loss=-0.135 g_loss=-0.384 KID= 0.01909\n",
      "epoch 381, batch 18, d_loss=-0.046 g_loss=-0.470 KID= 0.01909\n",
      "epoch 381, batch 19, d_loss=-0.121 g_loss=-0.537 KID= 0.01909\n",
      "epoch 382, batch 0, d_loss=-0.084 g_loss=-0.570 KID= 0.01909\n",
      "epoch 382, batch 1, d_loss=-0.139 g_loss=-0.618 KID= 0.01909\n",
      "epoch 382, batch 2, d_loss=-0.058 g_loss=-0.628 KID= 0.01909\n",
      "epoch 382, batch 3, d_loss=-0.177 g_loss=-0.621 KID= 0.01909\n",
      "epoch 382, batch 4, d_loss=-0.117 g_loss=-0.551 KID= 0.01909\n",
      "epoch 382, batch 5, d_loss=-0.052 g_loss=-0.451 KID= 0.01909\n",
      "epoch 382, batch 6, d_loss=-0.123 g_loss=-0.394 KID= 0.01909\n",
      "epoch 382, batch 7, d_loss=-0.093 g_loss=-0.397 KID= 0.01909\n",
      "epoch 382, batch 8, d_loss=-0.064 g_loss=-0.420 KID= 0.01909\n",
      "epoch 382, batch 9, d_loss=-0.153 g_loss=-0.482 KID= 0.01909\n",
      "epoch 382, batch 10, d_loss=-0.143 g_loss=-0.460 KID= 0.01909\n",
      "epoch 382, batch 11, d_loss=-0.098 g_loss=-0.383 KID= 0.01909\n",
      "epoch 382, batch 12, d_loss=-0.164 g_loss=-0.378 KID= 0.01909\n",
      "epoch 382, batch 13, d_loss=-0.130 g_loss=-0.364 KID= 0.01909\n",
      "epoch 382, batch 14, d_loss=-0.139 g_loss=-0.330 KID= 0.01909\n",
      "epoch 382, batch 15, d_loss=-0.004 g_loss=-0.316 KID= 0.01909\n",
      "epoch 382, batch 16, d_loss=-0.006 g_loss=-0.336 KID= 0.01909\n",
      "epoch 382, batch 17, d_loss=-0.092 g_loss=-0.398 KID= 0.01909\n",
      "epoch 382, batch 18, d_loss=-0.112 g_loss=-0.425 KID= 0.01909\n",
      "epoch 382, batch 19, d_loss=-0.118 g_loss=-0.428 KID= 0.01909\n",
      "epoch 383, batch 0, d_loss=-0.123 g_loss=-0.339 KID= 0.01909\n",
      "epoch 383, batch 1, d_loss=-0.133 g_loss=-0.322 KID= 0.01909\n",
      "epoch 383, batch 2, d_loss=-0.049 g_loss=-0.268 KID= 0.01909\n",
      "epoch 383, batch 3, d_loss=-0.119 g_loss=-0.218 KID= 0.01909\n",
      "epoch 383, batch 4, d_loss=-0.150 g_loss=-0.230 KID= 0.01909\n",
      "epoch 383, batch 5, d_loss=0.029 g_loss=-0.213 KID= 0.01909\n",
      "epoch 383, batch 6, d_loss=-0.079 g_loss=-0.158 KID= 0.01909\n",
      "epoch 383, batch 7, d_loss=-0.112 g_loss=-0.222 KID= 0.01909\n",
      "epoch 383, batch 8, d_loss=-0.055 g_loss=-0.287 KID= 0.01909\n",
      "epoch 383, batch 9, d_loss=-0.149 g_loss=-0.343 KID= 0.01909\n",
      "epoch 383, batch 10, d_loss=-0.153 g_loss=-0.366 KID= 0.01909\n",
      "epoch 383, batch 11, d_loss=-0.204 g_loss=-0.366 KID= 0.01909\n",
      "epoch 383, batch 12, d_loss=-0.114 g_loss=-0.393 KID= 0.01909\n",
      "epoch 383, batch 13, d_loss=-0.165 g_loss=-0.393 KID= 0.01909\n",
      "epoch 383, batch 14, d_loss=-0.097 g_loss=-0.446 KID= 0.01909\n",
      "epoch 383, batch 15, d_loss=-0.076 g_loss=-0.450 KID= 0.01909\n",
      "epoch 383, batch 16, d_loss=-0.078 g_loss=-0.458 KID= 0.01909\n",
      "epoch 383, batch 17, d_loss=-0.089 g_loss=-0.406 KID= 0.01909\n",
      "epoch 383, batch 18, d_loss=-0.172 g_loss=-0.411 KID= 0.01909\n",
      "epoch 383, batch 19, d_loss=-0.125 g_loss=-0.388 KID= 0.01909\n",
      "epoch 384, batch 0, d_loss=-0.085 g_loss=-0.441 KID= 0.01909\n",
      "epoch 384, batch 1, d_loss=-0.093 g_loss=-0.447 KID= 0.01909\n",
      "epoch 384, batch 2, d_loss=-0.065 g_loss=-0.401 KID= 0.01909\n",
      "epoch 384, batch 3, d_loss=-0.065 g_loss=-0.347 KID= 0.01909\n",
      "epoch 384, batch 4, d_loss=-0.125 g_loss=-0.324 KID= 0.01909\n",
      "epoch 384, batch 5, d_loss=-0.057 g_loss=-0.264 KID= 0.01909\n",
      "epoch 384, batch 6, d_loss=-0.138 g_loss=-0.207 KID= 0.01909\n",
      "epoch 384, batch 7, d_loss=-0.149 g_loss=-0.215 KID= 0.01909\n",
      "epoch 384, batch 8, d_loss=-0.078 g_loss=-0.294 KID= 0.01909\n",
      "epoch 384, batch 9, d_loss=-0.149 g_loss=-0.348 KID= 0.01909\n",
      "epoch 384, batch 10, d_loss=-0.164 g_loss=-0.485 KID= 0.01909\n",
      "epoch 384, batch 11, d_loss=-0.187 g_loss=-0.642 KID= 0.01909\n",
      "epoch 384, batch 12, d_loss=-0.119 g_loss=-0.774 KID= 0.01909\n",
      "epoch 384, batch 13, d_loss=-0.190 g_loss=-0.871 KID= 0.01909\n",
      "epoch 384, batch 14, d_loss=-0.117 g_loss=-0.846 KID= 0.01909\n",
      "epoch 384, batch 15, d_loss=-0.052 g_loss=-0.765 KID= 0.01909\n",
      "epoch 384, batch 16, d_loss=-0.107 g_loss=-0.666 KID= 0.01909\n",
      "epoch 384, batch 17, d_loss=-0.120 g_loss=-0.614 KID= 0.01909\n",
      "epoch 384, batch 18, d_loss=-0.031 g_loss=-0.588 KID= 0.01909\n",
      "epoch 384, batch 19, d_loss=-0.155 g_loss=-0.511 KID= 0.01909\n",
      "epoch 385, batch 0, d_loss=-0.082 g_loss=-0.439 KID= 0.01909\n",
      "epoch 385, batch 1, d_loss=-0.107 g_loss=-0.426 KID= 0.01909\n",
      "epoch 385, batch 2, d_loss=-0.091 g_loss=-0.383 KID= 0.01909\n",
      "epoch 385, batch 3, d_loss=-0.116 g_loss=-0.361 KID= 0.01909\n",
      "epoch 385, batch 4, d_loss=-0.138 g_loss=-0.290 KID= 0.01909\n",
      "epoch 385, batch 5, d_loss=-0.136 g_loss=-0.248 KID= 0.01909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 385, batch 6, d_loss=-0.166 g_loss=-0.221 KID= 0.01909\n",
      "epoch 385, batch 7, d_loss=-0.134 g_loss=-0.215 KID= 0.01909\n",
      "epoch 385, batch 8, d_loss=-0.061 g_loss=-0.271 KID= 0.01909\n",
      "epoch 385, batch 9, d_loss=-0.095 g_loss=-0.249 KID= 0.01909\n",
      "epoch 385, batch 10, d_loss=-0.127 g_loss=-0.167 KID= 0.01909\n",
      "epoch 385, batch 11, d_loss=-0.155 g_loss=-0.092 KID= 0.01909\n",
      "epoch 385, batch 12, d_loss=-0.073 g_loss=-0.085 KID= 0.01909\n",
      "epoch 385, batch 13, d_loss=-0.159 g_loss=-0.113 KID= 0.01909\n",
      "epoch 385, batch 14, d_loss=-0.115 g_loss=-0.117 KID= 0.01909\n",
      "epoch 385, batch 15, d_loss=-0.078 g_loss=-0.161 KID= 0.01909\n",
      "epoch 385, batch 16, d_loss=-0.122 g_loss=-0.163 KID= 0.01909\n",
      "epoch 385, batch 17, d_loss=-0.139 g_loss=-0.174 KID= 0.01909\n",
      "epoch 385, batch 18, d_loss=-0.104 g_loss=-0.237 KID= 0.01909\n",
      "epoch 385, batch 19, d_loss=-0.222 g_loss=-0.293 KID= 0.01909\n",
      "epoch 386, batch 0, d_loss=-0.057 g_loss=-0.334 KID= 0.01909\n",
      "epoch 386, batch 1, d_loss=-0.111 g_loss=-0.328 KID= 0.01909\n",
      "epoch 386, batch 2, d_loss=-0.099 g_loss=-0.368 KID= 0.01909\n",
      "epoch 386, batch 3, d_loss=-0.080 g_loss=-0.423 KID= 0.01909\n",
      "epoch 386, batch 4, d_loss=-0.099 g_loss=-0.528 KID= 0.01909\n",
      "epoch 386, batch 5, d_loss=-0.115 g_loss=-0.629 KID= 0.01909\n",
      "epoch 386, batch 6, d_loss=-0.136 g_loss=-0.764 KID= 0.01909\n",
      "epoch 386, batch 7, d_loss=-0.114 g_loss=-0.890 KID= 0.01909\n",
      "epoch 386, batch 8, d_loss=-0.083 g_loss=-0.964 KID= 0.01909\n",
      "epoch 386, batch 9, d_loss=-0.100 g_loss=-1.005 KID= 0.01909\n",
      "epoch 386, batch 10, d_loss=-0.138 g_loss=-1.019 KID= 0.01909\n",
      "epoch 386, batch 11, d_loss=-0.154 g_loss=-0.849 KID= 0.01909\n",
      "epoch 386, batch 12, d_loss=-0.122 g_loss=-0.672 KID= 0.01909\n",
      "epoch 386, batch 13, d_loss=-0.241 g_loss=-0.552 KID= 0.01909\n",
      "epoch 386, batch 14, d_loss=-0.121 g_loss=-0.491 KID= 0.01909\n",
      "epoch 386, batch 15, d_loss=-0.086 g_loss=-0.345 KID= 0.01909\n",
      "epoch 386, batch 16, d_loss=-0.092 g_loss=-0.173 KID= 0.01909\n",
      "epoch 386, batch 17, d_loss=-0.115 g_loss=-0.156 KID= 0.01909\n",
      "epoch 386, batch 18, d_loss=-0.072 g_loss=-0.124 KID= 0.01909\n",
      "epoch 386, batch 19, d_loss=-0.117 g_loss=-0.144 KID= 0.01909\n",
      "epoch 387, batch 0, d_loss=-0.076 g_loss=-0.090 KID= 0.01909\n",
      "epoch 387, batch 1, d_loss=-0.151 g_loss=-0.063 KID= 0.01909\n",
      "epoch 387, batch 2, d_loss=-0.103 g_loss=-0.017 KID= 0.01909\n",
      "epoch 387, batch 3, d_loss=-0.121 g_loss=0.031 KID= 0.01909\n",
      "epoch 387, batch 4, d_loss=-0.199 g_loss=0.019 KID= 0.01909\n",
      "epoch 387, batch 5, d_loss=-0.024 g_loss=0.042 KID= 0.01909\n",
      "epoch 387, batch 6, d_loss=-0.057 g_loss=0.081 KID= 0.01909\n",
      "epoch 387, batch 7, d_loss=-0.109 g_loss=0.035 KID= 0.01909\n",
      "epoch 387, batch 8, d_loss=-0.073 g_loss=-0.079 KID= 0.01909\n",
      "epoch 387, batch 9, d_loss=-0.132 g_loss=-0.166 KID= 0.01909\n",
      "epoch 387, batch 10, d_loss=-0.151 g_loss=-0.201 KID= 0.01909\n",
      "epoch 387, batch 11, d_loss=-0.175 g_loss=-0.233 KID= 0.01909\n",
      "epoch 387, batch 12, d_loss=-0.104 g_loss=-0.204 KID= 0.01909\n",
      "epoch 387, batch 13, d_loss=-0.221 g_loss=-0.230 KID= 0.01909\n",
      "epoch 387, batch 14, d_loss=-0.087 g_loss=-0.292 KID= 0.01909\n",
      "epoch 387, batch 15, d_loss=-0.124 g_loss=-0.211 KID= 0.01909\n",
      "epoch 387, batch 16, d_loss=-0.110 g_loss=-0.156 KID= 0.01909\n",
      "epoch 387, batch 17, d_loss=-0.050 g_loss=-0.254 KID= 0.01909\n",
      "epoch 387, batch 18, d_loss=-0.074 g_loss=-0.412 KID= 0.01909\n",
      "epoch 387, batch 19, d_loss=-0.180 g_loss=-0.561 KID= 0.01909\n",
      "epoch 388, batch 0, d_loss=-0.140 g_loss=-0.659 KID= 0.01909\n",
      "epoch 388, batch 1, d_loss=-0.132 g_loss=-0.834 KID= 0.01909\n",
      "epoch 388, batch 2, d_loss=-0.066 g_loss=-0.789 KID= 0.01909\n",
      "epoch 388, batch 3, d_loss=-0.068 g_loss=-0.779 KID= 0.01909\n",
      "epoch 388, batch 4, d_loss=-0.153 g_loss=-0.631 KID= 0.01909\n",
      "epoch 388, batch 5, d_loss=-0.101 g_loss=-0.377 KID= 0.01909\n",
      "epoch 388, batch 6, d_loss=-0.160 g_loss=-0.230 KID= 0.01909\n",
      "epoch 388, batch 7, d_loss=-0.111 g_loss=-0.252 KID= 0.01909\n",
      "epoch 388, batch 8, d_loss=-0.057 g_loss=-0.352 KID= 0.01909\n",
      "epoch 388, batch 9, d_loss=-0.145 g_loss=-0.435 KID= 0.01909\n",
      "epoch 388, batch 10, d_loss=-0.084 g_loss=-0.411 KID= 0.01909\n",
      "epoch 388, batch 11, d_loss=-0.107 g_loss=-0.380 KID= 0.01909\n",
      "epoch 388, batch 12, d_loss=-0.076 g_loss=-0.259 KID= 0.01909\n",
      "epoch 388, batch 13, d_loss=-0.142 g_loss=-0.166 KID= 0.01909\n",
      "epoch 388, batch 14, d_loss=-0.143 g_loss=-0.098 KID= 0.01909\n",
      "epoch 388, batch 15, d_loss=-0.135 g_loss=-0.028 KID= 0.01909\n",
      "epoch 388, batch 16, d_loss=-0.145 g_loss=0.089 KID= 0.01909\n",
      "epoch 388, batch 17, d_loss=-0.173 g_loss=0.076 KID= 0.01909\n",
      "epoch 388, batch 18, d_loss=-0.054 g_loss=0.015 KID= 0.01909\n",
      "epoch 388, batch 19, d_loss=-0.111 g_loss=-0.064 KID= 0.01909\n",
      "epoch 389, batch 0, d_loss=-0.076 g_loss=-0.125 KID= 0.01909\n",
      "epoch 389, batch 1, d_loss=-0.077 g_loss=-0.161 KID= 0.01909\n",
      "epoch 389, batch 2, d_loss=-0.079 g_loss=-0.204 KID= 0.01909\n",
      "epoch 389, batch 3, d_loss=-0.178 g_loss=-0.285 KID= 0.01909\n",
      "epoch 389, batch 4, d_loss=-0.199 g_loss=-0.323 KID= 0.01909\n",
      "epoch 389, batch 5, d_loss=-0.143 g_loss=-0.258 KID= 0.01909\n",
      "epoch 389, batch 6, d_loss=-0.075 g_loss=-0.310 KID= 0.01909\n",
      "epoch 389, batch 7, d_loss=-0.070 g_loss=-0.453 KID= 0.01909\n",
      "epoch 389, batch 8, d_loss=-0.051 g_loss=-0.601 KID= 0.01909\n",
      "epoch 389, batch 9, d_loss=-0.091 g_loss=-0.772 KID= 0.01909\n",
      "epoch 389, batch 10, d_loss=-0.115 g_loss=-0.981 KID= 0.01909\n",
      "epoch 389, batch 11, d_loss=-0.124 g_loss=-0.994 KID= 0.01909\n",
      "epoch 389, batch 12, d_loss=-0.133 g_loss=-1.117 KID= 0.01909\n",
      "epoch 389, batch 13, d_loss=-0.149 g_loss=-1.126 KID= 0.01909\n",
      "epoch 389, batch 14, d_loss=-0.250 g_loss=-1.157 KID= 0.01909\n",
      "epoch 389, batch 15, d_loss=-0.058 g_loss=-0.919 KID= 0.01909\n",
      "epoch 389, batch 16, d_loss=-0.108 g_loss=-0.735 KID= 0.01909\n",
      "epoch 389, batch 17, d_loss=-0.165 g_loss=-0.591 KID= 0.01909\n",
      "epoch 389, batch 18, d_loss=-0.050 g_loss=-0.302 KID= 0.01909\n",
      "epoch 389, batch 19, d_loss=-0.131 g_loss=-0.170 KID= 0.01909\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 390, batch 0, d_loss=-0.073 g_loss=-0.054 KID= 0.02180\n",
      "epoch 390, batch 1, d_loss=-0.119 g_loss=0.072 KID= 0.02180\n",
      "epoch 390, batch 2, d_loss=-0.111 g_loss=0.200 KID= 0.02180\n",
      "epoch 390, batch 3, d_loss=-0.145 g_loss=0.328 KID= 0.02180\n",
      "epoch 390, batch 4, d_loss=-0.151 g_loss=0.288 KID= 0.02180\n",
      "epoch 390, batch 5, d_loss=-0.163 g_loss=0.357 KID= 0.02180\n",
      "epoch 390, batch 6, d_loss=-0.113 g_loss=0.247 KID= 0.02180\n",
      "epoch 390, batch 7, d_loss=-0.116 g_loss=0.075 KID= 0.02180\n",
      "epoch 390, batch 8, d_loss=-0.038 g_loss=-0.029 KID= 0.02180\n",
      "epoch 390, batch 9, d_loss=-0.103 g_loss=-0.176 KID= 0.02180\n",
      "epoch 390, batch 10, d_loss=-0.126 g_loss=-0.286 KID= 0.02180\n",
      "epoch 390, batch 11, d_loss=-0.135 g_loss=-0.339 KID= 0.02180\n",
      "epoch 390, batch 12, d_loss=-0.133 g_loss=-0.411 KID= 0.02180\n",
      "epoch 390, batch 13, d_loss=-0.169 g_loss=-0.455 KID= 0.02180\n",
      "epoch 390, batch 14, d_loss=-0.148 g_loss=-0.545 KID= 0.02180\n",
      "epoch 390, batch 15, d_loss=-0.041 g_loss=-0.515 KID= 0.02180\n",
      "epoch 390, batch 16, d_loss=-0.141 g_loss=-0.532 KID= 0.02180\n",
      "epoch 390, batch 17, d_loss=-0.091 g_loss=-0.535 KID= 0.02180\n",
      "epoch 390, batch 18, d_loss=-0.049 g_loss=-0.567 KID= 0.02180\n",
      "epoch 390, batch 19, d_loss=-0.189 g_loss=-0.499 KID= 0.02180\n",
      "epoch 391, batch 0, d_loss=-0.101 g_loss=-0.382 KID= 0.02180\n",
      "epoch 391, batch 1, d_loss=-0.133 g_loss=-0.340 KID= 0.02180\n",
      "epoch 391, batch 2, d_loss=-0.071 g_loss=-0.224 KID= 0.02180\n",
      "epoch 391, batch 3, d_loss=-0.150 g_loss=-0.212 KID= 0.02180\n",
      "epoch 391, batch 4, d_loss=-0.127 g_loss=-0.228 KID= 0.02180\n",
      "epoch 391, batch 5, d_loss=-0.114 g_loss=-0.164 KID= 0.02180\n",
      "epoch 391, batch 6, d_loss=-0.090 g_loss=-0.153 KID= 0.02180\n",
      "epoch 391, batch 7, d_loss=-0.146 g_loss=-0.186 KID= 0.02180\n",
      "epoch 391, batch 8, d_loss=-0.127 g_loss=-0.224 KID= 0.02180\n",
      "epoch 391, batch 9, d_loss=-0.116 g_loss=-0.265 KID= 0.02180\n",
      "epoch 391, batch 10, d_loss=-0.187 g_loss=-0.289 KID= 0.02180\n",
      "epoch 391, batch 11, d_loss=-0.136 g_loss=-0.241 KID= 0.02180\n",
      "epoch 391, batch 12, d_loss=-0.103 g_loss=-0.257 KID= 0.02180\n",
      "epoch 391, batch 13, d_loss=-0.167 g_loss=-0.256 KID= 0.02180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 391, batch 14, d_loss=-0.153 g_loss=-0.320 KID= 0.02180\n",
      "epoch 391, batch 15, d_loss=-0.094 g_loss=-0.252 KID= 0.02180\n",
      "epoch 391, batch 16, d_loss=-0.123 g_loss=-0.277 KID= 0.02180\n",
      "epoch 391, batch 17, d_loss=-0.092 g_loss=-0.328 KID= 0.02180\n",
      "epoch 391, batch 18, d_loss=-0.010 g_loss=-0.423 KID= 0.02180\n",
      "epoch 391, batch 19, d_loss=-0.170 g_loss=-0.552 KID= 0.02180\n",
      "epoch 392, batch 0, d_loss=-0.115 g_loss=-0.670 KID= 0.02180\n",
      "epoch 392, batch 1, d_loss=-0.147 g_loss=-0.784 KID= 0.02180\n",
      "epoch 392, batch 2, d_loss=-0.152 g_loss=-0.772 KID= 0.02180\n",
      "epoch 392, batch 3, d_loss=-0.167 g_loss=-0.695 KID= 0.02180\n",
      "epoch 392, batch 4, d_loss=-0.186 g_loss=-0.688 KID= 0.02180\n",
      "epoch 392, batch 5, d_loss=-0.068 g_loss=-0.519 KID= 0.02180\n",
      "epoch 392, batch 6, d_loss=-0.054 g_loss=-0.444 KID= 0.02180\n",
      "epoch 392, batch 7, d_loss=-0.092 g_loss=-0.397 KID= 0.02180\n",
      "epoch 392, batch 8, d_loss=-0.077 g_loss=-0.229 KID= 0.02180\n",
      "epoch 392, batch 9, d_loss=-0.165 g_loss=-0.147 KID= 0.02180\n",
      "epoch 392, batch 10, d_loss=-0.149 g_loss=-0.090 KID= 0.02180\n",
      "epoch 392, batch 11, d_loss=-0.117 g_loss=-0.127 KID= 0.02180\n",
      "epoch 392, batch 12, d_loss=-0.080 g_loss=-0.178 KID= 0.02180\n",
      "epoch 392, batch 13, d_loss=-0.123 g_loss=-0.179 KID= 0.02180\n",
      "epoch 392, batch 14, d_loss=-0.148 g_loss=-0.187 KID= 0.02180\n",
      "epoch 392, batch 15, d_loss=-0.092 g_loss=-0.139 KID= 0.02180\n",
      "epoch 392, batch 16, d_loss=-0.132 g_loss=-0.154 KID= 0.02180\n",
      "epoch 392, batch 17, d_loss=-0.140 g_loss=-0.234 KID= 0.02180\n",
      "epoch 392, batch 18, d_loss=-0.077 g_loss=-0.252 KID= 0.02180\n",
      "epoch 392, batch 19, d_loss=-0.093 g_loss=-0.276 KID= 0.02180\n",
      "epoch 393, batch 0, d_loss=-0.135 g_loss=-0.254 KID= 0.02180\n",
      "epoch 393, batch 1, d_loss=-0.144 g_loss=-0.241 KID= 0.02180\n",
      "epoch 393, batch 2, d_loss=-0.158 g_loss=-0.168 KID= 0.02180\n",
      "epoch 393, batch 3, d_loss=-0.203 g_loss=-0.162 KID= 0.02180\n",
      "epoch 393, batch 4, d_loss=-0.156 g_loss=-0.231 KID= 0.02180\n",
      "epoch 393, batch 5, d_loss=-0.074 g_loss=-0.184 KID= 0.02180\n",
      "epoch 393, batch 6, d_loss=-0.117 g_loss=-0.238 KID= 0.02180\n",
      "epoch 393, batch 7, d_loss=-0.094 g_loss=-0.337 KID= 0.02180\n",
      "epoch 393, batch 8, d_loss=-0.065 g_loss=-0.448 KID= 0.02180\n",
      "epoch 393, batch 9, d_loss=-0.163 g_loss=-0.579 KID= 0.02180\n",
      "epoch 393, batch 10, d_loss=-0.059 g_loss=-0.629 KID= 0.02180\n",
      "epoch 393, batch 11, d_loss=-0.107 g_loss=-0.774 KID= 0.02180\n",
      "epoch 393, batch 12, d_loss=-0.074 g_loss=-0.755 KID= 0.02180\n",
      "epoch 393, batch 13, d_loss=-0.175 g_loss=-0.852 KID= 0.02180\n",
      "epoch 393, batch 14, d_loss=-0.219 g_loss=-1.089 KID= 0.02180\n",
      "epoch 393, batch 15, d_loss=-0.084 g_loss=-0.998 KID= 0.02180\n",
      "epoch 393, batch 16, d_loss=-0.117 g_loss=-1.036 KID= 0.02180\n",
      "epoch 393, batch 17, d_loss=-0.158 g_loss=-1.021 KID= 0.02180\n",
      "epoch 393, batch 18, d_loss=-0.041 g_loss=-0.864 KID= 0.02180\n",
      "epoch 393, batch 19, d_loss=-0.094 g_loss=-0.733 KID= 0.02180\n",
      "epoch 394, batch 0, d_loss=-0.129 g_loss=-0.591 KID= 0.02180\n",
      "epoch 394, batch 1, d_loss=-0.183 g_loss=-0.478 KID= 0.02180\n",
      "epoch 394, batch 2, d_loss=-0.159 g_loss=-0.294 KID= 0.02180\n",
      "epoch 394, batch 3, d_loss=-0.176 g_loss=-0.056 KID= 0.02180\n",
      "epoch 394, batch 4, d_loss=-0.143 g_loss=0.112 KID= 0.02180\n",
      "epoch 394, batch 5, d_loss=-0.162 g_loss=0.204 KID= 0.02180\n",
      "epoch 394, batch 6, d_loss=-0.153 g_loss=0.177 KID= 0.02180\n",
      "epoch 394, batch 7, d_loss=-0.119 g_loss=0.090 KID= 0.02180\n",
      "epoch 394, batch 8, d_loss=-0.037 g_loss=-0.050 KID= 0.02180\n",
      "epoch 394, batch 9, d_loss=-0.148 g_loss=-0.028 KID= 0.02180\n",
      "epoch 394, batch 10, d_loss=-0.150 g_loss=0.087 KID= 0.02180\n",
      "epoch 394, batch 11, d_loss=-0.107 g_loss=0.106 KID= 0.02180\n",
      "epoch 394, batch 12, d_loss=-0.171 g_loss=0.139 KID= 0.02180\n",
      "epoch 394, batch 13, d_loss=-0.161 g_loss=0.141 KID= 0.02180\n",
      "epoch 394, batch 14, d_loss=-0.221 g_loss=0.218 KID= 0.02180\n",
      "epoch 394, batch 15, d_loss=0.038 g_loss=0.243 KID= 0.02180\n",
      "epoch 394, batch 16, d_loss=-0.076 g_loss=0.255 KID= 0.02180\n",
      "epoch 394, batch 17, d_loss=-0.142 g_loss=0.188 KID= 0.02180\n",
      "epoch 394, batch 18, d_loss=-0.121 g_loss=0.036 KID= 0.02180\n",
      "epoch 394, batch 19, d_loss=-0.134 g_loss=-0.127 KID= 0.02180\n",
      "epoch 395, batch 0, d_loss=-0.145 g_loss=-0.209 KID= 0.02180\n",
      "epoch 395, batch 1, d_loss=-0.199 g_loss=-0.267 KID= 0.02180\n",
      "epoch 395, batch 2, d_loss=-0.121 g_loss=-0.325 KID= 0.02180\n",
      "epoch 395, batch 3, d_loss=-0.134 g_loss=-0.445 KID= 0.02180\n",
      "epoch 395, batch 4, d_loss=-0.077 g_loss=-0.533 KID= 0.02180\n",
      "epoch 395, batch 5, d_loss=-0.104 g_loss=-0.475 KID= 0.02180\n",
      "epoch 395, batch 6, d_loss=-0.129 g_loss=-0.489 KID= 0.02180\n",
      "epoch 395, batch 7, d_loss=-0.115 g_loss=-0.573 KID= 0.02180\n",
      "epoch 395, batch 8, d_loss=-0.095 g_loss=-0.653 KID= 0.02180\n",
      "epoch 395, batch 9, d_loss=-0.207 g_loss=-0.696 KID= 0.02180\n",
      "epoch 395, batch 10, d_loss=-0.130 g_loss=-0.753 KID= 0.02180\n",
      "epoch 395, batch 11, d_loss=-0.148 g_loss=-0.780 KID= 0.02180\n",
      "epoch 395, batch 12, d_loss=-0.095 g_loss=-0.759 KID= 0.02180\n",
      "epoch 395, batch 13, d_loss=-0.118 g_loss=-0.792 KID= 0.02180\n",
      "epoch 395, batch 14, d_loss=-0.156 g_loss=-0.721 KID= 0.02180\n",
      "epoch 395, batch 15, d_loss=-0.074 g_loss=-0.524 KID= 0.02180\n",
      "epoch 395, batch 16, d_loss=-0.123 g_loss=-0.385 KID= 0.02180\n",
      "epoch 395, batch 17, d_loss=-0.200 g_loss=-0.375 KID= 0.02180\n",
      "epoch 395, batch 18, d_loss=-0.124 g_loss=-0.326 KID= 0.02180\n",
      "epoch 395, batch 19, d_loss=-0.122 g_loss=-0.285 KID= 0.02180\n",
      "epoch 396, batch 0, d_loss=-0.055 g_loss=-0.245 KID= 0.02180\n",
      "epoch 396, batch 1, d_loss=-0.083 g_loss=-0.173 KID= 0.02180\n",
      "epoch 396, batch 2, d_loss=-0.163 g_loss=-0.149 KID= 0.02180\n",
      "epoch 396, batch 3, d_loss=-0.154 g_loss=-0.244 KID= 0.02180\n",
      "epoch 396, batch 4, d_loss=-0.108 g_loss=-0.321 KID= 0.02180\n",
      "epoch 396, batch 5, d_loss=-0.052 g_loss=-0.281 KID= 0.02180\n",
      "epoch 396, batch 6, d_loss=-0.120 g_loss=-0.296 KID= 0.02180\n",
      "epoch 396, batch 7, d_loss=-0.174 g_loss=-0.318 KID= 0.02180\n",
      "epoch 396, batch 8, d_loss=-0.134 g_loss=-0.308 KID= 0.02180\n",
      "epoch 396, batch 9, d_loss=-0.137 g_loss=-0.421 KID= 0.02180\n",
      "epoch 396, batch 10, d_loss=-0.109 g_loss=-0.509 KID= 0.02180\n",
      "epoch 396, batch 11, d_loss=-0.183 g_loss=-0.572 KID= 0.02180\n",
      "epoch 396, batch 12, d_loss=-0.078 g_loss=-0.607 KID= 0.02180\n",
      "epoch 396, batch 13, d_loss=-0.116 g_loss=-0.602 KID= 0.02180\n",
      "epoch 396, batch 14, d_loss=-0.144 g_loss=-0.504 KID= 0.02180\n",
      "epoch 396, batch 15, d_loss=-0.131 g_loss=-0.397 KID= 0.02180\n",
      "epoch 396, batch 16, d_loss=-0.174 g_loss=-0.411 KID= 0.02180\n",
      "epoch 396, batch 17, d_loss=-0.112 g_loss=-0.526 KID= 0.02180\n",
      "epoch 396, batch 18, d_loss=-0.059 g_loss=-0.514 KID= 0.02180\n",
      "epoch 396, batch 19, d_loss=-0.186 g_loss=-0.533 KID= 0.02180\n",
      "epoch 397, batch 0, d_loss=-0.111 g_loss=-0.604 KID= 0.02180\n",
      "epoch 397, batch 1, d_loss=-0.129 g_loss=-0.597 KID= 0.02180\n",
      "epoch 397, batch 2, d_loss=-0.191 g_loss=-0.517 KID= 0.02180\n",
      "epoch 397, batch 3, d_loss=-0.187 g_loss=-0.547 KID= 0.02180\n",
      "epoch 397, batch 4, d_loss=-0.134 g_loss=-0.545 KID= 0.02180\n",
      "epoch 397, batch 5, d_loss=-0.084 g_loss=-0.344 KID= 0.02180\n",
      "epoch 397, batch 6, d_loss=-0.079 g_loss=-0.144 KID= 0.02180\n",
      "epoch 397, batch 7, d_loss=-0.125 g_loss=-0.085 KID= 0.02180\n",
      "epoch 397, batch 8, d_loss=-0.100 g_loss=-0.023 KID= 0.02180\n",
      "epoch 397, batch 9, d_loss=-0.135 g_loss=-0.005 KID= 0.02180\n",
      "epoch 397, batch 10, d_loss=-0.119 g_loss=-0.064 KID= 0.02180\n",
      "epoch 397, batch 11, d_loss=-0.131 g_loss=-0.162 KID= 0.02180\n",
      "epoch 397, batch 12, d_loss=-0.140 g_loss=-0.202 KID= 0.02180\n",
      "epoch 397, batch 13, d_loss=-0.133 g_loss=-0.265 KID= 0.02180\n",
      "epoch 397, batch 14, d_loss=-0.159 g_loss=-0.355 KID= 0.02180\n",
      "epoch 397, batch 15, d_loss=-0.092 g_loss=-0.283 KID= 0.02180\n",
      "epoch 397, batch 16, d_loss=-0.091 g_loss=-0.348 KID= 0.02180\n",
      "epoch 397, batch 17, d_loss=-0.102 g_loss=-0.450 KID= 0.02180\n",
      "epoch 397, batch 18, d_loss=-0.067 g_loss=-0.538 KID= 0.02180\n",
      "epoch 397, batch 19, d_loss=-0.147 g_loss=-0.575 KID= 0.02180\n",
      "epoch 398, batch 0, d_loss=-0.153 g_loss=-0.658 KID= 0.02180\n",
      "epoch 398, batch 1, d_loss=-0.171 g_loss=-0.681 KID= 0.02180\n",
      "epoch 398, batch 2, d_loss=-0.105 g_loss=-0.598 KID= 0.02180\n",
      "epoch 398, batch 3, d_loss=-0.182 g_loss=-0.493 KID= 0.02180\n",
      "epoch 398, batch 4, d_loss=-0.141 g_loss=-0.349 KID= 0.02180\n",
      "epoch 398, batch 5, d_loss=-0.123 g_loss=-0.198 KID= 0.02180\n",
      "epoch 398, batch 6, d_loss=-0.131 g_loss=-0.093 KID= 0.02180\n",
      "epoch 398, batch 7, d_loss=-0.124 g_loss=-0.135 KID= 0.02180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 398, batch 8, d_loss=-0.102 g_loss=-0.168 KID= 0.02180\n",
      "epoch 398, batch 9, d_loss=-0.139 g_loss=-0.181 KID= 0.02180\n",
      "epoch 398, batch 10, d_loss=-0.119 g_loss=-0.191 KID= 0.02180\n",
      "epoch 398, batch 11, d_loss=-0.140 g_loss=-0.218 KID= 0.02180\n",
      "epoch 398, batch 12, d_loss=-0.157 g_loss=-0.313 KID= 0.02180\n",
      "epoch 398, batch 13, d_loss=-0.168 g_loss=-0.444 KID= 0.02180\n",
      "epoch 398, batch 14, d_loss=-0.173 g_loss=-0.579 KID= 0.02180\n",
      "epoch 398, batch 15, d_loss=-0.040 g_loss=-0.607 KID= 0.02180\n",
      "epoch 398, batch 16, d_loss=-0.073 g_loss=-0.631 KID= 0.02180\n",
      "epoch 398, batch 17, d_loss=-0.150 g_loss=-0.683 KID= 0.02180\n",
      "epoch 398, batch 18, d_loss=-0.134 g_loss=-0.653 KID= 0.02180\n",
      "epoch 398, batch 19, d_loss=-0.140 g_loss=-0.654 KID= 0.02180\n",
      "epoch 399, batch 0, d_loss=-0.142 g_loss=-0.578 KID= 0.02180\n",
      "epoch 399, batch 1, d_loss=-0.181 g_loss=-0.538 KID= 0.02180\n",
      "epoch 399, batch 2, d_loss=-0.146 g_loss=-0.440 KID= 0.02180\n",
      "epoch 399, batch 3, d_loss=-0.141 g_loss=-0.415 KID= 0.02180\n",
      "epoch 399, batch 4, d_loss=-0.129 g_loss=-0.422 KID= 0.02180\n",
      "epoch 399, batch 5, d_loss=-0.127 g_loss=-0.378 KID= 0.02180\n",
      "epoch 399, batch 6, d_loss=-0.165 g_loss=-0.315 KID= 0.02180\n",
      "epoch 399, batch 7, d_loss=-0.122 g_loss=-0.307 KID= 0.02180\n",
      "epoch 399, batch 8, d_loss=-0.076 g_loss=-0.304 KID= 0.02180\n",
      "epoch 399, batch 9, d_loss=-0.139 g_loss=-0.290 KID= 0.02180\n",
      "epoch 399, batch 10, d_loss=-0.094 g_loss=-0.299 KID= 0.02180\n",
      "epoch 399, batch 11, d_loss=-0.149 g_loss=-0.257 KID= 0.02180\n",
      "epoch 399, batch 12, d_loss=-0.139 g_loss=-0.217 KID= 0.02180\n",
      "epoch 399, batch 13, d_loss=-0.151 g_loss=-0.155 KID= 0.02180\n",
      "epoch 399, batch 14, d_loss=-0.198 g_loss=-0.123 KID= 0.02180\n",
      "epoch 399, batch 15, d_loss=-0.145 g_loss=-0.059 KID= 0.02180\n",
      "epoch 399, batch 16, d_loss=-0.153 g_loss=-0.061 KID= 0.02180\n",
      "epoch 399, batch 17, d_loss=-0.168 g_loss=-0.153 KID= 0.02180\n",
      "epoch 399, batch 18, d_loss=-0.104 g_loss=-0.245 KID= 0.02180\n",
      "epoch 399, batch 19, d_loss=-0.104 g_loss=-0.388 KID= 0.02180\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 400, batch 0, d_loss=-0.106 g_loss=-0.397 KID= 0.01484\n",
      "epoch 400, batch 1, d_loss=-0.111 g_loss=-0.341 KID= 0.01484\n",
      "epoch 400, batch 2, d_loss=-0.158 g_loss=-0.285 KID= 0.01484\n",
      "epoch 400, batch 3, d_loss=-0.190 g_loss=-0.272 KID= 0.01484\n",
      "epoch 400, batch 4, d_loss=-0.189 g_loss=-0.318 KID= 0.01484\n",
      "epoch 400, batch 5, d_loss=-0.075 g_loss=-0.304 KID= 0.01484\n",
      "epoch 400, batch 6, d_loss=-0.093 g_loss=-0.359 KID= 0.01484\n",
      "epoch 400, batch 7, d_loss=-0.135 g_loss=-0.466 KID= 0.01484\n",
      "epoch 400, batch 8, d_loss=-0.102 g_loss=-0.494 KID= 0.01484\n",
      "epoch 400, batch 9, d_loss=-0.159 g_loss=-0.530 KID= 0.01484\n",
      "epoch 400, batch 10, d_loss=-0.086 g_loss=-0.504 KID= 0.01484\n",
      "epoch 400, batch 11, d_loss=-0.107 g_loss=-0.490 KID= 0.01484\n",
      "epoch 400, batch 12, d_loss=-0.130 g_loss=-0.296 KID= 0.01484\n",
      "epoch 400, batch 13, d_loss=-0.173 g_loss=-0.090 KID= 0.01484\n",
      "epoch 400, batch 14, d_loss=-0.172 g_loss=0.072 KID= 0.01484\n",
      "epoch 400, batch 15, d_loss=-0.182 g_loss=0.258 KID= 0.01484\n",
      "epoch 400, batch 16, d_loss=-0.119 g_loss=0.276 KID= 0.01484\n",
      "epoch 400, batch 17, d_loss=-0.144 g_loss=0.130 KID= 0.01484\n",
      "epoch 400, batch 18, d_loss=-0.079 g_loss=-0.038 KID= 0.01484\n",
      "epoch 400, batch 19, d_loss=-0.147 g_loss=-0.221 KID= 0.01484\n",
      "epoch 401, batch 0, d_loss=-0.127 g_loss=-0.341 KID= 0.01484\n",
      "epoch 401, batch 1, d_loss=-0.097 g_loss=-0.515 KID= 0.01484\n",
      "epoch 401, batch 2, d_loss=-0.114 g_loss=-0.565 KID= 0.01484\n",
      "epoch 401, batch 3, d_loss=-0.150 g_loss=-0.611 KID= 0.01484\n",
      "epoch 401, batch 4, d_loss=-0.170 g_loss=-0.552 KID= 0.01484\n",
      "epoch 401, batch 5, d_loss=-0.144 g_loss=-0.431 KID= 0.01484\n",
      "epoch 401, batch 6, d_loss=-0.138 g_loss=-0.476 KID= 0.01484\n",
      "epoch 401, batch 7, d_loss=-0.165 g_loss=-0.548 KID= 0.01484\n",
      "epoch 401, batch 8, d_loss=-0.157 g_loss=-0.498 KID= 0.01484\n",
      "epoch 401, batch 9, d_loss=-0.153 g_loss=-0.442 KID= 0.01484\n",
      "epoch 401, batch 10, d_loss=-0.178 g_loss=-0.422 KID= 0.01484\n",
      "epoch 401, batch 11, d_loss=-0.138 g_loss=-0.508 KID= 0.01484\n",
      "epoch 401, batch 12, d_loss=-0.112 g_loss=-0.540 KID= 0.01484\n",
      "epoch 401, batch 13, d_loss=-0.166 g_loss=-0.616 KID= 0.01484\n",
      "epoch 401, batch 14, d_loss=-0.117 g_loss=-0.630 KID= 0.01484\n",
      "epoch 401, batch 15, d_loss=-0.083 g_loss=-0.557 KID= 0.01484\n",
      "epoch 401, batch 16, d_loss=-0.112 g_loss=-0.467 KID= 0.01484\n",
      "epoch 401, batch 17, d_loss=-0.059 g_loss=-0.393 KID= 0.01484\n",
      "epoch 401, batch 18, d_loss=-0.090 g_loss=-0.290 KID= 0.01484\n",
      "epoch 401, batch 19, d_loss=-0.151 g_loss=-0.230 KID= 0.01484\n",
      "epoch 402, batch 0, d_loss=-0.142 g_loss=-0.234 KID= 0.01484\n",
      "epoch 402, batch 1, d_loss=-0.152 g_loss=-0.243 KID= 0.01484\n",
      "epoch 402, batch 2, d_loss=-0.164 g_loss=-0.258 KID= 0.01484\n",
      "epoch 402, batch 3, d_loss=-0.152 g_loss=-0.232 KID= 0.01484\n",
      "epoch 402, batch 4, d_loss=-0.163 g_loss=-0.184 KID= 0.01484\n",
      "epoch 402, batch 5, d_loss=-0.117 g_loss=0.016 KID= 0.01484\n",
      "epoch 402, batch 6, d_loss=-0.124 g_loss=0.093 KID= 0.01484\n",
      "epoch 402, batch 7, d_loss=-0.134 g_loss=0.026 KID= 0.01484\n",
      "epoch 402, batch 8, d_loss=-0.110 g_loss=-0.026 KID= 0.01484\n",
      "epoch 402, batch 9, d_loss=-0.093 g_loss=-0.050 KID= 0.01484\n",
      "epoch 402, batch 10, d_loss=-0.139 g_loss=-0.032 KID= 0.01484\n",
      "epoch 402, batch 11, d_loss=-0.137 g_loss=-0.122 KID= 0.01484\n",
      "epoch 402, batch 12, d_loss=-0.157 g_loss=-0.278 KID= 0.01484\n",
      "epoch 402, batch 13, d_loss=-0.157 g_loss=-0.438 KID= 0.01484\n",
      "epoch 402, batch 14, d_loss=-0.134 g_loss=-0.562 KID= 0.01484\n",
      "epoch 402, batch 15, d_loss=-0.087 g_loss=-0.559 KID= 0.01484\n",
      "epoch 402, batch 16, d_loss=-0.140 g_loss=-0.570 KID= 0.01484\n",
      "epoch 402, batch 17, d_loss=-0.104 g_loss=-0.603 KID= 0.01484\n",
      "epoch 402, batch 18, d_loss=-0.102 g_loss=-0.590 KID= 0.01484\n",
      "epoch 402, batch 19, d_loss=-0.179 g_loss=-0.481 KID= 0.01484\n",
      "epoch 403, batch 0, d_loss=-0.158 g_loss=-0.404 KID= 0.01484\n",
      "epoch 403, batch 1, d_loss=-0.113 g_loss=-0.382 KID= 0.01484\n",
      "epoch 403, batch 2, d_loss=-0.115 g_loss=-0.371 KID= 0.01484\n",
      "epoch 403, batch 3, d_loss=-0.149 g_loss=-0.336 KID= 0.01484\n",
      "epoch 403, batch 4, d_loss=-0.175 g_loss=-0.381 KID= 0.01484\n",
      "epoch 403, batch 5, d_loss=-0.030 g_loss=-0.419 KID= 0.01484\n",
      "epoch 403, batch 6, d_loss=-0.160 g_loss=-0.430 KID= 0.01484\n",
      "epoch 403, batch 7, d_loss=-0.145 g_loss=-0.442 KID= 0.01484\n",
      "epoch 403, batch 8, d_loss=-0.152 g_loss=-0.514 KID= 0.01484\n",
      "epoch 403, batch 9, d_loss=-0.152 g_loss=-0.519 KID= 0.01484\n",
      "epoch 403, batch 10, d_loss=-0.154 g_loss=-0.477 KID= 0.01484\n",
      "epoch 403, batch 11, d_loss=-0.176 g_loss=-0.398 KID= 0.01484\n",
      "epoch 403, batch 12, d_loss=-0.165 g_loss=-0.285 KID= 0.01484\n",
      "epoch 403, batch 13, d_loss=-0.177 g_loss=-0.243 KID= 0.01484\n",
      "epoch 403, batch 14, d_loss=-0.105 g_loss=-0.265 KID= 0.01484\n",
      "epoch 403, batch 15, d_loss=-0.110 g_loss=-0.188 KID= 0.01484\n",
      "epoch 403, batch 16, d_loss=-0.150 g_loss=-0.155 KID= 0.01484\n",
      "epoch 403, batch 17, d_loss=-0.125 g_loss=-0.214 KID= 0.01484\n",
      "epoch 403, batch 18, d_loss=-0.106 g_loss=-0.243 KID= 0.01484\n",
      "epoch 403, batch 19, d_loss=-0.171 g_loss=-0.224 KID= 0.01484\n",
      "epoch 404, batch 0, d_loss=-0.181 g_loss=-0.251 KID= 0.01484\n",
      "epoch 404, batch 1, d_loss=-0.103 g_loss=-0.235 KID= 0.01484\n",
      "epoch 404, batch 2, d_loss=-0.119 g_loss=-0.186 KID= 0.01484\n",
      "epoch 404, batch 3, d_loss=-0.170 g_loss=-0.226 KID= 0.01484\n",
      "epoch 404, batch 4, d_loss=-0.163 g_loss=-0.316 KID= 0.01484\n",
      "epoch 404, batch 5, d_loss=-0.031 g_loss=-0.371 KID= 0.01484\n",
      "epoch 404, batch 6, d_loss=-0.118 g_loss=-0.406 KID= 0.01484\n",
      "epoch 404, batch 7, d_loss=-0.135 g_loss=-0.515 KID= 0.01484\n",
      "epoch 404, batch 8, d_loss=-0.107 g_loss=-0.610 KID= 0.01484\n",
      "epoch 404, batch 9, d_loss=-0.163 g_loss=-0.704 KID= 0.01484\n",
      "epoch 404, batch 10, d_loss=-0.149 g_loss=-0.708 KID= 0.01484\n",
      "epoch 404, batch 11, d_loss=-0.159 g_loss=-0.724 KID= 0.01484\n",
      "epoch 404, batch 12, d_loss=-0.190 g_loss=-0.639 KID= 0.01484\n",
      "epoch 404, batch 13, d_loss=-0.163 g_loss=-0.636 KID= 0.01484\n",
      "epoch 404, batch 14, d_loss=-0.136 g_loss=-0.619 KID= 0.01484\n",
      "epoch 404, batch 15, d_loss=-0.116 g_loss=-0.449 KID= 0.01484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 404, batch 16, d_loss=-0.187 g_loss=-0.236 KID= 0.01484\n",
      "epoch 404, batch 17, d_loss=-0.109 g_loss=-0.130 KID= 0.01484\n",
      "epoch 404, batch 18, d_loss=-0.093 g_loss=-0.190 KID= 0.01484\n",
      "epoch 404, batch 19, d_loss=-0.137 g_loss=-0.202 KID= 0.01484\n",
      "epoch 405, batch 0, d_loss=-0.126 g_loss=-0.204 KID= 0.01484\n",
      "epoch 405, batch 1, d_loss=-0.102 g_loss=-0.114 KID= 0.01484\n",
      "epoch 405, batch 2, d_loss=-0.151 g_loss=0.121 KID= 0.01484\n",
      "epoch 405, batch 3, d_loss=-0.148 g_loss=0.333 KID= 0.01484\n",
      "epoch 405, batch 4, d_loss=-0.144 g_loss=0.386 KID= 0.01484\n",
      "epoch 405, batch 5, d_loss=-0.151 g_loss=0.380 KID= 0.01484\n",
      "epoch 405, batch 6, d_loss=-0.131 g_loss=0.266 KID= 0.01484\n",
      "epoch 405, batch 7, d_loss=-0.115 g_loss=0.030 KID= 0.01484\n",
      "epoch 405, batch 8, d_loss=-0.161 g_loss=-0.212 KID= 0.01484\n",
      "epoch 405, batch 9, d_loss=-0.157 g_loss=-0.499 KID= 0.01484\n",
      "epoch 405, batch 10, d_loss=-0.190 g_loss=-0.776 KID= 0.01484\n",
      "epoch 405, batch 11, d_loss=-0.095 g_loss=-0.936 KID= 0.01484\n",
      "epoch 405, batch 12, d_loss=-0.120 g_loss=-1.073 KID= 0.01484\n",
      "epoch 405, batch 13, d_loss=-0.183 g_loss=-1.160 KID= 0.01484\n",
      "epoch 405, batch 14, d_loss=-0.168 g_loss=-1.278 KID= 0.01484\n",
      "epoch 405, batch 15, d_loss=-0.034 g_loss=-1.212 KID= 0.01484\n",
      "epoch 405, batch 16, d_loss=-0.151 g_loss=-1.145 KID= 0.01484\n",
      "epoch 405, batch 17, d_loss=-0.095 g_loss=-1.054 KID= 0.01484\n",
      "epoch 405, batch 18, d_loss=-0.104 g_loss=-0.918 KID= 0.01484\n",
      "epoch 405, batch 19, d_loss=-0.127 g_loss=-0.788 KID= 0.01484\n",
      "epoch 406, batch 0, d_loss=-0.142 g_loss=-0.561 KID= 0.01484\n",
      "epoch 406, batch 1, d_loss=-0.151 g_loss=-0.328 KID= 0.01484\n",
      "epoch 406, batch 2, d_loss=-0.208 g_loss=-0.076 KID= 0.01484\n",
      "epoch 406, batch 3, d_loss=-0.204 g_loss=0.078 KID= 0.01484\n",
      "epoch 406, batch 4, d_loss=-0.167 g_loss=0.127 KID= 0.01484\n",
      "epoch 406, batch 5, d_loss=-0.069 g_loss=0.114 KID= 0.01484\n",
      "epoch 406, batch 6, d_loss=-0.096 g_loss=0.053 KID= 0.01484\n",
      "epoch 406, batch 7, d_loss=-0.121 g_loss=-0.026 KID= 0.01484\n",
      "epoch 406, batch 8, d_loss=-0.109 g_loss=-0.044 KID= 0.01484\n",
      "epoch 406, batch 9, d_loss=-0.152 g_loss=-0.051 KID= 0.01484\n",
      "epoch 406, batch 10, d_loss=-0.160 g_loss=-0.077 KID= 0.01484\n",
      "epoch 406, batch 11, d_loss=-0.156 g_loss=-0.034 KID= 0.01484\n",
      "epoch 406, batch 12, d_loss=-0.165 g_loss=0.037 KID= 0.01484\n",
      "epoch 406, batch 13, d_loss=-0.113 g_loss=0.013 KID= 0.01484\n",
      "epoch 406, batch 14, d_loss=-0.187 g_loss=-0.026 KID= 0.01484\n",
      "epoch 406, batch 15, d_loss=-0.122 g_loss=-0.031 KID= 0.01484\n",
      "epoch 406, batch 16, d_loss=-0.160 g_loss=-0.042 KID= 0.01484\n",
      "epoch 406, batch 17, d_loss=-0.142 g_loss=-0.117 KID= 0.01484\n",
      "epoch 406, batch 18, d_loss=-0.098 g_loss=-0.228 KID= 0.01484\n",
      "epoch 406, batch 19, d_loss=-0.154 g_loss=-0.311 KID= 0.01484\n",
      "epoch 407, batch 0, d_loss=-0.126 g_loss=-0.389 KID= 0.01484\n",
      "epoch 407, batch 1, d_loss=-0.075 g_loss=-0.438 KID= 0.01484\n",
      "epoch 407, batch 2, d_loss=-0.101 g_loss=-0.435 KID= 0.01484\n",
      "epoch 407, batch 3, d_loss=-0.142 g_loss=-0.567 KID= 0.01484\n",
      "epoch 407, batch 4, d_loss=-0.127 g_loss=-0.708 KID= 0.01484\n",
      "epoch 407, batch 5, d_loss=-0.110 g_loss=-0.670 KID= 0.01484\n",
      "epoch 407, batch 6, d_loss=-0.201 g_loss=-0.769 KID= 0.01484\n",
      "epoch 407, batch 7, d_loss=-0.118 g_loss=-0.864 KID= 0.01484\n",
      "epoch 407, batch 8, d_loss=-0.121 g_loss=-0.944 KID= 0.01484\n",
      "epoch 407, batch 9, d_loss=-0.204 g_loss=-0.994 KID= 0.01484\n",
      "epoch 407, batch 10, d_loss=-0.198 g_loss=-1.071 KID= 0.01484\n",
      "epoch 407, batch 11, d_loss=-0.166 g_loss=-1.026 KID= 0.01484\n",
      "epoch 407, batch 12, d_loss=-0.164 g_loss=-1.020 KID= 0.01484\n",
      "epoch 407, batch 13, d_loss=-0.133 g_loss=-0.945 KID= 0.01484\n",
      "epoch 407, batch 14, d_loss=-0.131 g_loss=-0.682 KID= 0.01484\n",
      "epoch 407, batch 15, d_loss=-0.119 g_loss=-0.434 KID= 0.01484\n",
      "epoch 407, batch 16, d_loss=-0.159 g_loss=-0.218 KID= 0.01484\n",
      "epoch 407, batch 17, d_loss=-0.156 g_loss=-0.201 KID= 0.01484\n",
      "epoch 407, batch 18, d_loss=-0.075 g_loss=-0.154 KID= 0.01484\n",
      "epoch 407, batch 19, d_loss=-0.112 g_loss=-0.131 KID= 0.01484\n",
      "epoch 408, batch 0, d_loss=-0.147 g_loss=-0.170 KID= 0.01484\n",
      "epoch 408, batch 1, d_loss=-0.113 g_loss=0.006 KID= 0.01484\n",
      "epoch 408, batch 2, d_loss=-0.194 g_loss=0.237 KID= 0.01484\n",
      "epoch 408, batch 3, d_loss=-0.195 g_loss=0.276 KID= 0.01484\n",
      "epoch 408, batch 4, d_loss=-0.109 g_loss=0.217 KID= 0.01484\n",
      "epoch 408, batch 5, d_loss=-0.118 g_loss=0.171 KID= 0.01484\n",
      "epoch 408, batch 6, d_loss=-0.127 g_loss=0.091 KID= 0.01484\n",
      "epoch 408, batch 7, d_loss=-0.114 g_loss=-0.075 KID= 0.01484\n",
      "epoch 408, batch 8, d_loss=-0.148 g_loss=-0.253 KID= 0.01484\n",
      "epoch 408, batch 9, d_loss=-0.164 g_loss=-0.443 KID= 0.01484\n",
      "epoch 408, batch 10, d_loss=-0.186 g_loss=-0.646 KID= 0.01484\n",
      "epoch 408, batch 11, d_loss=-0.128 g_loss=-0.759 KID= 0.01484\n",
      "epoch 408, batch 12, d_loss=-0.151 g_loss=-0.812 KID= 0.01484\n",
      "epoch 408, batch 13, d_loss=-0.184 g_loss=-0.889 KID= 0.01484\n",
      "epoch 408, batch 14, d_loss=-0.191 g_loss=-0.894 KID= 0.01484\n",
      "epoch 408, batch 15, d_loss=-0.047 g_loss=-0.786 KID= 0.01484\n",
      "epoch 408, batch 16, d_loss=-0.187 g_loss=-0.735 KID= 0.01484\n",
      "epoch 408, batch 17, d_loss=-0.119 g_loss=-0.778 KID= 0.01484\n",
      "epoch 408, batch 18, d_loss=-0.093 g_loss=-0.743 KID= 0.01484\n",
      "epoch 408, batch 19, d_loss=-0.116 g_loss=-0.607 KID= 0.01484\n",
      "epoch 409, batch 0, d_loss=-0.179 g_loss=-0.527 KID= 0.01484\n",
      "epoch 409, batch 1, d_loss=-0.145 g_loss=-0.450 KID= 0.01484\n",
      "epoch 409, batch 2, d_loss=-0.186 g_loss=-0.346 KID= 0.01484\n",
      "epoch 409, batch 3, d_loss=-0.195 g_loss=-0.316 KID= 0.01484\n",
      "epoch 409, batch 4, d_loss=-0.263 g_loss=-0.242 KID= 0.01484\n",
      "epoch 409, batch 5, d_loss=-0.158 g_loss=-0.070 KID= 0.01484\n",
      "epoch 409, batch 6, d_loss=-0.081 g_loss=0.004 KID= 0.01484\n",
      "epoch 409, batch 7, d_loss=-0.108 g_loss=-0.111 KID= 0.01484\n",
      "epoch 409, batch 8, d_loss=-0.139 g_loss=-0.025 KID= 0.01484\n",
      "epoch 409, batch 9, d_loss=-0.192 g_loss=-0.008 KID= 0.01484\n",
      "epoch 409, batch 10, d_loss=-0.165 g_loss=-0.085 KID= 0.01484\n",
      "epoch 409, batch 11, d_loss=-0.100 g_loss=-0.141 KID= 0.01484\n",
      "epoch 409, batch 12, d_loss=-0.134 g_loss=-0.131 KID= 0.01484\n",
      "epoch 409, batch 13, d_loss=-0.140 g_loss=-0.194 KID= 0.01484\n",
      "epoch 409, batch 14, d_loss=-0.182 g_loss=-0.309 KID= 0.01484\n",
      "epoch 409, batch 15, d_loss=-0.164 g_loss=-0.233 KID= 0.01484\n",
      "epoch 409, batch 16, d_loss=-0.158 g_loss=-0.193 KID= 0.01484\n",
      "epoch 409, batch 17, d_loss=-0.092 g_loss=-0.234 KID= 0.01484\n",
      "epoch 409, batch 18, d_loss=-0.135 g_loss=-0.244 KID= 0.01484\n",
      "epoch 409, batch 19, d_loss=-0.116 g_loss=-0.175 KID= 0.01484\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 410, batch 0, d_loss=-0.165 g_loss=-0.162 KID= 0.01918\n",
      "epoch 410, batch 1, d_loss=-0.093 g_loss=-0.157 KID= 0.01918\n",
      "epoch 410, batch 2, d_loss=-0.140 g_loss=-0.214 KID= 0.01918\n",
      "epoch 410, batch 3, d_loss=-0.163 g_loss=-0.201 KID= 0.01918\n",
      "epoch 410, batch 4, d_loss=-0.198 g_loss=-0.178 KID= 0.01918\n",
      "epoch 410, batch 5, d_loss=-0.158 g_loss=-0.141 KID= 0.01918\n",
      "epoch 410, batch 6, d_loss=-0.171 g_loss=-0.093 KID= 0.01918\n",
      "epoch 410, batch 7, d_loss=-0.155 g_loss=-0.199 KID= 0.01918\n",
      "epoch 410, batch 8, d_loss=-0.092 g_loss=-0.206 KID= 0.01918\n",
      "epoch 410, batch 9, d_loss=-0.114 g_loss=-0.180 KID= 0.01918\n",
      "epoch 410, batch 10, d_loss=-0.184 g_loss=-0.246 KID= 0.01918\n",
      "epoch 410, batch 11, d_loss=-0.130 g_loss=-0.300 KID= 0.01918\n",
      "epoch 410, batch 12, d_loss=-0.166 g_loss=-0.372 KID= 0.01918\n",
      "epoch 410, batch 13, d_loss=-0.168 g_loss=-0.394 KID= 0.01918\n",
      "epoch 410, batch 14, d_loss=-0.145 g_loss=-0.438 KID= 0.01918\n",
      "epoch 410, batch 15, d_loss=-0.037 g_loss=-0.414 KID= 0.01918\n",
      "epoch 410, batch 16, d_loss=-0.163 g_loss=-0.409 KID= 0.01918\n",
      "epoch 410, batch 17, d_loss=-0.165 g_loss=-0.401 KID= 0.01918\n",
      "epoch 410, batch 18, d_loss=-0.143 g_loss=-0.421 KID= 0.01918\n",
      "epoch 410, batch 19, d_loss=-0.145 g_loss=-0.387 KID= 0.01918\n",
      "epoch 411, batch 0, d_loss=-0.144 g_loss=-0.361 KID= 0.01918\n",
      "epoch 411, batch 1, d_loss=-0.113 g_loss=-0.309 KID= 0.01918\n",
      "epoch 411, batch 2, d_loss=-0.147 g_loss=-0.193 KID= 0.01918\n",
      "epoch 411, batch 3, d_loss=-0.151 g_loss=-0.107 KID= 0.01918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 411, batch 4, d_loss=-0.223 g_loss=-0.131 KID= 0.01918\n",
      "epoch 411, batch 5, d_loss=-0.063 g_loss=-0.102 KID= 0.01918\n",
      "epoch 411, batch 6, d_loss=-0.107 g_loss=-0.127 KID= 0.01918\n",
      "epoch 411, batch 7, d_loss=-0.209 g_loss=-0.193 KID= 0.01918\n",
      "epoch 411, batch 8, d_loss=-0.141 g_loss=-0.223 KID= 0.01918\n",
      "epoch 411, batch 9, d_loss=-0.164 g_loss=-0.310 KID= 0.01918\n",
      "epoch 411, batch 10, d_loss=-0.148 g_loss=-0.361 KID= 0.01918\n",
      "epoch 411, batch 11, d_loss=-0.118 g_loss=-0.396 KID= 0.01918\n",
      "epoch 411, batch 12, d_loss=-0.159 g_loss=-0.353 KID= 0.01918\n",
      "epoch 411, batch 13, d_loss=-0.123 g_loss=-0.332 KID= 0.01918\n",
      "epoch 411, batch 14, d_loss=-0.106 g_loss=-0.393 KID= 0.01918\n",
      "epoch 411, batch 15, d_loss=-0.149 g_loss=-0.270 KID= 0.01918\n",
      "epoch 411, batch 16, d_loss=-0.189 g_loss=-0.271 KID= 0.01918\n",
      "epoch 411, batch 17, d_loss=-0.072 g_loss=-0.404 KID= 0.01918\n",
      "epoch 411, batch 18, d_loss=-0.092 g_loss=-0.475 KID= 0.01918\n",
      "epoch 411, batch 19, d_loss=-0.126 g_loss=-0.510 KID= 0.01918\n",
      "epoch 412, batch 0, d_loss=-0.169 g_loss=-0.612 KID= 0.01918\n",
      "epoch 412, batch 1, d_loss=-0.186 g_loss=-0.660 KID= 0.01918\n",
      "epoch 412, batch 2, d_loss=-0.197 g_loss=-0.556 KID= 0.01918\n",
      "epoch 412, batch 3, d_loss=-0.209 g_loss=-0.577 KID= 0.01918\n",
      "epoch 412, batch 4, d_loss=-0.204 g_loss=-0.572 KID= 0.01918\n",
      "epoch 412, batch 5, d_loss=-0.055 g_loss=-0.500 KID= 0.01918\n",
      "epoch 412, batch 6, d_loss=-0.147 g_loss=-0.419 KID= 0.01918\n",
      "epoch 412, batch 7, d_loss=-0.118 g_loss=-0.421 KID= 0.01918\n",
      "epoch 412, batch 8, d_loss=-0.075 g_loss=-0.386 KID= 0.01918\n",
      "epoch 412, batch 9, d_loss=-0.151 g_loss=-0.382 KID= 0.01918\n",
      "epoch 412, batch 10, d_loss=-0.181 g_loss=-0.425 KID= 0.01918\n",
      "epoch 412, batch 11, d_loss=-0.158 g_loss=-0.444 KID= 0.01918\n",
      "epoch 412, batch 12, d_loss=-0.160 g_loss=-0.427 KID= 0.01918\n",
      "epoch 412, batch 13, d_loss=-0.174 g_loss=-0.359 KID= 0.01918\n",
      "epoch 412, batch 14, d_loss=-0.097 g_loss=-0.338 KID= 0.01918\n",
      "epoch 412, batch 15, d_loss=-0.109 g_loss=-0.242 KID= 0.01918\n",
      "epoch 412, batch 16, d_loss=-0.132 g_loss=-0.141 KID= 0.01918\n",
      "epoch 412, batch 17, d_loss=-0.130 g_loss=-0.144 KID= 0.01918\n",
      "epoch 412, batch 18, d_loss=-0.137 g_loss=-0.014 KID= 0.01918\n",
      "epoch 412, batch 19, d_loss=-0.170 g_loss=0.053 KID= 0.01918\n",
      "epoch 413, batch 0, d_loss=-0.192 g_loss=0.074 KID= 0.01918\n",
      "epoch 413, batch 1, d_loss=-0.137 g_loss=-0.036 KID= 0.01918\n",
      "epoch 413, batch 2, d_loss=-0.173 g_loss=-0.187 KID= 0.01918\n",
      "epoch 413, batch 3, d_loss=-0.121 g_loss=-0.293 KID= 0.01918\n",
      "epoch 413, batch 4, d_loss=-0.117 g_loss=-0.378 KID= 0.01918\n",
      "epoch 413, batch 5, d_loss=-0.112 g_loss=-0.405 KID= 0.01918\n",
      "epoch 413, batch 6, d_loss=-0.171 g_loss=-0.504 KID= 0.01918\n",
      "epoch 413, batch 7, d_loss=-0.148 g_loss=-0.580 KID= 0.01918\n",
      "epoch 413, batch 8, d_loss=-0.117 g_loss=-0.620 KID= 0.01918\n",
      "epoch 413, batch 9, d_loss=-0.201 g_loss=-0.659 KID= 0.01918\n",
      "epoch 413, batch 10, d_loss=-0.159 g_loss=-0.655 KID= 0.01918\n",
      "epoch 413, batch 11, d_loss=-0.155 g_loss=-0.649 KID= 0.01918\n",
      "epoch 413, batch 12, d_loss=-0.167 g_loss=-0.521 KID= 0.01918\n",
      "epoch 413, batch 13, d_loss=-0.216 g_loss=-0.485 KID= 0.01918\n",
      "epoch 413, batch 14, d_loss=-0.129 g_loss=-0.418 KID= 0.01918\n",
      "epoch 413, batch 15, d_loss=-0.133 g_loss=-0.381 KID= 0.01918\n",
      "epoch 413, batch 16, d_loss=-0.181 g_loss=-0.396 KID= 0.01918\n",
      "epoch 413, batch 17, d_loss=-0.160 g_loss=-0.513 KID= 0.01918\n",
      "epoch 413, batch 18, d_loss=-0.162 g_loss=-0.584 KID= 0.01918\n",
      "epoch 413, batch 19, d_loss=-0.143 g_loss=-0.676 KID= 0.01918\n",
      "epoch 414, batch 0, d_loss=-0.142 g_loss=-0.688 KID= 0.01918\n",
      "epoch 414, batch 1, d_loss=-0.126 g_loss=-0.693 KID= 0.01918\n",
      "epoch 414, batch 2, d_loss=-0.203 g_loss=-0.659 KID= 0.01918\n",
      "epoch 414, batch 3, d_loss=-0.142 g_loss=-0.640 KID= 0.01918\n",
      "epoch 414, batch 4, d_loss=-0.067 g_loss=-0.649 KID= 0.01918\n",
      "epoch 414, batch 5, d_loss=-0.117 g_loss=-0.501 KID= 0.01918\n",
      "epoch 414, batch 6, d_loss=-0.149 g_loss=-0.380 KID= 0.01918\n",
      "epoch 414, batch 7, d_loss=-0.196 g_loss=-0.338 KID= 0.01918\n",
      "epoch 414, batch 8, d_loss=-0.123 g_loss=-0.261 KID= 0.01918\n",
      "epoch 414, batch 9, d_loss=-0.165 g_loss=-0.253 KID= 0.01918\n",
      "epoch 414, batch 10, d_loss=-0.162 g_loss=-0.161 KID= 0.01918\n",
      "epoch 414, batch 11, d_loss=-0.152 g_loss=-0.100 KID= 0.01918\n",
      "epoch 414, batch 12, d_loss=-0.207 g_loss=-0.003 KID= 0.01918\n",
      "epoch 414, batch 13, d_loss=-0.146 g_loss=0.015 KID= 0.01918\n",
      "epoch 414, batch 14, d_loss=-0.168 g_loss=-0.063 KID= 0.01918\n",
      "epoch 414, batch 15, d_loss=-0.208 g_loss=-0.028 KID= 0.01918\n",
      "epoch 414, batch 16, d_loss=-0.155 g_loss=-0.129 KID= 0.01918\n",
      "epoch 414, batch 17, d_loss=-0.123 g_loss=-0.299 KID= 0.01918\n",
      "epoch 414, batch 18, d_loss=-0.112 g_loss=-0.437 KID= 0.01918\n",
      "epoch 414, batch 19, d_loss=-0.170 g_loss=-0.595 KID= 0.01918\n",
      "epoch 415, batch 0, d_loss=-0.154 g_loss=-0.664 KID= 0.01918\n",
      "epoch 415, batch 1, d_loss=-0.119 g_loss=-0.723 KID= 0.01918\n",
      "epoch 415, batch 2, d_loss=-0.131 g_loss=-0.687 KID= 0.01918\n",
      "epoch 415, batch 3, d_loss=-0.157 g_loss=-0.620 KID= 0.01918\n",
      "epoch 415, batch 4, d_loss=-0.144 g_loss=-0.521 KID= 0.01918\n",
      "epoch 415, batch 5, d_loss=-0.134 g_loss=-0.346 KID= 0.01918\n",
      "epoch 415, batch 6, d_loss=-0.125 g_loss=-0.251 KID= 0.01918\n",
      "epoch 415, batch 7, d_loss=-0.173 g_loss=-0.227 KID= 0.01918\n",
      "epoch 415, batch 8, d_loss=-0.143 g_loss=-0.132 KID= 0.01918\n",
      "epoch 415, batch 9, d_loss=-0.170 g_loss=-0.122 KID= 0.01918\n",
      "epoch 415, batch 10, d_loss=-0.182 g_loss=-0.090 KID= 0.01918\n",
      "epoch 415, batch 11, d_loss=-0.148 g_loss=-0.174 KID= 0.01918\n",
      "epoch 415, batch 12, d_loss=-0.159 g_loss=-0.330 KID= 0.01918\n",
      "epoch 415, batch 13, d_loss=-0.185 g_loss=-0.470 KID= 0.01918\n",
      "epoch 415, batch 14, d_loss=-0.076 g_loss=-0.526 KID= 0.01918\n",
      "epoch 415, batch 15, d_loss=-0.074 g_loss=-0.528 KID= 0.01918\n",
      "epoch 415, batch 16, d_loss=-0.165 g_loss=-0.511 KID= 0.01918\n",
      "epoch 415, batch 17, d_loss=-0.175 g_loss=-0.468 KID= 0.01918\n",
      "epoch 415, batch 18, d_loss=-0.119 g_loss=-0.418 KID= 0.01918\n",
      "epoch 415, batch 19, d_loss=-0.171 g_loss=-0.398 KID= 0.01918\n",
      "epoch 416, batch 0, d_loss=-0.192 g_loss=-0.382 KID= 0.01918\n",
      "epoch 416, batch 1, d_loss=-0.093 g_loss=-0.350 KID= 0.01918\n",
      "epoch 416, batch 2, d_loss=-0.161 g_loss=-0.283 KID= 0.01918\n",
      "epoch 416, batch 3, d_loss=-0.173 g_loss=-0.145 KID= 0.01918\n",
      "epoch 416, batch 4, d_loss=-0.163 g_loss=-0.084 KID= 0.01918\n",
      "epoch 416, batch 5, d_loss=-0.172 g_loss=-0.131 KID= 0.01918\n",
      "epoch 416, batch 6, d_loss=-0.135 g_loss=-0.254 KID= 0.01918\n",
      "epoch 416, batch 7, d_loss=-0.170 g_loss=-0.456 KID= 0.01918\n",
      "epoch 416, batch 8, d_loss=-0.125 g_loss=-0.596 KID= 0.01918\n",
      "epoch 416, batch 9, d_loss=-0.197 g_loss=-0.727 KID= 0.01918\n",
      "epoch 416, batch 10, d_loss=-0.106 g_loss=-0.746 KID= 0.01918\n",
      "epoch 416, batch 11, d_loss=-0.184 g_loss=-0.785 KID= 0.01918\n",
      "epoch 416, batch 12, d_loss=-0.146 g_loss=-0.740 KID= 0.01918\n",
      "epoch 416, batch 13, d_loss=-0.180 g_loss=-0.724 KID= 0.01918\n",
      "epoch 416, batch 14, d_loss=-0.141 g_loss=-0.662 KID= 0.01918\n",
      "epoch 416, batch 15, d_loss=-0.137 g_loss=-0.548 KID= 0.01918\n",
      "epoch 416, batch 16, d_loss=-0.148 g_loss=-0.546 KID= 0.01918\n",
      "epoch 416, batch 17, d_loss=-0.131 g_loss=-0.515 KID= 0.01918\n",
      "epoch 416, batch 18, d_loss=-0.133 g_loss=-0.528 KID= 0.01918\n",
      "epoch 416, batch 19, d_loss=-0.161 g_loss=-0.501 KID= 0.01918\n",
      "epoch 417, batch 0, d_loss=-0.181 g_loss=-0.469 KID= 0.01918\n",
      "epoch 417, batch 1, d_loss=-0.086 g_loss=-0.349 KID= 0.01918\n",
      "epoch 417, batch 2, d_loss=-0.165 g_loss=-0.293 KID= 0.01918\n",
      "epoch 417, batch 3, d_loss=-0.174 g_loss=-0.213 KID= 0.01918\n",
      "epoch 417, batch 4, d_loss=-0.113 g_loss=-0.167 KID= 0.01918\n",
      "epoch 417, batch 5, d_loss=-0.106 g_loss=-0.109 KID= 0.01918\n",
      "epoch 417, batch 6, d_loss=-0.137 g_loss=-0.158 KID= 0.01918\n",
      "epoch 417, batch 7, d_loss=-0.146 g_loss=-0.231 KID= 0.01918\n",
      "epoch 417, batch 8, d_loss=-0.112 g_loss=-0.305 KID= 0.01918\n",
      "epoch 417, batch 9, d_loss=-0.190 g_loss=-0.326 KID= 0.01918\n",
      "epoch 417, batch 10, d_loss=-0.207 g_loss=-0.340 KID= 0.01918\n",
      "epoch 417, batch 11, d_loss=-0.168 g_loss=-0.335 KID= 0.01918\n",
      "epoch 417, batch 12, d_loss=-0.199 g_loss=-0.312 KID= 0.01918\n",
      "epoch 417, batch 13, d_loss=-0.213 g_loss=-0.297 KID= 0.01918\n",
      "epoch 417, batch 14, d_loss=-0.085 g_loss=-0.250 KID= 0.01918\n",
      "epoch 417, batch 15, d_loss=-0.163 g_loss=-0.164 KID= 0.01918\n",
      "epoch 417, batch 16, d_loss=-0.152 g_loss=-0.221 KID= 0.01918\n",
      "epoch 417, batch 17, d_loss=-0.167 g_loss=-0.434 KID= 0.01918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 417, batch 18, d_loss=-0.068 g_loss=-0.599 KID= 0.01918\n",
      "epoch 417, batch 19, d_loss=-0.156 g_loss=-0.827 KID= 0.01918\n",
      "epoch 418, batch 0, d_loss=-0.150 g_loss=-0.824 KID= 0.01918\n",
      "epoch 418, batch 1, d_loss=-0.165 g_loss=-0.822 KID= 0.01918\n",
      "epoch 418, batch 2, d_loss=-0.164 g_loss=-0.741 KID= 0.01918\n",
      "epoch 418, batch 3, d_loss=-0.183 g_loss=-0.700 KID= 0.01918\n",
      "epoch 418, batch 4, d_loss=-0.098 g_loss=-0.647 KID= 0.01918\n",
      "epoch 418, batch 5, d_loss=-0.152 g_loss=-0.540 KID= 0.01918\n",
      "epoch 418, batch 6, d_loss=-0.141 g_loss=-0.460 KID= 0.01918\n",
      "epoch 418, batch 7, d_loss=-0.140 g_loss=-0.482 KID= 0.01918\n",
      "epoch 418, batch 8, d_loss=-0.203 g_loss=-0.514 KID= 0.01918\n",
      "epoch 418, batch 9, d_loss=-0.170 g_loss=-0.627 KID= 0.01918\n",
      "epoch 418, batch 10, d_loss=-0.164 g_loss=-0.691 KID= 0.01918\n",
      "epoch 418, batch 11, d_loss=-0.146 g_loss=-0.730 KID= 0.01918\n",
      "epoch 418, batch 12, d_loss=-0.175 g_loss=-0.681 KID= 0.01918\n",
      "epoch 418, batch 13, d_loss=-0.209 g_loss=-0.660 KID= 0.01918\n",
      "epoch 418, batch 14, d_loss=-0.089 g_loss=-0.551 KID= 0.01918\n",
      "epoch 418, batch 15, d_loss=-0.111 g_loss=-0.489 KID= 0.01918\n",
      "epoch 418, batch 16, d_loss=-0.128 g_loss=-0.436 KID= 0.01918\n",
      "epoch 418, batch 17, d_loss=-0.113 g_loss=-0.430 KID= 0.01918\n",
      "epoch 418, batch 18, d_loss=-0.148 g_loss=-0.381 KID= 0.01918\n",
      "epoch 418, batch 19, d_loss=-0.173 g_loss=-0.351 KID= 0.01918\n",
      "epoch 419, batch 0, d_loss=-0.222 g_loss=-0.386 KID= 0.01918\n",
      "epoch 419, batch 1, d_loss=-0.159 g_loss=-0.421 KID= 0.01918\n",
      "epoch 419, batch 2, d_loss=-0.139 g_loss=-0.454 KID= 0.01918\n",
      "epoch 419, batch 3, d_loss=-0.182 g_loss=-0.438 KID= 0.01918\n",
      "epoch 419, batch 4, d_loss=-0.136 g_loss=-0.385 KID= 0.01918\n",
      "epoch 419, batch 5, d_loss=-0.176 g_loss=-0.350 KID= 0.01918\n",
      "epoch 419, batch 6, d_loss=-0.166 g_loss=-0.387 KID= 0.01918\n",
      "epoch 419, batch 7, d_loss=-0.144 g_loss=-0.482 KID= 0.01918\n",
      "epoch 419, batch 8, d_loss=-0.101 g_loss=-0.589 KID= 0.01918\n",
      "epoch 419, batch 9, d_loss=-0.145 g_loss=-0.681 KID= 0.01918\n",
      "epoch 419, batch 10, d_loss=-0.146 g_loss=-0.699 KID= 0.01918\n",
      "epoch 419, batch 11, d_loss=-0.179 g_loss=-0.676 KID= 0.01918\n",
      "epoch 419, batch 12, d_loss=-0.178 g_loss=-0.711 KID= 0.01918\n",
      "epoch 419, batch 13, d_loss=-0.181 g_loss=-0.773 KID= 0.01918\n",
      "epoch 419, batch 14, d_loss=-0.095 g_loss=-0.727 KID= 0.01918\n",
      "epoch 419, batch 15, d_loss=-0.166 g_loss=-0.687 KID= 0.01918\n",
      "epoch 419, batch 16, d_loss=-0.158 g_loss=-0.589 KID= 0.01918\n",
      "epoch 419, batch 17, d_loss=-0.142 g_loss=-0.625 KID= 0.01918\n",
      "epoch 419, batch 18, d_loss=-0.130 g_loss=-0.554 KID= 0.01918\n",
      "epoch 419, batch 19, d_loss=-0.132 g_loss=-0.503 KID= 0.01918\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 420, batch 0, d_loss=-0.196 g_loss=-0.444 KID= 0.01758\n",
      "epoch 420, batch 1, d_loss=-0.145 g_loss=-0.385 KID= 0.01758\n",
      "epoch 420, batch 2, d_loss=-0.197 g_loss=-0.481 KID= 0.01758\n",
      "epoch 420, batch 3, d_loss=-0.257 g_loss=-0.622 KID= 0.01758\n",
      "epoch 420, batch 4, d_loss=-0.095 g_loss=-0.721 KID= 0.01758\n",
      "epoch 420, batch 5, d_loss=-0.052 g_loss=-0.707 KID= 0.01758\n",
      "epoch 420, batch 6, d_loss=-0.143 g_loss=-0.672 KID= 0.01758\n",
      "epoch 420, batch 7, d_loss=-0.113 g_loss=-0.639 KID= 0.01758\n",
      "epoch 420, batch 8, d_loss=-0.184 g_loss=-0.586 KID= 0.01758\n",
      "epoch 420, batch 9, d_loss=-0.197 g_loss=-0.626 KID= 0.01758\n",
      "epoch 420, batch 10, d_loss=-0.202 g_loss=-0.566 KID= 0.01758\n",
      "epoch 420, batch 11, d_loss=-0.104 g_loss=-0.485 KID= 0.01758\n",
      "epoch 420, batch 12, d_loss=-0.185 g_loss=-0.459 KID= 0.01758\n",
      "epoch 420, batch 13, d_loss=-0.132 g_loss=-0.423 KID= 0.01758\n",
      "epoch 420, batch 14, d_loss=-0.112 g_loss=-0.375 KID= 0.01758\n",
      "epoch 420, batch 15, d_loss=-0.176 g_loss=-0.362 KID= 0.01758\n",
      "epoch 420, batch 16, d_loss=-0.146 g_loss=-0.383 KID= 0.01758\n",
      "epoch 420, batch 17, d_loss=-0.140 g_loss=-0.429 KID= 0.01758\n",
      "epoch 420, batch 18, d_loss=-0.111 g_loss=-0.488 KID= 0.01758\n",
      "epoch 420, batch 19, d_loss=-0.169 g_loss=-0.500 KID= 0.01758\n",
      "epoch 421, batch 0, d_loss=-0.160 g_loss=-0.473 KID= 0.01758\n",
      "epoch 421, batch 1, d_loss=-0.179 g_loss=-0.461 KID= 0.01758\n",
      "epoch 421, batch 2, d_loss=-0.166 g_loss=-0.410 KID= 0.01758\n",
      "epoch 421, batch 3, d_loss=-0.193 g_loss=-0.386 KID= 0.01758\n",
      "epoch 421, batch 4, d_loss=-0.116 g_loss=-0.368 KID= 0.01758\n",
      "epoch 421, batch 5, d_loss=-0.175 g_loss=-0.448 KID= 0.01758\n",
      "epoch 421, batch 6, d_loss=-0.143 g_loss=-0.612 KID= 0.01758\n",
      "epoch 421, batch 7, d_loss=-0.147 g_loss=-0.809 KID= 0.01758\n",
      "epoch 421, batch 8, d_loss=-0.177 g_loss=-0.941 KID= 0.01758\n",
      "epoch 421, batch 9, d_loss=-0.146 g_loss=-0.970 KID= 0.01758\n",
      "epoch 421, batch 10, d_loss=-0.190 g_loss=-0.952 KID= 0.01758\n",
      "epoch 421, batch 11, d_loss=-0.175 g_loss=-0.854 KID= 0.01758\n",
      "epoch 421, batch 12, d_loss=-0.133 g_loss=-0.684 KID= 0.01758\n",
      "epoch 421, batch 13, d_loss=-0.235 g_loss=-0.618 KID= 0.01758\n",
      "epoch 421, batch 14, d_loss=-0.117 g_loss=-0.580 KID= 0.01758\n",
      "epoch 421, batch 15, d_loss=-0.100 g_loss=-0.372 KID= 0.01758\n",
      "epoch 421, batch 16, d_loss=-0.207 g_loss=-0.340 KID= 0.01758\n",
      "epoch 421, batch 17, d_loss=-0.096 g_loss=-0.311 KID= 0.01758\n",
      "epoch 421, batch 18, d_loss=-0.103 g_loss=-0.280 KID= 0.01758\n",
      "epoch 421, batch 19, d_loss=-0.193 g_loss=-0.211 KID= 0.01758\n",
      "epoch 422, batch 0, d_loss=-0.212 g_loss=-0.093 KID= 0.01758\n",
      "epoch 422, batch 1, d_loss=-0.146 g_loss=-0.031 KID= 0.01758\n",
      "epoch 422, batch 2, d_loss=-0.277 g_loss=0.069 KID= 0.01758\n",
      "epoch 422, batch 3, d_loss=-0.171 g_loss=0.023 KID= 0.01758\n",
      "epoch 422, batch 4, d_loss=-0.102 g_loss=-0.083 KID= 0.01758\n",
      "epoch 422, batch 5, d_loss=-0.182 g_loss=-0.051 KID= 0.01758\n",
      "epoch 422, batch 6, d_loss=-0.158 g_loss=-0.179 KID= 0.01758\n",
      "epoch 422, batch 7, d_loss=-0.098 g_loss=-0.294 KID= 0.01758\n",
      "epoch 422, batch 8, d_loss=-0.158 g_loss=-0.434 KID= 0.01758\n",
      "epoch 422, batch 9, d_loss=-0.197 g_loss=-0.622 KID= 0.01758\n",
      "epoch 422, batch 10, d_loss=-0.126 g_loss=-0.794 KID= 0.01758\n",
      "epoch 422, batch 11, d_loss=-0.167 g_loss=-0.920 KID= 0.01758\n",
      "epoch 422, batch 12, d_loss=-0.110 g_loss=-0.867 KID= 0.01758\n",
      "epoch 422, batch 13, d_loss=-0.176 g_loss=-0.844 KID= 0.01758\n",
      "epoch 422, batch 14, d_loss=-0.088 g_loss=-0.629 KID= 0.01758\n",
      "epoch 422, batch 15, d_loss=-0.152 g_loss=-0.496 KID= 0.01758\n",
      "epoch 422, batch 16, d_loss=-0.184 g_loss=-0.500 KID= 0.01758\n",
      "epoch 422, batch 17, d_loss=-0.184 g_loss=-0.589 KID= 0.01758\n",
      "epoch 422, batch 18, d_loss=-0.210 g_loss=-0.607 KID= 0.01758\n",
      "epoch 422, batch 19, d_loss=-0.149 g_loss=-0.663 KID= 0.01758\n",
      "epoch 423, batch 0, d_loss=-0.228 g_loss=-0.758 KID= 0.01758\n",
      "epoch 423, batch 1, d_loss=-0.109 g_loss=-0.707 KID= 0.01758\n",
      "epoch 423, batch 2, d_loss=-0.200 g_loss=-0.690 KID= 0.01758\n",
      "epoch 423, batch 3, d_loss=-0.181 g_loss=-0.619 KID= 0.01758\n",
      "epoch 423, batch 4, d_loss=-0.106 g_loss=-0.544 KID= 0.01758\n",
      "epoch 423, batch 5, d_loss=-0.139 g_loss=-0.459 KID= 0.01758\n",
      "epoch 423, batch 6, d_loss=-0.190 g_loss=-0.474 KID= 0.01758\n",
      "epoch 423, batch 7, d_loss=-0.127 g_loss=-0.513 KID= 0.01758\n",
      "epoch 423, batch 8, d_loss=-0.090 g_loss=-0.547 KID= 0.01758\n",
      "epoch 423, batch 9, d_loss=-0.195 g_loss=-0.552 KID= 0.01758\n",
      "epoch 423, batch 10, d_loss=-0.146 g_loss=-0.539 KID= 0.01758\n",
      "epoch 423, batch 11, d_loss=-0.183 g_loss=-0.515 KID= 0.01758\n",
      "epoch 423, batch 12, d_loss=-0.176 g_loss=-0.426 KID= 0.01758\n",
      "epoch 423, batch 13, d_loss=-0.214 g_loss=-0.361 KID= 0.01758\n",
      "epoch 423, batch 14, d_loss=-0.172 g_loss=-0.282 KID= 0.01758\n",
      "epoch 423, batch 15, d_loss=-0.170 g_loss=-0.231 KID= 0.01758\n",
      "epoch 423, batch 16, d_loss=-0.141 g_loss=-0.260 KID= 0.01758\n",
      "epoch 423, batch 17, d_loss=-0.097 g_loss=-0.411 KID= 0.01758\n",
      "epoch 423, batch 18, d_loss=-0.167 g_loss=-0.414 KID= 0.01758\n",
      "epoch 423, batch 19, d_loss=-0.136 g_loss=-0.500 KID= 0.01758\n",
      "epoch 424, batch 0, d_loss=-0.214 g_loss=-0.487 KID= 0.01758\n",
      "epoch 424, batch 1, d_loss=-0.167 g_loss=-0.556 KID= 0.01758\n",
      "epoch 424, batch 2, d_loss=-0.221 g_loss=-0.537 KID= 0.01758\n",
      "epoch 424, batch 3, d_loss=-0.217 g_loss=-0.582 KID= 0.01758\n",
      "epoch 424, batch 4, d_loss=-0.055 g_loss=-0.512 KID= 0.01758\n",
      "epoch 424, batch 5, d_loss=-0.044 g_loss=-0.432 KID= 0.01758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 424, batch 6, d_loss=-0.171 g_loss=-0.421 KID= 0.01758\n",
      "epoch 424, batch 7, d_loss=-0.121 g_loss=-0.376 KID= 0.01758\n",
      "epoch 424, batch 8, d_loss=-0.156 g_loss=-0.337 KID= 0.01758\n",
      "epoch 424, batch 9, d_loss=-0.173 g_loss=-0.350 KID= 0.01758\n",
      "epoch 424, batch 10, d_loss=-0.167 g_loss=-0.300 KID= 0.01758\n",
      "epoch 424, batch 11, d_loss=-0.147 g_loss=-0.346 KID= 0.01758\n",
      "epoch 424, batch 12, d_loss=-0.193 g_loss=-0.378 KID= 0.01758\n",
      "epoch 424, batch 13, d_loss=-0.185 g_loss=-0.370 KID= 0.01758\n",
      "epoch 424, batch 14, d_loss=-0.129 g_loss=-0.395 KID= 0.01758\n",
      "epoch 424, batch 15, d_loss=-0.188 g_loss=-0.387 KID= 0.01758\n",
      "epoch 424, batch 16, d_loss=-0.153 g_loss=-0.499 KID= 0.01758\n",
      "epoch 424, batch 17, d_loss=-0.129 g_loss=-0.638 KID= 0.01758\n",
      "epoch 424, batch 18, d_loss=-0.137 g_loss=-0.673 KID= 0.01758\n",
      "epoch 424, batch 19, d_loss=-0.190 g_loss=-0.753 KID= 0.01758\n",
      "epoch 425, batch 0, d_loss=-0.174 g_loss=-0.778 KID= 0.01758\n",
      "epoch 425, batch 1, d_loss=-0.190 g_loss=-0.810 KID= 0.01758\n",
      "epoch 425, batch 2, d_loss=-0.170 g_loss=-0.756 KID= 0.01758\n",
      "epoch 425, batch 3, d_loss=-0.194 g_loss=-0.699 KID= 0.01758\n",
      "epoch 425, batch 4, d_loss=-0.083 g_loss=-0.498 KID= 0.01758\n",
      "epoch 425, batch 5, d_loss=-0.149 g_loss=-0.329 KID= 0.01758\n",
      "epoch 425, batch 6, d_loss=-0.142 g_loss=-0.275 KID= 0.01758\n",
      "epoch 425, batch 7, d_loss=-0.146 g_loss=-0.303 KID= 0.01758\n",
      "epoch 425, batch 8, d_loss=-0.175 g_loss=-0.260 KID= 0.01758\n",
      "epoch 425, batch 9, d_loss=-0.143 g_loss=-0.334 KID= 0.01758\n",
      "epoch 425, batch 10, d_loss=-0.202 g_loss=-0.384 KID= 0.01758\n",
      "epoch 425, batch 11, d_loss=-0.132 g_loss=-0.473 KID= 0.01758\n",
      "epoch 425, batch 12, d_loss=-0.239 g_loss=-0.503 KID= 0.01758\n",
      "epoch 425, batch 13, d_loss=-0.205 g_loss=-0.558 KID= 0.01758\n",
      "epoch 425, batch 14, d_loss=-0.111 g_loss=-0.608 KID= 0.01758\n",
      "epoch 425, batch 15, d_loss=-0.155 g_loss=-0.614 KID= 0.01758\n",
      "epoch 425, batch 16, d_loss=-0.170 g_loss=-0.646 KID= 0.01758\n",
      "epoch 425, batch 17, d_loss=-0.101 g_loss=-0.677 KID= 0.01758\n",
      "epoch 425, batch 18, d_loss=-0.210 g_loss=-0.551 KID= 0.01758\n",
      "epoch 425, batch 19, d_loss=-0.173 g_loss=-0.549 KID= 0.01758\n",
      "epoch 426, batch 0, d_loss=-0.148 g_loss=-0.465 KID= 0.01758\n",
      "epoch 426, batch 1, d_loss=-0.149 g_loss=-0.432 KID= 0.01758\n",
      "epoch 426, batch 2, d_loss=-0.190 g_loss=-0.387 KID= 0.01758\n",
      "epoch 426, batch 3, d_loss=-0.230 g_loss=-0.323 KID= 0.01758\n",
      "epoch 426, batch 4, d_loss=-0.155 g_loss=-0.225 KID= 0.01758\n",
      "epoch 426, batch 5, d_loss=-0.178 g_loss=-0.200 KID= 0.01758\n",
      "epoch 426, batch 6, d_loss=-0.082 g_loss=-0.243 KID= 0.01758\n",
      "epoch 426, batch 7, d_loss=-0.099 g_loss=-0.344 KID= 0.01758\n",
      "epoch 426, batch 8, d_loss=-0.095 g_loss=-0.374 KID= 0.01758\n",
      "epoch 426, batch 9, d_loss=-0.175 g_loss=-0.479 KID= 0.01758\n",
      "epoch 426, batch 10, d_loss=-0.214 g_loss=-0.497 KID= 0.01758\n",
      "epoch 426, batch 11, d_loss=-0.209 g_loss=-0.589 KID= 0.01758\n",
      "epoch 426, batch 12, d_loss=-0.193 g_loss=-0.636 KID= 0.01758\n",
      "epoch 426, batch 13, d_loss=-0.270 g_loss=-0.894 KID= 0.01758\n",
      "epoch 426, batch 14, d_loss=-0.113 g_loss=-0.956 KID= 0.01758\n",
      "epoch 426, batch 15, d_loss=-0.072 g_loss=-0.940 KID= 0.01758\n",
      "epoch 426, batch 16, d_loss=-0.146 g_loss=-0.891 KID= 0.01758\n",
      "epoch 426, batch 17, d_loss=-0.126 g_loss=-0.850 KID= 0.01758\n",
      "epoch 426, batch 18, d_loss=-0.143 g_loss=-0.896 KID= 0.01758\n",
      "epoch 426, batch 19, d_loss=-0.118 g_loss=-0.902 KID= 0.01758\n",
      "epoch 427, batch 0, d_loss=-0.174 g_loss=-0.794 KID= 0.01758\n",
      "epoch 427, batch 1, d_loss=-0.133 g_loss=-0.506 KID= 0.01758\n",
      "epoch 427, batch 2, d_loss=-0.235 g_loss=-0.271 KID= 0.01758\n",
      "epoch 427, batch 3, d_loss=-0.224 g_loss=-0.066 KID= 0.01758\n",
      "epoch 427, batch 4, d_loss=-0.199 g_loss=0.225 KID= 0.01758\n",
      "epoch 427, batch 5, d_loss=-0.219 g_loss=0.456 KID= 0.01758\n",
      "epoch 427, batch 6, d_loss=-0.244 g_loss=0.435 KID= 0.01758\n",
      "epoch 427, batch 7, d_loss=-0.138 g_loss=0.300 KID= 0.01758\n",
      "epoch 427, batch 8, d_loss=-0.153 g_loss=0.056 KID= 0.01758\n",
      "epoch 427, batch 9, d_loss=-0.044 g_loss=-0.131 KID= 0.01758\n",
      "epoch 427, batch 10, d_loss=-0.148 g_loss=-0.301 KID= 0.01758\n",
      "epoch 427, batch 11, d_loss=-0.076 g_loss=-0.427 KID= 0.01758\n",
      "epoch 427, batch 12, d_loss=-0.123 g_loss=-0.541 KID= 0.01758\n",
      "epoch 427, batch 13, d_loss=-0.172 g_loss=-0.475 KID= 0.01758\n",
      "epoch 427, batch 14, d_loss=-0.166 g_loss=-0.436 KID= 0.01758\n",
      "epoch 427, batch 15, d_loss=-0.169 g_loss=-0.419 KID= 0.01758\n",
      "epoch 427, batch 16, d_loss=-0.136 g_loss=-0.413 KID= 0.01758\n",
      "epoch 427, batch 17, d_loss=-0.138 g_loss=-0.425 KID= 0.01758\n",
      "epoch 427, batch 18, d_loss=-0.127 g_loss=-0.413 KID= 0.01758\n",
      "epoch 427, batch 19, d_loss=-0.168 g_loss=-0.461 KID= 0.01758\n",
      "epoch 428, batch 0, d_loss=-0.210 g_loss=-0.423 KID= 0.01758\n",
      "epoch 428, batch 1, d_loss=-0.141 g_loss=-0.417 KID= 0.01758\n",
      "epoch 428, batch 2, d_loss=-0.244 g_loss=-0.427 KID= 0.01758\n",
      "epoch 428, batch 3, d_loss=-0.182 g_loss=-0.315 KID= 0.01758\n",
      "epoch 428, batch 4, d_loss=-0.075 g_loss=-0.252 KID= 0.01758\n",
      "epoch 428, batch 5, d_loss=-0.144 g_loss=-0.201 KID= 0.01758\n",
      "epoch 428, batch 6, d_loss=-0.183 g_loss=-0.203 KID= 0.01758\n",
      "epoch 428, batch 7, d_loss=-0.109 g_loss=-0.166 KID= 0.01758\n",
      "epoch 428, batch 8, d_loss=-0.175 g_loss=-0.179 KID= 0.01758\n",
      "epoch 428, batch 9, d_loss=-0.159 g_loss=-0.247 KID= 0.01758\n",
      "epoch 428, batch 10, d_loss=-0.150 g_loss=-0.278 KID= 0.01758\n",
      "epoch 428, batch 11, d_loss=-0.134 g_loss=-0.233 KID= 0.01758\n",
      "epoch 428, batch 12, d_loss=-0.221 g_loss=-0.156 KID= 0.01758\n",
      "epoch 428, batch 13, d_loss=-0.198 g_loss=-0.186 KID= 0.01758\n",
      "epoch 428, batch 14, d_loss=-0.216 g_loss=-0.219 KID= 0.01758\n",
      "epoch 428, batch 15, d_loss=-0.170 g_loss=-0.316 KID= 0.01758\n",
      "epoch 428, batch 16, d_loss=-0.175 g_loss=-0.550 KID= 0.01758\n",
      "epoch 428, batch 17, d_loss=-0.127 g_loss=-0.718 KID= 0.01758\n",
      "epoch 428, batch 18, d_loss=-0.213 g_loss=-0.870 KID= 0.01758\n",
      "epoch 428, batch 19, d_loss=-0.159 g_loss=-0.968 KID= 0.01758\n",
      "epoch 429, batch 0, d_loss=-0.150 g_loss=-1.055 KID= 0.01758\n",
      "epoch 429, batch 1, d_loss=-0.160 g_loss=-0.930 KID= 0.01758\n",
      "epoch 429, batch 2, d_loss=-0.192 g_loss=-0.813 KID= 0.01758\n",
      "epoch 429, batch 3, d_loss=-0.201 g_loss=-0.753 KID= 0.01758\n",
      "epoch 429, batch 4, d_loss=-0.136 g_loss=-0.579 KID= 0.01758\n",
      "epoch 429, batch 5, d_loss=-0.159 g_loss=-0.515 KID= 0.01758\n",
      "epoch 429, batch 6, d_loss=-0.152 g_loss=-0.520 KID= 0.01758\n",
      "epoch 429, batch 7, d_loss=-0.138 g_loss=-0.538 KID= 0.01758\n",
      "epoch 429, batch 8, d_loss=-0.127 g_loss=-0.471 KID= 0.01758\n",
      "epoch 429, batch 9, d_loss=-0.160 g_loss=-0.499 KID= 0.01758\n",
      "epoch 429, batch 10, d_loss=-0.206 g_loss=-0.536 KID= 0.01758\n",
      "epoch 429, batch 11, d_loss=-0.169 g_loss=-0.509 KID= 0.01758\n",
      "epoch 429, batch 12, d_loss=-0.235 g_loss=-0.518 KID= 0.01758\n",
      "epoch 429, batch 13, d_loss=-0.176 g_loss=-0.547 KID= 0.01758\n",
      "epoch 429, batch 14, d_loss=-0.091 g_loss=-0.443 KID= 0.01758\n",
      "epoch 429, batch 15, d_loss=-0.152 g_loss=-0.336 KID= 0.01758\n",
      "epoch 429, batch 16, d_loss=-0.180 g_loss=-0.341 KID= 0.01758\n",
      "epoch 429, batch 17, d_loss=-0.122 g_loss=-0.404 KID= 0.01758\n",
      "epoch 429, batch 18, d_loss=-0.266 g_loss=-0.503 KID= 0.01758\n",
      "epoch 429, batch 19, d_loss=-0.176 g_loss=-0.618 KID= 0.01758\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 430, batch 0, d_loss=-0.206 g_loss=-0.724 KID= 0.00944\n",
      "epoch 430, batch 1, d_loss=-0.165 g_loss=-0.722 KID= 0.00944\n",
      "epoch 430, batch 2, d_loss=-0.184 g_loss=-0.775 KID= 0.00944\n",
      "epoch 430, batch 3, d_loss=-0.162 g_loss=-0.739 KID= 0.00944\n",
      "epoch 430, batch 4, d_loss=-0.123 g_loss=-0.636 KID= 0.00944\n",
      "epoch 430, batch 5, d_loss=-0.111 g_loss=-0.515 KID= 0.00944\n",
      "epoch 430, batch 6, d_loss=-0.191 g_loss=-0.466 KID= 0.00944\n",
      "epoch 430, batch 7, d_loss=-0.152 g_loss=-0.369 KID= 0.00944\n",
      "epoch 430, batch 8, d_loss=-0.162 g_loss=-0.317 KID= 0.00944\n",
      "epoch 430, batch 9, d_loss=-0.162 g_loss=-0.246 KID= 0.00944\n",
      "epoch 430, batch 10, d_loss=-0.211 g_loss=-0.234 KID= 0.00944\n",
      "epoch 430, batch 11, d_loss=-0.087 g_loss=-0.214 KID= 0.00944\n",
      "epoch 430, batch 12, d_loss=-0.199 g_loss=-0.167 KID= 0.00944\n",
      "epoch 430, batch 13, d_loss=-0.208 g_loss=-0.198 KID= 0.00944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 430, batch 14, d_loss=-0.187 g_loss=-0.156 KID= 0.00944\n",
      "epoch 430, batch 15, d_loss=-0.144 g_loss=-0.216 KID= 0.00944\n",
      "epoch 430, batch 16, d_loss=-0.162 g_loss=-0.407 KID= 0.00944\n",
      "epoch 430, batch 17, d_loss=-0.102 g_loss=-0.519 KID= 0.00944\n",
      "epoch 430, batch 18, d_loss=-0.151 g_loss=-0.570 KID= 0.00944\n",
      "epoch 430, batch 19, d_loss=-0.145 g_loss=-0.725 KID= 0.00944\n",
      "epoch 431, batch 0, d_loss=-0.166 g_loss=-0.814 KID= 0.00944\n",
      "epoch 431, batch 1, d_loss=-0.205 g_loss=-0.806 KID= 0.00944\n",
      "epoch 431, batch 2, d_loss=-0.250 g_loss=-0.765 KID= 0.00944\n",
      "epoch 431, batch 3, d_loss=-0.253 g_loss=-0.793 KID= 0.00944\n",
      "epoch 431, batch 4, d_loss=-0.125 g_loss=-0.595 KID= 0.00944\n",
      "epoch 431, batch 5, d_loss=-0.169 g_loss=-0.429 KID= 0.00944\n",
      "epoch 431, batch 6, d_loss=-0.165 g_loss=-0.428 KID= 0.00944\n",
      "epoch 431, batch 7, d_loss=-0.122 g_loss=-0.350 KID= 0.00944\n",
      "epoch 431, batch 8, d_loss=-0.188 g_loss=-0.374 KID= 0.00944\n",
      "epoch 431, batch 9, d_loss=-0.153 g_loss=-0.407 KID= 0.00944\n",
      "epoch 431, batch 10, d_loss=-0.179 g_loss=-0.529 KID= 0.00944\n",
      "epoch 431, batch 11, d_loss=-0.192 g_loss=-0.600 KID= 0.00944\n",
      "epoch 431, batch 12, d_loss=-0.242 g_loss=-0.698 KID= 0.00944\n",
      "epoch 431, batch 13, d_loss=-0.217 g_loss=-0.841 KID= 0.00944\n",
      "epoch 431, batch 14, d_loss=-0.092 g_loss=-0.650 KID= 0.00944\n",
      "epoch 431, batch 15, d_loss=-0.092 g_loss=-0.599 KID= 0.00944\n",
      "epoch 431, batch 16, d_loss=-0.173 g_loss=-0.568 KID= 0.00944\n",
      "epoch 431, batch 17, d_loss=-0.125 g_loss=-0.430 KID= 0.00944\n",
      "epoch 431, batch 18, d_loss=-0.209 g_loss=-0.350 KID= 0.00944\n",
      "epoch 431, batch 19, d_loss=-0.178 g_loss=-0.268 KID= 0.00944\n",
      "epoch 432, batch 0, d_loss=-0.182 g_loss=-0.171 KID= 0.00944\n",
      "epoch 432, batch 1, d_loss=-0.168 g_loss=-0.076 KID= 0.00944\n",
      "epoch 432, batch 2, d_loss=-0.204 g_loss=0.001 KID= 0.00944\n",
      "epoch 432, batch 3, d_loss=-0.143 g_loss=-0.069 KID= 0.00944\n",
      "epoch 432, batch 4, d_loss=-0.192 g_loss=0.034 KID= 0.00944\n",
      "epoch 432, batch 5, d_loss=-0.157 g_loss=0.076 KID= 0.00944\n",
      "epoch 432, batch 6, d_loss=-0.148 g_loss=-0.057 KID= 0.00944\n",
      "epoch 432, batch 7, d_loss=-0.107 g_loss=-0.123 KID= 0.00944\n",
      "epoch 432, batch 8, d_loss=-0.150 g_loss=-0.239 KID= 0.00944\n",
      "epoch 432, batch 9, d_loss=-0.186 g_loss=-0.331 KID= 0.00944\n",
      "epoch 432, batch 10, d_loss=-0.156 g_loss=-0.303 KID= 0.00944\n",
      "epoch 432, batch 11, d_loss=-0.173 g_loss=-0.396 KID= 0.00944\n",
      "epoch 432, batch 12, d_loss=-0.217 g_loss=-0.496 KID= 0.00944\n",
      "epoch 432, batch 13, d_loss=-0.265 g_loss=-0.572 KID= 0.00944\n",
      "epoch 432, batch 14, d_loss=-0.119 g_loss=-0.550 KID= 0.00944\n",
      "epoch 432, batch 15, d_loss=-0.143 g_loss=-0.513 KID= 0.00944\n",
      "epoch 432, batch 16, d_loss=-0.197 g_loss=-0.442 KID= 0.00944\n",
      "epoch 432, batch 17, d_loss=-0.146 g_loss=-0.431 KID= 0.00944\n",
      "epoch 432, batch 18, d_loss=-0.166 g_loss=-0.438 KID= 0.00944\n",
      "epoch 432, batch 19, d_loss=-0.161 g_loss=-0.403 KID= 0.00944\n",
      "epoch 433, batch 0, d_loss=-0.188 g_loss=-0.357 KID= 0.00944\n",
      "epoch 433, batch 1, d_loss=-0.163 g_loss=-0.389 KID= 0.00944\n",
      "epoch 433, batch 2, d_loss=-0.216 g_loss=-0.451 KID= 0.00944\n",
      "epoch 433, batch 3, d_loss=-0.239 g_loss=-0.528 KID= 0.00944\n",
      "epoch 433, batch 4, d_loss=-0.158 g_loss=-0.421 KID= 0.00944\n",
      "epoch 433, batch 5, d_loss=-0.177 g_loss=-0.424 KID= 0.00944\n",
      "epoch 433, batch 6, d_loss=-0.202 g_loss=-0.448 KID= 0.00944\n",
      "epoch 433, batch 7, d_loss=-0.107 g_loss=-0.437 KID= 0.00944\n",
      "epoch 433, batch 8, d_loss=-0.176 g_loss=-0.439 KID= 0.00944\n",
      "epoch 433, batch 9, d_loss=-0.157 g_loss=-0.471 KID= 0.00944\n",
      "epoch 433, batch 10, d_loss=-0.159 g_loss=-0.443 KID= 0.00944\n",
      "epoch 433, batch 11, d_loss=-0.180 g_loss=-0.488 KID= 0.00944\n",
      "epoch 433, batch 12, d_loss=-0.203 g_loss=-0.514 KID= 0.00944\n",
      "epoch 433, batch 13, d_loss=-0.214 g_loss=-0.488 KID= 0.00944\n",
      "epoch 433, batch 14, d_loss=-0.153 g_loss=-0.403 KID= 0.00944\n",
      "epoch 433, batch 15, d_loss=-0.165 g_loss=-0.451 KID= 0.00944\n",
      "epoch 433, batch 16, d_loss=-0.186 g_loss=-0.521 KID= 0.00944\n",
      "epoch 433, batch 17, d_loss=-0.122 g_loss=-0.500 KID= 0.00944\n",
      "epoch 433, batch 18, d_loss=-0.178 g_loss=-0.454 KID= 0.00944\n",
      "epoch 433, batch 19, d_loss=-0.177 g_loss=-0.396 KID= 0.00944\n",
      "epoch 434, batch 0, d_loss=-0.188 g_loss=-0.261 KID= 0.00944\n",
      "epoch 434, batch 1, d_loss=-0.194 g_loss=-0.134 KID= 0.00944\n",
      "epoch 434, batch 2, d_loss=-0.246 g_loss=-0.060 KID= 0.00944\n",
      "epoch 434, batch 3, d_loss=-0.196 g_loss=-0.044 KID= 0.00944\n",
      "epoch 434, batch 4, d_loss=-0.152 g_loss=0.024 KID= 0.00944\n",
      "epoch 434, batch 5, d_loss=-0.232 g_loss=0.056 KID= 0.00944\n",
      "epoch 434, batch 6, d_loss=-0.131 g_loss=-0.122 KID= 0.00944\n",
      "epoch 434, batch 7, d_loss=-0.106 g_loss=-0.335 KID= 0.00944\n",
      "epoch 434, batch 8, d_loss=-0.208 g_loss=-0.461 KID= 0.00944\n",
      "epoch 434, batch 9, d_loss=-0.124 g_loss=-0.516 KID= 0.00944\n",
      "epoch 434, batch 10, d_loss=-0.172 g_loss=-0.532 KID= 0.00944\n",
      "epoch 434, batch 11, d_loss=-0.162 g_loss=-0.523 KID= 0.00944\n",
      "epoch 434, batch 12, d_loss=-0.220 g_loss=-0.555 KID= 0.00944\n",
      "epoch 434, batch 13, d_loss=-0.271 g_loss=-0.559 KID= 0.00944\n",
      "epoch 434, batch 14, d_loss=-0.135 g_loss=-0.469 KID= 0.00944\n",
      "epoch 434, batch 15, d_loss=-0.086 g_loss=-0.420 KID= 0.00944\n",
      "epoch 434, batch 16, d_loss=-0.194 g_loss=-0.417 KID= 0.00944\n",
      "epoch 434, batch 17, d_loss=-0.161 g_loss=-0.423 KID= 0.00944\n",
      "epoch 434, batch 18, d_loss=-0.132 g_loss=-0.457 KID= 0.00944\n",
      "epoch 434, batch 19, d_loss=-0.217 g_loss=-0.573 KID= 0.00944\n",
      "epoch 435, batch 0, d_loss=-0.183 g_loss=-0.670 KID= 0.00944\n",
      "epoch 435, batch 1, d_loss=-0.170 g_loss=-0.747 KID= 0.00944\n",
      "epoch 435, batch 2, d_loss=-0.210 g_loss=-0.797 KID= 0.00944\n",
      "epoch 435, batch 3, d_loss=-0.189 g_loss=-0.749 KID= 0.00944\n",
      "epoch 435, batch 4, d_loss=-0.146 g_loss=-0.540 KID= 0.00944\n",
      "epoch 435, batch 5, d_loss=-0.153 g_loss=-0.431 KID= 0.00944\n",
      "epoch 435, batch 6, d_loss=-0.199 g_loss=-0.439 KID= 0.00944\n",
      "epoch 435, batch 7, d_loss=-0.101 g_loss=-0.471 KID= 0.00944\n",
      "epoch 435, batch 8, d_loss=-0.233 g_loss=-0.594 KID= 0.00944\n",
      "epoch 435, batch 9, d_loss=-0.171 g_loss=-0.634 KID= 0.00944\n",
      "epoch 435, batch 10, d_loss=-0.178 g_loss=-0.679 KID= 0.00944\n",
      "epoch 435, batch 11, d_loss=-0.106 g_loss=-0.543 KID= 0.00944\n",
      "epoch 435, batch 12, d_loss=-0.217 g_loss=-0.387 KID= 0.00944\n",
      "epoch 435, batch 13, d_loss=-0.280 g_loss=-0.278 KID= 0.00944\n",
      "epoch 435, batch 14, d_loss=-0.173 g_loss=-0.090 KID= 0.00944\n",
      "epoch 435, batch 15, d_loss=-0.175 g_loss=-0.014 KID= 0.00944\n",
      "epoch 435, batch 16, d_loss=-0.176 g_loss=-0.129 KID= 0.00944\n",
      "epoch 435, batch 17, d_loss=-0.073 g_loss=-0.225 KID= 0.00944\n",
      "epoch 435, batch 18, d_loss=-0.179 g_loss=-0.381 KID= 0.00944\n",
      "epoch 435, batch 19, d_loss=-0.188 g_loss=-0.543 KID= 0.00944\n",
      "epoch 436, batch 0, d_loss=-0.174 g_loss=-0.695 KID= 0.00944\n",
      "epoch 436, batch 1, d_loss=-0.201 g_loss=-0.821 KID= 0.00944\n",
      "epoch 436, batch 2, d_loss=-0.222 g_loss=-0.889 KID= 0.00944\n",
      "epoch 436, batch 3, d_loss=-0.230 g_loss=-0.923 KID= 0.00944\n",
      "epoch 436, batch 4, d_loss=-0.065 g_loss=-0.755 KID= 0.00944\n",
      "epoch 436, batch 5, d_loss=-0.181 g_loss=-0.612 KID= 0.00944\n",
      "epoch 436, batch 6, d_loss=-0.136 g_loss=-0.532 KID= 0.00944\n",
      "epoch 436, batch 7, d_loss=-0.094 g_loss=-0.480 KID= 0.00944\n",
      "epoch 436, batch 8, d_loss=-0.171 g_loss=-0.450 KID= 0.00944\n",
      "epoch 436, batch 9, d_loss=-0.179 g_loss=-0.485 KID= 0.00944\n",
      "epoch 436, batch 10, d_loss=-0.216 g_loss=-0.511 KID= 0.00944\n",
      "epoch 436, batch 11, d_loss=-0.180 g_loss=-0.498 KID= 0.00944\n",
      "epoch 436, batch 12, d_loss=-0.190 g_loss=-0.480 KID= 0.00944\n",
      "epoch 436, batch 13, d_loss=-0.244 g_loss=-0.505 KID= 0.00944\n",
      "epoch 436, batch 14, d_loss=-0.124 g_loss=-0.410 KID= 0.00944\n",
      "epoch 436, batch 15, d_loss=-0.171 g_loss=-0.385 KID= 0.00944\n",
      "epoch 436, batch 16, d_loss=-0.188 g_loss=-0.376 KID= 0.00944\n",
      "epoch 436, batch 17, d_loss=-0.135 g_loss=-0.314 KID= 0.00944\n",
      "epoch 436, batch 18, d_loss=-0.177 g_loss=-0.288 KID= 0.00944\n",
      "epoch 436, batch 19, d_loss=-0.227 g_loss=-0.239 KID= 0.00944\n",
      "epoch 437, batch 0, d_loss=-0.186 g_loss=-0.300 KID= 0.00944\n",
      "epoch 437, batch 1, d_loss=-0.186 g_loss=-0.373 KID= 0.00944\n",
      "epoch 437, batch 2, d_loss=-0.235 g_loss=-0.451 KID= 0.00944\n",
      "epoch 437, batch 3, d_loss=-0.236 g_loss=-0.562 KID= 0.00944\n",
      "epoch 437, batch 4, d_loss=-0.168 g_loss=-0.510 KID= 0.00944\n",
      "epoch 437, batch 5, d_loss=-0.180 g_loss=-0.518 KID= 0.00944\n",
      "epoch 437, batch 6, d_loss=-0.138 g_loss=-0.552 KID= 0.00944\n",
      "epoch 437, batch 7, d_loss=-0.045 g_loss=-0.494 KID= 0.00944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 437, batch 8, d_loss=-0.149 g_loss=-0.567 KID= 0.00944\n",
      "epoch 437, batch 9, d_loss=-0.182 g_loss=-0.598 KID= 0.00944\n",
      "epoch 437, batch 10, d_loss=-0.157 g_loss=-0.677 KID= 0.00944\n",
      "epoch 437, batch 11, d_loss=-0.219 g_loss=-0.702 KID= 0.00944\n",
      "epoch 437, batch 12, d_loss=-0.244 g_loss=-0.721 KID= 0.00944\n",
      "epoch 437, batch 13, d_loss=-0.237 g_loss=-0.761 KID= 0.00944\n",
      "epoch 437, batch 14, d_loss=-0.131 g_loss=-0.624 KID= 0.00944\n",
      "epoch 437, batch 15, d_loss=-0.168 g_loss=-0.555 KID= 0.00944\n",
      "epoch 437, batch 16, d_loss=-0.197 g_loss=-0.509 KID= 0.00944\n",
      "epoch 437, batch 17, d_loss=-0.133 g_loss=-0.354 KID= 0.00944\n",
      "epoch 437, batch 18, d_loss=-0.220 g_loss=-0.358 KID= 0.00944\n",
      "epoch 437, batch 19, d_loss=-0.183 g_loss=-0.479 KID= 0.00944\n",
      "epoch 438, batch 0, d_loss=-0.166 g_loss=-0.529 KID= 0.00944\n",
      "epoch 438, batch 1, d_loss=-0.159 g_loss=-0.546 KID= 0.00944\n",
      "epoch 438, batch 2, d_loss=-0.163 g_loss=-0.458 KID= 0.00944\n",
      "epoch 438, batch 3, d_loss=-0.229 g_loss=-0.364 KID= 0.00944\n",
      "epoch 438, batch 4, d_loss=-0.135 g_loss=-0.210 KID= 0.00944\n",
      "epoch 438, batch 5, d_loss=-0.157 g_loss=-0.216 KID= 0.00944\n",
      "epoch 438, batch 6, d_loss=-0.156 g_loss=-0.230 KID= 0.00944\n",
      "epoch 438, batch 7, d_loss=-0.123 g_loss=-0.173 KID= 0.00944\n",
      "epoch 438, batch 8, d_loss=-0.186 g_loss=-0.264 KID= 0.00944\n",
      "epoch 438, batch 9, d_loss=-0.218 g_loss=-0.317 KID= 0.00944\n",
      "epoch 438, batch 10, d_loss=-0.205 g_loss=-0.264 KID= 0.00944\n",
      "epoch 438, batch 11, d_loss=-0.241 g_loss=-0.288 KID= 0.00944\n",
      "epoch 438, batch 12, d_loss=-0.228 g_loss=-0.273 KID= 0.00944\n",
      "epoch 438, batch 13, d_loss=-0.168 g_loss=-0.325 KID= 0.00944\n",
      "epoch 438, batch 14, d_loss=-0.116 g_loss=-0.275 KID= 0.00944\n",
      "epoch 438, batch 15, d_loss=-0.161 g_loss=-0.301 KID= 0.00944\n",
      "epoch 438, batch 16, d_loss=-0.135 g_loss=-0.374 KID= 0.00944\n",
      "epoch 438, batch 17, d_loss=-0.099 g_loss=-0.351 KID= 0.00944\n",
      "epoch 438, batch 18, d_loss=-0.209 g_loss=-0.386 KID= 0.00944\n",
      "epoch 438, batch 19, d_loss=-0.187 g_loss=-0.434 KID= 0.00944\n",
      "epoch 439, batch 0, d_loss=-0.230 g_loss=-0.547 KID= 0.00944\n",
      "epoch 439, batch 1, d_loss=-0.192 g_loss=-0.639 KID= 0.00944\n",
      "epoch 439, batch 2, d_loss=-0.204 g_loss=-0.685 KID= 0.00944\n",
      "epoch 439, batch 3, d_loss=-0.242 g_loss=-0.706 KID= 0.00944\n",
      "epoch 439, batch 4, d_loss=-0.143 g_loss=-0.561 KID= 0.00944\n",
      "epoch 439, batch 5, d_loss=-0.150 g_loss=-0.497 KID= 0.00944\n",
      "epoch 439, batch 6, d_loss=-0.193 g_loss=-0.431 KID= 0.00944\n",
      "epoch 439, batch 7, d_loss=-0.163 g_loss=-0.281 KID= 0.00944\n",
      "epoch 439, batch 8, d_loss=-0.174 g_loss=-0.221 KID= 0.00944\n",
      "epoch 439, batch 9, d_loss=-0.179 g_loss=-0.234 KID= 0.00944\n",
      "epoch 439, batch 10, d_loss=-0.148 g_loss=-0.285 KID= 0.00944\n",
      "epoch 439, batch 11, d_loss=-0.204 g_loss=-0.288 KID= 0.00944\n",
      "epoch 439, batch 12, d_loss=-0.259 g_loss=-0.305 KID= 0.00944\n",
      "epoch 439, batch 13, d_loss=-0.213 g_loss=-0.360 KID= 0.00944\n",
      "epoch 439, batch 14, d_loss=-0.154 g_loss=-0.389 KID= 0.00944\n",
      "epoch 439, batch 15, d_loss=-0.183 g_loss=-0.514 KID= 0.00944\n",
      "epoch 439, batch 16, d_loss=-0.187 g_loss=-0.583 KID= 0.00944\n",
      "epoch 439, batch 17, d_loss=-0.136 g_loss=-0.595 KID= 0.00944\n",
      "epoch 439, batch 18, d_loss=-0.185 g_loss=-0.643 KID= 0.00944\n",
      "epoch 439, batch 19, d_loss=-0.197 g_loss=-0.697 KID= 0.00944\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 440, batch 0, d_loss=-0.185 g_loss=-0.678 KID= 0.00767\n",
      "epoch 440, batch 1, d_loss=-0.195 g_loss=-0.672 KID= 0.00767\n",
      "epoch 440, batch 2, d_loss=-0.237 g_loss=-0.610 KID= 0.00767\n",
      "epoch 440, batch 3, d_loss=-0.157 g_loss=-0.566 KID= 0.00767\n",
      "epoch 440, batch 4, d_loss=-0.138 g_loss=-0.365 KID= 0.00767\n",
      "epoch 440, batch 5, d_loss=-0.157 g_loss=-0.197 KID= 0.00767\n",
      "epoch 440, batch 6, d_loss=-0.181 g_loss=-0.196 KID= 0.00767\n",
      "epoch 440, batch 7, d_loss=-0.185 g_loss=-0.210 KID= 0.00767\n",
      "epoch 440, batch 8, d_loss=-0.185 g_loss=-0.304 KID= 0.00767\n",
      "epoch 440, batch 9, d_loss=-0.198 g_loss=-0.359 KID= 0.00767\n",
      "epoch 440, batch 10, d_loss=-0.194 g_loss=-0.375 KID= 0.00767\n",
      "epoch 440, batch 11, d_loss=-0.203 g_loss=-0.363 KID= 0.00767\n",
      "epoch 440, batch 12, d_loss=-0.174 g_loss=-0.262 KID= 0.00767\n",
      "epoch 440, batch 13, d_loss=-0.218 g_loss=-0.189 KID= 0.00767\n",
      "epoch 440, batch 14, d_loss=-0.148 g_loss=-0.142 KID= 0.00767\n",
      "epoch 440, batch 15, d_loss=-0.233 g_loss=-0.123 KID= 0.00767\n",
      "epoch 440, batch 16, d_loss=-0.202 g_loss=-0.194 KID= 0.00767\n",
      "epoch 440, batch 17, d_loss=-0.118 g_loss=-0.241 KID= 0.00767\n",
      "epoch 440, batch 18, d_loss=-0.189 g_loss=-0.378 KID= 0.00767\n",
      "epoch 440, batch 19, d_loss=-0.169 g_loss=-0.382 KID= 0.00767\n",
      "epoch 441, batch 0, d_loss=-0.191 g_loss=-0.415 KID= 0.00767\n",
      "epoch 441, batch 1, d_loss=-0.208 g_loss=-0.381 KID= 0.00767\n",
      "epoch 441, batch 2, d_loss=-0.210 g_loss=-0.405 KID= 0.00767\n",
      "epoch 441, batch 3, d_loss=-0.199 g_loss=-0.477 KID= 0.00767\n",
      "epoch 441, batch 4, d_loss=-0.166 g_loss=-0.479 KID= 0.00767\n",
      "epoch 441, batch 5, d_loss=-0.151 g_loss=-0.528 KID= 0.00767\n",
      "epoch 441, batch 6, d_loss=-0.228 g_loss=-0.614 KID= 0.00767\n",
      "epoch 441, batch 7, d_loss=-0.162 g_loss=-0.648 KID= 0.00767\n",
      "epoch 441, batch 8, d_loss=-0.189 g_loss=-0.685 KID= 0.00767\n",
      "epoch 441, batch 9, d_loss=-0.174 g_loss=-0.636 KID= 0.00767\n",
      "epoch 441, batch 10, d_loss=-0.148 g_loss=-0.579 KID= 0.00767\n",
      "epoch 441, batch 11, d_loss=-0.185 g_loss=-0.519 KID= 0.00767\n",
      "epoch 441, batch 12, d_loss=-0.216 g_loss=-0.535 KID= 0.00767\n",
      "epoch 441, batch 13, d_loss=-0.172 g_loss=-0.479 KID= 0.00767\n",
      "epoch 441, batch 14, d_loss=-0.140 g_loss=-0.352 KID= 0.00767\n",
      "epoch 441, batch 15, d_loss=-0.165 g_loss=-0.201 KID= 0.00767\n",
      "epoch 441, batch 16, d_loss=-0.172 g_loss=-0.203 KID= 0.00767\n",
      "epoch 441, batch 17, d_loss=-0.179 g_loss=-0.245 KID= 0.00767\n",
      "epoch 441, batch 18, d_loss=-0.234 g_loss=-0.426 KID= 0.00767\n",
      "epoch 441, batch 19, d_loss=-0.163 g_loss=-0.551 KID= 0.00767\n",
      "epoch 442, batch 0, d_loss=-0.180 g_loss=-0.551 KID= 0.00767\n",
      "epoch 442, batch 1, d_loss=-0.186 g_loss=-0.426 KID= 0.00767\n",
      "epoch 442, batch 2, d_loss=-0.197 g_loss=-0.307 KID= 0.00767\n",
      "epoch 442, batch 3, d_loss=-0.226 g_loss=-0.123 KID= 0.00767\n",
      "epoch 442, batch 4, d_loss=-0.178 g_loss=0.065 KID= 0.00767\n",
      "epoch 442, batch 5, d_loss=-0.147 g_loss=0.102 KID= 0.00767\n",
      "epoch 442, batch 6, d_loss=-0.186 g_loss=0.077 KID= 0.00767\n",
      "epoch 442, batch 7, d_loss=-0.167 g_loss=0.005 KID= 0.00767\n",
      "epoch 442, batch 8, d_loss=-0.176 g_loss=-0.204 KID= 0.00767\n",
      "epoch 442, batch 9, d_loss=-0.182 g_loss=-0.328 KID= 0.00767\n",
      "epoch 442, batch 10, d_loss=-0.149 g_loss=-0.417 KID= 0.00767\n",
      "epoch 442, batch 11, d_loss=-0.182 g_loss=-0.510 KID= 0.00767\n",
      "epoch 442, batch 12, d_loss=-0.244 g_loss=-0.668 KID= 0.00767\n",
      "epoch 442, batch 13, d_loss=-0.227 g_loss=-0.842 KID= 0.00767\n",
      "epoch 442, batch 14, d_loss=-0.149 g_loss=-0.870 KID= 0.00767\n",
      "epoch 442, batch 15, d_loss=-0.121 g_loss=-0.865 KID= 0.00767\n",
      "epoch 442, batch 16, d_loss=-0.131 g_loss=-0.802 KID= 0.00767\n",
      "epoch 442, batch 17, d_loss=-0.125 g_loss=-0.713 KID= 0.00767\n",
      "epoch 442, batch 18, d_loss=-0.225 g_loss=-0.739 KID= 0.00767\n",
      "epoch 442, batch 19, d_loss=-0.198 g_loss=-0.940 KID= 0.00767\n",
      "epoch 443, batch 0, d_loss=-0.161 g_loss=-1.010 KID= 0.00767\n",
      "epoch 443, batch 1, d_loss=-0.196 g_loss=-0.926 KID= 0.00767\n",
      "epoch 443, batch 2, d_loss=-0.229 g_loss=-0.850 KID= 0.00767\n",
      "epoch 443, batch 3, d_loss=-0.229 g_loss=-0.635 KID= 0.00767\n",
      "epoch 443, batch 4, d_loss=-0.198 g_loss=-0.280 KID= 0.00767\n",
      "epoch 443, batch 5, d_loss=-0.207 g_loss=-0.068 KID= 0.00767\n",
      "epoch 443, batch 6, d_loss=-0.230 g_loss=0.109 KID= 0.00767\n",
      "epoch 443, batch 7, d_loss=-0.165 g_loss=0.335 KID= 0.00767\n",
      "epoch 443, batch 8, d_loss=-0.107 g_loss=0.345 KID= 0.00767\n",
      "epoch 443, batch 9, d_loss=-0.125 g_loss=0.445 KID= 0.00767\n",
      "epoch 443, batch 10, d_loss=-0.195 g_loss=0.510 KID= 0.00767\n",
      "epoch 443, batch 11, d_loss=-0.172 g_loss=0.400 KID= 0.00767\n",
      "epoch 443, batch 12, d_loss=-0.171 g_loss=0.188 KID= 0.00767\n",
      "epoch 443, batch 13, d_loss=-0.148 g_loss=0.026 KID= 0.00767\n",
      "epoch 443, batch 14, d_loss=-0.164 g_loss=-0.106 KID= 0.00767\n",
      "epoch 443, batch 15, d_loss=-0.225 g_loss=-0.125 KID= 0.00767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 443, batch 16, d_loss=-0.151 g_loss=-0.083 KID= 0.00767\n",
      "epoch 443, batch 17, d_loss=-0.129 g_loss=-0.098 KID= 0.00767\n",
      "epoch 443, batch 18, d_loss=-0.167 g_loss=-0.076 KID= 0.00767\n",
      "epoch 443, batch 19, d_loss=-0.155 g_loss=-0.022 KID= 0.00767\n",
      "epoch 444, batch 0, d_loss=-0.219 g_loss=0.028 KID= 0.00767\n",
      "epoch 444, batch 1, d_loss=-0.217 g_loss=0.047 KID= 0.00767\n",
      "epoch 444, batch 2, d_loss=-0.197 g_loss=-0.049 KID= 0.00767\n",
      "epoch 444, batch 3, d_loss=-0.163 g_loss=-0.156 KID= 0.00767\n",
      "epoch 444, batch 4, d_loss=-0.175 g_loss=-0.255 KID= 0.00767\n",
      "epoch 444, batch 5, d_loss=-0.165 g_loss=-0.325 KID= 0.00767\n",
      "epoch 444, batch 6, d_loss=-0.225 g_loss=-0.372 KID= 0.00767\n",
      "epoch 444, batch 7, d_loss=-0.171 g_loss=-0.368 KID= 0.00767\n",
      "epoch 444, batch 8, d_loss=-0.164 g_loss=-0.402 KID= 0.00767\n",
      "epoch 444, batch 9, d_loss=-0.208 g_loss=-0.375 KID= 0.00767\n",
      "epoch 444, batch 10, d_loss=-0.156 g_loss=-0.323 KID= 0.00767\n",
      "epoch 444, batch 11, d_loss=-0.184 g_loss=-0.261 KID= 0.00767\n",
      "epoch 444, batch 12, d_loss=-0.227 g_loss=-0.309 KID= 0.00767\n",
      "epoch 444, batch 13, d_loss=-0.175 g_loss=-0.312 KID= 0.00767\n",
      "epoch 444, batch 14, d_loss=-0.104 g_loss=-0.315 KID= 0.00767\n",
      "epoch 444, batch 15, d_loss=-0.188 g_loss=-0.366 KID= 0.00767\n",
      "epoch 444, batch 16, d_loss=-0.112 g_loss=-0.361 KID= 0.00767\n",
      "epoch 444, batch 17, d_loss=-0.158 g_loss=-0.292 KID= 0.00767\n",
      "epoch 444, batch 18, d_loss=-0.195 g_loss=-0.217 KID= 0.00767\n",
      "epoch 444, batch 19, d_loss=-0.223 g_loss=-0.133 KID= 0.00767\n",
      "epoch 445, batch 0, d_loss=-0.196 g_loss=-0.092 KID= 0.00767\n",
      "epoch 445, batch 1, d_loss=-0.235 g_loss=-0.052 KID= 0.00767\n",
      "epoch 445, batch 2, d_loss=-0.214 g_loss=-0.012 KID= 0.00767\n",
      "epoch 445, batch 3, d_loss=-0.193 g_loss=0.040 KID= 0.00767\n",
      "epoch 445, batch 4, d_loss=-0.159 g_loss=0.080 KID= 0.00767\n",
      "epoch 445, batch 5, d_loss=-0.239 g_loss=0.104 KID= 0.00767\n",
      "epoch 445, batch 6, d_loss=-0.192 g_loss=0.238 KID= 0.00767\n",
      "epoch 445, batch 7, d_loss=-0.178 g_loss=0.258 KID= 0.00767\n",
      "epoch 445, batch 8, d_loss=-0.179 g_loss=0.213 KID= 0.00767\n",
      "epoch 445, batch 9, d_loss=-0.218 g_loss=0.074 KID= 0.00767\n",
      "epoch 445, batch 10, d_loss=-0.192 g_loss=-0.046 KID= 0.00767\n",
      "epoch 445, batch 11, d_loss=-0.227 g_loss=-0.034 KID= 0.00767\n",
      "epoch 445, batch 12, d_loss=-0.251 g_loss=-0.207 KID= 0.00767\n",
      "epoch 445, batch 13, d_loss=-0.193 g_loss=-0.373 KID= 0.00767\n",
      "epoch 445, batch 14, d_loss=-0.194 g_loss=-0.326 KID= 0.00767\n",
      "epoch 445, batch 15, d_loss=-0.208 g_loss=-0.283 KID= 0.00767\n",
      "epoch 445, batch 16, d_loss=-0.158 g_loss=-0.323 KID= 0.00767\n",
      "epoch 445, batch 17, d_loss=-0.116 g_loss=-0.422 KID= 0.00767\n",
      "epoch 445, batch 18, d_loss=-0.156 g_loss=-0.378 KID= 0.00767\n",
      "epoch 445, batch 19, d_loss=-0.152 g_loss=-0.324 KID= 0.00767\n",
      "epoch 446, batch 0, d_loss=-0.162 g_loss=-0.334 KID= 0.00767\n",
      "epoch 446, batch 1, d_loss=-0.173 g_loss=-0.292 KID= 0.00767\n",
      "epoch 446, batch 2, d_loss=-0.214 g_loss=-0.305 KID= 0.00767\n",
      "epoch 446, batch 3, d_loss=-0.232 g_loss=-0.241 KID= 0.00767\n",
      "epoch 446, batch 4, d_loss=-0.114 g_loss=-0.196 KID= 0.00767\n",
      "epoch 446, batch 5, d_loss=-0.165 g_loss=-0.109 KID= 0.00767\n",
      "epoch 446, batch 6, d_loss=-0.215 g_loss=-0.028 KID= 0.00767\n",
      "epoch 446, batch 7, d_loss=-0.193 g_loss=-0.049 KID= 0.00767\n",
      "epoch 446, batch 8, d_loss=-0.187 g_loss=-0.100 KID= 0.00767\n",
      "epoch 446, batch 9, d_loss=-0.211 g_loss=-0.137 KID= 0.00767\n",
      "epoch 446, batch 10, d_loss=-0.139 g_loss=-0.198 KID= 0.00767\n",
      "epoch 446, batch 11, d_loss=-0.212 g_loss=-0.199 KID= 0.00767\n",
      "epoch 446, batch 12, d_loss=-0.246 g_loss=-0.210 KID= 0.00767\n",
      "epoch 446, batch 13, d_loss=-0.175 g_loss=-0.224 KID= 0.00767\n",
      "epoch 446, batch 14, d_loss=-0.200 g_loss=-0.236 KID= 0.00767\n",
      "epoch 446, batch 15, d_loss=-0.192 g_loss=-0.244 KID= 0.00767\n",
      "epoch 446, batch 16, d_loss=-0.139 g_loss=-0.193 KID= 0.00767\n",
      "epoch 446, batch 17, d_loss=-0.174 g_loss=-0.145 KID= 0.00767\n",
      "epoch 446, batch 18, d_loss=-0.188 g_loss=-0.169 KID= 0.00767\n",
      "epoch 446, batch 19, d_loss=-0.233 g_loss=-0.218 KID= 0.00767\n",
      "epoch 447, batch 0, d_loss=-0.165 g_loss=-0.327 KID= 0.00767\n",
      "epoch 447, batch 1, d_loss=-0.247 g_loss=-0.434 KID= 0.00767\n",
      "epoch 447, batch 2, d_loss=-0.252 g_loss=-0.597 KID= 0.00767\n",
      "epoch 447, batch 3, d_loss=-0.200 g_loss=-0.670 KID= 0.00767\n",
      "epoch 447, batch 4, d_loss=-0.175 g_loss=-0.697 KID= 0.00767\n",
      "epoch 447, batch 5, d_loss=-0.190 g_loss=-0.640 KID= 0.00767\n",
      "epoch 447, batch 6, d_loss=-0.178 g_loss=-0.554 KID= 0.00767\n",
      "epoch 447, batch 7, d_loss=-0.149 g_loss=-0.477 KID= 0.00767\n",
      "epoch 447, batch 8, d_loss=-0.205 g_loss=-0.417 KID= 0.00767\n",
      "epoch 447, batch 9, d_loss=-0.250 g_loss=-0.467 KID= 0.00767\n",
      "epoch 447, batch 10, d_loss=-0.159 g_loss=-0.585 KID= 0.00767\n",
      "epoch 447, batch 11, d_loss=-0.197 g_loss=-0.606 KID= 0.00767\n",
      "epoch 447, batch 12, d_loss=-0.200 g_loss=-0.553 KID= 0.00767\n",
      "epoch 447, batch 13, d_loss=-0.186 g_loss=-0.515 KID= 0.00767\n",
      "epoch 447, batch 14, d_loss=-0.178 g_loss=-0.402 KID= 0.00767\n",
      "epoch 447, batch 15, d_loss=-0.226 g_loss=-0.272 KID= 0.00767\n",
      "epoch 447, batch 16, d_loss=-0.158 g_loss=-0.216 KID= 0.00767\n",
      "epoch 447, batch 17, d_loss=-0.164 g_loss=-0.127 KID= 0.00767\n",
      "epoch 447, batch 18, d_loss=-0.190 g_loss=-0.065 KID= 0.00767\n",
      "epoch 447, batch 19, d_loss=-0.185 g_loss=0.014 KID= 0.00767\n",
      "epoch 448, batch 0, d_loss=-0.150 g_loss=0.067 KID= 0.00767\n",
      "epoch 448, batch 1, d_loss=-0.251 g_loss=0.033 KID= 0.00767\n",
      "epoch 448, batch 2, d_loss=-0.225 g_loss=-0.093 KID= 0.00767\n",
      "epoch 448, batch 3, d_loss=-0.195 g_loss=-0.314 KID= 0.00767\n",
      "epoch 448, batch 4, d_loss=-0.057 g_loss=-0.486 KID= 0.00767\n",
      "epoch 448, batch 5, d_loss=-0.157 g_loss=-0.592 KID= 0.00767\n",
      "epoch 448, batch 6, d_loss=-0.167 g_loss=-0.574 KID= 0.00767\n",
      "epoch 448, batch 7, d_loss=-0.108 g_loss=-0.447 KID= 0.00767\n",
      "epoch 448, batch 8, d_loss=-0.172 g_loss=-0.472 KID= 0.00767\n",
      "epoch 448, batch 9, d_loss=-0.223 g_loss=-0.516 KID= 0.00767\n",
      "epoch 448, batch 10, d_loss=-0.178 g_loss=-0.599 KID= 0.00767\n",
      "epoch 448, batch 11, d_loss=-0.245 g_loss=-0.690 KID= 0.00767\n",
      "epoch 448, batch 12, d_loss=-0.189 g_loss=-0.866 KID= 0.00767\n",
      "epoch 448, batch 13, d_loss=-0.165 g_loss=-1.016 KID= 0.00767\n",
      "epoch 448, batch 14, d_loss=-0.247 g_loss=-1.025 KID= 0.00767\n",
      "epoch 448, batch 15, d_loss=-0.216 g_loss=-0.931 KID= 0.00767\n",
      "epoch 448, batch 16, d_loss=-0.160 g_loss=-0.790 KID= 0.00767\n",
      "epoch 448, batch 17, d_loss=-0.130 g_loss=-0.531 KID= 0.00767\n",
      "epoch 448, batch 18, d_loss=-0.194 g_loss=-0.252 KID= 0.00767\n",
      "epoch 448, batch 19, d_loss=-0.198 g_loss=-0.076 KID= 0.00767\n",
      "epoch 449, batch 0, d_loss=-0.172 g_loss=0.122 KID= 0.00767\n",
      "epoch 449, batch 1, d_loss=-0.203 g_loss=0.375 KID= 0.00767\n",
      "epoch 449, batch 2, d_loss=-0.236 g_loss=0.539 KID= 0.00767\n",
      "epoch 449, batch 3, d_loss=-0.239 g_loss=0.598 KID= 0.00767\n",
      "epoch 449, batch 4, d_loss=-0.248 g_loss=0.598 KID= 0.00767\n",
      "epoch 449, batch 5, d_loss=-0.222 g_loss=0.506 KID= 0.00767\n",
      "epoch 449, batch 6, d_loss=-0.121 g_loss=0.230 KID= 0.00767\n",
      "epoch 449, batch 7, d_loss=-0.100 g_loss=-0.044 KID= 0.00767\n",
      "epoch 449, batch 8, d_loss=-0.161 g_loss=-0.220 KID= 0.00767\n",
      "epoch 449, batch 9, d_loss=-0.187 g_loss=-0.367 KID= 0.00767\n",
      "epoch 449, batch 10, d_loss=-0.171 g_loss=-0.528 KID= 0.00767\n",
      "epoch 449, batch 11, d_loss=-0.253 g_loss=-0.690 KID= 0.00767\n",
      "epoch 449, batch 12, d_loss=-0.312 g_loss=-0.933 KID= 0.00767\n",
      "epoch 449, batch 13, d_loss=-0.195 g_loss=-1.178 KID= 0.00767\n",
      "epoch 449, batch 14, d_loss=-0.058 g_loss=-1.073 KID= 0.00767\n",
      "epoch 449, batch 15, d_loss=-0.145 g_loss=-1.064 KID= 0.00767\n",
      "epoch 449, batch 16, d_loss=-0.229 g_loss=-0.947 KID= 0.00767\n",
      "epoch 449, batch 17, d_loss=-0.165 g_loss=-0.813 KID= 0.00767\n",
      "epoch 449, batch 18, d_loss=-0.187 g_loss=-0.701 KID= 0.00767\n",
      "epoch 449, batch 19, d_loss=-0.182 g_loss=-0.546 KID= 0.00767\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 450, batch 0, d_loss=-0.165 g_loss=-0.373 KID= 0.00939\n",
      "epoch 450, batch 1, d_loss=-0.275 g_loss=-0.183 KID= 0.00939\n",
      "epoch 450, batch 2, d_loss=-0.174 g_loss=-0.127 KID= 0.00939\n",
      "epoch 450, batch 3, d_loss=-0.111 g_loss=-0.194 KID= 0.00939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 450, batch 4, d_loss=-0.134 g_loss=-0.348 KID= 0.00939\n",
      "epoch 450, batch 5, d_loss=-0.197 g_loss=-0.455 KID= 0.00939\n",
      "epoch 450, batch 6, d_loss=-0.247 g_loss=-0.577 KID= 0.00939\n",
      "epoch 450, batch 7, d_loss=-0.194 g_loss=-0.609 KID= 0.00939\n",
      "epoch 450, batch 8, d_loss=-0.218 g_loss=-0.599 KID= 0.00939\n",
      "epoch 450, batch 9, d_loss=-0.206 g_loss=-0.541 KID= 0.00939\n",
      "epoch 450, batch 10, d_loss=-0.150 g_loss=-0.429 KID= 0.00939\n",
      "epoch 450, batch 11, d_loss=-0.184 g_loss=-0.285 KID= 0.00939\n",
      "epoch 450, batch 12, d_loss=-0.210 g_loss=-0.176 KID= 0.00939\n",
      "epoch 450, batch 13, d_loss=-0.175 g_loss=-0.105 KID= 0.00939\n",
      "epoch 450, batch 14, d_loss=-0.185 g_loss=-0.079 KID= 0.00939\n",
      "epoch 450, batch 15, d_loss=-0.193 g_loss=-0.127 KID= 0.00939\n",
      "epoch 450, batch 16, d_loss=-0.134 g_loss=-0.231 KID= 0.00939\n",
      "epoch 450, batch 17, d_loss=-0.140 g_loss=-0.424 KID= 0.00939\n",
      "epoch 450, batch 18, d_loss=-0.184 g_loss=-0.468 KID= 0.00939\n",
      "epoch 450, batch 19, d_loss=-0.245 g_loss=-0.490 KID= 0.00939\n",
      "epoch 451, batch 0, d_loss=-0.192 g_loss=-0.533 KID= 0.00939\n",
      "epoch 451, batch 1, d_loss=-0.270 g_loss=-0.540 KID= 0.00939\n",
      "epoch 451, batch 2, d_loss=-0.192 g_loss=-0.652 KID= 0.00939\n",
      "epoch 451, batch 3, d_loss=-0.200 g_loss=-0.688 KID= 0.00939\n",
      "epoch 451, batch 4, d_loss=-0.159 g_loss=-0.641 KID= 0.00939\n",
      "epoch 451, batch 5, d_loss=-0.255 g_loss=-0.551 KID= 0.00939\n",
      "epoch 451, batch 6, d_loss=-0.210 g_loss=-0.525 KID= 0.00939\n",
      "epoch 451, batch 7, d_loss=-0.148 g_loss=-0.513 KID= 0.00939\n",
      "epoch 451, batch 8, d_loss=-0.153 g_loss=-0.394 KID= 0.00939\n",
      "epoch 451, batch 9, d_loss=-0.195 g_loss=-0.250 KID= 0.00939\n",
      "epoch 451, batch 10, d_loss=-0.166 g_loss=-0.001 KID= 0.00939\n",
      "epoch 451, batch 11, d_loss=-0.219 g_loss=0.266 KID= 0.00939\n",
      "epoch 451, batch 12, d_loss=-0.233 g_loss=0.448 KID= 0.00939\n",
      "epoch 451, batch 13, d_loss=-0.198 g_loss=0.549 KID= 0.00939\n",
      "epoch 451, batch 14, d_loss=-0.173 g_loss=0.548 KID= 0.00939\n",
      "epoch 451, batch 15, d_loss=-0.204 g_loss=0.652 KID= 0.00939\n",
      "epoch 451, batch 16, d_loss=-0.175 g_loss=0.485 KID= 0.00939\n",
      "epoch 451, batch 17, d_loss=-0.159 g_loss=0.231 KID= 0.00939\n",
      "epoch 451, batch 18, d_loss=-0.201 g_loss=-0.008 KID= 0.00939\n",
      "epoch 451, batch 19, d_loss=-0.214 g_loss=-0.238 KID= 0.00939\n",
      "epoch 452, batch 0, d_loss=-0.179 g_loss=-0.420 KID= 0.00939\n",
      "epoch 452, batch 1, d_loss=-0.220 g_loss=-0.460 KID= 0.00939\n",
      "epoch 452, batch 2, d_loss=-0.237 g_loss=-0.576 KID= 0.00939\n",
      "epoch 452, batch 3, d_loss=-0.200 g_loss=-0.687 KID= 0.00939\n",
      "epoch 452, batch 4, d_loss=-0.164 g_loss=-0.651 KID= 0.00939\n",
      "epoch 452, batch 5, d_loss=-0.223 g_loss=-0.577 KID= 0.00939\n",
      "epoch 452, batch 6, d_loss=-0.194 g_loss=-0.554 KID= 0.00939\n",
      "epoch 452, batch 7, d_loss=-0.132 g_loss=-0.483 KID= 0.00939\n",
      "epoch 452, batch 8, d_loss=-0.186 g_loss=-0.425 KID= 0.00939\n",
      "epoch 452, batch 9, d_loss=-0.224 g_loss=-0.470 KID= 0.00939\n",
      "epoch 452, batch 10, d_loss=-0.163 g_loss=-0.416 KID= 0.00939\n",
      "epoch 452, batch 11, d_loss=-0.219 g_loss=-0.431 KID= 0.00939\n",
      "epoch 452, batch 12, d_loss=-0.192 g_loss=-0.400 KID= 0.00939\n",
      "epoch 452, batch 13, d_loss=-0.235 g_loss=-0.430 KID= 0.00939\n",
      "epoch 452, batch 14, d_loss=-0.159 g_loss=-0.371 KID= 0.00939\n",
      "epoch 452, batch 15, d_loss=-0.267 g_loss=-0.340 KID= 0.00939\n",
      "epoch 452, batch 16, d_loss=-0.180 g_loss=-0.354 KID= 0.00939\n",
      "epoch 452, batch 17, d_loss=-0.176 g_loss=-0.257 KID= 0.00939\n",
      "epoch 452, batch 18, d_loss=-0.184 g_loss=-0.185 KID= 0.00939\n",
      "epoch 452, batch 19, d_loss=-0.194 g_loss=-0.174 KID= 0.00939\n",
      "epoch 453, batch 0, d_loss=-0.179 g_loss=-0.144 KID= 0.00939\n",
      "epoch 453, batch 1, d_loss=-0.205 g_loss=-0.101 KID= 0.00939\n",
      "epoch 453, batch 2, d_loss=-0.247 g_loss=-0.105 KID= 0.00939\n",
      "epoch 453, batch 3, d_loss=-0.166 g_loss=-0.178 KID= 0.00939\n",
      "epoch 453, batch 4, d_loss=-0.123 g_loss=-0.301 KID= 0.00939\n",
      "epoch 453, batch 5, d_loss=-0.205 g_loss=-0.360 KID= 0.00939\n",
      "epoch 453, batch 6, d_loss=-0.233 g_loss=-0.474 KID= 0.00939\n",
      "epoch 453, batch 7, d_loss=-0.168 g_loss=-0.577 KID= 0.00939\n",
      "epoch 453, batch 8, d_loss=-0.227 g_loss=-0.597 KID= 0.00939\n",
      "epoch 453, batch 9, d_loss=-0.210 g_loss=-0.601 KID= 0.00939\n",
      "epoch 453, batch 10, d_loss=-0.152 g_loss=-0.513 KID= 0.00939\n",
      "epoch 453, batch 11, d_loss=-0.227 g_loss=-0.435 KID= 0.00939\n",
      "epoch 453, batch 12, d_loss=-0.201 g_loss=-0.349 KID= 0.00939\n",
      "epoch 453, batch 13, d_loss=-0.211 g_loss=-0.302 KID= 0.00939\n",
      "epoch 453, batch 14, d_loss=-0.137 g_loss=-0.178 KID= 0.00939\n",
      "epoch 453, batch 15, d_loss=-0.245 g_loss=-0.125 KID= 0.00939\n",
      "epoch 453, batch 16, d_loss=-0.200 g_loss=-0.150 KID= 0.00939\n",
      "epoch 453, batch 17, d_loss=-0.172 g_loss=-0.130 KID= 0.00939\n",
      "epoch 453, batch 18, d_loss=-0.186 g_loss=-0.064 KID= 0.00939\n",
      "epoch 453, batch 19, d_loss=-0.232 g_loss=-0.100 KID= 0.00939\n",
      "epoch 454, batch 0, d_loss=-0.200 g_loss=-0.136 KID= 0.00939\n",
      "epoch 454, batch 1, d_loss=-0.226 g_loss=-0.125 KID= 0.00939\n",
      "epoch 454, batch 2, d_loss=-0.201 g_loss=-0.207 KID= 0.00939\n",
      "epoch 454, batch 3, d_loss=-0.197 g_loss=-0.289 KID= 0.00939\n",
      "epoch 454, batch 4, d_loss=-0.200 g_loss=-0.305 KID= 0.00939\n",
      "epoch 454, batch 5, d_loss=-0.218 g_loss=-0.409 KID= 0.00939\n",
      "epoch 454, batch 6, d_loss=-0.143 g_loss=-0.575 KID= 0.00939\n",
      "epoch 454, batch 7, d_loss=-0.148 g_loss=-0.575 KID= 0.00939\n",
      "epoch 454, batch 8, d_loss=-0.217 g_loss=-0.547 KID= 0.00939\n",
      "epoch 454, batch 9, d_loss=-0.194 g_loss=-0.525 KID= 0.00939\n",
      "epoch 454, batch 10, d_loss=-0.219 g_loss=-0.383 KID= 0.00939\n",
      "epoch 454, batch 11, d_loss=-0.284 g_loss=-0.229 KID= 0.00939\n",
      "epoch 454, batch 12, d_loss=-0.260 g_loss=-0.194 KID= 0.00939\n",
      "epoch 454, batch 13, d_loss=-0.305 g_loss=-0.170 KID= 0.00939\n",
      "epoch 454, batch 14, d_loss=-0.176 g_loss=-0.163 KID= 0.00939\n",
      "epoch 454, batch 15, d_loss=-0.206 g_loss=-0.104 KID= 0.00939\n",
      "epoch 454, batch 16, d_loss=-0.216 g_loss=-0.235 KID= 0.00939\n",
      "epoch 454, batch 17, d_loss=-0.167 g_loss=-0.233 KID= 0.00939\n",
      "epoch 454, batch 18, d_loss=-0.180 g_loss=-0.208 KID= 0.00939\n",
      "epoch 454, batch 19, d_loss=-0.230 g_loss=-0.225 KID= 0.00939\n",
      "epoch 455, batch 0, d_loss=-0.216 g_loss=-0.129 KID= 0.00939\n",
      "epoch 455, batch 1, d_loss=-0.254 g_loss=-0.070 KID= 0.00939\n",
      "epoch 455, batch 2, d_loss=-0.222 g_loss=-0.015 KID= 0.00939\n",
      "epoch 455, batch 3, d_loss=-0.214 g_loss=-0.039 KID= 0.00939\n",
      "epoch 455, batch 4, d_loss=-0.155 g_loss=-0.079 KID= 0.00939\n",
      "epoch 455, batch 5, d_loss=-0.213 g_loss=-0.126 KID= 0.00939\n",
      "epoch 455, batch 6, d_loss=-0.229 g_loss=-0.273 KID= 0.00939\n",
      "epoch 455, batch 7, d_loss=-0.120 g_loss=-0.312 KID= 0.00939\n",
      "epoch 455, batch 8, d_loss=-0.178 g_loss=-0.379 KID= 0.00939\n",
      "epoch 455, batch 9, d_loss=-0.196 g_loss=-0.535 KID= 0.00939\n",
      "epoch 455, batch 10, d_loss=-0.146 g_loss=-0.568 KID= 0.00939\n",
      "epoch 455, batch 11, d_loss=-0.272 g_loss=-0.641 KID= 0.00939\n",
      "epoch 455, batch 12, d_loss=-0.200 g_loss=-0.726 KID= 0.00939\n",
      "epoch 455, batch 13, d_loss=-0.175 g_loss=-0.902 KID= 0.00939\n",
      "epoch 455, batch 14, d_loss=-0.173 g_loss=-0.863 KID= 0.00939\n",
      "epoch 455, batch 15, d_loss=-0.214 g_loss=-0.736 KID= 0.00939\n",
      "epoch 455, batch 16, d_loss=-0.191 g_loss=-0.669 KID= 0.00939\n",
      "epoch 455, batch 17, d_loss=-0.257 g_loss=-0.532 KID= 0.00939\n",
      "epoch 455, batch 18, d_loss=-0.244 g_loss=-0.402 KID= 0.00939\n",
      "epoch 455, batch 19, d_loss=-0.217 g_loss=-0.232 KID= 0.00939\n",
      "epoch 456, batch 0, d_loss=-0.219 g_loss=-0.127 KID= 0.00939\n",
      "epoch 456, batch 1, d_loss=-0.182 g_loss=-0.037 KID= 0.00939\n",
      "epoch 456, batch 2, d_loss=-0.225 g_loss=0.020 KID= 0.00939\n",
      "epoch 456, batch 3, d_loss=-0.134 g_loss=0.026 KID= 0.00939\n",
      "epoch 456, batch 4, d_loss=-0.145 g_loss=0.096 KID= 0.00939\n",
      "epoch 456, batch 5, d_loss=-0.229 g_loss=0.062 KID= 0.00939\n",
      "epoch 456, batch 6, d_loss=-0.238 g_loss=-0.086 KID= 0.00939\n",
      "epoch 456, batch 7, d_loss=-0.166 g_loss=-0.190 KID= 0.00939\n",
      "epoch 456, batch 8, d_loss=-0.241 g_loss=-0.378 KID= 0.00939\n",
      "epoch 456, batch 9, d_loss=-0.230 g_loss=-0.509 KID= 0.00939\n",
      "epoch 456, batch 10, d_loss=-0.150 g_loss=-0.500 KID= 0.00939\n",
      "epoch 456, batch 11, d_loss=-0.237 g_loss=-0.468 KID= 0.00939\n",
      "epoch 456, batch 12, d_loss=-0.196 g_loss=-0.457 KID= 0.00939\n",
      "epoch 456, batch 13, d_loss=-0.217 g_loss=-0.507 KID= 0.00939\n",
      "epoch 456, batch 14, d_loss=-0.175 g_loss=-0.569 KID= 0.00939\n",
      "epoch 456, batch 15, d_loss=-0.187 g_loss=-0.614 KID= 0.00939\n",
      "epoch 456, batch 16, d_loss=-0.216 g_loss=-0.709 KID= 0.00939\n",
      "epoch 456, batch 17, d_loss=-0.162 g_loss=-0.784 KID= 0.00939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 456, batch 18, d_loss=-0.197 g_loss=-0.838 KID= 0.00939\n",
      "epoch 456, batch 19, d_loss=-0.221 g_loss=-0.831 KID= 0.00939\n",
      "epoch 457, batch 0, d_loss=-0.167 g_loss=-0.787 KID= 0.00939\n",
      "epoch 457, batch 1, d_loss=-0.272 g_loss=-0.668 KID= 0.00939\n",
      "epoch 457, batch 2, d_loss=-0.243 g_loss=-0.522 KID= 0.00939\n",
      "epoch 457, batch 3, d_loss=-0.208 g_loss=-0.351 KID= 0.00939\n",
      "epoch 457, batch 4, d_loss=-0.164 g_loss=-0.128 KID= 0.00939\n",
      "epoch 457, batch 5, d_loss=-0.181 g_loss=-0.062 KID= 0.00939\n",
      "epoch 457, batch 6, d_loss=-0.191 g_loss=0.009 KID= 0.00939\n",
      "epoch 457, batch 7, d_loss=-0.161 g_loss=0.125 KID= 0.00939\n",
      "epoch 457, batch 8, d_loss=-0.186 g_loss=0.252 KID= 0.00939\n",
      "epoch 457, batch 9, d_loss=-0.214 g_loss=0.326 KID= 0.00939\n",
      "epoch 457, batch 10, d_loss=-0.177 g_loss=0.343 KID= 0.00939\n",
      "epoch 457, batch 11, d_loss=-0.268 g_loss=0.311 KID= 0.00939\n",
      "epoch 457, batch 12, d_loss=-0.247 g_loss=0.184 KID= 0.00939\n",
      "epoch 457, batch 13, d_loss=-0.254 g_loss=0.092 KID= 0.00939\n",
      "epoch 457, batch 14, d_loss=-0.161 g_loss=-0.113 KID= 0.00939\n",
      "epoch 457, batch 15, d_loss=-0.234 g_loss=-0.327 KID= 0.00939\n",
      "epoch 457, batch 16, d_loss=-0.157 g_loss=-0.434 KID= 0.00939\n",
      "epoch 457, batch 17, d_loss=-0.075 g_loss=-0.491 KID= 0.00939\n",
      "epoch 457, batch 18, d_loss=-0.235 g_loss=-0.584 KID= 0.00939\n",
      "epoch 457, batch 19, d_loss=-0.212 g_loss=-0.546 KID= 0.00939\n",
      "epoch 458, batch 0, d_loss=-0.165 g_loss=-0.522 KID= 0.00939\n",
      "epoch 458, batch 1, d_loss=-0.259 g_loss=-0.416 KID= 0.00939\n",
      "epoch 458, batch 2, d_loss=-0.189 g_loss=-0.359 KID= 0.00939\n",
      "epoch 458, batch 3, d_loss=-0.192 g_loss=-0.235 KID= 0.00939\n",
      "epoch 458, batch 4, d_loss=-0.200 g_loss=-0.274 KID= 0.00939\n",
      "epoch 458, batch 5, d_loss=-0.193 g_loss=-0.430 KID= 0.00939\n",
      "epoch 458, batch 6, d_loss=-0.189 g_loss=-0.560 KID= 0.00939\n",
      "epoch 458, batch 7, d_loss=-0.184 g_loss=-0.587 KID= 0.00939\n",
      "epoch 458, batch 8, d_loss=-0.226 g_loss=-0.533 KID= 0.00939\n",
      "epoch 458, batch 9, d_loss=-0.185 g_loss=-0.465 KID= 0.00939\n",
      "epoch 458, batch 10, d_loss=-0.182 g_loss=-0.425 KID= 0.00939\n",
      "epoch 458, batch 11, d_loss=-0.242 g_loss=-0.279 KID= 0.00939\n",
      "epoch 458, batch 12, d_loss=-0.237 g_loss=-0.176 KID= 0.00939\n",
      "epoch 458, batch 13, d_loss=-0.220 g_loss=-0.121 KID= 0.00939\n",
      "epoch 458, batch 14, d_loss=-0.214 g_loss=-0.195 KID= 0.00939\n",
      "epoch 458, batch 15, d_loss=-0.200 g_loss=-0.310 KID= 0.00939\n",
      "epoch 458, batch 16, d_loss=-0.240 g_loss=-0.435 KID= 0.00939\n",
      "epoch 458, batch 17, d_loss=-0.098 g_loss=-0.514 KID= 0.00939\n",
      "epoch 458, batch 18, d_loss=-0.202 g_loss=-0.616 KID= 0.00939\n",
      "epoch 458, batch 19, d_loss=-0.177 g_loss=-0.632 KID= 0.00939\n",
      "epoch 459, batch 0, d_loss=-0.186 g_loss=-0.565 KID= 0.00939\n",
      "epoch 459, batch 1, d_loss=-0.203 g_loss=-0.428 KID= 0.00939\n",
      "epoch 459, batch 2, d_loss=-0.264 g_loss=-0.314 KID= 0.00939\n",
      "epoch 459, batch 3, d_loss=-0.216 g_loss=-0.250 KID= 0.00939\n",
      "epoch 459, batch 4, d_loss=-0.210 g_loss=-0.119 KID= 0.00939\n",
      "epoch 459, batch 5, d_loss=-0.189 g_loss=-0.083 KID= 0.00939\n",
      "epoch 459, batch 6, d_loss=-0.192 g_loss=-0.189 KID= 0.00939\n",
      "epoch 459, batch 7, d_loss=-0.224 g_loss=-0.200 KID= 0.00939\n",
      "epoch 459, batch 8, d_loss=-0.208 g_loss=-0.209 KID= 0.00939\n",
      "epoch 459, batch 9, d_loss=-0.206 g_loss=-0.225 KID= 0.00939\n",
      "epoch 459, batch 10, d_loss=-0.211 g_loss=-0.169 KID= 0.00939\n",
      "epoch 459, batch 11, d_loss=-0.261 g_loss=-0.158 KID= 0.00939\n",
      "epoch 459, batch 12, d_loss=-0.249 g_loss=-0.253 KID= 0.00939\n",
      "epoch 459, batch 13, d_loss=-0.169 g_loss=-0.328 KID= 0.00939\n",
      "epoch 459, batch 14, d_loss=-0.141 g_loss=-0.449 KID= 0.00939\n",
      "epoch 459, batch 15, d_loss=-0.207 g_loss=-0.587 KID= 0.00939\n",
      "epoch 459, batch 16, d_loss=-0.229 g_loss=-0.680 KID= 0.00939\n",
      "epoch 459, batch 17, d_loss=-0.155 g_loss=-0.775 KID= 0.00939\n",
      "epoch 459, batch 18, d_loss=-0.221 g_loss=-0.873 KID= 0.00939\n",
      "epoch 459, batch 19, d_loss=-0.246 g_loss=-0.857 KID= 0.00939\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 460, batch 0, d_loss=-0.174 g_loss=-0.753 KID= 0.00873\n",
      "epoch 460, batch 1, d_loss=-0.247 g_loss=-0.660 KID= 0.00873\n",
      "epoch 460, batch 2, d_loss=-0.201 g_loss=-0.557 KID= 0.00873\n",
      "epoch 460, batch 3, d_loss=-0.149 g_loss=-0.480 KID= 0.00873\n",
      "epoch 460, batch 4, d_loss=-0.241 g_loss=-0.468 KID= 0.00873\n",
      "epoch 460, batch 5, d_loss=-0.212 g_loss=-0.499 KID= 0.00873\n",
      "epoch 460, batch 6, d_loss=-0.182 g_loss=-0.552 KID= 0.00873\n",
      "epoch 460, batch 7, d_loss=-0.145 g_loss=-0.568 KID= 0.00873\n",
      "epoch 460, batch 8, d_loss=-0.255 g_loss=-0.542 KID= 0.00873\n",
      "epoch 460, batch 9, d_loss=-0.203 g_loss=-0.448 KID= 0.00873\n",
      "epoch 460, batch 10, d_loss=-0.183 g_loss=-0.303 KID= 0.00873\n",
      "epoch 460, batch 11, d_loss=-0.237 g_loss=-0.172 KID= 0.00873\n",
      "epoch 460, batch 12, d_loss=-0.225 g_loss=-0.101 KID= 0.00873\n",
      "epoch 460, batch 13, d_loss=-0.205 g_loss=-0.074 KID= 0.00873\n",
      "epoch 460, batch 14, d_loss=-0.199 g_loss=0.014 KID= 0.00873\n",
      "epoch 460, batch 15, d_loss=-0.228 g_loss=-0.087 KID= 0.00873\n",
      "epoch 460, batch 16, d_loss=-0.127 g_loss=-0.212 KID= 0.00873\n",
      "epoch 460, batch 17, d_loss=-0.146 g_loss=-0.315 KID= 0.00873\n",
      "epoch 460, batch 18, d_loss=-0.188 g_loss=-0.450 KID= 0.00873\n",
      "epoch 460, batch 19, d_loss=-0.255 g_loss=-0.457 KID= 0.00873\n",
      "epoch 461, batch 0, d_loss=-0.207 g_loss=-0.413 KID= 0.00873\n",
      "epoch 461, batch 1, d_loss=-0.242 g_loss=-0.332 KID= 0.00873\n",
      "epoch 461, batch 2, d_loss=-0.308 g_loss=-0.302 KID= 0.00873\n",
      "epoch 461, batch 3, d_loss=-0.129 g_loss=-0.212 KID= 0.00873\n",
      "epoch 461, batch 4, d_loss=-0.210 g_loss=-0.108 KID= 0.00873\n",
      "epoch 461, batch 5, d_loss=-0.228 g_loss=-0.167 KID= 0.00873\n",
      "epoch 461, batch 6, d_loss=-0.200 g_loss=-0.281 KID= 0.00873\n",
      "epoch 461, batch 7, d_loss=-0.145 g_loss=-0.412 KID= 0.00873\n",
      "epoch 461, batch 8, d_loss=-0.188 g_loss=-0.522 KID= 0.00873\n",
      "epoch 461, batch 9, d_loss=-0.229 g_loss=-0.601 KID= 0.00873\n",
      "epoch 461, batch 10, d_loss=-0.190 g_loss=-0.587 KID= 0.00873\n",
      "epoch 461, batch 11, d_loss=-0.198 g_loss=-0.618 KID= 0.00873\n",
      "epoch 461, batch 12, d_loss=-0.264 g_loss=-0.674 KID= 0.00873\n",
      "epoch 461, batch 13, d_loss=-0.209 g_loss=-0.626 KID= 0.00873\n",
      "epoch 461, batch 14, d_loss=-0.193 g_loss=-0.546 KID= 0.00873\n",
      "epoch 461, batch 15, d_loss=-0.209 g_loss=-0.534 KID= 0.00873\n",
      "epoch 461, batch 16, d_loss=-0.155 g_loss=-0.534 KID= 0.00873\n",
      "epoch 461, batch 17, d_loss=-0.192 g_loss=-0.531 KID= 0.00873\n",
      "epoch 461, batch 18, d_loss=-0.222 g_loss=-0.505 KID= 0.00873\n",
      "epoch 461, batch 19, d_loss=-0.225 g_loss=-0.492 KID= 0.00873\n",
      "epoch 462, batch 0, d_loss=-0.192 g_loss=-0.448 KID= 0.00873\n",
      "epoch 462, batch 1, d_loss=-0.223 g_loss=-0.369 KID= 0.00873\n",
      "epoch 462, batch 2, d_loss=-0.279 g_loss=-0.299 KID= 0.00873\n",
      "epoch 462, batch 3, d_loss=-0.164 g_loss=-0.255 KID= 0.00873\n",
      "epoch 462, batch 4, d_loss=-0.217 g_loss=-0.266 KID= 0.00873\n",
      "epoch 462, batch 5, d_loss=-0.230 g_loss=-0.280 KID= 0.00873\n",
      "epoch 462, batch 6, d_loss=-0.212 g_loss=-0.408 KID= 0.00873\n",
      "epoch 462, batch 7, d_loss=-0.160 g_loss=-0.404 KID= 0.00873\n",
      "epoch 462, batch 8, d_loss=-0.215 g_loss=-0.474 KID= 0.00873\n",
      "epoch 462, batch 9, d_loss=-0.235 g_loss=-0.506 KID= 0.00873\n",
      "epoch 462, batch 10, d_loss=-0.217 g_loss=-0.513 KID= 0.00873\n",
      "epoch 462, batch 11, d_loss=-0.202 g_loss=-0.544 KID= 0.00873\n",
      "epoch 462, batch 12, d_loss=-0.239 g_loss=-0.523 KID= 0.00873\n",
      "epoch 462, batch 13, d_loss=-0.169 g_loss=-0.383 KID= 0.00873\n",
      "epoch 462, batch 14, d_loss=-0.198 g_loss=-0.320 KID= 0.00873\n",
      "epoch 462, batch 15, d_loss=-0.182 g_loss=-0.375 KID= 0.00873\n",
      "epoch 462, batch 16, d_loss=-0.195 g_loss=-0.479 KID= 0.00873\n",
      "epoch 462, batch 17, d_loss=-0.209 g_loss=-0.496 KID= 0.00873\n",
      "epoch 462, batch 18, d_loss=-0.233 g_loss=-0.469 KID= 0.00873\n",
      "epoch 462, batch 19, d_loss=-0.240 g_loss=-0.411 KID= 0.00873\n",
      "epoch 463, batch 0, d_loss=-0.178 g_loss=-0.296 KID= 0.00873\n",
      "epoch 463, batch 1, d_loss=-0.216 g_loss=-0.230 KID= 0.00873\n",
      "epoch 463, batch 2, d_loss=-0.288 g_loss=-0.138 KID= 0.00873\n",
      "epoch 463, batch 3, d_loss=-0.207 g_loss=-0.011 KID= 0.00873\n",
      "epoch 463, batch 4, d_loss=-0.149 g_loss=0.009 KID= 0.00873\n",
      "epoch 463, batch 5, d_loss=-0.171 g_loss=-0.102 KID= 0.00873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 463, batch 6, d_loss=-0.188 g_loss=-0.243 KID= 0.00873\n",
      "epoch 463, batch 7, d_loss=-0.218 g_loss=-0.383 KID= 0.00873\n",
      "epoch 463, batch 8, d_loss=-0.200 g_loss=-0.506 KID= 0.00873\n",
      "epoch 463, batch 9, d_loss=-0.229 g_loss=-0.601 KID= 0.00873\n",
      "epoch 463, batch 10, d_loss=-0.219 g_loss=-0.577 KID= 0.00873\n",
      "epoch 463, batch 11, d_loss=-0.260 g_loss=-0.652 KID= 0.00873\n",
      "epoch 463, batch 12, d_loss=-0.288 g_loss=-0.631 KID= 0.00873\n",
      "epoch 463, batch 13, d_loss=-0.228 g_loss=-0.529 KID= 0.00873\n",
      "epoch 463, batch 14, d_loss=-0.177 g_loss=-0.493 KID= 0.00873\n",
      "epoch 463, batch 15, d_loss=-0.190 g_loss=-0.401 KID= 0.00873\n",
      "epoch 463, batch 16, d_loss=-0.154 g_loss=-0.425 KID= 0.00873\n",
      "epoch 463, batch 17, d_loss=-0.188 g_loss=-0.412 KID= 0.00873\n",
      "epoch 463, batch 18, d_loss=-0.268 g_loss=-0.456 KID= 0.00873\n",
      "epoch 463, batch 19, d_loss=-0.223 g_loss=-0.504 KID= 0.00873\n",
      "epoch 464, batch 0, d_loss=-0.141 g_loss=-0.429 KID= 0.00873\n",
      "epoch 464, batch 1, d_loss=-0.209 g_loss=-0.342 KID= 0.00873\n",
      "epoch 464, batch 2, d_loss=-0.240 g_loss=-0.337 KID= 0.00873\n",
      "epoch 464, batch 3, d_loss=-0.164 g_loss=-0.243 KID= 0.00873\n",
      "epoch 464, batch 4, d_loss=-0.247 g_loss=-0.121 KID= 0.00873\n",
      "epoch 464, batch 5, d_loss=-0.280 g_loss=-0.101 KID= 0.00873\n",
      "epoch 464, batch 6, d_loss=-0.276 g_loss=-0.165 KID= 0.00873\n",
      "epoch 464, batch 7, d_loss=-0.180 g_loss=-0.186 KID= 0.00873\n",
      "epoch 464, batch 8, d_loss=-0.167 g_loss=-0.252 KID= 0.00873\n",
      "epoch 464, batch 9, d_loss=-0.184 g_loss=-0.231 KID= 0.00873\n",
      "epoch 464, batch 10, d_loss=-0.216 g_loss=-0.208 KID= 0.00873\n",
      "epoch 464, batch 11, d_loss=-0.224 g_loss=-0.224 KID= 0.00873\n",
      "epoch 464, batch 12, d_loss=-0.173 g_loss=-0.254 KID= 0.00873\n",
      "epoch 464, batch 13, d_loss=-0.066 g_loss=-0.195 KID= 0.00873\n",
      "epoch 464, batch 14, d_loss=-0.192 g_loss=-0.115 KID= 0.00873\n",
      "epoch 464, batch 15, d_loss=-0.223 g_loss=-0.157 KID= 0.00873\n",
      "epoch 464, batch 16, d_loss=-0.220 g_loss=-0.196 KID= 0.00873\n",
      "epoch 464, batch 17, d_loss=-0.243 g_loss=-0.319 KID= 0.00873\n",
      "epoch 464, batch 18, d_loss=-0.277 g_loss=-0.396 KID= 0.00873\n",
      "epoch 464, batch 19, d_loss=-0.278 g_loss=-0.570 KID= 0.00873\n",
      "epoch 465, batch 0, d_loss=-0.212 g_loss=-0.649 KID= 0.00873\n",
      "epoch 465, batch 1, d_loss=-0.165 g_loss=-0.676 KID= 0.00873\n",
      "epoch 465, batch 2, d_loss=-0.231 g_loss=-0.641 KID= 0.00873\n",
      "epoch 465, batch 3, d_loss=-0.143 g_loss=-0.565 KID= 0.00873\n",
      "epoch 465, batch 4, d_loss=-0.161 g_loss=-0.548 KID= 0.00873\n",
      "epoch 465, batch 5, d_loss=-0.194 g_loss=-0.483 KID= 0.00873\n",
      "epoch 465, batch 6, d_loss=-0.188 g_loss=-0.465 KID= 0.00873\n",
      "epoch 465, batch 7, d_loss=-0.170 g_loss=-0.450 KID= 0.00873\n",
      "epoch 465, batch 8, d_loss=-0.215 g_loss=-0.429 KID= 0.00873\n",
      "epoch 465, batch 9, d_loss=-0.251 g_loss=-0.374 KID= 0.00873\n",
      "epoch 465, batch 10, d_loss=-0.187 g_loss=-0.281 KID= 0.00873\n",
      "epoch 465, batch 11, d_loss=-0.266 g_loss=-0.126 KID= 0.00873\n",
      "epoch 465, batch 12, d_loss=-0.258 g_loss=-0.023 KID= 0.00873\n",
      "epoch 465, batch 13, d_loss=-0.183 g_loss=0.162 KID= 0.00873\n",
      "epoch 465, batch 14, d_loss=-0.216 g_loss=0.307 KID= 0.00873\n",
      "epoch 465, batch 15, d_loss=-0.235 g_loss=0.241 KID= 0.00873\n",
      "epoch 465, batch 16, d_loss=-0.217 g_loss=0.108 KID= 0.00873\n",
      "epoch 465, batch 17, d_loss=-0.191 g_loss=0.041 KID= 0.00873\n",
      "epoch 465, batch 18, d_loss=-0.145 g_loss=-0.144 KID= 0.00873\n",
      "epoch 465, batch 19, d_loss=-0.186 g_loss=-0.275 KID= 0.00873\n",
      "epoch 466, batch 0, d_loss=-0.230 g_loss=-0.329 KID= 0.00873\n",
      "epoch 466, batch 1, d_loss=-0.228 g_loss=-0.456 KID= 0.00873\n",
      "epoch 466, batch 2, d_loss=-0.263 g_loss=-0.615 KID= 0.00873\n",
      "epoch 466, batch 3, d_loss=-0.103 g_loss=-0.690 KID= 0.00873\n",
      "epoch 466, batch 4, d_loss=-0.158 g_loss=-0.823 KID= 0.00873\n",
      "epoch 466, batch 5, d_loss=-0.228 g_loss=-0.884 KID= 0.00873\n",
      "epoch 466, batch 6, d_loss=-0.184 g_loss=-0.968 KID= 0.00873\n",
      "epoch 466, batch 7, d_loss=-0.189 g_loss=-0.994 KID= 0.00873\n",
      "epoch 466, batch 8, d_loss=-0.209 g_loss=-1.030 KID= 0.00873\n",
      "epoch 466, batch 9, d_loss=-0.258 g_loss=-1.021 KID= 0.00873\n",
      "epoch 466, batch 10, d_loss=-0.205 g_loss=-0.753 KID= 0.00873\n",
      "epoch 466, batch 11, d_loss=-0.280 g_loss=-0.533 KID= 0.00873\n",
      "epoch 466, batch 12, d_loss=-0.294 g_loss=-0.376 KID= 0.00873\n",
      "epoch 466, batch 13, d_loss=-0.170 g_loss=-0.202 KID= 0.00873\n",
      "epoch 466, batch 14, d_loss=-0.170 g_loss=-0.073 KID= 0.00873\n",
      "epoch 466, batch 15, d_loss=-0.247 g_loss=-0.107 KID= 0.00873\n",
      "epoch 466, batch 16, d_loss=-0.177 g_loss=-0.250 KID= 0.00873\n",
      "epoch 466, batch 17, d_loss=-0.210 g_loss=-0.433 KID= 0.00873\n",
      "epoch 466, batch 18, d_loss=-0.226 g_loss=-0.469 KID= 0.00873\n",
      "epoch 466, batch 19, d_loss=-0.249 g_loss=-0.551 KID= 0.00873\n",
      "epoch 467, batch 0, d_loss=-0.230 g_loss=-0.611 KID= 0.00873\n",
      "epoch 467, batch 1, d_loss=-0.246 g_loss=-0.599 KID= 0.00873\n",
      "epoch 467, batch 2, d_loss=-0.242 g_loss=-0.591 KID= 0.00873\n",
      "epoch 467, batch 3, d_loss=-0.155 g_loss=-0.511 KID= 0.00873\n",
      "epoch 467, batch 4, d_loss=-0.241 g_loss=-0.475 KID= 0.00873\n",
      "epoch 467, batch 5, d_loss=-0.201 g_loss=-0.545 KID= 0.00873\n",
      "epoch 467, batch 6, d_loss=-0.223 g_loss=-0.632 KID= 0.00873\n",
      "epoch 467, batch 7, d_loss=-0.243 g_loss=-0.716 KID= 0.00873\n",
      "epoch 467, batch 8, d_loss=-0.164 g_loss=-0.675 KID= 0.00873\n",
      "epoch 467, batch 9, d_loss=-0.225 g_loss=-0.699 KID= 0.00873\n",
      "epoch 467, batch 10, d_loss=-0.189 g_loss=-0.586 KID= 0.00873\n",
      "epoch 467, batch 11, d_loss=-0.246 g_loss=-0.542 KID= 0.00873\n",
      "epoch 467, batch 12, d_loss=-0.244 g_loss=-0.503 KID= 0.00873\n",
      "epoch 467, batch 13, d_loss=-0.140 g_loss=-0.262 KID= 0.00873\n",
      "epoch 467, batch 14, d_loss=-0.188 g_loss=-0.124 KID= 0.00873\n",
      "epoch 467, batch 15, d_loss=-0.200 g_loss=-0.159 KID= 0.00873\n",
      "epoch 467, batch 16, d_loss=-0.173 g_loss=-0.338 KID= 0.00873\n",
      "epoch 467, batch 17, d_loss=-0.203 g_loss=-0.472 KID= 0.00873\n",
      "epoch 467, batch 18, d_loss=-0.206 g_loss=-0.502 KID= 0.00873\n",
      "epoch 467, batch 19, d_loss=-0.234 g_loss=-0.442 KID= 0.00873\n",
      "epoch 468, batch 0, d_loss=-0.231 g_loss=-0.393 KID= 0.00873\n",
      "epoch 468, batch 1, d_loss=-0.264 g_loss=-0.428 KID= 0.00873\n",
      "epoch 468, batch 2, d_loss=-0.300 g_loss=-0.454 KID= 0.00873\n",
      "epoch 468, batch 3, d_loss=-0.107 g_loss=-0.469 KID= 0.00873\n",
      "epoch 468, batch 4, d_loss=-0.168 g_loss=-0.431 KID= 0.00873\n",
      "epoch 468, batch 5, d_loss=-0.234 g_loss=-0.507 KID= 0.00873\n",
      "epoch 468, batch 6, d_loss=-0.186 g_loss=-0.657 KID= 0.00873\n",
      "epoch 468, batch 7, d_loss=-0.188 g_loss=-0.727 KID= 0.00873\n",
      "epoch 468, batch 8, d_loss=-0.269 g_loss=-0.793 KID= 0.00873\n",
      "epoch 468, batch 9, d_loss=-0.251 g_loss=-0.892 KID= 0.00873\n",
      "epoch 468, batch 10, d_loss=-0.203 g_loss=-0.701 KID= 0.00873\n",
      "epoch 468, batch 11, d_loss=-0.235 g_loss=-0.584 KID= 0.00873\n",
      "epoch 468, batch 12, d_loss=-0.237 g_loss=-0.499 KID= 0.00873\n",
      "epoch 468, batch 13, d_loss=-0.184 g_loss=-0.279 KID= 0.00873\n",
      "epoch 468, batch 14, d_loss=-0.237 g_loss=-0.126 KID= 0.00873\n",
      "epoch 468, batch 15, d_loss=-0.186 g_loss=-0.124 KID= 0.00873\n",
      "epoch 468, batch 16, d_loss=-0.186 g_loss=-0.209 KID= 0.00873\n",
      "epoch 468, batch 17, d_loss=-0.157 g_loss=-0.223 KID= 0.00873\n",
      "epoch 468, batch 18, d_loss=-0.171 g_loss=-0.329 KID= 0.00873\n",
      "epoch 468, batch 19, d_loss=-0.224 g_loss=-0.424 KID= 0.00873\n",
      "epoch 469, batch 0, d_loss=-0.203 g_loss=-0.532 KID= 0.00873\n",
      "epoch 469, batch 1, d_loss=-0.240 g_loss=-0.649 KID= 0.00873\n",
      "epoch 469, batch 2, d_loss=-0.281 g_loss=-0.676 KID= 0.00873\n",
      "epoch 469, batch 3, d_loss=-0.152 g_loss=-0.626 KID= 0.00873\n",
      "epoch 469, batch 4, d_loss=-0.177 g_loss=-0.599 KID= 0.00873\n",
      "epoch 469, batch 5, d_loss=-0.259 g_loss=-0.574 KID= 0.00873\n",
      "epoch 469, batch 6, d_loss=-0.191 g_loss=-0.618 KID= 0.00873\n",
      "epoch 469, batch 7, d_loss=-0.225 g_loss=-0.647 KID= 0.00873\n",
      "epoch 469, batch 8, d_loss=-0.212 g_loss=-0.626 KID= 0.00873\n",
      "epoch 469, batch 9, d_loss=-0.253 g_loss=-0.615 KID= 0.00873\n",
      "epoch 469, batch 10, d_loss=-0.158 g_loss=-0.499 KID= 0.00873\n",
      "epoch 469, batch 11, d_loss=-0.279 g_loss=-0.470 KID= 0.00873\n",
      "epoch 469, batch 12, d_loss=-0.276 g_loss=-0.537 KID= 0.00873\n",
      "epoch 469, batch 13, d_loss=-0.163 g_loss=-0.507 KID= 0.00873\n",
      "epoch 469, batch 14, d_loss=-0.237 g_loss=-0.470 KID= 0.00873\n",
      "epoch 469, batch 15, d_loss=-0.208 g_loss=-0.483 KID= 0.00873\n",
      "epoch 469, batch 16, d_loss=-0.140 g_loss=-0.525 KID= 0.00873\n",
      "epoch 469, batch 17, d_loss=-0.240 g_loss=-0.429 KID= 0.00873\n",
      "epoch 469, batch 18, d_loss=-0.210 g_loss=-0.310 KID= 0.00873\n",
      "epoch 469, batch 19, d_loss=-0.225 g_loss=-0.276 KID= 0.00873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 470, batch 0, d_loss=-0.202 g_loss=-0.205 KID= 0.00843\n",
      "epoch 470, batch 1, d_loss=-0.230 g_loss=-0.147 KID= 0.00843\n",
      "epoch 470, batch 2, d_loss=-0.216 g_loss=-0.175 KID= 0.00843\n",
      "epoch 470, batch 3, d_loss=-0.175 g_loss=-0.164 KID= 0.00843\n",
      "epoch 470, batch 4, d_loss=-0.244 g_loss=-0.128 KID= 0.00843\n",
      "epoch 470, batch 5, d_loss=-0.230 g_loss=-0.239 KID= 0.00843\n",
      "epoch 470, batch 6, d_loss=-0.196 g_loss=-0.348 KID= 0.00843\n",
      "epoch 470, batch 7, d_loss=-0.194 g_loss=-0.495 KID= 0.00843\n",
      "epoch 470, batch 8, d_loss=-0.226 g_loss=-0.586 KID= 0.00843\n",
      "epoch 470, batch 9, d_loss=-0.239 g_loss=-0.658 KID= 0.00843\n",
      "epoch 470, batch 10, d_loss=-0.165 g_loss=-0.661 KID= 0.00843\n",
      "epoch 470, batch 11, d_loss=-0.247 g_loss=-0.609 KID= 0.00843\n",
      "epoch 470, batch 12, d_loss=-0.274 g_loss=-0.570 KID= 0.00843\n",
      "epoch 470, batch 13, d_loss=-0.116 g_loss=-0.500 KID= 0.00843\n",
      "epoch 470, batch 14, d_loss=-0.185 g_loss=-0.476 KID= 0.00843\n",
      "epoch 470, batch 15, d_loss=-0.232 g_loss=-0.492 KID= 0.00843\n",
      "epoch 470, batch 16, d_loss=-0.192 g_loss=-0.571 KID= 0.00843\n",
      "epoch 470, batch 17, d_loss=-0.254 g_loss=-0.579 KID= 0.00843\n",
      "epoch 470, batch 18, d_loss=-0.163 g_loss=-0.565 KID= 0.00843\n",
      "epoch 470, batch 19, d_loss=-0.245 g_loss=-0.633 KID= 0.00843\n",
      "epoch 471, batch 0, d_loss=-0.178 g_loss=-0.576 KID= 0.00843\n",
      "epoch 471, batch 1, d_loss=-0.244 g_loss=-0.476 KID= 0.00843\n",
      "epoch 471, batch 2, d_loss=-0.296 g_loss=-0.376 KID= 0.00843\n",
      "epoch 471, batch 3, d_loss=-0.188 g_loss=-0.185 KID= 0.00843\n",
      "epoch 471, batch 4, d_loss=-0.211 g_loss=-0.083 KID= 0.00843\n",
      "epoch 471, batch 5, d_loss=-0.222 g_loss=-0.072 KID= 0.00843\n",
      "epoch 471, batch 6, d_loss=-0.127 g_loss=-0.125 KID= 0.00843\n",
      "epoch 471, batch 7, d_loss=-0.216 g_loss=-0.237 KID= 0.00843\n",
      "epoch 471, batch 8, d_loss=-0.209 g_loss=-0.310 KID= 0.00843\n",
      "epoch 471, batch 9, d_loss=-0.231 g_loss=-0.357 KID= 0.00843\n",
      "epoch 471, batch 10, d_loss=-0.194 g_loss=-0.326 KID= 0.00843\n",
      "epoch 471, batch 11, d_loss=-0.263 g_loss=-0.282 KID= 0.00843\n",
      "epoch 471, batch 12, d_loss=-0.205 g_loss=-0.303 KID= 0.00843\n",
      "epoch 471, batch 13, d_loss=-0.222 g_loss=-0.311 KID= 0.00843\n",
      "epoch 471, batch 14, d_loss=-0.223 g_loss=-0.377 KID= 0.00843\n",
      "epoch 471, batch 15, d_loss=-0.166 g_loss=-0.572 KID= 0.00843\n",
      "epoch 471, batch 16, d_loss=-0.135 g_loss=-0.707 KID= 0.00843\n",
      "epoch 471, batch 17, d_loss=-0.216 g_loss=-0.748 KID= 0.00843\n",
      "epoch 471, batch 18, d_loss=-0.245 g_loss=-0.804 KID= 0.00843\n",
      "epoch 471, batch 19, d_loss=-0.227 g_loss=-0.827 KID= 0.00843\n",
      "epoch 472, batch 0, d_loss=-0.212 g_loss=-0.784 KID= 0.00843\n",
      "epoch 472, batch 1, d_loss=-0.269 g_loss=-0.717 KID= 0.00843\n",
      "epoch 472, batch 2, d_loss=-0.300 g_loss=-0.710 KID= 0.00843\n",
      "epoch 472, batch 3, d_loss=-0.198 g_loss=-0.514 KID= 0.00843\n",
      "epoch 472, batch 4, d_loss=-0.204 g_loss=-0.444 KID= 0.00843\n",
      "epoch 472, batch 5, d_loss=-0.162 g_loss=-0.532 KID= 0.00843\n",
      "epoch 472, batch 6, d_loss=-0.178 g_loss=-0.569 KID= 0.00843\n",
      "epoch 472, batch 7, d_loss=-0.240 g_loss=-0.514 KID= 0.00843\n",
      "epoch 472, batch 8, d_loss=-0.197 g_loss=-0.457 KID= 0.00843\n",
      "epoch 472, batch 9, d_loss=-0.251 g_loss=-0.539 KID= 0.00843\n",
      "epoch 472, batch 10, d_loss=-0.185 g_loss=-0.535 KID= 0.00843\n",
      "epoch 472, batch 11, d_loss=-0.272 g_loss=-0.478 KID= 0.00843\n",
      "epoch 472, batch 12, d_loss=-0.283 g_loss=-0.435 KID= 0.00843\n",
      "epoch 472, batch 13, d_loss=-0.166 g_loss=-0.229 KID= 0.00843\n",
      "epoch 472, batch 14, d_loss=-0.178 g_loss=-0.113 KID= 0.00843\n",
      "epoch 472, batch 15, d_loss=-0.226 g_loss=-0.214 KID= 0.00843\n",
      "epoch 472, batch 16, d_loss=-0.129 g_loss=-0.289 KID= 0.00843\n",
      "epoch 472, batch 17, d_loss=-0.171 g_loss=-0.372 KID= 0.00843\n",
      "epoch 472, batch 18, d_loss=-0.162 g_loss=-0.403 KID= 0.00843\n",
      "epoch 472, batch 19, d_loss=-0.200 g_loss=-0.385 KID= 0.00843\n",
      "epoch 473, batch 0, d_loss=-0.207 g_loss=-0.262 KID= 0.00843\n",
      "epoch 473, batch 1, d_loss=-0.270 g_loss=-0.119 KID= 0.00843\n",
      "epoch 473, batch 2, d_loss=-0.264 g_loss=-0.166 KID= 0.00843\n",
      "epoch 473, batch 3, d_loss=-0.230 g_loss=-0.127 KID= 0.00843\n",
      "epoch 473, batch 4, d_loss=-0.234 g_loss=-0.101 KID= 0.00843\n",
      "epoch 473, batch 5, d_loss=-0.262 g_loss=-0.278 KID= 0.00843\n",
      "epoch 473, batch 6, d_loss=-0.093 g_loss=-0.432 KID= 0.00843\n",
      "epoch 473, batch 7, d_loss=-0.193 g_loss=-0.575 KID= 0.00843\n",
      "epoch 473, batch 8, d_loss=-0.220 g_loss=-0.604 KID= 0.00843\n",
      "epoch 473, batch 9, d_loss=-0.257 g_loss=-0.674 KID= 0.00843\n",
      "epoch 473, batch 10, d_loss=-0.154 g_loss=-0.554 KID= 0.00843\n",
      "epoch 473, batch 11, d_loss=-0.278 g_loss=-0.459 KID= 0.00843\n",
      "epoch 473, batch 12, d_loss=-0.243 g_loss=-0.453 KID= 0.00843\n",
      "epoch 473, batch 13, d_loss=-0.203 g_loss=-0.374 KID= 0.00843\n",
      "epoch 473, batch 14, d_loss=-0.195 g_loss=-0.351 KID= 0.00843\n",
      "epoch 473, batch 15, d_loss=-0.205 g_loss=-0.513 KID= 0.00843\n",
      "epoch 473, batch 16, d_loss=-0.167 g_loss=-0.623 KID= 0.00843\n",
      "epoch 473, batch 17, d_loss=-0.232 g_loss=-0.733 KID= 0.00843\n",
      "epoch 473, batch 18, d_loss=-0.225 g_loss=-0.845 KID= 0.00843\n",
      "epoch 473, batch 19, d_loss=-0.183 g_loss=-0.876 KID= 0.00843\n",
      "epoch 474, batch 0, d_loss=-0.228 g_loss=-0.774 KID= 0.00843\n",
      "epoch 474, batch 1, d_loss=-0.299 g_loss=-0.713 KID= 0.00843\n",
      "epoch 474, batch 2, d_loss=-0.254 g_loss=-0.701 KID= 0.00843\n",
      "epoch 474, batch 3, d_loss=-0.190 g_loss=-0.482 KID= 0.00843\n",
      "epoch 474, batch 4, d_loss=-0.189 g_loss=-0.250 KID= 0.00843\n",
      "epoch 474, batch 5, d_loss=-0.195 g_loss=-0.196 KID= 0.00843\n",
      "epoch 474, batch 6, d_loss=-0.136 g_loss=-0.132 KID= 0.00843\n",
      "epoch 474, batch 7, d_loss=-0.276 g_loss=-0.127 KID= 0.00843\n",
      "epoch 474, batch 8, d_loss=-0.212 g_loss=-0.081 KID= 0.00843\n",
      "epoch 474, batch 9, d_loss=-0.208 g_loss=-0.014 KID= 0.00843\n",
      "epoch 474, batch 10, d_loss=-0.208 g_loss=-0.116 KID= 0.00843\n",
      "epoch 474, batch 11, d_loss=-0.269 g_loss=-0.133 KID= 0.00843\n",
      "epoch 474, batch 12, d_loss=-0.304 g_loss=-0.223 KID= 0.00843\n",
      "epoch 474, batch 13, d_loss=-0.181 g_loss=-0.104 KID= 0.00843\n",
      "epoch 474, batch 14, d_loss=-0.161 g_loss=-0.046 KID= 0.00843\n",
      "epoch 474, batch 15, d_loss=-0.208 g_loss=-0.174 KID= 0.00843\n",
      "epoch 474, batch 16, d_loss=-0.114 g_loss=-0.324 KID= 0.00843\n",
      "epoch 474, batch 17, d_loss=-0.219 g_loss=-0.509 KID= 0.00843\n",
      "epoch 474, batch 18, d_loss=-0.258 g_loss=-0.649 KID= 0.00843\n",
      "epoch 474, batch 19, d_loss=-0.290 g_loss=-0.818 KID= 0.00843\n",
      "epoch 475, batch 0, d_loss=-0.180 g_loss=-0.897 KID= 0.00843\n",
      "epoch 475, batch 1, d_loss=-0.315 g_loss=-0.944 KID= 0.00843\n",
      "epoch 475, batch 2, d_loss=-0.259 g_loss=-0.939 KID= 0.00843\n",
      "epoch 475, batch 3, d_loss=-0.147 g_loss=-0.738 KID= 0.00843\n",
      "epoch 475, batch 4, d_loss=-0.154 g_loss=-0.494 KID= 0.00843\n",
      "epoch 475, batch 5, d_loss=-0.231 g_loss=-0.440 KID= 0.00843\n",
      "epoch 475, batch 6, d_loss=-0.088 g_loss=-0.445 KID= 0.00843\n",
      "epoch 475, batch 7, d_loss=-0.234 g_loss=-0.517 KID= 0.00843\n",
      "epoch 475, batch 8, d_loss=-0.237 g_loss=-0.593 KID= 0.00843\n",
      "epoch 475, batch 9, d_loss=-0.259 g_loss=-0.701 KID= 0.00843\n",
      "epoch 475, batch 10, d_loss=-0.242 g_loss=-0.739 KID= 0.00843\n",
      "epoch 475, batch 11, d_loss=-0.283 g_loss=-0.714 KID= 0.00843\n",
      "epoch 475, batch 12, d_loss=-0.245 g_loss=-0.760 KID= 0.00843\n",
      "epoch 475, batch 13, d_loss=-0.220 g_loss=-0.640 KID= 0.00843\n",
      "epoch 475, batch 14, d_loss=-0.183 g_loss=-0.578 KID= 0.00843\n",
      "epoch 475, batch 15, d_loss=-0.216 g_loss=-0.509 KID= 0.00843\n",
      "epoch 475, batch 16, d_loss=-0.129 g_loss=-0.380 KID= 0.00843\n",
      "epoch 475, batch 17, d_loss=-0.217 g_loss=-0.315 KID= 0.00843\n",
      "epoch 475, batch 18, d_loss=-0.230 g_loss=-0.215 KID= 0.00843\n",
      "epoch 475, batch 19, d_loss=-0.238 g_loss=0.013 KID= 0.00843\n",
      "epoch 476, batch 0, d_loss=-0.214 g_loss=0.175 KID= 0.00843\n",
      "epoch 476, batch 1, d_loss=-0.306 g_loss=0.410 KID= 0.00843\n",
      "epoch 476, batch 2, d_loss=-0.270 g_loss=0.450 KID= 0.00843\n",
      "epoch 476, batch 3, d_loss=-0.219 g_loss=0.592 KID= 0.00843\n",
      "epoch 476, batch 4, d_loss=-0.171 g_loss=0.431 KID= 0.00843\n",
      "epoch 476, batch 5, d_loss=-0.224 g_loss=0.165 KID= 0.00843\n",
      "epoch 476, batch 6, d_loss=-0.138 g_loss=-0.093 KID= 0.00843\n",
      "epoch 476, batch 7, d_loss=-0.199 g_loss=-0.409 KID= 0.00843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 476, batch 8, d_loss=-0.261 g_loss=-0.528 KID= 0.00843\n",
      "epoch 476, batch 9, d_loss=-0.227 g_loss=-0.702 KID= 0.00843\n",
      "epoch 476, batch 10, d_loss=-0.238 g_loss=-0.828 KID= 0.00843\n",
      "epoch 476, batch 11, d_loss=-0.249 g_loss=-0.919 KID= 0.00843\n",
      "epoch 476, batch 12, d_loss=-0.278 g_loss=-0.983 KID= 0.00843\n",
      "epoch 476, batch 13, d_loss=-0.174 g_loss=-0.864 KID= 0.00843\n",
      "epoch 476, batch 14, d_loss=-0.238 g_loss=-0.794 KID= 0.00843\n",
      "epoch 476, batch 15, d_loss=-0.181 g_loss=-0.741 KID= 0.00843\n",
      "epoch 476, batch 16, d_loss=-0.194 g_loss=-0.663 KID= 0.00843\n",
      "epoch 476, batch 17, d_loss=-0.263 g_loss=-0.651 KID= 0.00843\n",
      "epoch 476, batch 18, d_loss=-0.264 g_loss=-0.632 KID= 0.00843\n",
      "epoch 476, batch 19, d_loss=-0.255 g_loss=-0.622 KID= 0.00843\n",
      "epoch 477, batch 0, d_loss=-0.174 g_loss=-0.512 KID= 0.00843\n",
      "epoch 477, batch 1, d_loss=-0.304 g_loss=-0.542 KID= 0.00843\n",
      "epoch 477, batch 2, d_loss=-0.276 g_loss=-0.546 KID= 0.00843\n",
      "epoch 477, batch 3, d_loss=-0.204 g_loss=-0.444 KID= 0.00843\n",
      "epoch 477, batch 4, d_loss=-0.173 g_loss=-0.378 KID= 0.00843\n",
      "epoch 477, batch 5, d_loss=-0.243 g_loss=-0.328 KID= 0.00843\n",
      "epoch 477, batch 6, d_loss=-0.134 g_loss=-0.222 KID= 0.00843\n",
      "epoch 477, batch 7, d_loss=-0.200 g_loss=-0.218 KID= 0.00843\n",
      "epoch 477, batch 8, d_loss=-0.261 g_loss=-0.273 KID= 0.00843\n",
      "epoch 477, batch 9, d_loss=-0.231 g_loss=-0.265 KID= 0.00843\n",
      "epoch 477, batch 10, d_loss=-0.236 g_loss=-0.267 KID= 0.00843\n",
      "epoch 477, batch 11, d_loss=-0.246 g_loss=-0.206 KID= 0.00843\n",
      "epoch 477, batch 12, d_loss=-0.261 g_loss=-0.135 KID= 0.00843\n",
      "epoch 477, batch 13, d_loss=-0.170 g_loss=-0.100 KID= 0.00843\n",
      "epoch 477, batch 14, d_loss=-0.215 g_loss=-0.071 KID= 0.00843\n",
      "epoch 477, batch 15, d_loss=-0.235 g_loss=-0.150 KID= 0.00843\n",
      "epoch 477, batch 16, d_loss=-0.137 g_loss=-0.222 KID= 0.00843\n",
      "epoch 477, batch 17, d_loss=-0.276 g_loss=-0.279 KID= 0.00843\n",
      "epoch 477, batch 18, d_loss=-0.252 g_loss=-0.361 KID= 0.00843\n",
      "epoch 477, batch 19, d_loss=-0.253 g_loss=-0.408 KID= 0.00843\n",
      "epoch 478, batch 0, d_loss=-0.238 g_loss=-0.473 KID= 0.00843\n",
      "epoch 478, batch 1, d_loss=-0.277 g_loss=-0.494 KID= 0.00843\n",
      "epoch 478, batch 2, d_loss=-0.309 g_loss=-0.499 KID= 0.00843\n",
      "epoch 478, batch 3, d_loss=-0.171 g_loss=-0.420 KID= 0.00843\n",
      "epoch 478, batch 4, d_loss=-0.185 g_loss=-0.318 KID= 0.00843\n",
      "epoch 478, batch 5, d_loss=-0.213 g_loss=-0.290 KID= 0.00843\n",
      "epoch 478, batch 6, d_loss=-0.139 g_loss=-0.256 KID= 0.00843\n",
      "epoch 478, batch 7, d_loss=-0.255 g_loss=-0.260 KID= 0.00843\n",
      "epoch 478, batch 8, d_loss=-0.270 g_loss=-0.374 KID= 0.00843\n",
      "epoch 478, batch 9, d_loss=-0.221 g_loss=-0.430 KID= 0.00843\n",
      "epoch 478, batch 10, d_loss=-0.240 g_loss=-0.463 KID= 0.00843\n",
      "epoch 478, batch 11, d_loss=-0.255 g_loss=-0.489 KID= 0.00843\n",
      "epoch 478, batch 12, d_loss=-0.223 g_loss=-0.500 KID= 0.00843\n",
      "epoch 478, batch 13, d_loss=-0.199 g_loss=-0.399 KID= 0.00843\n",
      "epoch 478, batch 14, d_loss=-0.249 g_loss=-0.396 KID= 0.00843\n",
      "epoch 478, batch 15, d_loss=-0.212 g_loss=-0.452 KID= 0.00843\n",
      "epoch 478, batch 16, d_loss=-0.182 g_loss=-0.462 KID= 0.00843\n",
      "epoch 478, batch 17, d_loss=-0.204 g_loss=-0.532 KID= 0.00843\n",
      "epoch 478, batch 18, d_loss=-0.259 g_loss=-0.568 KID= 0.00843\n",
      "epoch 478, batch 19, d_loss=-0.213 g_loss=-0.423 KID= 0.00843\n",
      "epoch 479, batch 0, d_loss=-0.217 g_loss=-0.239 KID= 0.00843\n",
      "epoch 479, batch 1, d_loss=-0.250 g_loss=-0.094 KID= 0.00843\n",
      "epoch 479, batch 2, d_loss=-0.296 g_loss=0.049 KID= 0.00843\n",
      "epoch 479, batch 3, d_loss=-0.204 g_loss=0.284 KID= 0.00843\n",
      "epoch 479, batch 4, d_loss=-0.174 g_loss=0.405 KID= 0.00843\n",
      "epoch 479, batch 5, d_loss=-0.221 g_loss=0.235 KID= 0.00843\n",
      "epoch 479, batch 6, d_loss=-0.121 g_loss=-0.017 KID= 0.00843\n",
      "epoch 479, batch 7, d_loss=-0.267 g_loss=-0.180 KID= 0.00843\n",
      "epoch 479, batch 8, d_loss=-0.237 g_loss=-0.327 KID= 0.00843\n",
      "epoch 479, batch 9, d_loss=-0.237 g_loss=-0.474 KID= 0.00843\n",
      "epoch 479, batch 10, d_loss=-0.196 g_loss=-0.561 KID= 0.00843\n",
      "epoch 479, batch 11, d_loss=-0.307 g_loss=-0.685 KID= 0.00843\n",
      "epoch 479, batch 12, d_loss=-0.264 g_loss=-0.815 KID= 0.00843\n",
      "epoch 479, batch 13, d_loss=-0.137 g_loss=-0.720 KID= 0.00843\n",
      "epoch 479, batch 14, d_loss=-0.153 g_loss=-0.670 KID= 0.00843\n",
      "epoch 479, batch 15, d_loss=-0.206 g_loss=-0.645 KID= 0.00843\n",
      "epoch 479, batch 16, d_loss=-0.193 g_loss=-0.594 KID= 0.00843\n",
      "epoch 479, batch 17, d_loss=-0.246 g_loss=-0.528 KID= 0.00843\n",
      "epoch 479, batch 18, d_loss=-0.277 g_loss=-0.559 KID= 0.00843\n",
      "epoch 479, batch 19, d_loss=-0.212 g_loss=-0.606 KID= 0.00843\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 480, batch 0, d_loss=-0.228 g_loss=-0.562 KID= 0.00937\n",
      "epoch 480, batch 1, d_loss=-0.247 g_loss=-0.573 KID= 0.00937\n",
      "epoch 480, batch 2, d_loss=-0.260 g_loss=-0.519 KID= 0.00937\n",
      "epoch 480, batch 3, d_loss=-0.206 g_loss=-0.398 KID= 0.00937\n",
      "epoch 480, batch 4, d_loss=-0.247 g_loss=-0.262 KID= 0.00937\n",
      "epoch 480, batch 5, d_loss=-0.189 g_loss=-0.295 KID= 0.00937\n",
      "epoch 480, batch 6, d_loss=-0.104 g_loss=-0.342 KID= 0.00937\n",
      "epoch 480, batch 7, d_loss=-0.216 g_loss=-0.294 KID= 0.00937\n",
      "epoch 480, batch 8, d_loss=-0.233 g_loss=-0.225 KID= 0.00937\n",
      "epoch 480, batch 9, d_loss=-0.227 g_loss=-0.188 KID= 0.00937\n",
      "epoch 480, batch 10, d_loss=-0.302 g_loss=-0.205 KID= 0.00937\n",
      "epoch 480, batch 11, d_loss=-0.285 g_loss=-0.235 KID= 0.00937\n",
      "epoch 480, batch 12, d_loss=-0.291 g_loss=-0.204 KID= 0.00937\n",
      "epoch 480, batch 13, d_loss=-0.229 g_loss=-0.167 KID= 0.00937\n",
      "epoch 480, batch 14, d_loss=-0.242 g_loss=-0.170 KID= 0.00937\n",
      "epoch 480, batch 15, d_loss=-0.220 g_loss=-0.252 KID= 0.00937\n",
      "epoch 480, batch 16, d_loss=-0.110 g_loss=-0.286 KID= 0.00937\n",
      "epoch 480, batch 17, d_loss=-0.250 g_loss=-0.246 KID= 0.00937\n",
      "epoch 480, batch 18, d_loss=-0.180 g_loss=-0.315 KID= 0.00937\n",
      "epoch 480, batch 19, d_loss=-0.206 g_loss=-0.335 KID= 0.00937\n",
      "epoch 481, batch 0, d_loss=-0.274 g_loss=-0.376 KID= 0.00937\n",
      "epoch 481, batch 1, d_loss=-0.277 g_loss=-0.471 KID= 0.00937\n",
      "epoch 481, batch 2, d_loss=-0.249 g_loss=-0.523 KID= 0.00937\n",
      "epoch 481, batch 3, d_loss=-0.211 g_loss=-0.445 KID= 0.00937\n",
      "epoch 481, batch 4, d_loss=-0.254 g_loss=-0.389 KID= 0.00937\n",
      "epoch 481, batch 5, d_loss=-0.214 g_loss=-0.493 KID= 0.00937\n",
      "epoch 481, batch 6, d_loss=-0.145 g_loss=-0.477 KID= 0.00937\n",
      "epoch 481, batch 7, d_loss=-0.254 g_loss=-0.463 KID= 0.00937\n",
      "epoch 481, batch 8, d_loss=-0.249 g_loss=-0.507 KID= 0.00937\n",
      "epoch 481, batch 9, d_loss=-0.161 g_loss=-0.496 KID= 0.00937\n",
      "epoch 481, batch 10, d_loss=-0.264 g_loss=-0.405 KID= 0.00937\n",
      "epoch 481, batch 11, d_loss=-0.269 g_loss=-0.351 KID= 0.00937\n",
      "epoch 481, batch 12, d_loss=-0.251 g_loss=-0.352 KID= 0.00937\n",
      "epoch 481, batch 13, d_loss=-0.188 g_loss=-0.319 KID= 0.00937\n",
      "epoch 481, batch 14, d_loss=-0.246 g_loss=-0.363 KID= 0.00937\n",
      "epoch 481, batch 15, d_loss=-0.217 g_loss=-0.520 KID= 0.00937\n",
      "epoch 481, batch 16, d_loss=-0.153 g_loss=-0.631 KID= 0.00937\n",
      "epoch 481, batch 17, d_loss=-0.235 g_loss=-0.729 KID= 0.00937\n",
      "epoch 481, batch 18, d_loss=-0.236 g_loss=-0.793 KID= 0.00937\n",
      "epoch 481, batch 19, d_loss=-0.276 g_loss=-0.842 KID= 0.00937\n",
      "epoch 482, batch 0, d_loss=-0.254 g_loss=-0.793 KID= 0.00937\n",
      "epoch 482, batch 1, d_loss=-0.282 g_loss=-0.772 KID= 0.00937\n",
      "epoch 482, batch 2, d_loss=-0.270 g_loss=-0.780 KID= 0.00937\n",
      "epoch 482, batch 3, d_loss=-0.206 g_loss=-0.625 KID= 0.00937\n",
      "epoch 482, batch 4, d_loss=-0.208 g_loss=-0.503 KID= 0.00937\n",
      "epoch 482, batch 5, d_loss=-0.247 g_loss=-0.537 KID= 0.00937\n",
      "epoch 482, batch 6, d_loss=-0.132 g_loss=-0.583 KID= 0.00937\n",
      "epoch 482, batch 7, d_loss=-0.242 g_loss=-0.488 KID= 0.00937\n",
      "epoch 482, batch 8, d_loss=-0.227 g_loss=-0.400 KID= 0.00937\n",
      "epoch 482, batch 9, d_loss=-0.202 g_loss=-0.335 KID= 0.00937\n",
      "epoch 482, batch 10, d_loss=-0.268 g_loss=-0.305 KID= 0.00937\n",
      "epoch 482, batch 11, d_loss=-0.283 g_loss=-0.298 KID= 0.00937\n",
      "epoch 482, batch 12, d_loss=-0.256 g_loss=-0.339 KID= 0.00937\n",
      "epoch 482, batch 13, d_loss=-0.206 g_loss=-0.289 KID= 0.00937\n",
      "epoch 482, batch 14, d_loss=-0.238 g_loss=-0.249 KID= 0.00937\n",
      "epoch 482, batch 15, d_loss=-0.240 g_loss=-0.363 KID= 0.00937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 482, batch 16, d_loss=-0.148 g_loss=-0.424 KID= 0.00937\n",
      "epoch 482, batch 17, d_loss=-0.281 g_loss=-0.457 KID= 0.00937\n",
      "epoch 482, batch 18, d_loss=-0.249 g_loss=-0.550 KID= 0.00937\n",
      "epoch 482, batch 19, d_loss=-0.202 g_loss=-0.573 KID= 0.00937\n",
      "epoch 483, batch 0, d_loss=-0.270 g_loss=-0.619 KID= 0.00937\n",
      "epoch 483, batch 1, d_loss=-0.295 g_loss=-0.553 KID= 0.00937\n",
      "epoch 483, batch 2, d_loss=-0.258 g_loss=-0.543 KID= 0.00937\n",
      "epoch 483, batch 3, d_loss=-0.191 g_loss=-0.430 KID= 0.00937\n",
      "epoch 483, batch 4, d_loss=-0.265 g_loss=-0.449 KID= 0.00937\n",
      "epoch 483, batch 5, d_loss=-0.219 g_loss=-0.545 KID= 0.00937\n",
      "epoch 483, batch 6, d_loss=-0.217 g_loss=-0.595 KID= 0.00937\n",
      "epoch 483, batch 7, d_loss=-0.209 g_loss=-0.583 KID= 0.00937\n",
      "epoch 483, batch 8, d_loss=-0.211 g_loss=-0.569 KID= 0.00937\n",
      "epoch 483, batch 9, d_loss=-0.239 g_loss=-0.563 KID= 0.00937\n",
      "epoch 483, batch 10, d_loss=-0.209 g_loss=-0.518 KID= 0.00937\n",
      "epoch 483, batch 11, d_loss=-0.254 g_loss=-0.447 KID= 0.00937\n",
      "epoch 483, batch 12, d_loss=-0.294 g_loss=-0.400 KID= 0.00937\n",
      "epoch 483, batch 13, d_loss=-0.201 g_loss=-0.273 KID= 0.00937\n",
      "epoch 483, batch 14, d_loss=-0.273 g_loss=-0.172 KID= 0.00937\n",
      "epoch 483, batch 15, d_loss=-0.219 g_loss=-0.278 KID= 0.00937\n",
      "epoch 483, batch 16, d_loss=-0.181 g_loss=-0.466 KID= 0.00937\n",
      "epoch 483, batch 17, d_loss=-0.256 g_loss=-0.596 KID= 0.00937\n",
      "epoch 483, batch 18, d_loss=-0.242 g_loss=-0.700 KID= 0.00937\n",
      "epoch 483, batch 19, d_loss=-0.260 g_loss=-0.661 KID= 0.00937\n",
      "epoch 484, batch 0, d_loss=-0.242 g_loss=-0.447 KID= 0.00937\n",
      "epoch 484, batch 1, d_loss=-0.255 g_loss=-0.248 KID= 0.00937\n",
      "epoch 484, batch 2, d_loss=-0.243 g_loss=-0.121 KID= 0.00937\n",
      "epoch 484, batch 3, d_loss=-0.212 g_loss=-0.027 KID= 0.00937\n",
      "epoch 484, batch 4, d_loss=-0.241 g_loss=0.041 KID= 0.00937\n",
      "epoch 484, batch 5, d_loss=-0.194 g_loss=-0.137 KID= 0.00937\n",
      "epoch 484, batch 6, d_loss=-0.193 g_loss=-0.311 KID= 0.00937\n",
      "epoch 484, batch 7, d_loss=-0.275 g_loss=-0.340 KID= 0.00937\n",
      "epoch 484, batch 8, d_loss=-0.251 g_loss=-0.413 KID= 0.00937\n",
      "epoch 484, batch 9, d_loss=-0.216 g_loss=-0.533 KID= 0.00937\n",
      "epoch 484, batch 10, d_loss=-0.239 g_loss=-0.548 KID= 0.00937\n",
      "epoch 484, batch 11, d_loss=-0.346 g_loss=-0.670 KID= 0.00937\n",
      "epoch 484, batch 12, d_loss=-0.229 g_loss=-0.652 KID= 0.00937\n",
      "epoch 484, batch 13, d_loss=-0.202 g_loss=-0.599 KID= 0.00937\n",
      "epoch 484, batch 14, d_loss=-0.219 g_loss=-0.528 KID= 0.00937\n",
      "epoch 484, batch 15, d_loss=-0.234 g_loss=-0.606 KID= 0.00937\n",
      "epoch 484, batch 16, d_loss=-0.165 g_loss=-0.625 KID= 0.00937\n",
      "epoch 484, batch 17, d_loss=-0.230 g_loss=-0.666 KID= 0.00937\n",
      "epoch 484, batch 18, d_loss=-0.258 g_loss=-0.635 KID= 0.00937\n",
      "epoch 484, batch 19, d_loss=-0.251 g_loss=-0.619 KID= 0.00937\n",
      "epoch 485, batch 0, d_loss=-0.268 g_loss=-0.535 KID= 0.00937\n",
      "epoch 485, batch 1, d_loss=-0.313 g_loss=-0.461 KID= 0.00937\n",
      "epoch 485, batch 2, d_loss=-0.252 g_loss=-0.453 KID= 0.00937\n",
      "epoch 485, batch 3, d_loss=-0.202 g_loss=-0.364 KID= 0.00937\n",
      "epoch 485, batch 4, d_loss=-0.210 g_loss=-0.263 KID= 0.00937\n",
      "epoch 485, batch 5, d_loss=-0.196 g_loss=-0.244 KID= 0.00937\n",
      "epoch 485, batch 6, d_loss=-0.185 g_loss=-0.305 KID= 0.00937\n",
      "epoch 485, batch 7, d_loss=-0.244 g_loss=-0.301 KID= 0.00937\n",
      "epoch 485, batch 8, d_loss=-0.226 g_loss=-0.378 KID= 0.00937\n",
      "epoch 485, batch 9, d_loss=-0.209 g_loss=-0.427 KID= 0.00937\n",
      "epoch 485, batch 10, d_loss=-0.243 g_loss=-0.438 KID= 0.00937\n",
      "epoch 485, batch 11, d_loss=-0.235 g_loss=-0.460 KID= 0.00937\n",
      "epoch 485, batch 12, d_loss=-0.242 g_loss=-0.477 KID= 0.00937\n",
      "epoch 485, batch 13, d_loss=-0.260 g_loss=-0.392 KID= 0.00937\n",
      "epoch 485, batch 14, d_loss=-0.204 g_loss=-0.295 KID= 0.00937\n",
      "epoch 485, batch 15, d_loss=-0.283 g_loss=-0.410 KID= 0.00937\n",
      "epoch 485, batch 16, d_loss=-0.128 g_loss=-0.511 KID= 0.00937\n",
      "epoch 485, batch 17, d_loss=-0.221 g_loss=-0.548 KID= 0.00937\n",
      "epoch 485, batch 18, d_loss=-0.214 g_loss=-0.547 KID= 0.00937\n",
      "epoch 485, batch 19, d_loss=-0.185 g_loss=-0.494 KID= 0.00937\n",
      "epoch 486, batch 0, d_loss=-0.263 g_loss=-0.432 KID= 0.00937\n",
      "epoch 486, batch 1, d_loss=-0.295 g_loss=-0.420 KID= 0.00937\n",
      "epoch 486, batch 2, d_loss=-0.269 g_loss=-0.389 KID= 0.00937\n",
      "epoch 486, batch 3, d_loss=-0.177 g_loss=-0.356 KID= 0.00937\n",
      "epoch 486, batch 4, d_loss=-0.265 g_loss=-0.296 KID= 0.00937\n",
      "epoch 486, batch 5, d_loss=-0.184 g_loss=-0.376 KID= 0.00937\n",
      "epoch 486, batch 6, d_loss=-0.224 g_loss=-0.355 KID= 0.00937\n",
      "epoch 486, batch 7, d_loss=-0.247 g_loss=-0.411 KID= 0.00937\n",
      "epoch 486, batch 8, d_loss=-0.228 g_loss=-0.408 KID= 0.00937\n",
      "epoch 486, batch 9, d_loss=-0.209 g_loss=-0.388 KID= 0.00937\n",
      "epoch 486, batch 10, d_loss=-0.255 g_loss=-0.308 KID= 0.00937\n",
      "epoch 486, batch 11, d_loss=-0.308 g_loss=-0.285 KID= 0.00937\n",
      "epoch 486, batch 12, d_loss=-0.242 g_loss=-0.252 KID= 0.00937\n",
      "epoch 486, batch 13, d_loss=-0.207 g_loss=-0.236 KID= 0.00937\n",
      "epoch 486, batch 14, d_loss=-0.213 g_loss=-0.225 KID= 0.00937\n",
      "epoch 486, batch 15, d_loss=-0.200 g_loss=-0.380 KID= 0.00937\n",
      "epoch 486, batch 16, d_loss=-0.150 g_loss=-0.552 KID= 0.00937\n",
      "epoch 486, batch 17, d_loss=-0.247 g_loss=-0.703 KID= 0.00937\n",
      "epoch 486, batch 18, d_loss=-0.276 g_loss=-0.751 KID= 0.00937\n",
      "epoch 486, batch 19, d_loss=-0.217 g_loss=-0.768 KID= 0.00937\n",
      "epoch 487, batch 0, d_loss=-0.286 g_loss=-0.723 KID= 0.00937\n",
      "epoch 487, batch 1, d_loss=-0.286 g_loss=-0.661 KID= 0.00937\n",
      "epoch 487, batch 2, d_loss=-0.271 g_loss=-0.646 KID= 0.00937\n",
      "epoch 487, batch 3, d_loss=-0.207 g_loss=-0.578 KID= 0.00937\n",
      "epoch 487, batch 4, d_loss=-0.214 g_loss=-0.432 KID= 0.00937\n",
      "epoch 487, batch 5, d_loss=-0.207 g_loss=-0.377 KID= 0.00937\n",
      "epoch 487, batch 6, d_loss=-0.214 g_loss=-0.365 KID= 0.00937\n",
      "epoch 487, batch 7, d_loss=-0.240 g_loss=-0.320 KID= 0.00937\n",
      "epoch 487, batch 8, d_loss=-0.221 g_loss=-0.293 KID= 0.00937\n",
      "epoch 487, batch 9, d_loss=-0.241 g_loss=-0.220 KID= 0.00937\n",
      "epoch 487, batch 10, d_loss=-0.291 g_loss=-0.091 KID= 0.00937\n",
      "epoch 487, batch 11, d_loss=-0.288 g_loss=-0.105 KID= 0.00937\n",
      "epoch 487, batch 12, d_loss=-0.266 g_loss=-0.108 KID= 0.00937\n",
      "epoch 487, batch 13, d_loss=-0.224 g_loss=-0.143 KID= 0.00937\n",
      "epoch 487, batch 14, d_loss=-0.226 g_loss=-0.088 KID= 0.00937\n",
      "epoch 487, batch 15, d_loss=-0.253 g_loss=-0.170 KID= 0.00937\n",
      "epoch 487, batch 16, d_loss=-0.222 g_loss=-0.340 KID= 0.00937\n",
      "epoch 487, batch 17, d_loss=-0.244 g_loss=-0.449 KID= 0.00937\n",
      "epoch 487, batch 18, d_loss=-0.245 g_loss=-0.466 KID= 0.00937\n",
      "epoch 487, batch 19, d_loss=-0.156 g_loss=-0.501 KID= 0.00937\n",
      "epoch 488, batch 0, d_loss=-0.289 g_loss=-0.533 KID= 0.00937\n",
      "epoch 488, batch 1, d_loss=-0.295 g_loss=-0.527 KID= 0.00937\n",
      "epoch 488, batch 2, d_loss=-0.276 g_loss=-0.507 KID= 0.00937\n",
      "epoch 488, batch 3, d_loss=-0.203 g_loss=-0.500 KID= 0.00937\n",
      "epoch 488, batch 4, d_loss=-0.243 g_loss=-0.526 KID= 0.00937\n",
      "epoch 488, batch 5, d_loss=-0.166 g_loss=-0.568 KID= 0.00937\n",
      "epoch 488, batch 6, d_loss=-0.196 g_loss=-0.650 KID= 0.00937\n",
      "epoch 488, batch 7, d_loss=-0.246 g_loss=-0.694 KID= 0.00937\n",
      "epoch 488, batch 8, d_loss=-0.219 g_loss=-0.746 KID= 0.00937\n",
      "epoch 488, batch 9, d_loss=-0.186 g_loss=-0.655 KID= 0.00937\n",
      "epoch 488, batch 10, d_loss=-0.311 g_loss=-0.546 KID= 0.00937\n",
      "epoch 488, batch 11, d_loss=-0.292 g_loss=-0.425 KID= 0.00937\n",
      "epoch 488, batch 12, d_loss=-0.282 g_loss=-0.271 KID= 0.00937\n",
      "epoch 488, batch 13, d_loss=-0.183 g_loss=-0.054 KID= 0.00937\n",
      "epoch 488, batch 14, d_loss=-0.265 g_loss=0.088 KID= 0.00937\n",
      "epoch 488, batch 15, d_loss=-0.221 g_loss=0.073 KID= 0.00937\n",
      "epoch 488, batch 16, d_loss=-0.198 g_loss=-0.079 KID= 0.00937\n",
      "epoch 488, batch 17, d_loss=-0.271 g_loss=-0.247 KID= 0.00937\n",
      "epoch 488, batch 18, d_loss=-0.274 g_loss=-0.362 KID= 0.00937\n",
      "epoch 488, batch 19, d_loss=-0.234 g_loss=-0.422 KID= 0.00937\n",
      "epoch 489, batch 0, d_loss=-0.263 g_loss=-0.522 KID= 0.00937\n",
      "epoch 489, batch 1, d_loss=-0.284 g_loss=-0.619 KID= 0.00937\n",
      "epoch 489, batch 2, d_loss=-0.216 g_loss=-0.664 KID= 0.00937\n",
      "epoch 489, batch 3, d_loss=-0.225 g_loss=-0.634 KID= 0.00937\n",
      "epoch 489, batch 4, d_loss=-0.269 g_loss=-0.657 KID= 0.00937\n",
      "epoch 489, batch 5, d_loss=-0.227 g_loss=-0.701 KID= 0.00937\n",
      "epoch 489, batch 6, d_loss=-0.205 g_loss=-0.789 KID= 0.00937\n",
      "epoch 489, batch 7, d_loss=-0.295 g_loss=-0.825 KID= 0.00937\n",
      "epoch 489, batch 8, d_loss=-0.239 g_loss=-0.784 KID= 0.00937\n",
      "epoch 489, batch 9, d_loss=-0.206 g_loss=-0.723 KID= 0.00937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 489, batch 10, d_loss=-0.344 g_loss=-0.614 KID= 0.00937\n",
      "epoch 489, batch 11, d_loss=-0.309 g_loss=-0.626 KID= 0.00937\n",
      "epoch 489, batch 12, d_loss=-0.267 g_loss=-0.544 KID= 0.00937\n",
      "epoch 489, batch 13, d_loss=-0.231 g_loss=-0.407 KID= 0.00937\n",
      "epoch 489, batch 14, d_loss=-0.217 g_loss=-0.218 KID= 0.00937\n",
      "epoch 489, batch 15, d_loss=-0.232 g_loss=-0.188 KID= 0.00937\n",
      "epoch 489, batch 16, d_loss=-0.191 g_loss=-0.143 KID= 0.00937\n",
      "epoch 489, batch 17, d_loss=-0.196 g_loss=-0.147 KID= 0.00937\n",
      "epoch 489, batch 18, d_loss=-0.275 g_loss=-0.199 KID= 0.00937\n",
      "epoch 489, batch 19, d_loss=-0.194 g_loss=-0.189 KID= 0.00937\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 490, batch 0, d_loss=-0.273 g_loss=-0.161 KID= 0.00803\n",
      "epoch 490, batch 1, d_loss=-0.271 g_loss=-0.174 KID= 0.00803\n",
      "epoch 490, batch 2, d_loss=-0.249 g_loss=-0.175 KID= 0.00803\n",
      "epoch 490, batch 3, d_loss=-0.263 g_loss=-0.112 KID= 0.00803\n",
      "epoch 490, batch 4, d_loss=-0.298 g_loss=-0.056 KID= 0.00803\n",
      "epoch 490, batch 5, d_loss=-0.196 g_loss=-0.165 KID= 0.00803\n",
      "epoch 490, batch 6, d_loss=-0.193 g_loss=-0.346 KID= 0.00803\n",
      "epoch 490, batch 7, d_loss=-0.252 g_loss=-0.444 KID= 0.00803\n",
      "epoch 490, batch 8, d_loss=-0.262 g_loss=-0.573 KID= 0.00803\n",
      "epoch 490, batch 9, d_loss=-0.187 g_loss=-0.650 KID= 0.00803\n",
      "epoch 490, batch 10, d_loss=-0.260 g_loss=-0.672 KID= 0.00803\n",
      "epoch 490, batch 11, d_loss=-0.257 g_loss=-0.715 KID= 0.00803\n",
      "epoch 490, batch 12, d_loss=-0.242 g_loss=-0.657 KID= 0.00803\n",
      "epoch 490, batch 13, d_loss=-0.230 g_loss=-0.587 KID= 0.00803\n",
      "epoch 490, batch 14, d_loss=-0.235 g_loss=-0.452 KID= 0.00803\n",
      "epoch 490, batch 15, d_loss=-0.203 g_loss=-0.458 KID= 0.00803\n",
      "epoch 490, batch 16, d_loss=-0.199 g_loss=-0.500 KID= 0.00803\n",
      "epoch 490, batch 17, d_loss=-0.276 g_loss=-0.504 KID= 0.00803\n",
      "epoch 490, batch 18, d_loss=-0.296 g_loss=-0.577 KID= 0.00803\n",
      "epoch 490, batch 19, d_loss=-0.203 g_loss=-0.550 KID= 0.00803\n",
      "epoch 491, batch 0, d_loss=-0.283 g_loss=-0.544 KID= 0.00803\n",
      "epoch 491, batch 1, d_loss=-0.331 g_loss=-0.530 KID= 0.00803\n",
      "epoch 491, batch 2, d_loss=-0.257 g_loss=-0.502 KID= 0.00803\n",
      "epoch 491, batch 3, d_loss=-0.201 g_loss=-0.461 KID= 0.00803\n",
      "epoch 491, batch 4, d_loss=-0.279 g_loss=-0.380 KID= 0.00803\n",
      "epoch 491, batch 5, d_loss=-0.245 g_loss=-0.498 KID= 0.00803\n",
      "epoch 491, batch 6, d_loss=-0.191 g_loss=-0.632 KID= 0.00803\n",
      "epoch 491, batch 7, d_loss=-0.272 g_loss=-0.708 KID= 0.00803\n",
      "epoch 491, batch 8, d_loss=-0.277 g_loss=-0.766 KID= 0.00803\n",
      "epoch 491, batch 9, d_loss=-0.172 g_loss=-0.704 KID= 0.00803\n",
      "epoch 491, batch 10, d_loss=-0.240 g_loss=-0.639 KID= 0.00803\n",
      "epoch 491, batch 11, d_loss=-0.291 g_loss=-0.485 KID= 0.00803\n",
      "epoch 491, batch 12, d_loss=-0.257 g_loss=-0.402 KID= 0.00803\n",
      "epoch 491, batch 13, d_loss=-0.266 g_loss=-0.371 KID= 0.00803\n",
      "epoch 491, batch 14, d_loss=-0.265 g_loss=-0.336 KID= 0.00803\n",
      "epoch 491, batch 15, d_loss=-0.191 g_loss=-0.468 KID= 0.00803\n",
      "epoch 491, batch 16, d_loss=-0.215 g_loss=-0.536 KID= 0.00803\n",
      "epoch 491, batch 17, d_loss=-0.255 g_loss=-0.485 KID= 0.00803\n",
      "epoch 491, batch 18, d_loss=-0.263 g_loss=-0.395 KID= 0.00803\n",
      "epoch 491, batch 19, d_loss=-0.198 g_loss=-0.240 KID= 0.00803\n",
      "epoch 492, batch 0, d_loss=-0.278 g_loss=-0.019 KID= 0.00803\n",
      "epoch 492, batch 1, d_loss=-0.309 g_loss=0.076 KID= 0.00803\n",
      "epoch 492, batch 2, d_loss=-0.248 g_loss=0.143 KID= 0.00803\n",
      "epoch 492, batch 3, d_loss=-0.216 g_loss=0.241 KID= 0.00803\n",
      "epoch 492, batch 4, d_loss=-0.287 g_loss=0.344 KID= 0.00803\n",
      "epoch 492, batch 5, d_loss=-0.234 g_loss=0.201 KID= 0.00803\n",
      "epoch 492, batch 6, d_loss=-0.175 g_loss=0.033 KID= 0.00803\n",
      "epoch 492, batch 7, d_loss=-0.259 g_loss=-0.233 KID= 0.00803\n",
      "epoch 492, batch 8, d_loss=-0.260 g_loss=-0.454 KID= 0.00803\n",
      "epoch 492, batch 9, d_loss=-0.225 g_loss=-0.556 KID= 0.00803\n",
      "epoch 492, batch 10, d_loss=-0.341 g_loss=-0.626 KID= 0.00803\n",
      "epoch 492, batch 11, d_loss=-0.300 g_loss=-0.631 KID= 0.00803\n",
      "epoch 492, batch 12, d_loss=-0.205 g_loss=-0.721 KID= 0.00803\n",
      "epoch 492, batch 13, d_loss=-0.171 g_loss=-0.643 KID= 0.00803\n",
      "epoch 492, batch 14, d_loss=-0.255 g_loss=-0.543 KID= 0.00803\n",
      "epoch 492, batch 15, d_loss=-0.225 g_loss=-0.560 KID= 0.00803\n",
      "epoch 492, batch 16, d_loss=-0.247 g_loss=-0.591 KID= 0.00803\n",
      "epoch 492, batch 17, d_loss=-0.223 g_loss=-0.684 KID= 0.00803\n",
      "epoch 492, batch 18, d_loss=-0.284 g_loss=-0.740 KID= 0.00803\n",
      "epoch 492, batch 19, d_loss=-0.207 g_loss=-0.607 KID= 0.00803\n",
      "epoch 493, batch 0, d_loss=-0.251 g_loss=-0.418 KID= 0.00803\n",
      "epoch 493, batch 1, d_loss=-0.286 g_loss=-0.317 KID= 0.00803\n",
      "epoch 493, batch 2, d_loss=-0.264 g_loss=-0.262 KID= 0.00803\n",
      "epoch 493, batch 3, d_loss=-0.200 g_loss=-0.182 KID= 0.00803\n",
      "epoch 493, batch 4, d_loss=-0.233 g_loss=-0.109 KID= 0.00803\n",
      "epoch 493, batch 5, d_loss=-0.257 g_loss=-0.148 KID= 0.00803\n",
      "epoch 493, batch 6, d_loss=-0.211 g_loss=-0.248 KID= 0.00803\n",
      "epoch 493, batch 7, d_loss=-0.290 g_loss=-0.351 KID= 0.00803\n",
      "epoch 493, batch 8, d_loss=-0.254 g_loss=-0.520 KID= 0.00803\n",
      "epoch 493, batch 9, d_loss=-0.202 g_loss=-0.575 KID= 0.00803\n",
      "epoch 493, batch 10, d_loss=-0.301 g_loss=-0.634 KID= 0.00803\n",
      "epoch 493, batch 11, d_loss=-0.287 g_loss=-0.572 KID= 0.00803\n",
      "epoch 493, batch 12, d_loss=-0.278 g_loss=-0.562 KID= 0.00803\n",
      "epoch 493, batch 13, d_loss=-0.225 g_loss=-0.437 KID= 0.00803\n",
      "epoch 493, batch 14, d_loss=-0.277 g_loss=-0.292 KID= 0.00803\n",
      "epoch 493, batch 15, d_loss=-0.227 g_loss=-0.407 KID= 0.00803\n",
      "epoch 493, batch 16, d_loss=-0.164 g_loss=-0.422 KID= 0.00803\n",
      "epoch 493, batch 17, d_loss=-0.220 g_loss=-0.393 KID= 0.00803\n",
      "epoch 493, batch 18, d_loss=-0.233 g_loss=-0.420 KID= 0.00803\n",
      "epoch 493, batch 19, d_loss=-0.235 g_loss=-0.312 KID= 0.00803\n",
      "epoch 494, batch 0, d_loss=-0.267 g_loss=-0.271 KID= 0.00803\n",
      "epoch 494, batch 1, d_loss=-0.279 g_loss=-0.304 KID= 0.00803\n",
      "epoch 494, batch 2, d_loss=-0.258 g_loss=-0.316 KID= 0.00803\n",
      "epoch 494, batch 3, d_loss=-0.232 g_loss=-0.319 KID= 0.00803\n",
      "epoch 494, batch 4, d_loss=-0.279 g_loss=-0.245 KID= 0.00803\n",
      "epoch 494, batch 5, d_loss=-0.237 g_loss=-0.317 KID= 0.00803\n",
      "epoch 494, batch 6, d_loss=-0.228 g_loss=-0.392 KID= 0.00803\n",
      "epoch 494, batch 7, d_loss=-0.247 g_loss=-0.409 KID= 0.00803\n",
      "epoch 494, batch 8, d_loss=-0.271 g_loss=-0.473 KID= 0.00803\n",
      "epoch 494, batch 9, d_loss=-0.203 g_loss=-0.483 KID= 0.00803\n",
      "epoch 494, batch 10, d_loss=-0.289 g_loss=-0.578 KID= 0.00803\n",
      "epoch 494, batch 11, d_loss=-0.316 g_loss=-0.636 KID= 0.00803\n",
      "epoch 494, batch 12, d_loss=-0.246 g_loss=-0.778 KID= 0.00803\n",
      "epoch 494, batch 13, d_loss=-0.105 g_loss=-0.731 KID= 0.00803\n",
      "epoch 494, batch 14, d_loss=-0.228 g_loss=-0.668 KID= 0.00803\n",
      "epoch 494, batch 15, d_loss=-0.234 g_loss=-0.694 KID= 0.00803\n",
      "epoch 494, batch 16, d_loss=-0.213 g_loss=-0.759 KID= 0.00803\n",
      "epoch 494, batch 17, d_loss=-0.261 g_loss=-0.769 KID= 0.00803\n",
      "epoch 494, batch 18, d_loss=-0.301 g_loss=-0.802 KID= 0.00803\n",
      "epoch 494, batch 19, d_loss=-0.247 g_loss=-0.800 KID= 0.00803\n",
      "epoch 495, batch 0, d_loss=-0.338 g_loss=-0.649 KID= 0.00803\n",
      "epoch 495, batch 1, d_loss=-0.275 g_loss=-0.469 KID= 0.00803\n",
      "epoch 495, batch 2, d_loss=-0.233 g_loss=-0.293 KID= 0.00803\n",
      "epoch 495, batch 3, d_loss=-0.210 g_loss=-0.185 KID= 0.00803\n",
      "epoch 495, batch 4, d_loss=-0.258 g_loss=-0.058 KID= 0.00803\n",
      "epoch 495, batch 5, d_loss=-0.246 g_loss=-0.049 KID= 0.00803\n",
      "epoch 495, batch 6, d_loss=-0.215 g_loss=-0.138 KID= 0.00803\n",
      "epoch 495, batch 7, d_loss=-0.309 g_loss=-0.231 KID= 0.00803\n",
      "epoch 495, batch 8, d_loss=-0.250 g_loss=-0.310 KID= 0.00803\n",
      "epoch 495, batch 9, d_loss=-0.232 g_loss=-0.391 KID= 0.00803\n",
      "epoch 495, batch 10, d_loss=-0.265 g_loss=-0.380 KID= 0.00803\n",
      "epoch 495, batch 11, d_loss=-0.305 g_loss=-0.457 KID= 0.00803\n",
      "epoch 495, batch 12, d_loss=-0.291 g_loss=-0.482 KID= 0.00803\n",
      "epoch 495, batch 13, d_loss=-0.192 g_loss=-0.432 KID= 0.00803\n",
      "epoch 495, batch 14, d_loss=-0.254 g_loss=-0.407 KID= 0.00803\n",
      "epoch 495, batch 15, d_loss=-0.267 g_loss=-0.478 KID= 0.00803\n",
      "epoch 495, batch 16, d_loss=-0.187 g_loss=-0.521 KID= 0.00803\n",
      "epoch 495, batch 17, d_loss=-0.245 g_loss=-0.637 KID= 0.00803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 495, batch 18, d_loss=-0.291 g_loss=-0.802 KID= 0.00803\n",
      "epoch 495, batch 19, d_loss=-0.181 g_loss=-0.816 KID= 0.00803\n",
      "epoch 496, batch 0, d_loss=-0.262 g_loss=-0.806 KID= 0.00803\n",
      "epoch 496, batch 1, d_loss=-0.271 g_loss=-0.662 KID= 0.00803\n",
      "epoch 496, batch 2, d_loss=-0.288 g_loss=-0.573 KID= 0.00803\n",
      "epoch 496, batch 3, d_loss=-0.195 g_loss=-0.436 KID= 0.00803\n",
      "epoch 496, batch 4, d_loss=-0.273 g_loss=-0.288 KID= 0.00803\n",
      "epoch 496, batch 5, d_loss=-0.224 g_loss=-0.244 KID= 0.00803\n",
      "epoch 496, batch 6, d_loss=-0.180 g_loss=-0.241 KID= 0.00803\n",
      "epoch 496, batch 7, d_loss=-0.259 g_loss=-0.168 KID= 0.00803\n",
      "epoch 496, batch 8, d_loss=-0.264 g_loss=-0.186 KID= 0.00803\n",
      "epoch 496, batch 9, d_loss=-0.231 g_loss=-0.177 KID= 0.00803\n",
      "epoch 496, batch 10, d_loss=-0.306 g_loss=-0.096 KID= 0.00803\n",
      "epoch 496, batch 11, d_loss=-0.253 g_loss=-0.079 KID= 0.00803\n",
      "epoch 496, batch 12, d_loss=-0.190 g_loss=-0.115 KID= 0.00803\n",
      "epoch 496, batch 13, d_loss=-0.170 g_loss=-0.045 KID= 0.00803\n",
      "epoch 496, batch 14, d_loss=-0.273 g_loss=0.019 KID= 0.00803\n",
      "epoch 496, batch 15, d_loss=-0.240 g_loss=-0.087 KID= 0.00803\n",
      "epoch 496, batch 16, d_loss=-0.228 g_loss=-0.189 KID= 0.00803\n",
      "epoch 496, batch 17, d_loss=-0.258 g_loss=-0.339 KID= 0.00803\n",
      "epoch 496, batch 18, d_loss=-0.264 g_loss=-0.470 KID= 0.00803\n",
      "epoch 496, batch 19, d_loss=-0.208 g_loss=-0.583 KID= 0.00803\n",
      "epoch 497, batch 0, d_loss=-0.245 g_loss=-0.670 KID= 0.00803\n",
      "epoch 497, batch 1, d_loss=-0.256 g_loss=-0.663 KID= 0.00803\n",
      "epoch 497, batch 2, d_loss=-0.264 g_loss=-0.684 KID= 0.00803\n",
      "epoch 497, batch 3, d_loss=-0.193 g_loss=-0.488 KID= 0.00803\n",
      "epoch 497, batch 4, d_loss=-0.277 g_loss=-0.353 KID= 0.00803\n",
      "epoch 497, batch 5, d_loss=-0.229 g_loss=-0.365 KID= 0.00803\n",
      "epoch 497, batch 6, d_loss=-0.173 g_loss=-0.227 KID= 0.00803\n",
      "epoch 497, batch 7, d_loss=-0.244 g_loss=-0.204 KID= 0.00803\n",
      "epoch 497, batch 8, d_loss=-0.265 g_loss=-0.190 KID= 0.00803\n",
      "epoch 497, batch 9, d_loss=-0.273 g_loss=-0.192 KID= 0.00803\n",
      "epoch 497, batch 10, d_loss=-0.287 g_loss=-0.151 KID= 0.00803\n",
      "epoch 497, batch 11, d_loss=-0.257 g_loss=-0.087 KID= 0.00803\n",
      "epoch 497, batch 12, d_loss=-0.304 g_loss=-0.080 KID= 0.00803\n",
      "epoch 497, batch 13, d_loss=-0.146 g_loss=-0.065 KID= 0.00803\n",
      "epoch 497, batch 14, d_loss=-0.280 g_loss=-0.062 KID= 0.00803\n",
      "epoch 497, batch 15, d_loss=-0.210 g_loss=-0.199 KID= 0.00803\n",
      "epoch 497, batch 16, d_loss=-0.194 g_loss=-0.303 KID= 0.00803\n",
      "epoch 497, batch 17, d_loss=-0.239 g_loss=-0.481 KID= 0.00803\n",
      "epoch 497, batch 18, d_loss=-0.256 g_loss=-0.614 KID= 0.00803\n",
      "epoch 497, batch 19, d_loss=-0.240 g_loss=-0.711 KID= 0.00803\n",
      "epoch 498, batch 0, d_loss=-0.348 g_loss=-0.751 KID= 0.00803\n",
      "epoch 498, batch 1, d_loss=-0.337 g_loss=-0.789 KID= 0.00803\n",
      "epoch 498, batch 2, d_loss=-0.285 g_loss=-0.789 KID= 0.00803\n",
      "epoch 498, batch 3, d_loss=-0.255 g_loss=-0.712 KID= 0.00803\n",
      "epoch 498, batch 4, d_loss=-0.202 g_loss=-0.508 KID= 0.00803\n",
      "epoch 498, batch 5, d_loss=-0.185 g_loss=-0.407 KID= 0.00803\n",
      "epoch 498, batch 6, d_loss=-0.201 g_loss=-0.268 KID= 0.00803\n",
      "epoch 498, batch 7, d_loss=-0.296 g_loss=-0.272 KID= 0.00803\n",
      "epoch 498, batch 8, d_loss=-0.212 g_loss=-0.292 KID= 0.00803\n",
      "epoch 498, batch 9, d_loss=-0.237 g_loss=-0.198 KID= 0.00803\n",
      "epoch 498, batch 10, d_loss=-0.310 g_loss=-0.003 KID= 0.00803\n",
      "epoch 498, batch 11, d_loss=-0.322 g_loss=0.218 KID= 0.00803\n",
      "epoch 498, batch 12, d_loss=-0.244 g_loss=0.276 KID= 0.00803\n",
      "epoch 498, batch 13, d_loss=-0.276 g_loss=0.386 KID= 0.00803\n",
      "epoch 498, batch 14, d_loss=-0.296 g_loss=0.377 KID= 0.00803\n",
      "epoch 498, batch 15, d_loss=-0.242 g_loss=0.202 KID= 0.00803\n",
      "epoch 498, batch 16, d_loss=-0.201 g_loss=-0.024 KID= 0.00803\n",
      "epoch 498, batch 17, d_loss=-0.176 g_loss=-0.235 KID= 0.00803\n",
      "epoch 498, batch 18, d_loss=-0.241 g_loss=-0.425 KID= 0.00803\n",
      "epoch 498, batch 19, d_loss=-0.185 g_loss=-0.469 KID= 0.00803\n",
      "epoch 499, batch 0, d_loss=-0.305 g_loss=-0.577 KID= 0.00803\n",
      "epoch 499, batch 1, d_loss=-0.351 g_loss=-0.720 KID= 0.00803\n",
      "epoch 499, batch 2, d_loss=-0.281 g_loss=-0.921 KID= 0.00803\n",
      "epoch 499, batch 3, d_loss=-0.121 g_loss=-0.857 KID= 0.00803\n",
      "epoch 499, batch 4, d_loss=-0.212 g_loss=-0.767 KID= 0.00803\n",
      "epoch 499, batch 5, d_loss=-0.251 g_loss=-0.768 KID= 0.00803\n",
      "epoch 499, batch 6, d_loss=-0.194 g_loss=-0.699 KID= 0.00803\n",
      "epoch 499, batch 7, d_loss=-0.300 g_loss=-0.682 KID= 0.00803\n",
      "epoch 499, batch 8, d_loss=-0.278 g_loss=-0.667 KID= 0.00803\n",
      "epoch 499, batch 9, d_loss=-0.218 g_loss=-0.715 KID= 0.00803\n",
      "epoch 499, batch 10, d_loss=-0.273 g_loss=-0.631 KID= 0.00803\n",
      "epoch 499, batch 11, d_loss=-0.260 g_loss=-0.523 KID= 0.00803\n",
      "epoch 499, batch 12, d_loss=-0.232 g_loss=-0.486 KID= 0.00803\n",
      "epoch 499, batch 13, d_loss=-0.291 g_loss=-0.418 KID= 0.00803\n",
      "epoch 499, batch 14, d_loss=-0.304 g_loss=-0.386 KID= 0.00803\n",
      "epoch 499, batch 15, d_loss=-0.221 g_loss=-0.475 KID= 0.00803\n",
      "epoch 499, batch 16, d_loss=-0.155 g_loss=-0.392 KID= 0.00803\n",
      "epoch 499, batch 17, d_loss=-0.251 g_loss=-0.310 KID= 0.00803\n",
      "epoch 499, batch 18, d_loss=-0.189 g_loss=-0.274 KID= 0.00803\n",
      "epoch 499, batch 19, d_loss=-0.243 g_loss=-0.269 KID= 0.00803\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 500, batch 0, d_loss=-0.309 g_loss=-0.293 KID= 0.01085\n",
      "epoch 500, batch 1, d_loss=-0.328 g_loss=-0.292 KID= 0.01085\n",
      "epoch 500, batch 2, d_loss=-0.289 g_loss=-0.349 KID= 0.01085\n",
      "epoch 500, batch 3, d_loss=-0.228 g_loss=-0.468 KID= 0.01085\n",
      "epoch 500, batch 4, d_loss=-0.219 g_loss=-0.494 KID= 0.01085\n",
      "epoch 500, batch 5, d_loss=-0.260 g_loss=-0.542 KID= 0.01085\n",
      "epoch 500, batch 6, d_loss=-0.157 g_loss=-0.632 KID= 0.01085\n",
      "epoch 500, batch 7, d_loss=-0.261 g_loss=-0.770 KID= 0.01085\n",
      "epoch 500, batch 8, d_loss=-0.282 g_loss=-0.849 KID= 0.01085\n",
      "epoch 500, batch 9, d_loss=-0.206 g_loss=-0.918 KID= 0.01085\n",
      "epoch 500, batch 10, d_loss=-0.285 g_loss=-0.787 KID= 0.01085\n",
      "epoch 500, batch 11, d_loss=-0.296 g_loss=-0.598 KID= 0.01085\n",
      "epoch 500, batch 12, d_loss=-0.279 g_loss=-0.496 KID= 0.01085\n",
      "epoch 500, batch 13, d_loss=-0.209 g_loss=-0.378 KID= 0.01085\n",
      "epoch 500, batch 14, d_loss=-0.290 g_loss=-0.340 KID= 0.01085\n",
      "epoch 500, batch 15, d_loss=-0.261 g_loss=-0.329 KID= 0.01085\n",
      "epoch 500, batch 16, d_loss=-0.214 g_loss=-0.295 KID= 0.01085\n",
      "epoch 500, batch 17, d_loss=-0.199 g_loss=-0.374 KID= 0.01085\n",
      "epoch 500, batch 18, d_loss=-0.240 g_loss=-0.412 KID= 0.01085\n",
      "epoch 500, batch 19, d_loss=-0.250 g_loss=-0.499 KID= 0.01085\n",
      "epoch 501, batch 0, d_loss=-0.291 g_loss=-0.573 KID= 0.01085\n",
      "epoch 501, batch 1, d_loss=-0.310 g_loss=-0.679 KID= 0.01085\n",
      "epoch 501, batch 2, d_loss=-0.249 g_loss=-0.722 KID= 0.01085\n",
      "epoch 501, batch 3, d_loss=-0.127 g_loss=-0.709 KID= 0.01085\n",
      "epoch 501, batch 4, d_loss=-0.262 g_loss=-0.731 KID= 0.01085\n",
      "epoch 501, batch 5, d_loss=-0.253 g_loss=-0.758 KID= 0.01085\n",
      "epoch 501, batch 6, d_loss=-0.204 g_loss=-0.705 KID= 0.01085\n",
      "epoch 501, batch 7, d_loss=-0.270 g_loss=-0.714 KID= 0.01085\n",
      "epoch 501, batch 8, d_loss=-0.288 g_loss=-0.640 KID= 0.01085\n",
      "epoch 501, batch 9, d_loss=-0.206 g_loss=-0.577 KID= 0.01085\n",
      "epoch 501, batch 10, d_loss=-0.367 g_loss=-0.533 KID= 0.01085\n",
      "epoch 501, batch 11, d_loss=-0.287 g_loss=-0.385 KID= 0.01085\n",
      "epoch 501, batch 12, d_loss=-0.175 g_loss=-0.265 KID= 0.01085\n",
      "epoch 501, batch 13, d_loss=-0.267 g_loss=-0.173 KID= 0.01085\n",
      "epoch 501, batch 14, d_loss=-0.228 g_loss=-0.164 KID= 0.01085\n",
      "epoch 501, batch 15, d_loss=-0.228 g_loss=-0.159 KID= 0.01085\n",
      "epoch 501, batch 16, d_loss=-0.212 g_loss=-0.119 KID= 0.01085\n",
      "epoch 501, batch 17, d_loss=-0.248 g_loss=-0.095 KID= 0.01085\n",
      "epoch 501, batch 18, d_loss=-0.283 g_loss=-0.096 KID= 0.01085\n",
      "epoch 501, batch 19, d_loss=-0.236 g_loss=-0.142 KID= 0.01085\n",
      "epoch 502, batch 0, d_loss=-0.247 g_loss=-0.208 KID= 0.01085\n",
      "epoch 502, batch 1, d_loss=-0.259 g_loss=-0.299 KID= 0.01085\n",
      "epoch 502, batch 2, d_loss=-0.263 g_loss=-0.352 KID= 0.01085\n",
      "epoch 502, batch 3, d_loss=-0.228 g_loss=-0.343 KID= 0.01085\n",
      "epoch 502, batch 4, d_loss=-0.254 g_loss=-0.425 KID= 0.01085\n",
      "epoch 502, batch 5, d_loss=-0.262 g_loss=-0.524 KID= 0.01085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 502, batch 6, d_loss=-0.195 g_loss=-0.469 KID= 0.01085\n",
      "epoch 502, batch 7, d_loss=-0.269 g_loss=-0.560 KID= 0.01085\n",
      "epoch 502, batch 8, d_loss=-0.242 g_loss=-0.621 KID= 0.01085\n",
      "epoch 502, batch 9, d_loss=-0.240 g_loss=-0.679 KID= 0.01085\n",
      "epoch 502, batch 10, d_loss=-0.306 g_loss=-0.721 KID= 0.01085\n",
      "epoch 502, batch 11, d_loss=-0.301 g_loss=-0.674 KID= 0.01085\n",
      "epoch 502, batch 12, d_loss=-0.255 g_loss=-0.653 KID= 0.01085\n",
      "epoch 502, batch 13, d_loss=-0.244 g_loss=-0.541 KID= 0.01085\n",
      "epoch 502, batch 14, d_loss=-0.265 g_loss=-0.433 KID= 0.01085\n",
      "epoch 502, batch 15, d_loss=-0.260 g_loss=-0.318 KID= 0.01085\n",
      "epoch 502, batch 16, d_loss=-0.200 g_loss=-0.135 KID= 0.01085\n",
      "epoch 502, batch 17, d_loss=-0.234 g_loss=-0.016 KID= 0.01085\n",
      "epoch 502, batch 18, d_loss=-0.264 g_loss=0.068 KID= 0.01085\n",
      "epoch 502, batch 19, d_loss=-0.212 g_loss=0.109 KID= 0.01085\n",
      "epoch 503, batch 0, d_loss=-0.226 g_loss=0.109 KID= 0.01085\n",
      "epoch 503, batch 1, d_loss=-0.336 g_loss=0.066 KID= 0.01085\n",
      "epoch 503, batch 2, d_loss=-0.217 g_loss=-0.097 KID= 0.01085\n",
      "epoch 503, batch 3, d_loss=-0.269 g_loss=-0.140 KID= 0.01085\n",
      "epoch 503, batch 4, d_loss=-0.246 g_loss=-0.268 KID= 0.01085\n",
      "epoch 503, batch 5, d_loss=-0.251 g_loss=-0.348 KID= 0.01085\n",
      "epoch 503, batch 6, d_loss=-0.183 g_loss=-0.263 KID= 0.01085\n",
      "epoch 503, batch 7, d_loss=-0.242 g_loss=-0.304 KID= 0.01085\n",
      "epoch 503, batch 8, d_loss=-0.272 g_loss=-0.416 KID= 0.01085\n",
      "epoch 503, batch 9, d_loss=-0.248 g_loss=-0.587 KID= 0.01085\n",
      "epoch 503, batch 10, d_loss=-0.275 g_loss=-0.737 KID= 0.01085\n",
      "epoch 503, batch 11, d_loss=-0.269 g_loss=-0.770 KID= 0.01085\n",
      "epoch 503, batch 12, d_loss=-0.241 g_loss=-0.740 KID= 0.01085\n",
      "epoch 503, batch 13, d_loss=-0.229 g_loss=-0.679 KID= 0.01085\n",
      "epoch 503, batch 14, d_loss=-0.274 g_loss=-0.618 KID= 0.01085\n",
      "epoch 503, batch 15, d_loss=-0.226 g_loss=-0.590 KID= 0.01085\n",
      "epoch 503, batch 16, d_loss=-0.220 g_loss=-0.505 KID= 0.01085\n",
      "epoch 503, batch 17, d_loss=-0.273 g_loss=-0.365 KID= 0.01085\n",
      "epoch 503, batch 18, d_loss=-0.273 g_loss=-0.154 KID= 0.01085\n",
      "epoch 503, batch 19, d_loss=-0.261 g_loss=0.061 KID= 0.01085\n",
      "epoch 504, batch 0, d_loss=-0.307 g_loss=0.289 KID= 0.01085\n",
      "epoch 504, batch 1, d_loss=-0.383 g_loss=0.309 KID= 0.01085\n",
      "epoch 504, batch 2, d_loss=-0.215 g_loss=0.333 KID= 0.01085\n",
      "epoch 504, batch 3, d_loss=-0.238 g_loss=0.375 KID= 0.01085\n",
      "epoch 504, batch 4, d_loss=-0.247 g_loss=0.247 KID= 0.01085\n",
      "epoch 504, batch 5, d_loss=-0.283 g_loss=0.081 KID= 0.01085\n",
      "epoch 504, batch 6, d_loss=-0.157 g_loss=0.019 KID= 0.01085\n",
      "epoch 504, batch 7, d_loss=-0.271 g_loss=-0.093 KID= 0.01085\n",
      "epoch 504, batch 8, d_loss=-0.232 g_loss=-0.205 KID= 0.01085\n",
      "epoch 504, batch 9, d_loss=-0.277 g_loss=-0.383 KID= 0.01085\n",
      "epoch 504, batch 10, d_loss=-0.303 g_loss=-0.618 KID= 0.01085\n",
      "epoch 504, batch 11, d_loss=-0.351 g_loss=-0.819 KID= 0.01085\n",
      "epoch 504, batch 12, d_loss=-0.262 g_loss=-0.938 KID= 0.01085\n",
      "epoch 504, batch 13, d_loss=-0.233 g_loss=-0.993 KID= 0.01085\n",
      "epoch 504, batch 14, d_loss=-0.199 g_loss=-0.948 KID= 0.01085\n",
      "epoch 504, batch 15, d_loss=-0.203 g_loss=-0.900 KID= 0.01085\n",
      "epoch 504, batch 16, d_loss=-0.210 g_loss=-0.595 KID= 0.01085\n",
      "epoch 504, batch 17, d_loss=-0.203 g_loss=-0.319 KID= 0.01085\n",
      "epoch 504, batch 18, d_loss=-0.262 g_loss=-0.138 KID= 0.01085\n",
      "epoch 504, batch 19, d_loss=-0.250 g_loss=0.013 KID= 0.01085\n",
      "epoch 505, batch 0, d_loss=-0.301 g_loss=0.086 KID= 0.01085\n",
      "epoch 505, batch 1, d_loss=-0.329 g_loss=0.111 KID= 0.01085\n",
      "epoch 505, batch 2, d_loss=-0.142 g_loss=0.147 KID= 0.01085\n",
      "epoch 505, batch 3, d_loss=-0.251 g_loss=0.121 KID= 0.01085\n",
      "epoch 505, batch 4, d_loss=-0.260 g_loss=-0.009 KID= 0.01085\n",
      "epoch 505, batch 5, d_loss=-0.246 g_loss=-0.255 KID= 0.01085\n",
      "epoch 505, batch 6, d_loss=-0.152 g_loss=-0.304 KID= 0.01085\n",
      "epoch 505, batch 7, d_loss=-0.194 g_loss=-0.386 KID= 0.01085\n",
      "epoch 505, batch 8, d_loss=-0.257 g_loss=-0.438 KID= 0.01085\n",
      "epoch 505, batch 9, d_loss=-0.271 g_loss=-0.418 KID= 0.01085\n",
      "epoch 505, batch 10, d_loss=-0.281 g_loss=-0.425 KID= 0.01085\n",
      "epoch 505, batch 11, d_loss=-0.325 g_loss=-0.467 KID= 0.01085\n",
      "epoch 505, batch 12, d_loss=-0.298 g_loss=-0.469 KID= 0.01085\n",
      "epoch 505, batch 13, d_loss=-0.230 g_loss=-0.485 KID= 0.01085\n",
      "epoch 505, batch 14, d_loss=-0.198 g_loss=-0.526 KID= 0.01085\n",
      "epoch 505, batch 15, d_loss=-0.216 g_loss=-0.556 KID= 0.01085\n",
      "epoch 505, batch 16, d_loss=-0.246 g_loss=-0.481 KID= 0.01085\n",
      "epoch 505, batch 17, d_loss=-0.298 g_loss=-0.553 KID= 0.01085\n",
      "epoch 505, batch 18, d_loss=-0.281 g_loss=-0.518 KID= 0.01085\n",
      "epoch 505, batch 19, d_loss=-0.281 g_loss=-0.452 KID= 0.01085\n",
      "epoch 506, batch 0, d_loss=-0.271 g_loss=-0.430 KID= 0.01085\n",
      "epoch 506, batch 1, d_loss=-0.307 g_loss=-0.435 KID= 0.01085\n",
      "epoch 506, batch 2, d_loss=-0.162 g_loss=-0.293 KID= 0.01085\n",
      "epoch 506, batch 3, d_loss=-0.225 g_loss=-0.164 KID= 0.01085\n",
      "epoch 506, batch 4, d_loss=-0.255 g_loss=-0.137 KID= 0.01085\n",
      "epoch 506, batch 5, d_loss=-0.230 g_loss=-0.100 KID= 0.01085\n",
      "epoch 506, batch 6, d_loss=-0.235 g_loss=-0.077 KID= 0.01085\n",
      "epoch 506, batch 7, d_loss=-0.295 g_loss=-0.108 KID= 0.01085\n",
      "epoch 506, batch 8, d_loss=-0.283 g_loss=-0.181 KID= 0.01085\n",
      "epoch 506, batch 9, d_loss=-0.244 g_loss=-0.243 KID= 0.01085\n",
      "epoch 506, batch 10, d_loss=-0.321 g_loss=-0.236 KID= 0.01085\n",
      "epoch 506, batch 11, d_loss=-0.387 g_loss=-0.299 KID= 0.01085\n",
      "epoch 506, batch 12, d_loss=-0.229 g_loss=-0.304 KID= 0.01085\n",
      "epoch 506, batch 13, d_loss=-0.160 g_loss=-0.282 KID= 0.01085\n",
      "epoch 506, batch 14, d_loss=-0.225 g_loss=-0.394 KID= 0.01085\n",
      "epoch 506, batch 15, d_loss=-0.189 g_loss=-0.530 KID= 0.01085\n",
      "epoch 506, batch 16, d_loss=-0.247 g_loss=-0.645 KID= 0.01085\n",
      "epoch 506, batch 17, d_loss=-0.240 g_loss=-0.791 KID= 0.01085\n",
      "epoch 506, batch 18, d_loss=-0.309 g_loss=-0.953 KID= 0.01085\n",
      "epoch 506, batch 19, d_loss=-0.226 g_loss=-0.896 KID= 0.01085\n",
      "epoch 507, batch 0, d_loss=-0.247 g_loss=-0.904 KID= 0.01085\n",
      "epoch 507, batch 1, d_loss=-0.348 g_loss=-0.861 KID= 0.01085\n",
      "epoch 507, batch 2, d_loss=-0.165 g_loss=-0.587 KID= 0.01085\n",
      "epoch 507, batch 3, d_loss=-0.266 g_loss=-0.399 KID= 0.01085\n",
      "epoch 507, batch 4, d_loss=-0.281 g_loss=-0.333 KID= 0.01085\n",
      "epoch 507, batch 5, d_loss=-0.276 g_loss=-0.405 KID= 0.01085\n",
      "epoch 507, batch 6, d_loss=-0.191 g_loss=-0.361 KID= 0.01085\n",
      "epoch 507, batch 7, d_loss=-0.244 g_loss=-0.281 KID= 0.01085\n",
      "epoch 507, batch 8, d_loss=-0.301 g_loss=-0.188 KID= 0.01085\n",
      "epoch 507, batch 9, d_loss=-0.221 g_loss=-0.045 KID= 0.01085\n",
      "epoch 507, batch 10, d_loss=-0.298 g_loss=0.077 KID= 0.01085\n",
      "epoch 507, batch 11, d_loss=-0.353 g_loss=0.093 KID= 0.01085\n",
      "epoch 507, batch 12, d_loss=-0.219 g_loss=0.080 KID= 0.01085\n",
      "epoch 507, batch 13, d_loss=-0.196 g_loss=-0.042 KID= 0.01085\n",
      "epoch 507, batch 14, d_loss=-0.279 g_loss=-0.294 KID= 0.01085\n",
      "epoch 507, batch 15, d_loss=-0.158 g_loss=-0.529 KID= 0.01085\n",
      "epoch 507, batch 16, d_loss=-0.242 g_loss=-0.710 KID= 0.01085\n",
      "epoch 507, batch 17, d_loss=-0.288 g_loss=-0.744 KID= 0.01085\n",
      "epoch 507, batch 18, d_loss=-0.278 g_loss=-0.813 KID= 0.01085\n",
      "epoch 507, batch 19, d_loss=-0.302 g_loss=-0.764 KID= 0.01085\n",
      "epoch 508, batch 0, d_loss=-0.275 g_loss=-0.703 KID= 0.01085\n",
      "epoch 508, batch 1, d_loss=-0.286 g_loss=-0.664 KID= 0.01085\n",
      "epoch 508, batch 2, d_loss=-0.264 g_loss=-0.454 KID= 0.01085\n",
      "epoch 508, batch 3, d_loss=-0.286 g_loss=-0.295 KID= 0.01085\n",
      "epoch 508, batch 4, d_loss=-0.216 g_loss=-0.309 KID= 0.01085\n",
      "epoch 508, batch 5, d_loss=-0.238 g_loss=-0.494 KID= 0.01085\n",
      "epoch 508, batch 6, d_loss=-0.276 g_loss=-0.510 KID= 0.01085\n",
      "epoch 508, batch 7, d_loss=-0.280 g_loss=-0.513 KID= 0.01085\n",
      "epoch 508, batch 8, d_loss=-0.267 g_loss=-0.503 KID= 0.01085\n",
      "epoch 508, batch 9, d_loss=-0.242 g_loss=-0.403 KID= 0.01085\n",
      "epoch 508, batch 10, d_loss=-0.292 g_loss=-0.278 KID= 0.01085\n",
      "epoch 508, batch 11, d_loss=-0.336 g_loss=-0.325 KID= 0.01085\n",
      "epoch 508, batch 12, d_loss=-0.252 g_loss=-0.317 KID= 0.01085\n",
      "epoch 508, batch 13, d_loss=-0.224 g_loss=-0.303 KID= 0.01085\n",
      "epoch 508, batch 14, d_loss=-0.204 g_loss=-0.361 KID= 0.01085\n",
      "epoch 508, batch 15, d_loss=-0.218 g_loss=-0.478 KID= 0.01085\n",
      "epoch 508, batch 16, d_loss=-0.243 g_loss=-0.444 KID= 0.01085\n",
      "epoch 508, batch 17, d_loss=-0.252 g_loss=-0.451 KID= 0.01085\n",
      "epoch 508, batch 18, d_loss=-0.281 g_loss=-0.565 KID= 0.01085\n",
      "epoch 508, batch 19, d_loss=-0.228 g_loss=-0.585 KID= 0.01085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 509, batch 0, d_loss=-0.266 g_loss=-0.592 KID= 0.01085\n",
      "epoch 509, batch 1, d_loss=-0.353 g_loss=-0.547 KID= 0.01085\n",
      "epoch 509, batch 2, d_loss=-0.156 g_loss=-0.393 KID= 0.01085\n",
      "epoch 509, batch 3, d_loss=-0.217 g_loss=-0.280 KID= 0.01085\n",
      "epoch 509, batch 4, d_loss=-0.254 g_loss=-0.276 KID= 0.01085\n",
      "epoch 509, batch 5, d_loss=-0.226 g_loss=-0.401 KID= 0.01085\n",
      "epoch 509, batch 6, d_loss=-0.224 g_loss=-0.414 KID= 0.01085\n",
      "epoch 509, batch 7, d_loss=-0.283 g_loss=-0.394 KID= 0.01085\n",
      "epoch 509, batch 8, d_loss=-0.283 g_loss=-0.386 KID= 0.01085\n",
      "epoch 509, batch 9, d_loss=-0.245 g_loss=-0.327 KID= 0.01085\n",
      "epoch 509, batch 10, d_loss=-0.290 g_loss=-0.318 KID= 0.01085\n",
      "epoch 509, batch 11, d_loss=-0.298 g_loss=-0.385 KID= 0.01085\n",
      "epoch 509, batch 12, d_loss=-0.266 g_loss=-0.319 KID= 0.01085\n",
      "epoch 509, batch 13, d_loss=-0.278 g_loss=-0.236 KID= 0.01085\n",
      "epoch 509, batch 14, d_loss=-0.261 g_loss=-0.293 KID= 0.01085\n",
      "epoch 509, batch 15, d_loss=-0.179 g_loss=-0.377 KID= 0.01085\n",
      "epoch 509, batch 16, d_loss=-0.256 g_loss=-0.492 KID= 0.01085\n",
      "epoch 509, batch 17, d_loss=-0.296 g_loss=-0.508 KID= 0.01085\n",
      "epoch 509, batch 18, d_loss=-0.248 g_loss=-0.655 KID= 0.01085\n",
      "epoch 509, batch 19, d_loss=-0.273 g_loss=-0.584 KID= 0.01085\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 510, batch 0, d_loss=-0.322 g_loss=-0.535 KID= 0.00872\n",
      "epoch 510, batch 1, d_loss=-0.304 g_loss=-0.565 KID= 0.00872\n",
      "epoch 510, batch 2, d_loss=-0.206 g_loss=-0.521 KID= 0.00872\n",
      "epoch 510, batch 3, d_loss=-0.286 g_loss=-0.491 KID= 0.00872\n",
      "epoch 510, batch 4, d_loss=-0.254 g_loss=-0.495 KID= 0.00872\n",
      "epoch 510, batch 5, d_loss=-0.232 g_loss=-0.509 KID= 0.00872\n",
      "epoch 510, batch 6, d_loss=-0.274 g_loss=-0.386 KID= 0.00872\n",
      "epoch 510, batch 7, d_loss=-0.265 g_loss=-0.417 KID= 0.00872\n",
      "epoch 510, batch 8, d_loss=-0.305 g_loss=-0.498 KID= 0.00872\n",
      "epoch 510, batch 9, d_loss=-0.210 g_loss=-0.560 KID= 0.00872\n",
      "epoch 510, batch 10, d_loss=-0.262 g_loss=-0.504 KID= 0.00872\n",
      "epoch 510, batch 11, d_loss=-0.301 g_loss=-0.420 KID= 0.00872\n",
      "epoch 510, batch 12, d_loss=-0.242 g_loss=-0.285 KID= 0.00872\n",
      "epoch 510, batch 13, d_loss=-0.276 g_loss=-0.237 KID= 0.00872\n",
      "epoch 510, batch 14, d_loss=-0.234 g_loss=-0.297 KID= 0.00872\n",
      "epoch 510, batch 15, d_loss=-0.199 g_loss=-0.476 KID= 0.00872\n",
      "epoch 510, batch 16, d_loss=-0.217 g_loss=-0.588 KID= 0.00872\n",
      "epoch 510, batch 17, d_loss=-0.289 g_loss=-0.636 KID= 0.00872\n",
      "epoch 510, batch 18, d_loss=-0.268 g_loss=-0.617 KID= 0.00872\n",
      "epoch 510, batch 19, d_loss=-0.228 g_loss=-0.598 KID= 0.00872\n",
      "epoch 511, batch 0, d_loss=-0.326 g_loss=-0.591 KID= 0.00872\n",
      "epoch 511, batch 1, d_loss=-0.324 g_loss=-0.591 KID= 0.00872\n",
      "epoch 511, batch 2, d_loss=-0.170 g_loss=-0.599 KID= 0.00872\n",
      "epoch 511, batch 3, d_loss=-0.228 g_loss=-0.528 KID= 0.00872\n",
      "epoch 511, batch 4, d_loss=-0.211 g_loss=-0.495 KID= 0.00872\n",
      "epoch 511, batch 5, d_loss=-0.170 g_loss=-0.539 KID= 0.00872\n",
      "epoch 511, batch 6, d_loss=-0.214 g_loss=-0.464 KID= 0.00872\n",
      "epoch 511, batch 7, d_loss=-0.255 g_loss=-0.332 KID= 0.00872\n",
      "epoch 511, batch 8, d_loss=-0.291 g_loss=-0.222 KID= 0.00872\n",
      "epoch 511, batch 9, d_loss=-0.230 g_loss=-0.064 KID= 0.00872\n",
      "epoch 511, batch 10, d_loss=-0.312 g_loss=0.011 KID= 0.00872\n",
      "epoch 511, batch 11, d_loss=-0.327 g_loss=0.150 KID= 0.00872\n",
      "epoch 511, batch 12, d_loss=-0.216 g_loss=0.209 KID= 0.00872\n",
      "epoch 511, batch 13, d_loss=-0.277 g_loss=0.289 KID= 0.00872\n",
      "epoch 511, batch 14, d_loss=-0.259 g_loss=0.304 KID= 0.00872\n",
      "epoch 511, batch 15, d_loss=-0.213 g_loss=0.095 KID= 0.00872\n",
      "epoch 511, batch 16, d_loss=-0.195 g_loss=-0.070 KID= 0.00872\n",
      "epoch 511, batch 17, d_loss=-0.283 g_loss=-0.191 KID= 0.00872\n",
      "epoch 511, batch 18, d_loss=-0.296 g_loss=-0.319 KID= 0.00872\n",
      "epoch 511, batch 19, d_loss=-0.249 g_loss=-0.523 KID= 0.00872\n",
      "epoch 512, batch 0, d_loss=-0.297 g_loss=-0.561 KID= 0.00872\n",
      "epoch 512, batch 1, d_loss=-0.349 g_loss=-0.606 KID= 0.00872\n",
      "epoch 512, batch 2, d_loss=-0.184 g_loss=-0.512 KID= 0.00872\n",
      "epoch 512, batch 3, d_loss=-0.224 g_loss=-0.540 KID= 0.00872\n",
      "epoch 512, batch 4, d_loss=-0.247 g_loss=-0.498 KID= 0.00872\n",
      "epoch 512, batch 5, d_loss=-0.226 g_loss=-0.492 KID= 0.00872\n",
      "epoch 512, batch 6, d_loss=-0.255 g_loss=-0.440 KID= 0.00872\n",
      "epoch 512, batch 7, d_loss=-0.231 g_loss=-0.377 KID= 0.00872\n",
      "epoch 512, batch 8, d_loss=-0.316 g_loss=-0.415 KID= 0.00872\n",
      "epoch 512, batch 9, d_loss=-0.218 g_loss=-0.528 KID= 0.00872\n",
      "epoch 512, batch 10, d_loss=-0.303 g_loss=-0.577 KID= 0.00872\n",
      "epoch 512, batch 11, d_loss=-0.323 g_loss=-0.647 KID= 0.00872\n",
      "epoch 512, batch 12, d_loss=-0.200 g_loss=-0.673 KID= 0.00872\n",
      "epoch 512, batch 13, d_loss=-0.284 g_loss=-0.630 KID= 0.00872\n",
      "epoch 512, batch 14, d_loss=-0.285 g_loss=-0.561 KID= 0.00872\n",
      "epoch 512, batch 15, d_loss=-0.239 g_loss=-0.488 KID= 0.00872\n",
      "epoch 512, batch 16, d_loss=-0.254 g_loss=-0.535 KID= 0.00872\n",
      "epoch 512, batch 17, d_loss=-0.261 g_loss=-0.502 KID= 0.00872\n",
      "epoch 512, batch 18, d_loss=-0.270 g_loss=-0.558 KID= 0.00872\n",
      "epoch 512, batch 19, d_loss=-0.245 g_loss=-0.530 KID= 0.00872\n",
      "epoch 513, batch 0, d_loss=-0.300 g_loss=-0.440 KID= 0.00872\n",
      "epoch 513, batch 1, d_loss=-0.307 g_loss=-0.289 KID= 0.00872\n",
      "epoch 513, batch 2, d_loss=-0.259 g_loss=-0.070 KID= 0.00872\n",
      "epoch 513, batch 3, d_loss=-0.304 g_loss=0.007 KID= 0.00872\n",
      "epoch 513, batch 4, d_loss=-0.236 g_loss=-0.137 KID= 0.00872\n",
      "epoch 513, batch 5, d_loss=-0.223 g_loss=-0.278 KID= 0.00872\n",
      "epoch 513, batch 6, d_loss=-0.255 g_loss=-0.345 KID= 0.00872\n",
      "epoch 513, batch 7, d_loss=-0.256 g_loss=-0.339 KID= 0.00872\n",
      "epoch 513, batch 8, d_loss=-0.312 g_loss=-0.336 KID= 0.00872\n",
      "epoch 513, batch 9, d_loss=-0.264 g_loss=-0.427 KID= 0.00872\n",
      "epoch 513, batch 10, d_loss=-0.323 g_loss=-0.488 KID= 0.00872\n",
      "epoch 513, batch 11, d_loss=-0.380 g_loss=-0.509 KID= 0.00872\n",
      "epoch 513, batch 12, d_loss=-0.208 g_loss=-0.405 KID= 0.00872\n",
      "epoch 513, batch 13, d_loss=-0.272 g_loss=-0.349 KID= 0.00872\n",
      "epoch 513, batch 14, d_loss=-0.231 g_loss=-0.342 KID= 0.00872\n",
      "epoch 513, batch 15, d_loss=-0.202 g_loss=-0.391 KID= 0.00872\n",
      "epoch 513, batch 16, d_loss=-0.277 g_loss=-0.450 KID= 0.00872\n",
      "epoch 513, batch 17, d_loss=-0.262 g_loss=-0.413 KID= 0.00872\n",
      "epoch 513, batch 18, d_loss=-0.273 g_loss=-0.434 KID= 0.00872\n",
      "epoch 513, batch 19, d_loss=-0.246 g_loss=-0.450 KID= 0.00872\n",
      "epoch 514, batch 0, d_loss=-0.321 g_loss=-0.426 KID= 0.00872\n",
      "epoch 514, batch 1, d_loss=-0.314 g_loss=-0.380 KID= 0.00872\n",
      "epoch 514, batch 2, d_loss=-0.215 g_loss=-0.340 KID= 0.00872\n",
      "epoch 514, batch 3, d_loss=-0.280 g_loss=-0.306 KID= 0.00872\n",
      "epoch 514, batch 4, d_loss=-0.304 g_loss=-0.301 KID= 0.00872\n",
      "epoch 514, batch 5, d_loss=-0.159 g_loss=-0.348 KID= 0.00872\n",
      "epoch 514, batch 6, d_loss=-0.244 g_loss=-0.447 KID= 0.00872\n",
      "epoch 514, batch 7, d_loss=-0.285 g_loss=-0.476 KID= 0.00872\n",
      "epoch 514, batch 8, d_loss=-0.307 g_loss=-0.508 KID= 0.00872\n",
      "epoch 514, batch 9, d_loss=-0.247 g_loss=-0.497 KID= 0.00872\n",
      "epoch 514, batch 10, d_loss=-0.333 g_loss=-0.364 KID= 0.00872\n",
      "epoch 514, batch 11, d_loss=-0.327 g_loss=-0.320 KID= 0.00872\n",
      "epoch 514, batch 12, d_loss=-0.249 g_loss=-0.171 KID= 0.00872\n",
      "epoch 514, batch 13, d_loss=-0.270 g_loss=0.053 KID= 0.00872\n",
      "epoch 514, batch 14, d_loss=-0.224 g_loss=0.038 KID= 0.00872\n",
      "epoch 514, batch 15, d_loss=-0.201 g_loss=0.021 KID= 0.00872\n",
      "epoch 514, batch 16, d_loss=-0.273 g_loss=-0.069 KID= 0.00872\n",
      "epoch 514, batch 17, d_loss=-0.244 g_loss=-0.187 KID= 0.00872\n",
      "epoch 514, batch 18, d_loss=-0.312 g_loss=-0.296 KID= 0.00872\n",
      "epoch 514, batch 19, d_loss=-0.258 g_loss=-0.492 KID= 0.00872\n",
      "epoch 515, batch 0, d_loss=-0.333 g_loss=-0.543 KID= 0.00872\n",
      "epoch 515, batch 1, d_loss=-0.322 g_loss=-0.511 KID= 0.00872\n",
      "epoch 515, batch 2, d_loss=-0.266 g_loss=-0.472 KID= 0.00872\n",
      "epoch 515, batch 3, d_loss=-0.233 g_loss=-0.489 KID= 0.00872\n",
      "epoch 515, batch 4, d_loss=-0.250 g_loss=-0.512 KID= 0.00872\n",
      "epoch 515, batch 5, d_loss=-0.203 g_loss=-0.555 KID= 0.00872\n",
      "epoch 515, batch 6, d_loss=-0.239 g_loss=-0.729 KID= 0.00872\n",
      "epoch 515, batch 7, d_loss=-0.301 g_loss=-0.833 KID= 0.00872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 515, batch 8, d_loss=-0.269 g_loss=-0.877 KID= 0.00872\n",
      "epoch 515, batch 9, d_loss=-0.266 g_loss=-0.838 KID= 0.00872\n",
      "epoch 515, batch 10, d_loss=-0.299 g_loss=-0.724 KID= 0.00872\n",
      "epoch 515, batch 11, d_loss=-0.342 g_loss=-0.619 KID= 0.00872\n",
      "epoch 515, batch 12, d_loss=-0.291 g_loss=-0.496 KID= 0.00872\n",
      "epoch 515, batch 13, d_loss=-0.261 g_loss=-0.279 KID= 0.00872\n",
      "epoch 515, batch 14, d_loss=-0.234 g_loss=-0.157 KID= 0.00872\n",
      "epoch 515, batch 15, d_loss=-0.226 g_loss=-0.025 KID= 0.00872\n",
      "epoch 515, batch 16, d_loss=-0.248 g_loss=0.026 KID= 0.00872\n",
      "epoch 515, batch 17, d_loss=-0.258 g_loss=0.245 KID= 0.00872\n",
      "epoch 515, batch 18, d_loss=-0.316 g_loss=0.289 KID= 0.00872\n",
      "epoch 515, batch 19, d_loss=-0.188 g_loss=0.246 KID= 0.00872\n",
      "epoch 516, batch 0, d_loss=-0.334 g_loss=0.352 KID= 0.00872\n",
      "epoch 516, batch 1, d_loss=-0.310 g_loss=0.405 KID= 0.00872\n",
      "epoch 516, batch 2, d_loss=-0.247 g_loss=0.493 KID= 0.00872\n",
      "epoch 516, batch 3, d_loss=-0.259 g_loss=0.474 KID= 0.00872\n",
      "epoch 516, batch 4, d_loss=-0.259 g_loss=0.223 KID= 0.00872\n",
      "epoch 516, batch 5, d_loss=-0.191 g_loss=-0.060 KID= 0.00872\n",
      "epoch 516, batch 6, d_loss=-0.296 g_loss=-0.261 KID= 0.00872\n",
      "epoch 516, batch 7, d_loss=-0.253 g_loss=-0.439 KID= 0.00872\n",
      "epoch 516, batch 8, d_loss=-0.281 g_loss=-0.646 KID= 0.00872\n",
      "epoch 516, batch 9, d_loss=-0.227 g_loss=-0.780 KID= 0.00872\n",
      "epoch 516, batch 10, d_loss=-0.342 g_loss=-0.964 KID= 0.00872\n",
      "epoch 516, batch 11, d_loss=-0.307 g_loss=-1.202 KID= 0.00872\n",
      "epoch 516, batch 12, d_loss=-0.209 g_loss=-1.046 KID= 0.00872\n",
      "epoch 516, batch 13, d_loss=-0.241 g_loss=-0.893 KID= 0.00872\n",
      "epoch 516, batch 14, d_loss=-0.272 g_loss=-0.600 KID= 0.00872\n",
      "epoch 516, batch 15, d_loss=-0.172 g_loss=-0.362 KID= 0.00872\n",
      "epoch 516, batch 16, d_loss=-0.280 g_loss=-0.307 KID= 0.00872\n",
      "epoch 516, batch 17, d_loss=-0.280 g_loss=-0.244 KID= 0.00872\n",
      "epoch 516, batch 18, d_loss=-0.306 g_loss=-0.195 KID= 0.00872\n",
      "epoch 516, batch 19, d_loss=-0.266 g_loss=-0.199 KID= 0.00872\n",
      "epoch 517, batch 0, d_loss=-0.370 g_loss=-0.118 KID= 0.00872\n",
      "epoch 517, batch 1, d_loss=-0.349 g_loss=0.038 KID= 0.00872\n",
      "epoch 517, batch 2, d_loss=-0.279 g_loss=0.109 KID= 0.00872\n",
      "epoch 517, batch 3, d_loss=-0.227 g_loss=0.126 KID= 0.00872\n",
      "epoch 517, batch 4, d_loss=-0.267 g_loss=0.041 KID= 0.00872\n",
      "epoch 517, batch 5, d_loss=-0.171 g_loss=-0.159 KID= 0.00872\n",
      "epoch 517, batch 6, d_loss=-0.265 g_loss=-0.271 KID= 0.00872\n",
      "epoch 517, batch 7, d_loss=-0.273 g_loss=-0.394 KID= 0.00872\n",
      "epoch 517, batch 8, d_loss=-0.257 g_loss=-0.499 KID= 0.00872\n",
      "epoch 517, batch 9, d_loss=-0.270 g_loss=-0.647 KID= 0.00872\n",
      "epoch 517, batch 10, d_loss=-0.374 g_loss=-0.792 KID= 0.00872\n",
      "epoch 517, batch 11, d_loss=-0.342 g_loss=-0.938 KID= 0.00872\n",
      "epoch 517, batch 12, d_loss=-0.272 g_loss=-0.944 KID= 0.00872\n",
      "epoch 517, batch 13, d_loss=-0.264 g_loss=-0.942 KID= 0.00872\n",
      "epoch 517, batch 14, d_loss=-0.241 g_loss=-0.836 KID= 0.00872\n",
      "epoch 517, batch 15, d_loss=-0.197 g_loss=-0.677 KID= 0.00872\n",
      "epoch 517, batch 16, d_loss=-0.255 g_loss=-0.582 KID= 0.00872\n",
      "epoch 517, batch 17, d_loss=-0.309 g_loss=-0.548 KID= 0.00872\n",
      "epoch 517, batch 18, d_loss=-0.273 g_loss=-0.589 KID= 0.00872\n",
      "epoch 517, batch 19, d_loss=-0.261 g_loss=-0.509 KID= 0.00872\n",
      "epoch 518, batch 0, d_loss=-0.373 g_loss=-0.375 KID= 0.00872\n",
      "epoch 518, batch 1, d_loss=-0.364 g_loss=-0.218 KID= 0.00872\n",
      "epoch 518, batch 2, d_loss=-0.166 g_loss=-0.108 KID= 0.00872\n",
      "epoch 518, batch 3, d_loss=-0.234 g_loss=0.028 KID= 0.00872\n",
      "epoch 518, batch 4, d_loss=-0.277 g_loss=0.093 KID= 0.00872\n",
      "epoch 518, batch 5, d_loss=-0.199 g_loss=0.099 KID= 0.00872\n",
      "epoch 518, batch 6, d_loss=-0.272 g_loss=0.043 KID= 0.00872\n",
      "epoch 518, batch 7, d_loss=-0.287 g_loss=-0.096 KID= 0.00872\n",
      "epoch 518, batch 8, d_loss=-0.269 g_loss=-0.288 KID= 0.00872\n",
      "epoch 518, batch 9, d_loss=-0.307 g_loss=-0.457 KID= 0.00872\n",
      "epoch 518, batch 10, d_loss=-0.334 g_loss=-0.619 KID= 0.00872\n",
      "epoch 518, batch 11, d_loss=-0.315 g_loss=-0.733 KID= 0.00872\n",
      "epoch 518, batch 12, d_loss=-0.263 g_loss=-0.668 KID= 0.00872\n",
      "epoch 518, batch 13, d_loss=-0.254 g_loss=-0.590 KID= 0.00872\n",
      "epoch 518, batch 14, d_loss=-0.284 g_loss=-0.482 KID= 0.00872\n",
      "epoch 518, batch 15, d_loss=-0.147 g_loss=-0.302 KID= 0.00872\n",
      "epoch 518, batch 16, d_loss=-0.288 g_loss=-0.283 KID= 0.00872\n",
      "epoch 518, batch 17, d_loss=-0.283 g_loss=-0.261 KID= 0.00872\n",
      "epoch 518, batch 18, d_loss=-0.286 g_loss=-0.330 KID= 0.00872\n",
      "epoch 518, batch 19, d_loss=-0.265 g_loss=-0.401 KID= 0.00872\n",
      "epoch 519, batch 0, d_loss=-0.322 g_loss=-0.517 KID= 0.00872\n",
      "epoch 519, batch 1, d_loss=-0.344 g_loss=-0.549 KID= 0.00872\n",
      "epoch 519, batch 2, d_loss=-0.242 g_loss=-0.379 KID= 0.00872\n",
      "epoch 519, batch 3, d_loss=-0.239 g_loss=-0.278 KID= 0.00872\n",
      "epoch 519, batch 4, d_loss=-0.289 g_loss=-0.158 KID= 0.00872\n",
      "epoch 519, batch 5, d_loss=-0.210 g_loss=-0.122 KID= 0.00872\n",
      "epoch 519, batch 6, d_loss=-0.299 g_loss=-0.120 KID= 0.00872\n",
      "epoch 519, batch 7, d_loss=-0.295 g_loss=-0.203 KID= 0.00872\n",
      "epoch 519, batch 8, d_loss=-0.262 g_loss=-0.321 KID= 0.00872\n",
      "epoch 519, batch 9, d_loss=-0.263 g_loss=-0.337 KID= 0.00872\n",
      "epoch 519, batch 10, d_loss=-0.336 g_loss=-0.389 KID= 0.00872\n",
      "epoch 519, batch 11, d_loss=-0.347 g_loss=-0.441 KID= 0.00872\n",
      "epoch 519, batch 12, d_loss=-0.257 g_loss=-0.426 KID= 0.00872\n",
      "epoch 519, batch 13, d_loss=-0.274 g_loss=-0.368 KID= 0.00872\n",
      "epoch 519, batch 14, d_loss=-0.302 g_loss=-0.301 KID= 0.00872\n",
      "epoch 519, batch 15, d_loss=-0.227 g_loss=-0.255 KID= 0.00872\n",
      "epoch 519, batch 16, d_loss=-0.260 g_loss=-0.267 KID= 0.00872\n",
      "epoch 519, batch 17, d_loss=-0.267 g_loss=-0.350 KID= 0.00872\n",
      "epoch 519, batch 18, d_loss=-0.278 g_loss=-0.485 KID= 0.00872\n",
      "epoch 519, batch 19, d_loss=-0.246 g_loss=-0.593 KID= 0.00872\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 520, batch 0, d_loss=-0.353 g_loss=-0.625 KID= 0.00560\n",
      "epoch 520, batch 1, d_loss=-0.363 g_loss=-0.634 KID= 0.00560\n",
      "epoch 520, batch 2, d_loss=-0.207 g_loss=-0.581 KID= 0.00560\n",
      "epoch 520, batch 3, d_loss=-0.255 g_loss=-0.562 KID= 0.00560\n",
      "epoch 520, batch 4, d_loss=-0.319 g_loss=-0.553 KID= 0.00560\n",
      "epoch 520, batch 5, d_loss=-0.137 g_loss=-0.415 KID= 0.00560\n",
      "epoch 520, batch 6, d_loss=-0.267 g_loss=-0.347 KID= 0.00560\n",
      "epoch 520, batch 7, d_loss=-0.280 g_loss=-0.339 KID= 0.00560\n",
      "epoch 520, batch 8, d_loss=-0.302 g_loss=-0.353 KID= 0.00560\n",
      "epoch 520, batch 9, d_loss=-0.287 g_loss=-0.469 KID= 0.00560\n",
      "epoch 520, batch 10, d_loss=-0.354 g_loss=-0.579 KID= 0.00560\n",
      "epoch 520, batch 11, d_loss=-0.345 g_loss=-0.665 KID= 0.00560\n",
      "epoch 520, batch 12, d_loss=-0.270 g_loss=-0.509 KID= 0.00560\n",
      "epoch 520, batch 13, d_loss=-0.262 g_loss=-0.301 KID= 0.00560\n",
      "epoch 520, batch 14, d_loss=-0.293 g_loss=-0.163 KID= 0.00560\n",
      "epoch 520, batch 15, d_loss=-0.181 g_loss=0.093 KID= 0.00560\n",
      "epoch 520, batch 16, d_loss=-0.345 g_loss=0.237 KID= 0.00560\n",
      "epoch 520, batch 17, d_loss=-0.300 g_loss=0.227 KID= 0.00560\n",
      "epoch 520, batch 18, d_loss=-0.288 g_loss=0.250 KID= 0.00560\n",
      "epoch 520, batch 19, d_loss=-0.286 g_loss=0.086 KID= 0.00560\n",
      "epoch 521, batch 0, d_loss=-0.348 g_loss=-0.077 KID= 0.00560\n",
      "epoch 521, batch 1, d_loss=-0.352 g_loss=-0.165 KID= 0.00560\n",
      "epoch 521, batch 2, d_loss=-0.222 g_loss=-0.242 KID= 0.00560\n",
      "epoch 521, batch 3, d_loss=-0.260 g_loss=-0.293 KID= 0.00560\n",
      "epoch 521, batch 4, d_loss=-0.314 g_loss=-0.309 KID= 0.00560\n",
      "epoch 521, batch 5, d_loss=-0.160 g_loss=-0.299 KID= 0.00560\n",
      "epoch 521, batch 6, d_loss=-0.292 g_loss=-0.297 KID= 0.00560\n",
      "epoch 521, batch 7, d_loss=-0.287 g_loss=-0.387 KID= 0.00560\n",
      "epoch 521, batch 8, d_loss=-0.270 g_loss=-0.569 KID= 0.00560\n",
      "epoch 521, batch 9, d_loss=-0.317 g_loss=-0.729 KID= 0.00560\n",
      "epoch 521, batch 10, d_loss=-0.347 g_loss=-0.869 KID= 0.00560\n",
      "epoch 521, batch 11, d_loss=-0.331 g_loss=-0.857 KID= 0.00560\n",
      "epoch 521, batch 12, d_loss=-0.258 g_loss=-0.740 KID= 0.00560\n",
      "epoch 521, batch 13, d_loss=-0.272 g_loss=-0.704 KID= 0.00560\n",
      "epoch 521, batch 14, d_loss=-0.299 g_loss=-0.573 KID= 0.00560\n",
      "epoch 521, batch 15, d_loss=-0.198 g_loss=-0.379 KID= 0.00560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 521, batch 16, d_loss=-0.284 g_loss=-0.297 KID= 0.00560\n",
      "epoch 521, batch 17, d_loss=-0.319 g_loss=-0.209 KID= 0.00560\n",
      "epoch 521, batch 18, d_loss=-0.240 g_loss=-0.225 KID= 0.00560\n",
      "epoch 521, batch 19, d_loss=-0.308 g_loss=-0.265 KID= 0.00560\n",
      "epoch 522, batch 0, d_loss=-0.358 g_loss=-0.216 KID= 0.00560\n",
      "epoch 522, batch 1, d_loss=-0.316 g_loss=-0.194 KID= 0.00560\n",
      "epoch 522, batch 2, d_loss=-0.248 g_loss=-0.187 KID= 0.00560\n",
      "epoch 522, batch 3, d_loss=-0.292 g_loss=-0.173 KID= 0.00560\n",
      "epoch 522, batch 4, d_loss=-0.233 g_loss=-0.099 KID= 0.00560\n",
      "epoch 522, batch 5, d_loss=-0.145 g_loss=-0.023 KID= 0.00560\n",
      "epoch 522, batch 6, d_loss=-0.311 g_loss=-0.146 KID= 0.00560\n",
      "epoch 522, batch 7, d_loss=-0.281 g_loss=-0.282 KID= 0.00560\n",
      "epoch 522, batch 8, d_loss=-0.271 g_loss=-0.500 KID= 0.00560\n",
      "epoch 522, batch 9, d_loss=-0.296 g_loss=-0.609 KID= 0.00560\n",
      "epoch 522, batch 10, d_loss=-0.334 g_loss=-0.656 KID= 0.00560\n",
      "epoch 522, batch 11, d_loss=-0.390 g_loss=-0.820 KID= 0.00560\n",
      "epoch 522, batch 12, d_loss=-0.245 g_loss=-0.716 KID= 0.00560\n",
      "epoch 522, batch 13, d_loss=-0.289 g_loss=-0.661 KID= 0.00560\n",
      "epoch 522, batch 14, d_loss=-0.320 g_loss=-0.582 KID= 0.00560\n",
      "epoch 522, batch 15, d_loss=-0.146 g_loss=-0.357 KID= 0.00560\n",
      "epoch 522, batch 16, d_loss=-0.276 g_loss=-0.171 KID= 0.00560\n",
      "epoch 522, batch 17, d_loss=-0.275 g_loss=-0.040 KID= 0.00560\n",
      "epoch 522, batch 18, d_loss=-0.209 g_loss=-0.067 KID= 0.00560\n",
      "epoch 522, batch 19, d_loss=-0.295 g_loss=-0.138 KID= 0.00560\n",
      "epoch 523, batch 0, d_loss=-0.366 g_loss=-0.255 KID= 0.00560\n",
      "epoch 523, batch 1, d_loss=-0.352 g_loss=-0.371 KID= 0.00560\n",
      "epoch 523, batch 2, d_loss=-0.209 g_loss=-0.384 KID= 0.00560\n",
      "epoch 523, batch 3, d_loss=-0.238 g_loss=-0.412 KID= 0.00560\n",
      "epoch 523, batch 4, d_loss=-0.291 g_loss=-0.336 KID= 0.00560\n",
      "epoch 523, batch 5, d_loss=-0.159 g_loss=-0.200 KID= 0.00560\n",
      "epoch 523, batch 6, d_loss=-0.276 g_loss=-0.139 KID= 0.00560\n",
      "epoch 523, batch 7, d_loss=-0.280 g_loss=-0.133 KID= 0.00560\n",
      "epoch 523, batch 8, d_loss=-0.289 g_loss=-0.250 KID= 0.00560\n",
      "epoch 523, batch 9, d_loss=-0.303 g_loss=-0.443 KID= 0.00560\n",
      "epoch 523, batch 10, d_loss=-0.353 g_loss=-0.609 KID= 0.00560\n",
      "epoch 523, batch 11, d_loss=-0.272 g_loss=-0.685 KID= 0.00560\n",
      "epoch 523, batch 12, d_loss=-0.240 g_loss=-0.720 KID= 0.00560\n",
      "epoch 523, batch 13, d_loss=-0.282 g_loss=-0.671 KID= 0.00560\n",
      "epoch 523, batch 14, d_loss=-0.291 g_loss=-0.558 KID= 0.00560\n",
      "epoch 523, batch 15, d_loss=-0.201 g_loss=-0.383 KID= 0.00560\n",
      "epoch 523, batch 16, d_loss=-0.324 g_loss=-0.234 KID= 0.00560\n",
      "epoch 523, batch 17, d_loss=-0.283 g_loss=-0.212 KID= 0.00560\n",
      "epoch 523, batch 18, d_loss=-0.256 g_loss=-0.258 KID= 0.00560\n",
      "epoch 523, batch 19, d_loss=-0.291 g_loss=-0.378 KID= 0.00560\n",
      "epoch 524, batch 0, d_loss=-0.394 g_loss=-0.526 KID= 0.00560\n",
      "epoch 524, batch 1, d_loss=-0.394 g_loss=-0.612 KID= 0.00560\n",
      "epoch 524, batch 2, d_loss=-0.226 g_loss=-0.502 KID= 0.00560\n",
      "epoch 524, batch 3, d_loss=-0.305 g_loss=-0.454 KID= 0.00560\n",
      "epoch 524, batch 4, d_loss=-0.278 g_loss=-0.317 KID= 0.00560\n",
      "epoch 524, batch 5, d_loss=-0.178 g_loss=-0.227 KID= 0.00560\n",
      "epoch 524, batch 6, d_loss=-0.308 g_loss=-0.193 KID= 0.00560\n",
      "epoch 524, batch 7, d_loss=-0.275 g_loss=-0.188 KID= 0.00560\n",
      "epoch 524, batch 8, d_loss=-0.262 g_loss=-0.341 KID= 0.00560\n",
      "epoch 524, batch 9, d_loss=-0.323 g_loss=-0.422 KID= 0.00560\n",
      "epoch 524, batch 10, d_loss=-0.334 g_loss=-0.470 KID= 0.00560\n",
      "epoch 524, batch 11, d_loss=-0.281 g_loss=-0.542 KID= 0.00560\n",
      "epoch 524, batch 12, d_loss=-0.264 g_loss=-0.502 KID= 0.00560\n",
      "epoch 524, batch 13, d_loss=-0.292 g_loss=-0.418 KID= 0.00560\n",
      "epoch 524, batch 14, d_loss=-0.288 g_loss=-0.304 KID= 0.00560\n",
      "epoch 524, batch 15, d_loss=-0.165 g_loss=-0.083 KID= 0.00560\n",
      "epoch 524, batch 16, d_loss=-0.281 g_loss=0.057 KID= 0.00560\n",
      "epoch 524, batch 17, d_loss=-0.265 g_loss=0.119 KID= 0.00560\n",
      "epoch 524, batch 18, d_loss=-0.233 g_loss=0.059 KID= 0.00560\n",
      "epoch 524, batch 19, d_loss=-0.282 g_loss=-0.146 KID= 0.00560\n",
      "epoch 525, batch 0, d_loss=-0.368 g_loss=-0.406 KID= 0.00560\n",
      "epoch 525, batch 1, d_loss=-0.348 g_loss=-0.708 KID= 0.00560\n",
      "epoch 525, batch 2, d_loss=-0.246 g_loss=-0.825 KID= 0.00560\n",
      "epoch 525, batch 3, d_loss=-0.283 g_loss=-0.924 KID= 0.00560\n",
      "epoch 525, batch 4, d_loss=-0.262 g_loss=-0.856 KID= 0.00560\n",
      "epoch 525, batch 5, d_loss=-0.200 g_loss=-0.577 KID= 0.00560\n",
      "epoch 525, batch 6, d_loss=-0.265 g_loss=-0.340 KID= 0.00560\n",
      "epoch 525, batch 7, d_loss=-0.301 g_loss=-0.175 KID= 0.00560\n",
      "epoch 525, batch 8, d_loss=-0.279 g_loss=-0.202 KID= 0.00560\n",
      "epoch 525, batch 9, d_loss=-0.266 g_loss=-0.302 KID= 0.00560\n",
      "epoch 525, batch 10, d_loss=-0.400 g_loss=-0.421 KID= 0.00560\n",
      "epoch 525, batch 11, d_loss=-0.335 g_loss=-0.526 KID= 0.00560\n",
      "epoch 525, batch 12, d_loss=-0.241 g_loss=-0.564 KID= 0.00560\n",
      "epoch 525, batch 13, d_loss=-0.329 g_loss=-0.586 KID= 0.00560\n",
      "epoch 525, batch 14, d_loss=-0.266 g_loss=-0.405 KID= 0.00560\n",
      "epoch 525, batch 15, d_loss=-0.203 g_loss=-0.242 KID= 0.00560\n",
      "epoch 525, batch 16, d_loss=-0.267 g_loss=-0.098 KID= 0.00560\n",
      "epoch 525, batch 17, d_loss=-0.259 g_loss=-0.024 KID= 0.00560\n",
      "epoch 525, batch 18, d_loss=-0.233 g_loss=-0.019 KID= 0.00560\n",
      "epoch 525, batch 19, d_loss=-0.310 g_loss=-0.101 KID= 0.00560\n",
      "epoch 526, batch 0, d_loss=-0.348 g_loss=-0.272 KID= 0.00560\n",
      "epoch 526, batch 1, d_loss=-0.301 g_loss=-0.477 KID= 0.00560\n",
      "epoch 526, batch 2, d_loss=-0.327 g_loss=-0.657 KID= 0.00560\n",
      "epoch 526, batch 3, d_loss=-0.265 g_loss=-0.738 KID= 0.00560\n",
      "epoch 526, batch 4, d_loss=-0.282 g_loss=-0.806 KID= 0.00560\n",
      "epoch 526, batch 5, d_loss=-0.173 g_loss=-0.489 KID= 0.00560\n",
      "epoch 526, batch 6, d_loss=-0.274 g_loss=-0.162 KID= 0.00560\n",
      "epoch 526, batch 7, d_loss=-0.276 g_loss=0.035 KID= 0.00560\n",
      "epoch 526, batch 8, d_loss=-0.240 g_loss=0.175 KID= 0.00560\n",
      "epoch 526, batch 9, d_loss=-0.277 g_loss=0.215 KID= 0.00560\n",
      "epoch 526, batch 10, d_loss=-0.355 g_loss=0.114 KID= 0.00560\n",
      "epoch 526, batch 11, d_loss=-0.288 g_loss=-0.101 KID= 0.00560\n",
      "epoch 526, batch 12, d_loss=-0.265 g_loss=-0.115 KID= 0.00560\n",
      "epoch 526, batch 13, d_loss=-0.337 g_loss=-0.180 KID= 0.00560\n",
      "epoch 526, batch 14, d_loss=-0.235 g_loss=-0.150 KID= 0.00560\n",
      "epoch 526, batch 15, d_loss=-0.140 g_loss=-0.060 KID= 0.00560\n",
      "epoch 526, batch 16, d_loss=-0.298 g_loss=0.047 KID= 0.00560\n",
      "epoch 526, batch 17, d_loss=-0.276 g_loss=0.182 KID= 0.00560\n",
      "epoch 526, batch 18, d_loss=-0.227 g_loss=0.294 KID= 0.00560\n",
      "epoch 526, batch 19, d_loss=-0.321 g_loss=0.182 KID= 0.00560\n",
      "epoch 527, batch 0, d_loss=-0.337 g_loss=-0.108 KID= 0.00560\n",
      "epoch 527, batch 1, d_loss=-0.291 g_loss=-0.480 KID= 0.00560\n",
      "epoch 527, batch 2, d_loss=-0.283 g_loss=-0.759 KID= 0.00560\n",
      "epoch 527, batch 3, d_loss=-0.306 g_loss=-1.027 KID= 0.00560\n",
      "epoch 527, batch 4, d_loss=-0.304 g_loss=-1.170 KID= 0.00560\n",
      "epoch 527, batch 5, d_loss=-0.219 g_loss=-1.053 KID= 0.00560\n",
      "epoch 527, batch 6, d_loss=-0.269 g_loss=-0.881 KID= 0.00560\n",
      "epoch 527, batch 7, d_loss=-0.209 g_loss=-0.696 KID= 0.00560\n",
      "epoch 527, batch 8, d_loss=-0.229 g_loss=-0.547 KID= 0.00560\n",
      "epoch 527, batch 9, d_loss=-0.263 g_loss=-0.355 KID= 0.00560\n",
      "epoch 527, batch 10, d_loss=-0.291 g_loss=-0.250 KID= 0.00560\n",
      "epoch 527, batch 11, d_loss=-0.291 g_loss=-0.265 KID= 0.00560\n",
      "epoch 527, batch 12, d_loss=-0.288 g_loss=-0.230 KID= 0.00560\n",
      "epoch 527, batch 13, d_loss=-0.234 g_loss=-0.128 KID= 0.00560\n",
      "epoch 527, batch 14, d_loss=-0.314 g_loss=-0.098 KID= 0.00560\n",
      "epoch 527, batch 15, d_loss=-0.200 g_loss=-0.022 KID= 0.00560\n",
      "epoch 527, batch 16, d_loss=-0.266 g_loss=0.006 KID= 0.00560\n",
      "epoch 527, batch 17, d_loss=-0.260 g_loss=0.145 KID= 0.00560\n",
      "epoch 527, batch 18, d_loss=-0.240 g_loss=0.231 KID= 0.00560\n",
      "epoch 527, batch 19, d_loss=-0.294 g_loss=0.243 KID= 0.00560\n",
      "epoch 528, batch 0, d_loss=-0.321 g_loss=0.195 KID= 0.00560\n",
      "epoch 528, batch 1, d_loss=-0.265 g_loss=-0.075 KID= 0.00560\n",
      "epoch 528, batch 2, d_loss=-0.252 g_loss=-0.286 KID= 0.00560\n",
      "epoch 528, batch 3, d_loss=-0.272 g_loss=-0.462 KID= 0.00560\n",
      "epoch 528, batch 4, d_loss=-0.336 g_loss=-0.601 KID= 0.00560\n",
      "epoch 528, batch 5, d_loss=-0.203 g_loss=-0.589 KID= 0.00560\n",
      "epoch 528, batch 6, d_loss=-0.308 g_loss=-0.533 KID= 0.00560\n",
      "epoch 528, batch 7, d_loss=-0.219 g_loss=-0.464 KID= 0.00560\n",
      "epoch 528, batch 8, d_loss=-0.196 g_loss=-0.479 KID= 0.00560\n",
      "epoch 528, batch 9, d_loss=-0.318 g_loss=-0.491 KID= 0.00560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 528, batch 10, d_loss=-0.359 g_loss=-0.575 KID= 0.00560\n",
      "epoch 528, batch 11, d_loss=-0.286 g_loss=-0.831 KID= 0.00560\n",
      "epoch 528, batch 12, d_loss=-0.263 g_loss=-0.922 KID= 0.00560\n",
      "epoch 528, batch 13, d_loss=-0.288 g_loss=-0.942 KID= 0.00560\n",
      "epoch 528, batch 14, d_loss=-0.264 g_loss=-0.851 KID= 0.00560\n",
      "epoch 528, batch 15, d_loss=-0.272 g_loss=-0.794 KID= 0.00560\n",
      "epoch 528, batch 16, d_loss=-0.242 g_loss=-0.545 KID= 0.00560\n",
      "epoch 528, batch 17, d_loss=-0.258 g_loss=-0.413 KID= 0.00560\n",
      "epoch 528, batch 18, d_loss=-0.194 g_loss=-0.188 KID= 0.00560\n",
      "epoch 528, batch 19, d_loss=-0.290 g_loss=-0.026 KID= 0.00560\n",
      "epoch 529, batch 0, d_loss=-0.318 g_loss=0.072 KID= 0.00560\n",
      "epoch 529, batch 1, d_loss=-0.267 g_loss=-0.009 KID= 0.00560\n",
      "epoch 529, batch 2, d_loss=-0.272 g_loss=-0.084 KID= 0.00560\n",
      "epoch 529, batch 3, d_loss=-0.303 g_loss=-0.237 KID= 0.00560\n",
      "epoch 529, batch 4, d_loss=-0.287 g_loss=-0.343 KID= 0.00560\n",
      "epoch 529, batch 5, d_loss=-0.251 g_loss=-0.397 KID= 0.00560\n",
      "epoch 529, batch 6, d_loss=-0.304 g_loss=-0.325 KID= 0.00560\n",
      "epoch 529, batch 7, d_loss=-0.261 g_loss=-0.318 KID= 0.00560\n",
      "epoch 529, batch 8, d_loss=-0.249 g_loss=-0.373 KID= 0.00560\n",
      "epoch 529, batch 9, d_loss=-0.304 g_loss=-0.455 KID= 0.00560\n",
      "epoch 529, batch 10, d_loss=-0.340 g_loss=-0.583 KID= 0.00560\n",
      "epoch 529, batch 11, d_loss=-0.270 g_loss=-0.754 KID= 0.00560\n",
      "epoch 529, batch 12, d_loss=-0.292 g_loss=-0.759 KID= 0.00560\n",
      "epoch 529, batch 13, d_loss=-0.303 g_loss=-0.763 KID= 0.00560\n",
      "epoch 529, batch 14, d_loss=-0.311 g_loss=-0.778 KID= 0.00560\n",
      "epoch 529, batch 15, d_loss=-0.229 g_loss=-0.725 KID= 0.00560\n",
      "epoch 529, batch 16, d_loss=-0.268 g_loss=-0.571 KID= 0.00560\n",
      "epoch 529, batch 17, d_loss=-0.275 g_loss=-0.449 KID= 0.00560\n",
      "epoch 529, batch 18, d_loss=-0.229 g_loss=-0.362 KID= 0.00560\n",
      "epoch 529, batch 19, d_loss=-0.324 g_loss=-0.227 KID= 0.00560\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 530, batch 0, d_loss=-0.392 g_loss=-0.091 KID= 0.01225\n",
      "epoch 530, batch 1, d_loss=-0.290 g_loss=-0.139 KID= 0.01225\n",
      "epoch 530, batch 2, d_loss=-0.241 g_loss=-0.293 KID= 0.01225\n",
      "epoch 530, batch 3, d_loss=-0.263 g_loss=-0.322 KID= 0.01225\n",
      "epoch 530, batch 4, d_loss=-0.281 g_loss=-0.367 KID= 0.01225\n",
      "epoch 530, batch 5, d_loss=-0.229 g_loss=-0.263 KID= 0.01225\n",
      "epoch 530, batch 6, d_loss=-0.278 g_loss=-0.194 KID= 0.01225\n",
      "epoch 530, batch 7, d_loss=-0.255 g_loss=-0.036 KID= 0.01225\n",
      "epoch 530, batch 8, d_loss=-0.217 g_loss=0.063 KID= 0.01225\n",
      "epoch 530, batch 9, d_loss=-0.395 g_loss=-0.044 KID= 0.01225\n",
      "epoch 530, batch 10, d_loss=-0.388 g_loss=-0.242 KID= 0.01225\n",
      "epoch 530, batch 11, d_loss=-0.303 g_loss=-0.557 KID= 0.01225\n",
      "epoch 530, batch 12, d_loss=-0.271 g_loss=-0.720 KID= 0.01225\n",
      "epoch 530, batch 13, d_loss=-0.307 g_loss=-0.828 KID= 0.01225\n",
      "epoch 530, batch 14, d_loss=-0.317 g_loss=-0.963 KID= 0.01225\n",
      "epoch 530, batch 15, d_loss=-0.236 g_loss=-0.884 KID= 0.01225\n",
      "epoch 530, batch 16, d_loss=-0.275 g_loss=-0.888 KID= 0.01225\n",
      "epoch 530, batch 17, d_loss=-0.265 g_loss=-0.783 KID= 0.01225\n",
      "epoch 530, batch 18, d_loss=-0.215 g_loss=-0.637 KID= 0.01225\n",
      "epoch 530, batch 19, d_loss=-0.281 g_loss=-0.513 KID= 0.01225\n",
      "epoch 531, batch 0, d_loss=-0.352 g_loss=-0.396 KID= 0.01225\n",
      "epoch 531, batch 1, d_loss=-0.305 g_loss=-0.378 KID= 0.01225\n",
      "epoch 531, batch 2, d_loss=-0.245 g_loss=-0.276 KID= 0.01225\n",
      "epoch 531, batch 3, d_loss=-0.327 g_loss=-0.275 KID= 0.01225\n",
      "epoch 531, batch 4, d_loss=-0.227 g_loss=-0.295 KID= 0.01225\n",
      "epoch 531, batch 5, d_loss=-0.280 g_loss=-0.324 KID= 0.01225\n",
      "epoch 531, batch 6, d_loss=-0.308 g_loss=-0.261 KID= 0.01225\n",
      "epoch 531, batch 7, d_loss=-0.295 g_loss=-0.140 KID= 0.01225\n",
      "epoch 531, batch 8, d_loss=-0.235 g_loss=-0.065 KID= 0.01225\n",
      "epoch 531, batch 9, d_loss=-0.377 g_loss=-0.059 KID= 0.01225\n",
      "epoch 531, batch 10, d_loss=-0.326 g_loss=-0.102 KID= 0.01225\n",
      "epoch 531, batch 11, d_loss=-0.261 g_loss=-0.291 KID= 0.01225\n",
      "epoch 531, batch 12, d_loss=-0.263 g_loss=-0.412 KID= 0.01225\n",
      "epoch 531, batch 13, d_loss=-0.282 g_loss=-0.509 KID= 0.01225\n",
      "epoch 531, batch 14, d_loss=-0.300 g_loss=-0.650 KID= 0.01225\n",
      "epoch 531, batch 15, d_loss=-0.252 g_loss=-0.781 KID= 0.01225\n",
      "epoch 531, batch 16, d_loss=-0.254 g_loss=-0.788 KID= 0.01225\n",
      "epoch 531, batch 17, d_loss=-0.254 g_loss=-0.786 KID= 0.01225\n",
      "epoch 531, batch 18, d_loss=-0.213 g_loss=-0.734 KID= 0.01225\n",
      "epoch 531, batch 19, d_loss=-0.347 g_loss=-0.623 KID= 0.01225\n",
      "epoch 532, batch 0, d_loss=-0.328 g_loss=-0.633 KID= 0.01225\n",
      "epoch 532, batch 1, d_loss=-0.317 g_loss=-0.778 KID= 0.01225\n",
      "epoch 532, batch 2, d_loss=-0.284 g_loss=-0.769 KID= 0.01225\n",
      "epoch 532, batch 3, d_loss=-0.360 g_loss=-0.781 KID= 0.01225\n",
      "epoch 532, batch 4, d_loss=-0.230 g_loss=-0.764 KID= 0.01225\n",
      "epoch 532, batch 5, d_loss=-0.227 g_loss=-0.485 KID= 0.01225\n",
      "epoch 532, batch 6, d_loss=-0.286 g_loss=-0.258 KID= 0.01225\n",
      "epoch 532, batch 7, d_loss=-0.274 g_loss=-0.110 KID= 0.01225\n",
      "epoch 532, batch 8, d_loss=-0.233 g_loss=0.026 KID= 0.01225\n",
      "epoch 532, batch 9, d_loss=-0.359 g_loss=0.163 KID= 0.01225\n",
      "epoch 532, batch 10, d_loss=-0.320 g_loss=0.211 KID= 0.01225\n",
      "epoch 532, batch 11, d_loss=-0.315 g_loss=0.166 KID= 0.01225\n",
      "epoch 532, batch 12, d_loss=-0.309 g_loss=0.137 KID= 0.01225\n",
      "epoch 532, batch 13, d_loss=-0.313 g_loss=-0.010 KID= 0.01225\n",
      "epoch 532, batch 14, d_loss=-0.256 g_loss=-0.240 KID= 0.01225\n",
      "epoch 532, batch 15, d_loss=-0.250 g_loss=-0.375 KID= 0.01225\n",
      "epoch 532, batch 16, d_loss=-0.310 g_loss=-0.462 KID= 0.01225\n",
      "epoch 532, batch 17, d_loss=-0.323 g_loss=-0.634 KID= 0.01225\n",
      "epoch 532, batch 18, d_loss=-0.183 g_loss=-0.600 KID= 0.01225\n",
      "epoch 532, batch 19, d_loss=-0.285 g_loss=-0.663 KID= 0.01225\n",
      "epoch 533, batch 0, d_loss=-0.352 g_loss=-0.641 KID= 0.01225\n",
      "epoch 533, batch 1, d_loss=-0.304 g_loss=-0.691 KID= 0.01225\n",
      "epoch 533, batch 2, d_loss=-0.239 g_loss=-0.525 KID= 0.01225\n",
      "epoch 533, batch 3, d_loss=-0.316 g_loss=-0.504 KID= 0.01225\n",
      "epoch 533, batch 4, d_loss=-0.291 g_loss=-0.504 KID= 0.01225\n",
      "epoch 533, batch 5, d_loss=-0.229 g_loss=-0.334 KID= 0.01225\n",
      "epoch 533, batch 6, d_loss=-0.296 g_loss=-0.187 KID= 0.01225\n",
      "epoch 533, batch 7, d_loss=-0.320 g_loss=-0.188 KID= 0.01225\n",
      "epoch 533, batch 8, d_loss=-0.241 g_loss=-0.144 KID= 0.01225\n",
      "epoch 533, batch 9, d_loss=-0.333 g_loss=-0.167 KID= 0.01225\n",
      "epoch 533, batch 10, d_loss=-0.303 g_loss=-0.337 KID= 0.01225\n",
      "epoch 533, batch 11, d_loss=-0.303 g_loss=-0.515 KID= 0.01225\n",
      "epoch 533, batch 12, d_loss=-0.261 g_loss=-0.639 KID= 0.01225\n",
      "epoch 533, batch 13, d_loss=-0.340 g_loss=-0.801 KID= 0.01225\n",
      "epoch 533, batch 14, d_loss=-0.298 g_loss=-1.024 KID= 0.01225\n",
      "epoch 533, batch 15, d_loss=-0.226 g_loss=-1.054 KID= 0.01225\n",
      "epoch 533, batch 16, d_loss=-0.318 g_loss=-0.931 KID= 0.01225\n",
      "epoch 533, batch 17, d_loss=-0.273 g_loss=-0.735 KID= 0.01225\n",
      "epoch 533, batch 18, d_loss=-0.202 g_loss=-0.505 KID= 0.01225\n",
      "epoch 533, batch 19, d_loss=-0.352 g_loss=-0.302 KID= 0.01225\n",
      "epoch 534, batch 0, d_loss=-0.380 g_loss=-0.309 KID= 0.01225\n",
      "epoch 534, batch 1, d_loss=-0.308 g_loss=-0.385 KID= 0.01225\n",
      "epoch 534, batch 2, d_loss=-0.285 g_loss=-0.357 KID= 0.01225\n",
      "epoch 534, batch 3, d_loss=-0.285 g_loss=-0.385 KID= 0.01225\n",
      "epoch 534, batch 4, d_loss=-0.304 g_loss=-0.486 KID= 0.01225\n",
      "epoch 534, batch 5, d_loss=-0.224 g_loss=-0.402 KID= 0.01225\n",
      "epoch 534, batch 6, d_loss=-0.292 g_loss=-0.387 KID= 0.01225\n",
      "epoch 534, batch 7, d_loss=-0.338 g_loss=-0.350 KID= 0.01225\n",
      "epoch 534, batch 8, d_loss=-0.214 g_loss=-0.296 KID= 0.01225\n",
      "epoch 534, batch 9, d_loss=-0.363 g_loss=-0.262 KID= 0.01225\n",
      "epoch 534, batch 10, d_loss=-0.365 g_loss=-0.265 KID= 0.01225\n",
      "epoch 534, batch 11, d_loss=-0.269 g_loss=-0.316 KID= 0.01225\n",
      "epoch 534, batch 12, d_loss=-0.250 g_loss=-0.353 KID= 0.01225\n",
      "epoch 534, batch 13, d_loss=-0.334 g_loss=-0.391 KID= 0.01225\n",
      "epoch 534, batch 14, d_loss=-0.290 g_loss=-0.530 KID= 0.01225\n",
      "epoch 534, batch 15, d_loss=-0.227 g_loss=-0.532 KID= 0.01225\n",
      "epoch 534, batch 16, d_loss=-0.344 g_loss=-0.325 KID= 0.01225\n",
      "epoch 534, batch 17, d_loss=-0.338 g_loss=-0.217 KID= 0.01225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 534, batch 18, d_loss=-0.242 g_loss=0.029 KID= 0.01225\n",
      "epoch 534, batch 19, d_loss=-0.360 g_loss=0.111 KID= 0.01225\n",
      "epoch 535, batch 0, d_loss=-0.351 g_loss=0.063 KID= 0.01225\n",
      "epoch 535, batch 1, d_loss=-0.362 g_loss=-0.015 KID= 0.01225\n",
      "epoch 535, batch 2, d_loss=-0.222 g_loss=-0.110 KID= 0.01225\n",
      "epoch 535, batch 3, d_loss=-0.287 g_loss=-0.325 KID= 0.01225\n",
      "epoch 535, batch 4, d_loss=-0.302 g_loss=-0.512 KID= 0.01225\n",
      "epoch 535, batch 5, d_loss=-0.184 g_loss=-0.560 KID= 0.01225\n",
      "epoch 535, batch 6, d_loss=-0.310 g_loss=-0.483 KID= 0.01225\n",
      "epoch 535, batch 7, d_loss=-0.299 g_loss=-0.479 KID= 0.01225\n",
      "epoch 535, batch 8, d_loss=-0.260 g_loss=-0.356 KID= 0.01225\n",
      "epoch 535, batch 9, d_loss=-0.351 g_loss=-0.300 KID= 0.01225\n",
      "epoch 535, batch 10, d_loss=-0.335 g_loss=-0.390 KID= 0.01225\n",
      "epoch 535, batch 11, d_loss=-0.309 g_loss=-0.463 KID= 0.01225\n",
      "epoch 535, batch 12, d_loss=-0.293 g_loss=-0.553 KID= 0.01225\n",
      "epoch 535, batch 13, d_loss=-0.303 g_loss=-0.655 KID= 0.01225\n",
      "epoch 535, batch 14, d_loss=-0.280 g_loss=-0.658 KID= 0.01225\n",
      "epoch 535, batch 15, d_loss=-0.243 g_loss=-0.567 KID= 0.01225\n",
      "epoch 535, batch 16, d_loss=-0.270 g_loss=-0.481 KID= 0.01225\n",
      "epoch 535, batch 17, d_loss=-0.330 g_loss=-0.469 KID= 0.01225\n",
      "epoch 535, batch 18, d_loss=-0.210 g_loss=-0.361 KID= 0.01225\n",
      "epoch 535, batch 19, d_loss=-0.317 g_loss=-0.290 KID= 0.01225\n",
      "epoch 536, batch 0, d_loss=-0.339 g_loss=-0.211 KID= 0.01225\n",
      "epoch 536, batch 1, d_loss=-0.329 g_loss=-0.051 KID= 0.01225\n",
      "epoch 536, batch 2, d_loss=-0.314 g_loss=0.093 KID= 0.01225\n",
      "epoch 536, batch 3, d_loss=-0.364 g_loss=0.055 KID= 0.01225\n",
      "epoch 536, batch 4, d_loss=-0.307 g_loss=0.091 KID= 0.01225\n",
      "epoch 536, batch 5, d_loss=-0.210 g_loss=0.166 KID= 0.01225\n",
      "epoch 536, batch 6, d_loss=-0.328 g_loss=0.323 KID= 0.01225\n",
      "epoch 536, batch 7, d_loss=-0.279 g_loss=0.323 KID= 0.01225\n",
      "epoch 536, batch 8, d_loss=-0.243 g_loss=0.483 KID= 0.01225\n",
      "epoch 536, batch 9, d_loss=-0.340 g_loss=0.545 KID= 0.01225\n",
      "epoch 536, batch 10, d_loss=-0.360 g_loss=0.385 KID= 0.01225\n",
      "epoch 536, batch 11, d_loss=-0.326 g_loss=0.138 KID= 0.01225\n",
      "epoch 536, batch 12, d_loss=-0.285 g_loss=-0.132 KID= 0.01225\n",
      "epoch 536, batch 13, d_loss=-0.363 g_loss=-0.409 KID= 0.01225\n",
      "epoch 536, batch 14, d_loss=-0.289 g_loss=-0.734 KID= 0.01225\n",
      "epoch 536, batch 15, d_loss=-0.167 g_loss=-0.826 KID= 0.01225\n",
      "epoch 536, batch 16, d_loss=-0.273 g_loss=-0.801 KID= 0.01225\n",
      "epoch 536, batch 17, d_loss=-0.318 g_loss=-0.795 KID= 0.01225\n",
      "epoch 536, batch 18, d_loss=-0.232 g_loss=-0.585 KID= 0.01225\n",
      "epoch 536, batch 19, d_loss=-0.353 g_loss=-0.510 KID= 0.01225\n",
      "epoch 537, batch 0, d_loss=-0.347 g_loss=-0.516 KID= 0.01225\n",
      "epoch 537, batch 1, d_loss=-0.291 g_loss=-0.604 KID= 0.01225\n",
      "epoch 537, batch 2, d_loss=-0.223 g_loss=-0.536 KID= 0.01225\n",
      "epoch 537, batch 3, d_loss=-0.258 g_loss=-0.534 KID= 0.01225\n",
      "epoch 537, batch 4, d_loss=-0.270 g_loss=-0.596 KID= 0.01225\n",
      "epoch 537, batch 5, d_loss=-0.266 g_loss=-0.603 KID= 0.01225\n",
      "epoch 537, batch 6, d_loss=-0.342 g_loss=-0.589 KID= 0.01225\n",
      "epoch 537, batch 7, d_loss=-0.292 g_loss=-0.478 KID= 0.01225\n",
      "epoch 537, batch 8, d_loss=-0.193 g_loss=-0.403 KID= 0.01225\n",
      "epoch 537, batch 9, d_loss=-0.321 g_loss=-0.143 KID= 0.01225\n",
      "epoch 537, batch 10, d_loss=-0.345 g_loss=0.019 KID= 0.01225\n",
      "epoch 537, batch 11, d_loss=-0.279 g_loss=0.090 KID= 0.01225\n",
      "epoch 537, batch 12, d_loss=-0.214 g_loss=0.071 KID= 0.01225\n",
      "epoch 537, batch 13, d_loss=-0.300 g_loss=-0.033 KID= 0.01225\n",
      "epoch 537, batch 14, d_loss=-0.235 g_loss=-0.260 KID= 0.01225\n",
      "epoch 537, batch 15, d_loss=-0.232 g_loss=-0.486 KID= 0.01225\n",
      "epoch 537, batch 16, d_loss=-0.355 g_loss=-0.658 KID= 0.01225\n",
      "epoch 537, batch 17, d_loss=-0.326 g_loss=-0.672 KID= 0.01225\n",
      "epoch 537, batch 18, d_loss=-0.225 g_loss=-0.693 KID= 0.01225\n",
      "epoch 537, batch 19, d_loss=-0.335 g_loss=-0.624 KID= 0.01225\n",
      "epoch 538, batch 0, d_loss=-0.321 g_loss=-0.564 KID= 0.01225\n",
      "epoch 538, batch 1, d_loss=-0.301 g_loss=-0.511 KID= 0.01225\n",
      "epoch 538, batch 2, d_loss=-0.246 g_loss=-0.394 KID= 0.01225\n",
      "epoch 538, batch 3, d_loss=-0.328 g_loss=-0.314 KID= 0.01225\n",
      "epoch 538, batch 4, d_loss=-0.276 g_loss=-0.445 KID= 0.01225\n",
      "epoch 538, batch 5, d_loss=-0.213 g_loss=-0.548 KID= 0.01225\n",
      "epoch 538, batch 6, d_loss=-0.324 g_loss=-0.568 KID= 0.01225\n",
      "epoch 538, batch 7, d_loss=-0.301 g_loss=-0.588 KID= 0.01225\n",
      "epoch 538, batch 8, d_loss=-0.259 g_loss=-0.426 KID= 0.01225\n",
      "epoch 538, batch 9, d_loss=-0.365 g_loss=-0.278 KID= 0.01225\n",
      "epoch 538, batch 10, d_loss=-0.358 g_loss=-0.173 KID= 0.01225\n",
      "epoch 538, batch 11, d_loss=-0.387 g_loss=-0.225 KID= 0.01225\n",
      "epoch 538, batch 12, d_loss=-0.230 g_loss=-0.163 KID= 0.01225\n",
      "epoch 538, batch 13, d_loss=-0.317 g_loss=-0.232 KID= 0.01225\n",
      "epoch 538, batch 14, d_loss=-0.272 g_loss=-0.497 KID= 0.01225\n",
      "epoch 538, batch 15, d_loss=-0.210 g_loss=-0.613 KID= 0.01225\n",
      "epoch 538, batch 16, d_loss=-0.279 g_loss=-0.732 KID= 0.01225\n",
      "epoch 538, batch 17, d_loss=-0.295 g_loss=-0.747 KID= 0.01225\n",
      "epoch 538, batch 18, d_loss=-0.247 g_loss=-0.543 KID= 0.01225\n",
      "epoch 538, batch 19, d_loss=-0.357 g_loss=-0.383 KID= 0.01225\n",
      "epoch 539, batch 0, d_loss=-0.350 g_loss=-0.228 KID= 0.01225\n",
      "epoch 539, batch 1, d_loss=-0.442 g_loss=-0.185 KID= 0.01225\n",
      "epoch 539, batch 2, d_loss=-0.209 g_loss=0.006 KID= 0.01225\n",
      "epoch 539, batch 3, d_loss=-0.268 g_loss=0.186 KID= 0.01225\n",
      "epoch 539, batch 4, d_loss=-0.236 g_loss=0.229 KID= 0.01225\n",
      "epoch 539, batch 5, d_loss=-0.215 g_loss=0.184 KID= 0.01225\n",
      "epoch 539, batch 6, d_loss=-0.256 g_loss=0.108 KID= 0.01225\n",
      "epoch 539, batch 7, d_loss=-0.245 g_loss=0.030 KID= 0.01225\n",
      "epoch 539, batch 8, d_loss=-0.257 g_loss=0.008 KID= 0.01225\n",
      "epoch 539, batch 9, d_loss=-0.364 g_loss=0.020 KID= 0.01225\n",
      "epoch 539, batch 10, d_loss=-0.361 g_loss=0.104 KID= 0.01225\n",
      "epoch 539, batch 11, d_loss=-0.425 g_loss=0.021 KID= 0.01225\n",
      "epoch 539, batch 12, d_loss=-0.278 g_loss=-0.024 KID= 0.01225\n",
      "epoch 539, batch 13, d_loss=-0.278 g_loss=-0.134 KID= 0.01225\n",
      "epoch 539, batch 14, d_loss=-0.245 g_loss=-0.328 KID= 0.01225\n",
      "epoch 539, batch 15, d_loss=-0.183 g_loss=-0.416 KID= 0.01225\n",
      "epoch 539, batch 16, d_loss=-0.289 g_loss=-0.451 KID= 0.01225\n",
      "epoch 539, batch 17, d_loss=-0.279 g_loss=-0.567 KID= 0.01225\n",
      "epoch 539, batch 18, d_loss=-0.207 g_loss=-0.595 KID= 0.01225\n",
      "epoch 539, batch 19, d_loss=-0.316 g_loss=-0.464 KID= 0.01225\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 540, batch 0, d_loss=-0.366 g_loss=-0.464 KID= 0.01329\n",
      "epoch 540, batch 1, d_loss=-0.364 g_loss=-0.527 KID= 0.01329\n",
      "epoch 540, batch 2, d_loss=-0.316 g_loss=-0.532 KID= 0.01329\n",
      "epoch 540, batch 3, d_loss=-0.363 g_loss=-0.529 KID= 0.01329\n",
      "epoch 540, batch 4, d_loss=-0.346 g_loss=-0.569 KID= 0.01329\n",
      "epoch 540, batch 5, d_loss=-0.182 g_loss=-0.531 KID= 0.01329\n",
      "epoch 540, batch 6, d_loss=-0.288 g_loss=-0.405 KID= 0.01329\n",
      "epoch 540, batch 7, d_loss=-0.257 g_loss=-0.195 KID= 0.01329\n",
      "epoch 540, batch 8, d_loss=-0.263 g_loss=0.024 KID= 0.01329\n",
      "epoch 540, batch 9, d_loss=-0.317 g_loss=0.408 KID= 0.01329\n",
      "epoch 540, batch 10, d_loss=-0.376 g_loss=0.719 KID= 0.01329\n",
      "epoch 540, batch 11, d_loss=-0.331 g_loss=0.877 KID= 0.01329\n",
      "epoch 540, batch 12, d_loss=-0.268 g_loss=0.910 KID= 0.01329\n",
      "epoch 540, batch 13, d_loss=-0.235 g_loss=0.772 KID= 0.01329\n",
      "epoch 540, batch 14, d_loss=-0.218 g_loss=0.504 KID= 0.01329\n",
      "epoch 540, batch 15, d_loss=-0.197 g_loss=0.287 KID= 0.01329\n",
      "epoch 540, batch 16, d_loss=-0.266 g_loss=-0.078 KID= 0.01329\n",
      "epoch 540, batch 17, d_loss=-0.324 g_loss=-0.305 KID= 0.01329\n",
      "epoch 540, batch 18, d_loss=-0.266 g_loss=-0.377 KID= 0.01329\n",
      "epoch 540, batch 19, d_loss=-0.382 g_loss=-0.397 KID= 0.01329\n",
      "epoch 541, batch 0, d_loss=-0.312 g_loss=-0.571 KID= 0.01329\n",
      "epoch 541, batch 1, d_loss=-0.268 g_loss=-0.778 KID= 0.01329\n",
      "epoch 541, batch 2, d_loss=-0.222 g_loss=-0.610 KID= 0.01329\n",
      "epoch 541, batch 3, d_loss=-0.320 g_loss=-0.541 KID= 0.01329\n",
      "epoch 541, batch 4, d_loss=-0.277 g_loss=-0.607 KID= 0.01329\n",
      "epoch 541, batch 5, d_loss=-0.225 g_loss=-0.667 KID= 0.01329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 541, batch 6, d_loss=-0.298 g_loss=-0.686 KID= 0.01329\n",
      "epoch 541, batch 7, d_loss=-0.314 g_loss=-0.755 KID= 0.01329\n",
      "epoch 541, batch 8, d_loss=-0.259 g_loss=-0.713 KID= 0.01329\n",
      "epoch 541, batch 9, d_loss=-0.345 g_loss=-0.616 KID= 0.01329\n",
      "epoch 541, batch 10, d_loss=-0.376 g_loss=-0.522 KID= 0.01329\n",
      "epoch 541, batch 11, d_loss=-0.326 g_loss=-0.406 KID= 0.01329\n",
      "epoch 541, batch 12, d_loss=-0.314 g_loss=-0.185 KID= 0.01329\n",
      "epoch 541, batch 13, d_loss=-0.275 g_loss=-0.165 KID= 0.01329\n",
      "epoch 541, batch 14, d_loss=-0.266 g_loss=-0.275 KID= 0.01329\n",
      "epoch 541, batch 15, d_loss=-0.235 g_loss=-0.287 KID= 0.01329\n",
      "epoch 541, batch 16, d_loss=-0.342 g_loss=-0.331 KID= 0.01329\n",
      "epoch 541, batch 17, d_loss=-0.350 g_loss=-0.385 KID= 0.01329\n",
      "epoch 541, batch 18, d_loss=-0.266 g_loss=-0.420 KID= 0.01329\n",
      "epoch 541, batch 19, d_loss=-0.348 g_loss=-0.423 KID= 0.01329\n",
      "epoch 542, batch 0, d_loss=-0.370 g_loss=-0.376 KID= 0.01329\n",
      "epoch 542, batch 1, d_loss=-0.203 g_loss=-0.406 KID= 0.01329\n",
      "epoch 542, batch 2, d_loss=-0.289 g_loss=-0.306 KID= 0.01329\n",
      "epoch 542, batch 3, d_loss=-0.298 g_loss=-0.246 KID= 0.01329\n",
      "epoch 542, batch 4, d_loss=-0.262 g_loss=-0.293 KID= 0.01329\n",
      "epoch 542, batch 5, d_loss=-0.286 g_loss=-0.358 KID= 0.01329\n",
      "epoch 542, batch 6, d_loss=-0.289 g_loss=-0.383 KID= 0.01329\n",
      "epoch 542, batch 7, d_loss=-0.282 g_loss=-0.326 KID= 0.01329\n",
      "epoch 542, batch 8, d_loss=-0.246 g_loss=-0.192 KID= 0.01329\n",
      "epoch 542, batch 9, d_loss=-0.308 g_loss=0.078 KID= 0.01329\n",
      "epoch 542, batch 10, d_loss=-0.338 g_loss=0.450 KID= 0.01329\n",
      "epoch 542, batch 11, d_loss=-0.360 g_loss=0.679 KID= 0.01329\n",
      "epoch 542, batch 12, d_loss=-0.270 g_loss=0.742 KID= 0.01329\n",
      "epoch 542, batch 13, d_loss=-0.303 g_loss=0.592 KID= 0.01329\n",
      "epoch 542, batch 14, d_loss=-0.260 g_loss=0.368 KID= 0.01329\n",
      "epoch 542, batch 15, d_loss=-0.183 g_loss=0.126 KID= 0.01329\n",
      "epoch 542, batch 16, d_loss=-0.320 g_loss=0.004 KID= 0.01329\n",
      "epoch 542, batch 17, d_loss=-0.340 g_loss=-0.104 KID= 0.01329\n",
      "epoch 542, batch 18, d_loss=-0.274 g_loss=-0.233 KID= 0.01329\n",
      "epoch 542, batch 19, d_loss=-0.375 g_loss=-0.347 KID= 0.01329\n",
      "epoch 543, batch 0, d_loss=-0.356 g_loss=-0.449 KID= 0.01329\n",
      "epoch 543, batch 1, d_loss=-0.321 g_loss=-0.508 KID= 0.01329\n",
      "epoch 543, batch 2, d_loss=-0.248 g_loss=-0.476 KID= 0.01329\n",
      "epoch 543, batch 3, d_loss=-0.330 g_loss=-0.542 KID= 0.01329\n",
      "epoch 543, batch 4, d_loss=-0.223 g_loss=-0.722 KID= 0.01329\n",
      "epoch 543, batch 5, d_loss=-0.182 g_loss=-0.820 KID= 0.01329\n",
      "epoch 543, batch 6, d_loss=-0.339 g_loss=-0.926 KID= 0.01329\n",
      "epoch 543, batch 7, d_loss=-0.321 g_loss=-0.915 KID= 0.01329\n",
      "epoch 543, batch 8, d_loss=-0.269 g_loss=-0.783 KID= 0.01329\n",
      "epoch 543, batch 9, d_loss=-0.333 g_loss=-0.516 KID= 0.01329\n",
      "epoch 543, batch 10, d_loss=-0.352 g_loss=-0.210 KID= 0.01329\n",
      "epoch 543, batch 11, d_loss=-0.324 g_loss=0.033 KID= 0.01329\n",
      "epoch 543, batch 12, d_loss=-0.319 g_loss=0.293 KID= 0.01329\n",
      "epoch 543, batch 13, d_loss=-0.273 g_loss=0.320 KID= 0.01329\n",
      "epoch 543, batch 14, d_loss=-0.272 g_loss=0.223 KID= 0.01329\n",
      "epoch 543, batch 15, d_loss=-0.193 g_loss=0.153 KID= 0.01329\n",
      "epoch 543, batch 16, d_loss=-0.299 g_loss=0.059 KID= 0.01329\n",
      "epoch 543, batch 17, d_loss=-0.334 g_loss=-0.110 KID= 0.01329\n",
      "epoch 543, batch 18, d_loss=-0.319 g_loss=-0.266 KID= 0.01329\n",
      "epoch 543, batch 19, d_loss=-0.341 g_loss=-0.456 KID= 0.01329\n",
      "epoch 544, batch 0, d_loss=-0.380 g_loss=-0.579 KID= 0.01329\n",
      "epoch 544, batch 1, d_loss=-0.257 g_loss=-0.659 KID= 0.01329\n",
      "epoch 544, batch 2, d_loss=-0.255 g_loss=-0.688 KID= 0.01329\n",
      "epoch 544, batch 3, d_loss=-0.322 g_loss=-0.705 KID= 0.01329\n",
      "epoch 544, batch 4, d_loss=-0.310 g_loss=-0.791 KID= 0.01329\n",
      "epoch 544, batch 5, d_loss=-0.256 g_loss=-0.823 KID= 0.01329\n",
      "epoch 544, batch 6, d_loss=-0.344 g_loss=-0.853 KID= 0.01329\n",
      "epoch 544, batch 7, d_loss=-0.347 g_loss=-0.769 KID= 0.01329\n",
      "epoch 544, batch 8, d_loss=-0.219 g_loss=-0.728 KID= 0.01329\n",
      "epoch 544, batch 9, d_loss=-0.333 g_loss=-0.532 KID= 0.01329\n",
      "epoch 544, batch 10, d_loss=-0.351 g_loss=-0.372 KID= 0.01329\n",
      "epoch 544, batch 11, d_loss=-0.238 g_loss=-0.205 KID= 0.01329\n",
      "epoch 544, batch 12, d_loss=-0.263 g_loss=-0.017 KID= 0.01329\n",
      "epoch 544, batch 13, d_loss=-0.288 g_loss=-0.055 KID= 0.01329\n",
      "epoch 544, batch 14, d_loss=-0.238 g_loss=-0.242 KID= 0.01329\n",
      "epoch 544, batch 15, d_loss=-0.283 g_loss=-0.383 KID= 0.01329\n",
      "epoch 544, batch 16, d_loss=-0.373 g_loss=-0.491 KID= 0.01329\n",
      "epoch 544, batch 17, d_loss=-0.328 g_loss=-0.607 KID= 0.01329\n",
      "epoch 544, batch 18, d_loss=-0.271 g_loss=-0.567 KID= 0.01329\n",
      "epoch 544, batch 19, d_loss=-0.314 g_loss=-0.507 KID= 0.01329\n",
      "epoch 545, batch 0, d_loss=-0.421 g_loss=-0.375 KID= 0.01329\n",
      "epoch 545, batch 1, d_loss=-0.264 g_loss=-0.254 KID= 0.01329\n",
      "epoch 545, batch 2, d_loss=-0.299 g_loss=-0.052 KID= 0.01329\n",
      "epoch 545, batch 3, d_loss=-0.318 g_loss=-0.027 KID= 0.01329\n",
      "epoch 545, batch 4, d_loss=-0.266 g_loss=-0.069 KID= 0.01329\n",
      "epoch 545, batch 5, d_loss=-0.209 g_loss=-0.130 KID= 0.01329\n",
      "epoch 545, batch 6, d_loss=-0.284 g_loss=-0.264 KID= 0.01329\n",
      "epoch 545, batch 7, d_loss=-0.338 g_loss=-0.443 KID= 0.01329\n",
      "epoch 545, batch 8, d_loss=-0.312 g_loss=-0.615 KID= 0.01329\n",
      "epoch 545, batch 9, d_loss=-0.308 g_loss=-0.672 KID= 0.01329\n",
      "epoch 545, batch 10, d_loss=-0.343 g_loss=-0.651 KID= 0.01329\n",
      "epoch 545, batch 11, d_loss=-0.240 g_loss=-0.554 KID= 0.01329\n",
      "epoch 545, batch 12, d_loss=-0.287 g_loss=-0.328 KID= 0.01329\n",
      "epoch 545, batch 13, d_loss=-0.268 g_loss=-0.190 KID= 0.01329\n",
      "epoch 545, batch 14, d_loss=-0.255 g_loss=-0.251 KID= 0.01329\n",
      "epoch 545, batch 15, d_loss=-0.278 g_loss=-0.229 KID= 0.01329\n",
      "epoch 545, batch 16, d_loss=-0.324 g_loss=-0.204 KID= 0.01329\n",
      "epoch 545, batch 17, d_loss=-0.359 g_loss=-0.227 KID= 0.01329\n",
      "epoch 545, batch 18, d_loss=-0.271 g_loss=-0.292 KID= 0.01329\n",
      "epoch 545, batch 19, d_loss=-0.330 g_loss=-0.341 KID= 0.01329\n",
      "epoch 546, batch 0, d_loss=-0.374 g_loss=-0.266 KID= 0.01329\n",
      "epoch 546, batch 1, d_loss=-0.273 g_loss=-0.200 KID= 0.01329\n",
      "epoch 546, batch 2, d_loss=-0.265 g_loss=-0.144 KID= 0.01329\n",
      "epoch 546, batch 3, d_loss=-0.309 g_loss=-0.110 KID= 0.01329\n",
      "epoch 546, batch 4, d_loss=-0.307 g_loss=-0.192 KID= 0.01329\n",
      "epoch 546, batch 5, d_loss=-0.209 g_loss=-0.237 KID= 0.01329\n",
      "epoch 546, batch 6, d_loss=-0.349 g_loss=-0.328 KID= 0.01329\n",
      "epoch 546, batch 7, d_loss=-0.329 g_loss=-0.285 KID= 0.01329\n",
      "epoch 546, batch 8, d_loss=-0.293 g_loss=-0.310 KID= 0.01329\n",
      "epoch 546, batch 9, d_loss=-0.362 g_loss=-0.409 KID= 0.01329\n",
      "epoch 546, batch 10, d_loss=-0.375 g_loss=-0.415 KID= 0.01329\n",
      "epoch 546, batch 11, d_loss=-0.249 g_loss=-0.379 KID= 0.01329\n",
      "epoch 546, batch 12, d_loss=-0.294 g_loss=-0.284 KID= 0.01329\n",
      "epoch 546, batch 13, d_loss=-0.306 g_loss=-0.184 KID= 0.01329\n",
      "epoch 546, batch 14, d_loss=-0.244 g_loss=-0.206 KID= 0.01329\n",
      "epoch 546, batch 15, d_loss=-0.289 g_loss=-0.188 KID= 0.01329\n",
      "epoch 546, batch 16, d_loss=-0.324 g_loss=-0.159 KID= 0.01329\n",
      "epoch 546, batch 17, d_loss=-0.357 g_loss=-0.168 KID= 0.01329\n",
      "epoch 546, batch 18, d_loss=-0.294 g_loss=-0.142 KID= 0.01329\n",
      "epoch 546, batch 19, d_loss=-0.321 g_loss=-0.115 KID= 0.01329\n",
      "epoch 547, batch 0, d_loss=-0.395 g_loss=-0.144 KID= 0.01329\n",
      "epoch 547, batch 1, d_loss=-0.246 g_loss=-0.128 KID= 0.01329\n",
      "epoch 547, batch 2, d_loss=-0.293 g_loss=-0.146 KID= 0.01329\n",
      "epoch 547, batch 3, d_loss=-0.306 g_loss=-0.253 KID= 0.01329\n",
      "epoch 547, batch 4, d_loss=-0.278 g_loss=-0.420 KID= 0.01329\n",
      "epoch 547, batch 5, d_loss=-0.263 g_loss=-0.542 KID= 0.01329\n",
      "epoch 547, batch 6, d_loss=-0.339 g_loss=-0.715 KID= 0.01329\n",
      "epoch 547, batch 7, d_loss=-0.311 g_loss=-0.853 KID= 0.01329\n",
      "epoch 547, batch 8, d_loss=-0.287 g_loss=-0.816 KID= 0.01329\n",
      "epoch 547, batch 9, d_loss=-0.343 g_loss=-0.788 KID= 0.01329\n",
      "epoch 547, batch 10, d_loss=-0.380 g_loss=-0.777 KID= 0.01329\n",
      "epoch 547, batch 11, d_loss=-0.254 g_loss=-0.549 KID= 0.01329\n",
      "epoch 547, batch 12, d_loss=-0.324 g_loss=-0.389 KID= 0.01329\n",
      "epoch 547, batch 13, d_loss=-0.311 g_loss=-0.324 KID= 0.01329\n",
      "epoch 547, batch 14, d_loss=-0.259 g_loss=-0.274 KID= 0.01329\n",
      "epoch 547, batch 15, d_loss=-0.288 g_loss=-0.261 KID= 0.01329\n",
      "epoch 547, batch 16, d_loss=-0.320 g_loss=-0.273 KID= 0.01329\n",
      "epoch 547, batch 17, d_loss=-0.355 g_loss=-0.283 KID= 0.01329\n",
      "epoch 547, batch 18, d_loss=-0.246 g_loss=-0.308 KID= 0.01329\n",
      "epoch 547, batch 19, d_loss=-0.320 g_loss=-0.454 KID= 0.01329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 548, batch 0, d_loss=-0.417 g_loss=-0.505 KID= 0.01329\n",
      "epoch 548, batch 1, d_loss=-0.252 g_loss=-0.462 KID= 0.01329\n",
      "epoch 548, batch 2, d_loss=-0.303 g_loss=-0.435 KID= 0.01329\n",
      "epoch 548, batch 3, d_loss=-0.323 g_loss=-0.498 KID= 0.01329\n",
      "epoch 548, batch 4, d_loss=-0.235 g_loss=-0.566 KID= 0.01329\n",
      "epoch 548, batch 5, d_loss=-0.243 g_loss=-0.556 KID= 0.01329\n",
      "epoch 548, batch 6, d_loss=-0.277 g_loss=-0.568 KID= 0.01329\n",
      "epoch 548, batch 7, d_loss=-0.347 g_loss=-0.590 KID= 0.01329\n",
      "epoch 548, batch 8, d_loss=-0.305 g_loss=-0.560 KID= 0.01329\n",
      "epoch 548, batch 9, d_loss=-0.333 g_loss=-0.511 KID= 0.01329\n",
      "epoch 548, batch 10, d_loss=-0.376 g_loss=-0.417 KID= 0.01329\n",
      "epoch 548, batch 11, d_loss=-0.317 g_loss=-0.214 KID= 0.01329\n",
      "epoch 548, batch 12, d_loss=-0.338 g_loss=0.012 KID= 0.01329\n",
      "epoch 548, batch 13, d_loss=-0.331 g_loss=0.087 KID= 0.01329\n",
      "epoch 548, batch 14, d_loss=-0.273 g_loss=0.065 KID= 0.01329\n",
      "epoch 548, batch 15, d_loss=-0.291 g_loss=0.064 KID= 0.01329\n",
      "epoch 548, batch 16, d_loss=-0.281 g_loss=-0.026 KID= 0.01329\n",
      "epoch 548, batch 17, d_loss=-0.327 g_loss=-0.155 KID= 0.01329\n",
      "epoch 548, batch 18, d_loss=-0.221 g_loss=-0.318 KID= 0.01329\n",
      "epoch 548, batch 19, d_loss=-0.326 g_loss=-0.458 KID= 0.01329\n",
      "epoch 549, batch 0, d_loss=-0.403 g_loss=-0.598 KID= 0.01329\n",
      "epoch 549, batch 1, d_loss=-0.295 g_loss=-0.669 KID= 0.01329\n",
      "epoch 549, batch 2, d_loss=-0.303 g_loss=-0.596 KID= 0.01329\n",
      "epoch 549, batch 3, d_loss=-0.378 g_loss=-0.610 KID= 0.01329\n",
      "epoch 549, batch 4, d_loss=-0.218 g_loss=-0.531 KID= 0.01329\n",
      "epoch 549, batch 5, d_loss=-0.233 g_loss=-0.464 KID= 0.01329\n",
      "epoch 549, batch 6, d_loss=-0.356 g_loss=-0.415 KID= 0.01329\n",
      "epoch 549, batch 7, d_loss=-0.308 g_loss=-0.322 KID= 0.01329\n",
      "epoch 549, batch 8, d_loss=-0.307 g_loss=-0.443 KID= 0.01329\n",
      "epoch 549, batch 9, d_loss=-0.320 g_loss=-0.402 KID= 0.01329\n",
      "epoch 549, batch 10, d_loss=-0.369 g_loss=-0.388 KID= 0.01329\n",
      "epoch 549, batch 11, d_loss=-0.253 g_loss=-0.323 KID= 0.01329\n",
      "epoch 549, batch 12, d_loss=-0.324 g_loss=-0.111 KID= 0.01329\n",
      "epoch 549, batch 13, d_loss=-0.306 g_loss=-0.086 KID= 0.01329\n",
      "epoch 549, batch 14, d_loss=-0.301 g_loss=-0.167 KID= 0.01329\n",
      "epoch 549, batch 15, d_loss=-0.285 g_loss=-0.103 KID= 0.01329\n",
      "epoch 549, batch 16, d_loss=-0.315 g_loss=0.004 KID= 0.01329\n",
      "epoch 549, batch 17, d_loss=-0.313 g_loss=0.201 KID= 0.01329\n",
      "epoch 549, batch 18, d_loss=-0.305 g_loss=0.170 KID= 0.01329\n",
      "epoch 549, batch 19, d_loss=-0.341 g_loss=0.094 KID= 0.01329\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 550, batch 0, d_loss=-0.401 g_loss=0.013 KID= 0.00672\n",
      "epoch 550, batch 1, d_loss=-0.267 g_loss=-0.061 KID= 0.00672\n",
      "epoch 550, batch 2, d_loss=-0.310 g_loss=-0.008 KID= 0.00672\n",
      "epoch 550, batch 3, d_loss=-0.290 g_loss=-0.035 KID= 0.00672\n",
      "epoch 550, batch 4, d_loss=-0.259 g_loss=-0.133 KID= 0.00672\n",
      "epoch 550, batch 5, d_loss=-0.301 g_loss=-0.217 KID= 0.00672\n",
      "epoch 550, batch 6, d_loss=-0.293 g_loss=-0.337 KID= 0.00672\n",
      "epoch 550, batch 7, d_loss=-0.326 g_loss=-0.428 KID= 0.00672\n",
      "epoch 550, batch 8, d_loss=-0.306 g_loss=-0.448 KID= 0.00672\n",
      "epoch 550, batch 9, d_loss=-0.351 g_loss=-0.435 KID= 0.00672\n",
      "epoch 550, batch 10, d_loss=-0.369 g_loss=-0.498 KID= 0.00672\n",
      "epoch 550, batch 11, d_loss=-0.233 g_loss=-0.508 KID= 0.00672\n",
      "epoch 550, batch 12, d_loss=-0.343 g_loss=-0.431 KID= 0.00672\n",
      "epoch 550, batch 13, d_loss=-0.353 g_loss=-0.343 KID= 0.00672\n",
      "epoch 550, batch 14, d_loss=-0.304 g_loss=-0.330 KID= 0.00672\n",
      "epoch 550, batch 15, d_loss=-0.280 g_loss=-0.309 KID= 0.00672\n",
      "epoch 550, batch 16, d_loss=-0.279 g_loss=-0.268 KID= 0.00672\n",
      "epoch 550, batch 17, d_loss=-0.349 g_loss=-0.287 KID= 0.00672\n",
      "epoch 550, batch 18, d_loss=-0.291 g_loss=-0.369 KID= 0.00672\n",
      "epoch 550, batch 19, d_loss=-0.327 g_loss=-0.411 KID= 0.00672\n",
      "epoch 551, batch 0, d_loss=-0.391 g_loss=-0.425 KID= 0.00672\n",
      "epoch 551, batch 1, d_loss=-0.281 g_loss=-0.324 KID= 0.00672\n",
      "epoch 551, batch 2, d_loss=-0.302 g_loss=-0.184 KID= 0.00672\n",
      "epoch 551, batch 3, d_loss=-0.333 g_loss=-0.136 KID= 0.00672\n",
      "epoch 551, batch 4, d_loss=-0.233 g_loss=-0.112 KID= 0.00672\n",
      "epoch 551, batch 5, d_loss=-0.188 g_loss=-0.061 KID= 0.00672\n",
      "epoch 551, batch 6, d_loss=-0.331 g_loss=0.011 KID= 0.00672\n",
      "epoch 551, batch 7, d_loss=-0.349 g_loss=0.080 KID= 0.00672\n",
      "epoch 551, batch 8, d_loss=-0.284 g_loss=-0.079 KID= 0.00672\n",
      "epoch 551, batch 9, d_loss=-0.392 g_loss=-0.156 KID= 0.00672\n",
      "epoch 551, batch 10, d_loss=-0.358 g_loss=-0.281 KID= 0.00672\n",
      "epoch 551, batch 11, d_loss=-0.235 g_loss=-0.327 KID= 0.00672\n",
      "epoch 551, batch 12, d_loss=-0.280 g_loss=-0.280 KID= 0.00672\n",
      "epoch 551, batch 13, d_loss=-0.294 g_loss=-0.309 KID= 0.00672\n",
      "epoch 551, batch 14, d_loss=-0.256 g_loss=-0.319 KID= 0.00672\n",
      "epoch 551, batch 15, d_loss=-0.303 g_loss=-0.304 KID= 0.00672\n",
      "epoch 551, batch 16, d_loss=-0.338 g_loss=-0.370 KID= 0.00672\n",
      "epoch 551, batch 17, d_loss=-0.372 g_loss=-0.362 KID= 0.00672\n",
      "epoch 551, batch 18, d_loss=-0.275 g_loss=-0.387 KID= 0.00672\n",
      "epoch 551, batch 19, d_loss=-0.345 g_loss=-0.358 KID= 0.00672\n",
      "epoch 552, batch 0, d_loss=-0.413 g_loss=-0.476 KID= 0.00672\n",
      "epoch 552, batch 1, d_loss=-0.271 g_loss=-0.340 KID= 0.00672\n",
      "epoch 552, batch 2, d_loss=-0.313 g_loss=-0.210 KID= 0.00672\n",
      "epoch 552, batch 3, d_loss=-0.322 g_loss=-0.188 KID= 0.00672\n",
      "epoch 552, batch 4, d_loss=-0.236 g_loss=-0.111 KID= 0.00672\n",
      "epoch 552, batch 5, d_loss=-0.288 g_loss=-0.056 KID= 0.00672\n",
      "epoch 552, batch 6, d_loss=-0.337 g_loss=-0.060 KID= 0.00672\n",
      "epoch 552, batch 7, d_loss=-0.316 g_loss=-0.118 KID= 0.00672\n",
      "epoch 552, batch 8, d_loss=-0.338 g_loss=-0.222 KID= 0.00672\n",
      "epoch 552, batch 9, d_loss=-0.340 g_loss=-0.364 KID= 0.00672\n",
      "epoch 552, batch 10, d_loss=-0.367 g_loss=-0.479 KID= 0.00672\n",
      "epoch 552, batch 11, d_loss=-0.298 g_loss=-0.614 KID= 0.00672\n",
      "epoch 552, batch 12, d_loss=-0.315 g_loss=-0.615 KID= 0.00672\n",
      "epoch 552, batch 13, d_loss=-0.373 g_loss=-0.590 KID= 0.00672\n",
      "epoch 552, batch 14, d_loss=-0.279 g_loss=-0.445 KID= 0.00672\n",
      "epoch 552, batch 15, d_loss=-0.256 g_loss=-0.360 KID= 0.00672\n",
      "epoch 552, batch 16, d_loss=-0.275 g_loss=-0.189 KID= 0.00672\n",
      "epoch 552, batch 17, d_loss=-0.312 g_loss=-0.077 KID= 0.00672\n",
      "epoch 552, batch 18, d_loss=-0.297 g_loss=-0.127 KID= 0.00672\n",
      "epoch 552, batch 19, d_loss=-0.360 g_loss=-0.159 KID= 0.00672\n",
      "epoch 553, batch 0, d_loss=-0.380 g_loss=-0.240 KID= 0.00672\n",
      "epoch 553, batch 1, d_loss=-0.221 g_loss=-0.242 KID= 0.00672\n",
      "epoch 553, batch 2, d_loss=-0.328 g_loss=-0.208 KID= 0.00672\n",
      "epoch 553, batch 3, d_loss=-0.308 g_loss=-0.201 KID= 0.00672\n",
      "epoch 553, batch 4, d_loss=-0.227 g_loss=-0.208 KID= 0.00672\n",
      "epoch 553, batch 5, d_loss=-0.299 g_loss=-0.235 KID= 0.00672\n",
      "epoch 553, batch 6, d_loss=-0.331 g_loss=-0.216 KID= 0.00672\n",
      "epoch 553, batch 7, d_loss=-0.363 g_loss=-0.266 KID= 0.00672\n",
      "epoch 553, batch 8, d_loss=-0.304 g_loss=-0.300 KID= 0.00672\n",
      "epoch 553, batch 9, d_loss=-0.358 g_loss=-0.298 KID= 0.00672\n",
      "epoch 553, batch 10, d_loss=-0.381 g_loss=-0.341 KID= 0.00672\n",
      "epoch 553, batch 11, d_loss=-0.239 g_loss=-0.316 KID= 0.00672\n",
      "epoch 553, batch 12, d_loss=-0.281 g_loss=-0.313 KID= 0.00672\n",
      "epoch 553, batch 13, d_loss=-0.300 g_loss=-0.299 KID= 0.00672\n",
      "epoch 553, batch 14, d_loss=-0.275 g_loss=-0.377 KID= 0.00672\n",
      "epoch 553, batch 15, d_loss=-0.291 g_loss=-0.390 KID= 0.00672\n",
      "epoch 553, batch 16, d_loss=-0.335 g_loss=-0.424 KID= 0.00672\n",
      "epoch 553, batch 17, d_loss=-0.314 g_loss=-0.491 KID= 0.00672\n",
      "epoch 553, batch 18, d_loss=-0.312 g_loss=-0.502 KID= 0.00672\n",
      "epoch 553, batch 19, d_loss=-0.389 g_loss=-0.545 KID= 0.00672\n",
      "epoch 554, batch 0, d_loss=-0.368 g_loss=-0.566 KID= 0.00672\n",
      "epoch 554, batch 1, d_loss=-0.280 g_loss=-0.516 KID= 0.00672\n",
      "epoch 554, batch 2, d_loss=-0.390 g_loss=-0.457 KID= 0.00672\n",
      "epoch 554, batch 3, d_loss=-0.271 g_loss=-0.391 KID= 0.00672\n",
      "epoch 554, batch 4, d_loss=-0.292 g_loss=-0.368 KID= 0.00672\n",
      "epoch 554, batch 5, d_loss=-0.288 g_loss=-0.316 KID= 0.00672\n",
      "epoch 554, batch 6, d_loss=-0.266 g_loss=-0.225 KID= 0.00672\n",
      "epoch 554, batch 7, d_loss=-0.338 g_loss=-0.185 KID= 0.00672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 554, batch 8, d_loss=-0.305 g_loss=-0.198 KID= 0.00672\n",
      "epoch 554, batch 9, d_loss=-0.413 g_loss=-0.199 KID= 0.00672\n",
      "epoch 554, batch 10, d_loss=-0.387 g_loss=-0.221 KID= 0.00672\n",
      "epoch 554, batch 11, d_loss=-0.270 g_loss=-0.126 KID= 0.00672\n",
      "epoch 554, batch 12, d_loss=-0.334 g_loss=-0.027 KID= 0.00672\n",
      "epoch 554, batch 13, d_loss=-0.336 g_loss=0.045 KID= 0.00672\n",
      "epoch 554, batch 14, d_loss=-0.245 g_loss=-0.054 KID= 0.00672\n",
      "epoch 554, batch 15, d_loss=-0.260 g_loss=-0.117 KID= 0.00672\n",
      "epoch 554, batch 16, d_loss=-0.286 g_loss=-0.266 KID= 0.00672\n",
      "epoch 554, batch 17, d_loss=-0.353 g_loss=-0.378 KID= 0.00672\n",
      "epoch 554, batch 18, d_loss=-0.285 g_loss=-0.610 KID= 0.00672\n",
      "epoch 554, batch 19, d_loss=-0.423 g_loss=-0.749 KID= 0.00672\n",
      "epoch 555, batch 0, d_loss=-0.396 g_loss=-0.932 KID= 0.00672\n",
      "epoch 555, batch 1, d_loss=-0.244 g_loss=-0.880 KID= 0.00672\n",
      "epoch 555, batch 2, d_loss=-0.324 g_loss=-0.867 KID= 0.00672\n",
      "epoch 555, batch 3, d_loss=-0.264 g_loss=-0.774 KID= 0.00672\n",
      "epoch 555, batch 4, d_loss=-0.211 g_loss=-0.728 KID= 0.00672\n",
      "epoch 555, batch 5, d_loss=-0.311 g_loss=-0.542 KID= 0.00672\n",
      "epoch 555, batch 6, d_loss=-0.289 g_loss=-0.421 KID= 0.00672\n",
      "epoch 555, batch 7, d_loss=-0.343 g_loss=-0.344 KID= 0.00672\n",
      "epoch 555, batch 8, d_loss=-0.330 g_loss=-0.336 KID= 0.00672\n",
      "epoch 555, batch 9, d_loss=-0.390 g_loss=-0.288 KID= 0.00672\n",
      "epoch 555, batch 10, d_loss=-0.371 g_loss=-0.353 KID= 0.00672\n",
      "epoch 555, batch 11, d_loss=-0.282 g_loss=-0.373 KID= 0.00672\n",
      "epoch 555, batch 12, d_loss=-0.367 g_loss=-0.316 KID= 0.00672\n",
      "epoch 555, batch 13, d_loss=-0.282 g_loss=-0.256 KID= 0.00672\n",
      "epoch 555, batch 14, d_loss=-0.245 g_loss=-0.233 KID= 0.00672\n",
      "epoch 555, batch 15, d_loss=-0.252 g_loss=-0.108 KID= 0.00672\n",
      "epoch 555, batch 16, d_loss=-0.347 g_loss=-0.045 KID= 0.00672\n",
      "epoch 555, batch 17, d_loss=-0.329 g_loss=-0.117 KID= 0.00672\n",
      "epoch 555, batch 18, d_loss=-0.304 g_loss=-0.214 KID= 0.00672\n",
      "epoch 555, batch 19, d_loss=-0.363 g_loss=-0.240 KID= 0.00672\n",
      "epoch 556, batch 0, d_loss=-0.397 g_loss=-0.309 KID= 0.00672\n",
      "epoch 556, batch 1, d_loss=-0.278 g_loss=-0.311 KID= 0.00672\n",
      "epoch 556, batch 2, d_loss=-0.340 g_loss=-0.285 KID= 0.00672\n",
      "epoch 556, batch 3, d_loss=-0.317 g_loss=-0.338 KID= 0.00672\n",
      "epoch 556, batch 4, d_loss=-0.286 g_loss=-0.350 KID= 0.00672\n",
      "epoch 556, batch 5, d_loss=-0.253 g_loss=-0.311 KID= 0.00672\n",
      "epoch 556, batch 6, d_loss=-0.286 g_loss=-0.336 KID= 0.00672\n",
      "epoch 556, batch 7, d_loss=-0.376 g_loss=-0.342 KID= 0.00672\n",
      "epoch 556, batch 8, d_loss=-0.265 g_loss=-0.445 KID= 0.00672\n",
      "epoch 556, batch 9, d_loss=-0.391 g_loss=-0.458 KID= 0.00672\n",
      "epoch 556, batch 10, d_loss=-0.327 g_loss=-0.599 KID= 0.00672\n",
      "epoch 556, batch 11, d_loss=-0.299 g_loss=-0.585 KID= 0.00672\n",
      "epoch 556, batch 12, d_loss=-0.355 g_loss=-0.524 KID= 0.00672\n",
      "epoch 556, batch 13, d_loss=-0.278 g_loss=-0.501 KID= 0.00672\n",
      "epoch 556, batch 14, d_loss=-0.243 g_loss=-0.434 KID= 0.00672\n",
      "epoch 556, batch 15, d_loss=-0.338 g_loss=-0.353 KID= 0.00672\n",
      "epoch 556, batch 16, d_loss=-0.315 g_loss=-0.225 KID= 0.00672\n",
      "epoch 556, batch 17, d_loss=-0.311 g_loss=-0.175 KID= 0.00672\n",
      "epoch 556, batch 18, d_loss=-0.280 g_loss=-0.158 KID= 0.00672\n",
      "epoch 556, batch 19, d_loss=-0.413 g_loss=-0.161 KID= 0.00672\n",
      "epoch 557, batch 0, d_loss=-0.360 g_loss=-0.272 KID= 0.00672\n",
      "epoch 557, batch 1, d_loss=-0.297 g_loss=-0.259 KID= 0.00672\n",
      "epoch 557, batch 2, d_loss=-0.339 g_loss=-0.254 KID= 0.00672\n",
      "epoch 557, batch 3, d_loss=-0.297 g_loss=-0.231 KID= 0.00672\n",
      "epoch 557, batch 4, d_loss=-0.257 g_loss=-0.104 KID= 0.00672\n",
      "epoch 557, batch 5, d_loss=-0.333 g_loss=0.069 KID= 0.00672\n",
      "epoch 557, batch 6, d_loss=-0.271 g_loss=0.125 KID= 0.00672\n",
      "epoch 557, batch 7, d_loss=-0.332 g_loss=0.103 KID= 0.00672\n",
      "epoch 557, batch 8, d_loss=-0.257 g_loss=-0.098 KID= 0.00672\n",
      "epoch 557, batch 9, d_loss=-0.356 g_loss=-0.290 KID= 0.00672\n",
      "epoch 557, batch 10, d_loss=-0.360 g_loss=-0.551 KID= 0.00672\n",
      "epoch 557, batch 11, d_loss=-0.323 g_loss=-0.647 KID= 0.00672\n",
      "epoch 557, batch 12, d_loss=-0.343 g_loss=-0.717 KID= 0.00672\n",
      "epoch 557, batch 13, d_loss=-0.317 g_loss=-0.794 KID= 0.00672\n",
      "epoch 557, batch 14, d_loss=-0.208 g_loss=-0.785 KID= 0.00672\n",
      "epoch 557, batch 15, d_loss=-0.259 g_loss=-0.619 KID= 0.00672\n",
      "epoch 557, batch 16, d_loss=-0.278 g_loss=-0.481 KID= 0.00672\n",
      "epoch 557, batch 17, d_loss=-0.305 g_loss=-0.349 KID= 0.00672\n",
      "epoch 557, batch 18, d_loss=-0.282 g_loss=-0.322 KID= 0.00672\n",
      "epoch 557, batch 19, d_loss=-0.409 g_loss=-0.353 KID= 0.00672\n",
      "epoch 558, batch 0, d_loss=-0.377 g_loss=-0.513 KID= 0.00672\n",
      "epoch 558, batch 1, d_loss=-0.303 g_loss=-0.627 KID= 0.00672\n",
      "epoch 558, batch 2, d_loss=-0.328 g_loss=-0.671 KID= 0.00672\n",
      "epoch 558, batch 3, d_loss=-0.340 g_loss=-0.644 KID= 0.00672\n",
      "epoch 558, batch 4, d_loss=-0.191 g_loss=-0.527 KID= 0.00672\n",
      "epoch 558, batch 5, d_loss=-0.292 g_loss=-0.452 KID= 0.00672\n",
      "epoch 558, batch 6, d_loss=-0.239 g_loss=-0.354 KID= 0.00672\n",
      "epoch 558, batch 7, d_loss=-0.301 g_loss=-0.267 KID= 0.00672\n",
      "epoch 558, batch 8, d_loss=-0.359 g_loss=-0.276 KID= 0.00672\n",
      "epoch 558, batch 9, d_loss=-0.415 g_loss=-0.253 KID= 0.00672\n",
      "epoch 558, batch 10, d_loss=-0.357 g_loss=-0.370 KID= 0.00672\n",
      "epoch 558, batch 11, d_loss=-0.268 g_loss=-0.370 KID= 0.00672\n",
      "epoch 558, batch 12, d_loss=-0.299 g_loss=-0.399 KID= 0.00672\n",
      "epoch 558, batch 13, d_loss=-0.308 g_loss=-0.461 KID= 0.00672\n",
      "epoch 558, batch 14, d_loss=-0.183 g_loss=-0.403 KID= 0.00672\n",
      "epoch 558, batch 15, d_loss=-0.299 g_loss=-0.352 KID= 0.00672\n",
      "epoch 558, batch 16, d_loss=-0.315 g_loss=-0.285 KID= 0.00672\n",
      "epoch 558, batch 17, d_loss=-0.356 g_loss=-0.246 KID= 0.00672\n",
      "epoch 558, batch 18, d_loss=-0.296 g_loss=-0.213 KID= 0.00672\n",
      "epoch 558, batch 19, d_loss=-0.367 g_loss=-0.216 KID= 0.00672\n",
      "epoch 559, batch 0, d_loss=-0.355 g_loss=-0.414 KID= 0.00672\n",
      "epoch 559, batch 1, d_loss=-0.288 g_loss=-0.480 KID= 0.00672\n",
      "epoch 559, batch 2, d_loss=-0.257 g_loss=-0.486 KID= 0.00672\n",
      "epoch 559, batch 3, d_loss=-0.329 g_loss=-0.519 KID= 0.00672\n",
      "epoch 559, batch 4, d_loss=-0.259 g_loss=-0.413 KID= 0.00672\n",
      "epoch 559, batch 5, d_loss=-0.335 g_loss=-0.293 KID= 0.00672\n",
      "epoch 559, batch 6, d_loss=-0.302 g_loss=-0.076 KID= 0.00672\n",
      "epoch 559, batch 7, d_loss=-0.348 g_loss=0.195 KID= 0.00672\n",
      "epoch 559, batch 8, d_loss=-0.320 g_loss=0.383 KID= 0.00672\n",
      "epoch 559, batch 9, d_loss=-0.414 g_loss=0.588 KID= 0.00672\n",
      "epoch 559, batch 10, d_loss=-0.359 g_loss=0.406 KID= 0.00672\n",
      "epoch 559, batch 11, d_loss=-0.278 g_loss=0.229 KID= 0.00672\n",
      "epoch 559, batch 12, d_loss=-0.270 g_loss=0.102 KID= 0.00672\n",
      "epoch 559, batch 13, d_loss=-0.321 g_loss=-0.077 KID= 0.00672\n",
      "epoch 559, batch 14, d_loss=-0.216 g_loss=-0.110 KID= 0.00672\n",
      "epoch 559, batch 15, d_loss=-0.305 g_loss=-0.201 KID= 0.00672\n",
      "epoch 559, batch 16, d_loss=-0.259 g_loss=-0.326 KID= 0.00672\n",
      "epoch 559, batch 17, d_loss=-0.296 g_loss=-0.290 KID= 0.00672\n",
      "epoch 559, batch 18, d_loss=-0.387 g_loss=-0.269 KID= 0.00672\n",
      "epoch 559, batch 19, d_loss=-0.393 g_loss=-0.356 KID= 0.00672\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 560, batch 0, d_loss=-0.383 g_loss=-0.577 KID= 0.00724\n",
      "epoch 560, batch 1, d_loss=-0.311 g_loss=-0.628 KID= 0.00724\n",
      "epoch 560, batch 2, d_loss=-0.257 g_loss=-0.700 KID= 0.00724\n",
      "epoch 560, batch 3, d_loss=-0.295 g_loss=-0.731 KID= 0.00724\n",
      "epoch 560, batch 4, d_loss=-0.223 g_loss=-0.726 KID= 0.00724\n",
      "epoch 560, batch 5, d_loss=-0.361 g_loss=-0.710 KID= 0.00724\n",
      "epoch 560, batch 6, d_loss=-0.321 g_loss=-0.622 KID= 0.00724\n",
      "epoch 560, batch 7, d_loss=-0.338 g_loss=-0.500 KID= 0.00724\n",
      "epoch 560, batch 8, d_loss=-0.298 g_loss=-0.345 KID= 0.00724\n",
      "epoch 560, batch 9, d_loss=-0.413 g_loss=-0.241 KID= 0.00724\n",
      "epoch 560, batch 10, d_loss=-0.309 g_loss=-0.311 KID= 0.00724\n",
      "epoch 560, batch 11, d_loss=-0.258 g_loss=-0.193 KID= 0.00724\n",
      "epoch 560, batch 12, d_loss=-0.347 g_loss=-0.133 KID= 0.00724\n",
      "epoch 560, batch 13, d_loss=-0.348 g_loss=-0.156 KID= 0.00724\n",
      "epoch 560, batch 14, d_loss=-0.240 g_loss=-0.197 KID= 0.00724\n",
      "epoch 560, batch 15, d_loss=-0.298 g_loss=-0.219 KID= 0.00724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 560, batch 16, d_loss=-0.348 g_loss=-0.169 KID= 0.00724\n",
      "epoch 560, batch 17, d_loss=-0.302 g_loss=-0.013 KID= 0.00724\n",
      "epoch 560, batch 18, d_loss=-0.284 g_loss=-0.034 KID= 0.00724\n",
      "epoch 560, batch 19, d_loss=-0.370 g_loss=-0.103 KID= 0.00724\n",
      "epoch 561, batch 0, d_loss=-0.379 g_loss=-0.347 KID= 0.00724\n",
      "epoch 561, batch 1, d_loss=-0.278 g_loss=-0.502 KID= 0.00724\n",
      "epoch 561, batch 2, d_loss=-0.363 g_loss=-0.644 KID= 0.00724\n",
      "epoch 561, batch 3, d_loss=-0.354 g_loss=-0.863 KID= 0.00724\n",
      "epoch 561, batch 4, d_loss=-0.264 g_loss=-0.999 KID= 0.00724\n",
      "epoch 561, batch 5, d_loss=-0.343 g_loss=-0.993 KID= 0.00724\n",
      "epoch 561, batch 6, d_loss=-0.327 g_loss=-0.935 KID= 0.00724\n",
      "epoch 561, batch 7, d_loss=-0.280 g_loss=-0.787 KID= 0.00724\n",
      "epoch 561, batch 8, d_loss=-0.342 g_loss=-0.618 KID= 0.00724\n",
      "epoch 561, batch 9, d_loss=-0.358 g_loss=-0.448 KID= 0.00724\n",
      "epoch 561, batch 10, d_loss=-0.387 g_loss=-0.466 KID= 0.00724\n",
      "epoch 561, batch 11, d_loss=-0.280 g_loss=-0.367 KID= 0.00724\n",
      "epoch 561, batch 12, d_loss=-0.296 g_loss=-0.296 KID= 0.00724\n",
      "epoch 561, batch 13, d_loss=-0.288 g_loss=-0.287 KID= 0.00724\n",
      "epoch 561, batch 14, d_loss=-0.261 g_loss=-0.295 KID= 0.00724\n",
      "epoch 561, batch 15, d_loss=-0.386 g_loss=-0.205 KID= 0.00724\n",
      "epoch 561, batch 16, d_loss=-0.285 g_loss=-0.139 KID= 0.00724\n",
      "epoch 561, batch 17, d_loss=-0.374 g_loss=-0.143 KID= 0.00724\n",
      "epoch 561, batch 18, d_loss=-0.270 g_loss=-0.112 KID= 0.00724\n",
      "epoch 561, batch 19, d_loss=-0.377 g_loss=-0.099 KID= 0.00724\n",
      "epoch 562, batch 0, d_loss=-0.324 g_loss=-0.269 KID= 0.00724\n",
      "epoch 562, batch 1, d_loss=-0.297 g_loss=-0.302 KID= 0.00724\n",
      "epoch 562, batch 2, d_loss=-0.345 g_loss=-0.382 KID= 0.00724\n",
      "epoch 562, batch 3, d_loss=-0.346 g_loss=-0.563 KID= 0.00724\n",
      "epoch 562, batch 4, d_loss=-0.223 g_loss=-0.665 KID= 0.00724\n",
      "epoch 562, batch 5, d_loss=-0.305 g_loss=-0.585 KID= 0.00724\n",
      "epoch 562, batch 6, d_loss=-0.336 g_loss=-0.469 KID= 0.00724\n",
      "epoch 562, batch 7, d_loss=-0.330 g_loss=-0.386 KID= 0.00724\n",
      "epoch 562, batch 8, d_loss=-0.323 g_loss=-0.375 KID= 0.00724\n",
      "epoch 562, batch 9, d_loss=-0.396 g_loss=-0.418 KID= 0.00724\n",
      "epoch 562, batch 10, d_loss=-0.396 g_loss=-0.637 KID= 0.00724\n",
      "epoch 562, batch 11, d_loss=-0.285 g_loss=-0.494 KID= 0.00724\n",
      "epoch 562, batch 12, d_loss=-0.309 g_loss=-0.524 KID= 0.00724\n",
      "epoch 562, batch 13, d_loss=-0.302 g_loss=-0.546 KID= 0.00724\n",
      "epoch 562, batch 14, d_loss=-0.248 g_loss=-0.548 KID= 0.00724\n",
      "epoch 562, batch 15, d_loss=-0.343 g_loss=-0.516 KID= 0.00724\n",
      "epoch 562, batch 16, d_loss=-0.317 g_loss=-0.457 KID= 0.00724\n",
      "epoch 562, batch 17, d_loss=-0.296 g_loss=-0.365 KID= 0.00724\n",
      "epoch 562, batch 18, d_loss=-0.298 g_loss=-0.275 KID= 0.00724\n",
      "epoch 562, batch 19, d_loss=-0.363 g_loss=-0.153 KID= 0.00724\n",
      "epoch 563, batch 0, d_loss=-0.369 g_loss=-0.255 KID= 0.00724\n",
      "epoch 563, batch 1, d_loss=-0.321 g_loss=-0.252 KID= 0.00724\n",
      "epoch 563, batch 2, d_loss=-0.306 g_loss=-0.330 KID= 0.00724\n",
      "epoch 563, batch 3, d_loss=-0.339 g_loss=-0.389 KID= 0.00724\n",
      "epoch 563, batch 4, d_loss=-0.238 g_loss=-0.471 KID= 0.00724\n",
      "epoch 563, batch 5, d_loss=-0.343 g_loss=-0.505 KID= 0.00724\n",
      "epoch 563, batch 6, d_loss=-0.282 g_loss=-0.541 KID= 0.00724\n",
      "epoch 563, batch 7, d_loss=-0.272 g_loss=-0.446 KID= 0.00724\n",
      "epoch 563, batch 8, d_loss=-0.342 g_loss=-0.215 KID= 0.00724\n",
      "epoch 563, batch 9, d_loss=-0.385 g_loss=0.040 KID= 0.00724\n",
      "epoch 563, batch 10, d_loss=-0.380 g_loss=0.035 KID= 0.00724\n",
      "epoch 563, batch 11, d_loss=-0.322 g_loss=0.079 KID= 0.00724\n",
      "epoch 563, batch 12, d_loss=-0.331 g_loss=0.014 KID= 0.00724\n",
      "epoch 563, batch 13, d_loss=-0.254 g_loss=-0.279 KID= 0.00724\n",
      "epoch 563, batch 14, d_loss=-0.196 g_loss=-0.417 KID= 0.00724\n",
      "epoch 563, batch 15, d_loss=-0.368 g_loss=-0.538 KID= 0.00724\n",
      "epoch 563, batch 16, d_loss=-0.328 g_loss=-0.588 KID= 0.00724\n",
      "epoch 563, batch 17, d_loss=-0.311 g_loss=-0.621 KID= 0.00724\n",
      "epoch 563, batch 18, d_loss=-0.300 g_loss=-0.484 KID= 0.00724\n",
      "epoch 563, batch 19, d_loss=-0.386 g_loss=-0.297 KID= 0.00724\n",
      "epoch 564, batch 0, d_loss=-0.436 g_loss=-0.322 KID= 0.00724\n",
      "epoch 564, batch 1, d_loss=-0.280 g_loss=-0.199 KID= 0.00724\n",
      "epoch 564, batch 2, d_loss=-0.273 g_loss=-0.169 KID= 0.00724\n",
      "epoch 564, batch 3, d_loss=-0.299 g_loss=-0.340 KID= 0.00724\n",
      "epoch 564, batch 4, d_loss=-0.225 g_loss=-0.374 KID= 0.00724\n",
      "epoch 564, batch 5, d_loss=-0.318 g_loss=-0.440 KID= 0.00724\n",
      "epoch 564, batch 6, d_loss=-0.336 g_loss=-0.395 KID= 0.00724\n",
      "epoch 564, batch 7, d_loss=-0.337 g_loss=-0.441 KID= 0.00724\n",
      "epoch 564, batch 8, d_loss=-0.376 g_loss=-0.407 KID= 0.00724\n",
      "epoch 564, batch 9, d_loss=-0.434 g_loss=-0.295 KID= 0.00724\n",
      "epoch 564, batch 10, d_loss=-0.364 g_loss=-0.351 KID= 0.00724\n",
      "epoch 564, batch 11, d_loss=-0.323 g_loss=-0.300 KID= 0.00724\n",
      "epoch 564, batch 12, d_loss=-0.298 g_loss=-0.315 KID= 0.00724\n",
      "epoch 564, batch 13, d_loss=-0.292 g_loss=-0.501 KID= 0.00724\n",
      "epoch 564, batch 14, d_loss=-0.206 g_loss=-0.575 KID= 0.00724\n",
      "epoch 564, batch 15, d_loss=-0.309 g_loss=-0.620 KID= 0.00724\n",
      "epoch 564, batch 16, d_loss=-0.321 g_loss=-0.687 KID= 0.00724\n",
      "epoch 564, batch 17, d_loss=-0.278 g_loss=-0.596 KID= 0.00724\n",
      "epoch 564, batch 18, d_loss=-0.338 g_loss=-0.449 KID= 0.00724\n",
      "epoch 564, batch 19, d_loss=-0.376 g_loss=-0.277 KID= 0.00724\n",
      "epoch 565, batch 0, d_loss=-0.418 g_loss=-0.332 KID= 0.00724\n",
      "epoch 565, batch 1, d_loss=-0.320 g_loss=-0.201 KID= 0.00724\n",
      "epoch 565, batch 2, d_loss=-0.344 g_loss=-0.192 KID= 0.00724\n",
      "epoch 565, batch 3, d_loss=-0.254 g_loss=-0.283 KID= 0.00724\n",
      "epoch 565, batch 4, d_loss=-0.236 g_loss=-0.397 KID= 0.00724\n",
      "epoch 565, batch 5, d_loss=-0.309 g_loss=-0.480 KID= 0.00724\n",
      "epoch 565, batch 6, d_loss=-0.365 g_loss=-0.505 KID= 0.00724\n",
      "epoch 565, batch 7, d_loss=-0.310 g_loss=-0.581 KID= 0.00724\n",
      "epoch 565, batch 8, d_loss=-0.331 g_loss=-0.524 KID= 0.00724\n",
      "epoch 565, batch 9, d_loss=-0.371 g_loss=-0.437 KID= 0.00724\n",
      "epoch 565, batch 10, d_loss=-0.417 g_loss=-0.643 KID= 0.00724\n",
      "epoch 565, batch 11, d_loss=-0.243 g_loss=-0.567 KID= 0.00724\n",
      "epoch 565, batch 12, d_loss=-0.275 g_loss=-0.527 KID= 0.00724\n",
      "epoch 565, batch 13, d_loss=-0.339 g_loss=-0.662 KID= 0.00724\n",
      "epoch 565, batch 14, d_loss=-0.223 g_loss=-0.599 KID= 0.00724\n",
      "epoch 565, batch 15, d_loss=-0.322 g_loss=-0.578 KID= 0.00724\n",
      "epoch 565, batch 16, d_loss=-0.303 g_loss=-0.570 KID= 0.00724\n",
      "epoch 565, batch 17, d_loss=-0.304 g_loss=-0.502 KID= 0.00724\n",
      "epoch 565, batch 18, d_loss=-0.389 g_loss=-0.382 KID= 0.00724\n",
      "epoch 565, batch 19, d_loss=-0.402 g_loss=-0.223 KID= 0.00724\n",
      "epoch 566, batch 0, d_loss=-0.349 g_loss=-0.182 KID= 0.00724\n",
      "epoch 566, batch 1, d_loss=-0.305 g_loss=-0.133 KID= 0.00724\n",
      "epoch 566, batch 2, d_loss=-0.319 g_loss=-0.146 KID= 0.00724\n",
      "epoch 566, batch 3, d_loss=-0.322 g_loss=-0.355 KID= 0.00724\n",
      "epoch 566, batch 4, d_loss=-0.234 g_loss=-0.445 KID= 0.00724\n",
      "epoch 566, batch 5, d_loss=-0.325 g_loss=-0.486 KID= 0.00724\n",
      "epoch 566, batch 6, d_loss=-0.302 g_loss=-0.492 KID= 0.00724\n",
      "epoch 566, batch 7, d_loss=-0.316 g_loss=-0.450 KID= 0.00724\n",
      "epoch 566, batch 8, d_loss=-0.378 g_loss=-0.382 KID= 0.00724\n",
      "epoch 566, batch 9, d_loss=-0.414 g_loss=-0.228 KID= 0.00724\n",
      "epoch 566, batch 10, d_loss=-0.397 g_loss=-0.341 KID= 0.00724\n",
      "epoch 566, batch 11, d_loss=-0.269 g_loss=-0.226 KID= 0.00724\n",
      "epoch 566, batch 12, d_loss=-0.317 g_loss=-0.203 KID= 0.00724\n",
      "epoch 566, batch 13, d_loss=-0.312 g_loss=-0.301 KID= 0.00724\n",
      "epoch 566, batch 14, d_loss=-0.247 g_loss=-0.420 KID= 0.00724\n",
      "epoch 566, batch 15, d_loss=-0.335 g_loss=-0.342 KID= 0.00724\n",
      "epoch 566, batch 16, d_loss=-0.335 g_loss=-0.390 KID= 0.00724\n",
      "epoch 566, batch 17, d_loss=-0.303 g_loss=-0.414 KID= 0.00724\n",
      "epoch 566, batch 18, d_loss=-0.312 g_loss=-0.347 KID= 0.00724\n",
      "epoch 566, batch 19, d_loss=-0.393 g_loss=-0.150 KID= 0.00724\n",
      "epoch 567, batch 0, d_loss=-0.355 g_loss=-0.108 KID= 0.00724\n",
      "epoch 567, batch 1, d_loss=-0.350 g_loss=0.061 KID= 0.00724\n",
      "epoch 567, batch 2, d_loss=-0.332 g_loss=0.192 KID= 0.00724\n",
      "epoch 567, batch 3, d_loss=-0.307 g_loss=0.067 KID= 0.00724\n",
      "epoch 567, batch 4, d_loss=-0.236 g_loss=-0.016 KID= 0.00724\n",
      "epoch 567, batch 5, d_loss=-0.353 g_loss=-0.150 KID= 0.00724\n",
      "epoch 567, batch 6, d_loss=-0.272 g_loss=-0.245 KID= 0.00724\n",
      "epoch 567, batch 7, d_loss=-0.273 g_loss=-0.258 KID= 0.00724\n",
      "epoch 567, batch 8, d_loss=-0.358 g_loss=-0.228 KID= 0.00724\n",
      "epoch 567, batch 9, d_loss=-0.450 g_loss=-0.140 KID= 0.00724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 567, batch 10, d_loss=-0.394 g_loss=-0.218 KID= 0.00724\n",
      "epoch 567, batch 11, d_loss=-0.331 g_loss=-0.242 KID= 0.00724\n",
      "epoch 567, batch 12, d_loss=-0.346 g_loss=-0.364 KID= 0.00724\n",
      "epoch 567, batch 13, d_loss=-0.288 g_loss=-0.439 KID= 0.00724\n",
      "epoch 567, batch 14, d_loss=-0.241 g_loss=-0.525 KID= 0.00724\n",
      "epoch 567, batch 15, d_loss=-0.284 g_loss=-0.673 KID= 0.00724\n",
      "epoch 567, batch 16, d_loss=-0.340 g_loss=-0.782 KID= 0.00724\n",
      "epoch 567, batch 17, d_loss=-0.343 g_loss=-0.812 KID= 0.00724\n",
      "epoch 567, batch 18, d_loss=-0.385 g_loss=-0.726 KID= 0.00724\n",
      "epoch 567, batch 19, d_loss=-0.387 g_loss=-0.598 KID= 0.00724\n",
      "epoch 568, batch 0, d_loss=-0.348 g_loss=-0.639 KID= 0.00724\n",
      "epoch 568, batch 1, d_loss=-0.247 g_loss=-0.503 KID= 0.00724\n",
      "epoch 568, batch 2, d_loss=-0.308 g_loss=-0.449 KID= 0.00724\n",
      "epoch 568, batch 3, d_loss=-0.287 g_loss=-0.387 KID= 0.00724\n",
      "epoch 568, batch 4, d_loss=-0.276 g_loss=-0.361 KID= 0.00724\n",
      "epoch 568, batch 5, d_loss=-0.376 g_loss=-0.429 KID= 0.00724\n",
      "epoch 568, batch 6, d_loss=-0.313 g_loss=-0.431 KID= 0.00724\n",
      "epoch 568, batch 7, d_loss=-0.295 g_loss=-0.399 KID= 0.00724\n",
      "epoch 568, batch 8, d_loss=-0.354 g_loss=-0.269 KID= 0.00724\n",
      "epoch 568, batch 9, d_loss=-0.423 g_loss=-0.113 KID= 0.00724\n",
      "epoch 568, batch 10, d_loss=-0.327 g_loss=-0.095 KID= 0.00724\n",
      "epoch 568, batch 11, d_loss=-0.322 g_loss=-0.098 KID= 0.00724\n",
      "epoch 568, batch 12, d_loss=-0.269 g_loss=-0.254 KID= 0.00724\n",
      "epoch 568, batch 13, d_loss=-0.331 g_loss=-0.419 KID= 0.00724\n",
      "epoch 568, batch 14, d_loss=-0.256 g_loss=-0.647 KID= 0.00724\n",
      "epoch 568, batch 15, d_loss=-0.354 g_loss=-0.810 KID= 0.00724\n",
      "epoch 568, batch 16, d_loss=-0.324 g_loss=-0.920 KID= 0.00724\n",
      "epoch 568, batch 17, d_loss=-0.320 g_loss=-0.983 KID= 0.00724\n",
      "epoch 568, batch 18, d_loss=-0.383 g_loss=-0.803 KID= 0.00724\n",
      "epoch 568, batch 19, d_loss=-0.389 g_loss=-0.636 KID= 0.00724\n",
      "epoch 569, batch 0, d_loss=-0.332 g_loss=-0.538 KID= 0.00724\n",
      "epoch 569, batch 1, d_loss=-0.324 g_loss=-0.336 KID= 0.00724\n",
      "epoch 569, batch 2, d_loss=-0.290 g_loss=-0.305 KID= 0.00724\n",
      "epoch 569, batch 3, d_loss=-0.300 g_loss=-0.340 KID= 0.00724\n",
      "epoch 569, batch 4, d_loss=-0.286 g_loss=-0.409 KID= 0.00724\n",
      "epoch 569, batch 5, d_loss=-0.305 g_loss=-0.467 KID= 0.00724\n",
      "epoch 569, batch 6, d_loss=-0.339 g_loss=-0.616 KID= 0.00724\n",
      "epoch 569, batch 7, d_loss=-0.279 g_loss=-0.653 KID= 0.00724\n",
      "epoch 569, batch 8, d_loss=-0.352 g_loss=-0.503 KID= 0.00724\n",
      "epoch 569, batch 9, d_loss=-0.434 g_loss=-0.342 KID= 0.00724\n",
      "epoch 569, batch 10, d_loss=-0.357 g_loss=-0.309 KID= 0.00724\n",
      "epoch 569, batch 11, d_loss=-0.277 g_loss=-0.157 KID= 0.00724\n",
      "epoch 569, batch 12, d_loss=-0.293 g_loss=-0.075 KID= 0.00724\n",
      "epoch 569, batch 13, d_loss=-0.289 g_loss=-0.032 KID= 0.00724\n",
      "epoch 569, batch 14, d_loss=-0.250 g_loss=-0.058 KID= 0.00724\n",
      "epoch 569, batch 15, d_loss=-0.365 g_loss=-0.118 KID= 0.00724\n",
      "epoch 569, batch 16, d_loss=-0.352 g_loss=-0.214 KID= 0.00724\n",
      "epoch 569, batch 17, d_loss=-0.308 g_loss=-0.225 KID= 0.00724\n",
      "epoch 569, batch 18, d_loss=-0.358 g_loss=-0.269 KID= 0.00724\n",
      "epoch 569, batch 19, d_loss=-0.399 g_loss=-0.287 KID= 0.00724\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 570, batch 0, d_loss=-0.317 g_loss=-0.369 KID= 0.00688\n",
      "epoch 570, batch 1, d_loss=-0.335 g_loss=-0.316 KID= 0.00688\n",
      "epoch 570, batch 2, d_loss=-0.294 g_loss=-0.280 KID= 0.00688\n",
      "epoch 570, batch 3, d_loss=-0.338 g_loss=-0.412 KID= 0.00688\n",
      "epoch 570, batch 4, d_loss=-0.289 g_loss=-0.553 KID= 0.00688\n",
      "epoch 570, batch 5, d_loss=-0.315 g_loss=-0.688 KID= 0.00688\n",
      "epoch 570, batch 6, d_loss=-0.359 g_loss=-0.730 KID= 0.00688\n",
      "epoch 570, batch 7, d_loss=-0.336 g_loss=-0.755 KID= 0.00688\n",
      "epoch 570, batch 8, d_loss=-0.318 g_loss=-0.624 KID= 0.00688\n",
      "epoch 570, batch 9, d_loss=-0.409 g_loss=-0.538 KID= 0.00688\n",
      "epoch 570, batch 10, d_loss=-0.352 g_loss=-0.508 KID= 0.00688\n",
      "epoch 570, batch 11, d_loss=-0.339 g_loss=-0.422 KID= 0.00688\n",
      "epoch 570, batch 12, d_loss=-0.323 g_loss=-0.360 KID= 0.00688\n",
      "epoch 570, batch 13, d_loss=-0.312 g_loss=-0.472 KID= 0.00688\n",
      "epoch 570, batch 14, d_loss=-0.253 g_loss=-0.586 KID= 0.00688\n",
      "epoch 570, batch 15, d_loss=-0.311 g_loss=-0.756 KID= 0.00688\n",
      "epoch 570, batch 16, d_loss=-0.291 g_loss=-0.863 KID= 0.00688\n",
      "epoch 570, batch 17, d_loss=-0.295 g_loss=-0.857 KID= 0.00688\n",
      "epoch 570, batch 18, d_loss=-0.376 g_loss=-0.729 KID= 0.00688\n",
      "epoch 570, batch 19, d_loss=-0.401 g_loss=-0.470 KID= 0.00688\n",
      "epoch 571, batch 0, d_loss=-0.345 g_loss=-0.371 KID= 0.00688\n",
      "epoch 571, batch 1, d_loss=-0.320 g_loss=-0.205 KID= 0.00688\n",
      "epoch 571, batch 2, d_loss=-0.299 g_loss=-0.121 KID= 0.00688\n",
      "epoch 571, batch 3, d_loss=-0.288 g_loss=-0.185 KID= 0.00688\n",
      "epoch 571, batch 4, d_loss=-0.272 g_loss=-0.259 KID= 0.00688\n",
      "epoch 571, batch 5, d_loss=-0.368 g_loss=-0.363 KID= 0.00688\n",
      "epoch 571, batch 6, d_loss=-0.333 g_loss=-0.488 KID= 0.00688\n",
      "epoch 571, batch 7, d_loss=-0.275 g_loss=-0.485 KID= 0.00688\n",
      "epoch 571, batch 8, d_loss=-0.323 g_loss=-0.456 KID= 0.00688\n",
      "epoch 571, batch 9, d_loss=-0.456 g_loss=-0.412 KID= 0.00688\n",
      "epoch 571, batch 10, d_loss=-0.328 g_loss=-0.441 KID= 0.00688\n",
      "epoch 571, batch 11, d_loss=-0.271 g_loss=-0.318 KID= 0.00688\n",
      "epoch 571, batch 12, d_loss=-0.320 g_loss=-0.254 KID= 0.00688\n",
      "epoch 571, batch 13, d_loss=-0.267 g_loss=-0.342 KID= 0.00688\n",
      "epoch 571, batch 14, d_loss=-0.291 g_loss=-0.369 KID= 0.00688\n",
      "epoch 571, batch 15, d_loss=-0.354 g_loss=-0.394 KID= 0.00688\n",
      "epoch 571, batch 16, d_loss=-0.349 g_loss=-0.387 KID= 0.00688\n",
      "epoch 571, batch 17, d_loss=-0.340 g_loss=-0.372 KID= 0.00688\n",
      "epoch 571, batch 18, d_loss=-0.370 g_loss=-0.335 KID= 0.00688\n",
      "epoch 571, batch 19, d_loss=-0.352 g_loss=-0.305 KID= 0.00688\n",
      "epoch 572, batch 0, d_loss=-0.316 g_loss=-0.380 KID= 0.00688\n",
      "epoch 572, batch 1, d_loss=-0.257 g_loss=-0.297 KID= 0.00688\n",
      "epoch 572, batch 2, d_loss=-0.322 g_loss=-0.188 KID= 0.00688\n",
      "epoch 572, batch 3, d_loss=-0.318 g_loss=-0.224 KID= 0.00688\n",
      "epoch 572, batch 4, d_loss=-0.257 g_loss=-0.340 KID= 0.00688\n",
      "epoch 572, batch 5, d_loss=-0.331 g_loss=-0.452 KID= 0.00688\n",
      "epoch 572, batch 6, d_loss=-0.304 g_loss=-0.545 KID= 0.00688\n",
      "epoch 572, batch 7, d_loss=-0.240 g_loss=-0.629 KID= 0.00688\n",
      "epoch 572, batch 8, d_loss=-0.397 g_loss=-0.635 KID= 0.00688\n",
      "epoch 572, batch 9, d_loss=-0.420 g_loss=-0.541 KID= 0.00688\n",
      "epoch 572, batch 10, d_loss=-0.329 g_loss=-0.601 KID= 0.00688\n",
      "epoch 572, batch 11, d_loss=-0.279 g_loss=-0.489 KID= 0.00688\n",
      "epoch 572, batch 12, d_loss=-0.347 g_loss=-0.349 KID= 0.00688\n",
      "epoch 572, batch 13, d_loss=-0.297 g_loss=-0.330 KID= 0.00688\n",
      "epoch 572, batch 14, d_loss=-0.280 g_loss=-0.319 KID= 0.00688\n",
      "epoch 572, batch 15, d_loss=-0.323 g_loss=-0.333 KID= 0.00688\n",
      "epoch 572, batch 16, d_loss=-0.348 g_loss=-0.432 KID= 0.00688\n",
      "epoch 572, batch 17, d_loss=-0.246 g_loss=-0.359 KID= 0.00688\n",
      "epoch 572, batch 18, d_loss=-0.383 g_loss=-0.262 KID= 0.00688\n",
      "epoch 572, batch 19, d_loss=-0.415 g_loss=-0.153 KID= 0.00688\n",
      "epoch 573, batch 0, d_loss=-0.353 g_loss=-0.092 KID= 0.00688\n",
      "epoch 573, batch 1, d_loss=-0.278 g_loss=-0.066 KID= 0.00688\n",
      "epoch 573, batch 2, d_loss=-0.331 g_loss=-0.149 KID= 0.00688\n",
      "epoch 573, batch 3, d_loss=-0.358 g_loss=-0.214 KID= 0.00688\n",
      "epoch 573, batch 4, d_loss=-0.300 g_loss=-0.329 KID= 0.00688\n",
      "epoch 573, batch 5, d_loss=-0.379 g_loss=-0.501 KID= 0.00688\n",
      "epoch 573, batch 6, d_loss=-0.278 g_loss=-0.610 KID= 0.00688\n",
      "epoch 573, batch 7, d_loss=-0.264 g_loss=-0.617 KID= 0.00688\n",
      "epoch 573, batch 8, d_loss=-0.401 g_loss=-0.505 KID= 0.00688\n",
      "epoch 573, batch 9, d_loss=-0.367 g_loss=-0.387 KID= 0.00688\n",
      "epoch 573, batch 10, d_loss=-0.346 g_loss=-0.271 KID= 0.00688\n",
      "epoch 573, batch 11, d_loss=-0.327 g_loss=-0.158 KID= 0.00688\n",
      "epoch 573, batch 12, d_loss=-0.332 g_loss=-0.161 KID= 0.00688\n",
      "epoch 573, batch 13, d_loss=-0.253 g_loss=-0.235 KID= 0.00688\n",
      "epoch 573, batch 14, d_loss=-0.287 g_loss=-0.327 KID= 0.00688\n",
      "epoch 573, batch 15, d_loss=-0.361 g_loss=-0.470 KID= 0.00688\n",
      "epoch 573, batch 16, d_loss=-0.366 g_loss=-0.684 KID= 0.00688\n",
      "epoch 573, batch 17, d_loss=-0.282 g_loss=-0.773 KID= 0.00688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 573, batch 18, d_loss=-0.393 g_loss=-0.750 KID= 0.00688\n",
      "epoch 573, batch 19, d_loss=-0.383 g_loss=-0.615 KID= 0.00688\n",
      "epoch 574, batch 0, d_loss=-0.331 g_loss=-0.543 KID= 0.00688\n",
      "epoch 574, batch 1, d_loss=-0.241 g_loss=-0.366 KID= 0.00688\n",
      "epoch 574, batch 2, d_loss=-0.331 g_loss=-0.321 KID= 0.00688\n",
      "epoch 574, batch 3, d_loss=-0.293 g_loss=-0.322 KID= 0.00688\n",
      "epoch 574, batch 4, d_loss=-0.286 g_loss=-0.379 KID= 0.00688\n",
      "epoch 574, batch 5, d_loss=-0.303 g_loss=-0.465 KID= 0.00688\n",
      "epoch 574, batch 6, d_loss=-0.339 g_loss=-0.560 KID= 0.00688\n",
      "epoch 574, batch 7, d_loss=-0.287 g_loss=-0.513 KID= 0.00688\n",
      "epoch 574, batch 8, d_loss=-0.408 g_loss=-0.416 KID= 0.00688\n",
      "epoch 574, batch 9, d_loss=-0.423 g_loss=-0.206 KID= 0.00688\n",
      "epoch 574, batch 10, d_loss=-0.318 g_loss=-0.077 KID= 0.00688\n",
      "epoch 574, batch 11, d_loss=-0.304 g_loss=0.109 KID= 0.00688\n",
      "epoch 574, batch 12, d_loss=-0.382 g_loss=0.271 KID= 0.00688\n",
      "epoch 574, batch 13, d_loss=-0.345 g_loss=0.300 KID= 0.00688\n",
      "epoch 574, batch 14, d_loss=-0.293 g_loss=0.219 KID= 0.00688\n",
      "epoch 574, batch 15, d_loss=-0.308 g_loss=0.057 KID= 0.00688\n",
      "epoch 574, batch 16, d_loss=-0.324 g_loss=-0.204 KID= 0.00688\n",
      "epoch 574, batch 17, d_loss=-0.250 g_loss=-0.271 KID= 0.00688\n",
      "epoch 574, batch 18, d_loss=-0.359 g_loss=-0.404 KID= 0.00688\n",
      "epoch 574, batch 19, d_loss=-0.375 g_loss=-0.457 KID= 0.00688\n",
      "epoch 575, batch 0, d_loss=-0.362 g_loss=-0.515 KID= 0.00688\n",
      "epoch 575, batch 1, d_loss=-0.309 g_loss=-0.494 KID= 0.00688\n",
      "epoch 575, batch 2, d_loss=-0.356 g_loss=-0.550 KID= 0.00688\n",
      "epoch 575, batch 3, d_loss=-0.323 g_loss=-0.550 KID= 0.00688\n",
      "epoch 575, batch 4, d_loss=-0.300 g_loss=-0.488 KID= 0.00688\n",
      "epoch 575, batch 5, d_loss=-0.292 g_loss=-0.409 KID= 0.00688\n",
      "epoch 575, batch 6, d_loss=-0.340 g_loss=-0.492 KID= 0.00688\n",
      "epoch 575, batch 7, d_loss=-0.229 g_loss=-0.517 KID= 0.00688\n",
      "epoch 575, batch 8, d_loss=-0.403 g_loss=-0.448 KID= 0.00688\n",
      "epoch 575, batch 9, d_loss=-0.403 g_loss=-0.311 KID= 0.00688\n",
      "epoch 575, batch 10, d_loss=-0.357 g_loss=-0.232 KID= 0.00688\n",
      "epoch 575, batch 11, d_loss=-0.320 g_loss=-0.143 KID= 0.00688\n",
      "epoch 575, batch 12, d_loss=-0.348 g_loss=-0.045 KID= 0.00688\n",
      "epoch 575, batch 13, d_loss=-0.345 g_loss=-0.084 KID= 0.00688\n",
      "epoch 575, batch 14, d_loss=-0.272 g_loss=-0.061 KID= 0.00688\n",
      "epoch 575, batch 15, d_loss=-0.334 g_loss=-0.103 KID= 0.00688\n",
      "epoch 575, batch 16, d_loss=-0.368 g_loss=-0.197 KID= 0.00688\n",
      "epoch 575, batch 17, d_loss=-0.299 g_loss=-0.190 KID= 0.00688\n",
      "epoch 575, batch 18, d_loss=-0.449 g_loss=-0.097 KID= 0.00688\n",
      "epoch 575, batch 19, d_loss=-0.416 g_loss=-0.095 KID= 0.00688\n",
      "epoch 576, batch 0, d_loss=-0.342 g_loss=-0.083 KID= 0.00688\n",
      "epoch 576, batch 1, d_loss=-0.287 g_loss=-0.099 KID= 0.00688\n",
      "epoch 576, batch 2, d_loss=-0.340 g_loss=-0.026 KID= 0.00688\n",
      "epoch 576, batch 3, d_loss=-0.275 g_loss=-0.067 KID= 0.00688\n",
      "epoch 576, batch 4, d_loss=-0.286 g_loss=-0.188 KID= 0.00688\n",
      "epoch 576, batch 5, d_loss=-0.346 g_loss=-0.391 KID= 0.00688\n",
      "epoch 576, batch 6, d_loss=-0.393 g_loss=-0.609 KID= 0.00688\n",
      "epoch 576, batch 7, d_loss=-0.265 g_loss=-0.677 KID= 0.00688\n",
      "epoch 576, batch 8, d_loss=-0.399 g_loss=-0.623 KID= 0.00688\n",
      "epoch 576, batch 9, d_loss=-0.368 g_loss=-0.548 KID= 0.00688\n",
      "epoch 576, batch 10, d_loss=-0.350 g_loss=-0.501 KID= 0.00688\n",
      "epoch 576, batch 11, d_loss=-0.319 g_loss=-0.447 KID= 0.00688\n",
      "epoch 576, batch 12, d_loss=-0.351 g_loss=-0.391 KID= 0.00688\n",
      "epoch 576, batch 13, d_loss=-0.317 g_loss=-0.356 KID= 0.00688\n",
      "epoch 576, batch 14, d_loss=-0.258 g_loss=-0.249 KID= 0.00688\n",
      "epoch 576, batch 15, d_loss=-0.369 g_loss=-0.120 KID= 0.00688\n",
      "epoch 576, batch 16, d_loss=-0.325 g_loss=-0.207 KID= 0.00688\n",
      "epoch 576, batch 17, d_loss=-0.282 g_loss=-0.213 KID= 0.00688\n",
      "epoch 576, batch 18, d_loss=-0.391 g_loss=-0.099 KID= 0.00688\n",
      "epoch 576, batch 19, d_loss=-0.371 g_loss=-0.055 KID= 0.00688\n",
      "epoch 577, batch 0, d_loss=-0.381 g_loss=-0.041 KID= 0.00688\n",
      "epoch 577, batch 1, d_loss=-0.338 g_loss=-0.117 KID= 0.00688\n",
      "epoch 577, batch 2, d_loss=-0.331 g_loss=-0.152 KID= 0.00688\n",
      "epoch 577, batch 3, d_loss=-0.278 g_loss=-0.260 KID= 0.00688\n",
      "epoch 577, batch 4, d_loss=-0.285 g_loss=-0.297 KID= 0.00688\n",
      "epoch 577, batch 5, d_loss=-0.349 g_loss=-0.414 KID= 0.00688\n",
      "epoch 577, batch 6, d_loss=-0.373 g_loss=-0.564 KID= 0.00688\n",
      "epoch 577, batch 7, d_loss=-0.296 g_loss=-0.787 KID= 0.00688\n",
      "epoch 577, batch 8, d_loss=-0.353 g_loss=-0.729 KID= 0.00688\n",
      "epoch 577, batch 9, d_loss=-0.367 g_loss=-0.695 KID= 0.00688\n",
      "epoch 577, batch 10, d_loss=-0.319 g_loss=-0.514 KID= 0.00688\n",
      "epoch 577, batch 11, d_loss=-0.265 g_loss=-0.197 KID= 0.00688\n",
      "epoch 577, batch 12, d_loss=-0.353 g_loss=0.170 KID= 0.00688\n",
      "epoch 577, batch 13, d_loss=-0.355 g_loss=0.302 KID= 0.00688\n",
      "epoch 577, batch 14, d_loss=-0.247 g_loss=0.579 KID= 0.00688\n",
      "epoch 577, batch 15, d_loss=-0.344 g_loss=0.725 KID= 0.00688\n",
      "epoch 577, batch 16, d_loss=-0.356 g_loss=0.480 KID= 0.00688\n",
      "epoch 577, batch 17, d_loss=-0.284 g_loss=0.334 KID= 0.00688\n",
      "epoch 577, batch 18, d_loss=-0.403 g_loss=0.204 KID= 0.00688\n",
      "epoch 577, batch 19, d_loss=-0.418 g_loss=0.081 KID= 0.00688\n",
      "epoch 578, batch 0, d_loss=-0.315 g_loss=-0.044 KID= 0.00688\n",
      "epoch 578, batch 1, d_loss=-0.306 g_loss=-0.115 KID= 0.00688\n",
      "epoch 578, batch 2, d_loss=-0.332 g_loss=-0.114 KID= 0.00688\n",
      "epoch 578, batch 3, d_loss=-0.329 g_loss=-0.199 KID= 0.00688\n",
      "epoch 578, batch 4, d_loss=-0.301 g_loss=-0.246 KID= 0.00688\n",
      "epoch 578, batch 5, d_loss=-0.344 g_loss=-0.409 KID= 0.00688\n",
      "epoch 578, batch 6, d_loss=-0.389 g_loss=-0.591 KID= 0.00688\n",
      "epoch 578, batch 7, d_loss=-0.247 g_loss=-0.656 KID= 0.00688\n",
      "epoch 578, batch 8, d_loss=-0.380 g_loss=-0.772 KID= 0.00688\n",
      "epoch 578, batch 9, d_loss=-0.416 g_loss=-0.804 KID= 0.00688\n",
      "epoch 578, batch 10, d_loss=-0.352 g_loss=-0.673 KID= 0.00688\n",
      "epoch 578, batch 11, d_loss=-0.281 g_loss=-0.530 KID= 0.00688\n",
      "epoch 578, batch 12, d_loss=-0.380 g_loss=-0.451 KID= 0.00688\n",
      "epoch 578, batch 13, d_loss=-0.367 g_loss=-0.365 KID= 0.00688\n",
      "epoch 578, batch 14, d_loss=-0.295 g_loss=-0.312 KID= 0.00688\n",
      "epoch 578, batch 15, d_loss=-0.345 g_loss=-0.239 KID= 0.00688\n",
      "epoch 578, batch 16, d_loss=-0.388 g_loss=-0.250 KID= 0.00688\n",
      "epoch 578, batch 17, d_loss=-0.218 g_loss=-0.171 KID= 0.00688\n",
      "epoch 578, batch 18, d_loss=-0.362 g_loss=-0.143 KID= 0.00688\n",
      "epoch 578, batch 19, d_loss=-0.394 g_loss=-0.088 KID= 0.00688\n",
      "epoch 579, batch 0, d_loss=-0.386 g_loss=-0.092 KID= 0.00688\n",
      "epoch 579, batch 1, d_loss=-0.327 g_loss=-0.039 KID= 0.00688\n",
      "epoch 579, batch 2, d_loss=-0.367 g_loss=0.060 KID= 0.00688\n",
      "epoch 579, batch 3, d_loss=-0.304 g_loss=0.094 KID= 0.00688\n",
      "epoch 579, batch 4, d_loss=-0.301 g_loss=0.185 KID= 0.00688\n",
      "epoch 579, batch 5, d_loss=-0.336 g_loss=0.150 KID= 0.00688\n",
      "epoch 579, batch 6, d_loss=-0.329 g_loss=-0.065 KID= 0.00688\n",
      "epoch 579, batch 7, d_loss=-0.298 g_loss=-0.211 KID= 0.00688\n",
      "epoch 579, batch 8, d_loss=-0.363 g_loss=-0.438 KID= 0.00688\n",
      "epoch 579, batch 9, d_loss=-0.416 g_loss=-0.499 KID= 0.00688\n",
      "epoch 579, batch 10, d_loss=-0.392 g_loss=-0.671 KID= 0.00688\n",
      "epoch 579, batch 11, d_loss=-0.296 g_loss=-0.702 KID= 0.00688\n",
      "epoch 579, batch 12, d_loss=-0.336 g_loss=-0.681 KID= 0.00688\n",
      "epoch 579, batch 13, d_loss=-0.277 g_loss=-0.750 KID= 0.00688\n",
      "epoch 579, batch 14, d_loss=-0.262 g_loss=-0.666 KID= 0.00688\n",
      "epoch 579, batch 15, d_loss=-0.374 g_loss=-0.592 KID= 0.00688\n",
      "epoch 579, batch 16, d_loss=-0.357 g_loss=-0.526 KID= 0.00688\n",
      "epoch 579, batch 17, d_loss=-0.277 g_loss=-0.564 KID= 0.00688\n",
      "epoch 579, batch 18, d_loss=-0.421 g_loss=-0.534 KID= 0.00688\n",
      "epoch 579, batch 19, d_loss=-0.405 g_loss=-0.393 KID= 0.00688\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 580, batch 0, d_loss=-0.406 g_loss=-0.182 KID= 0.01142\n",
      "epoch 580, batch 1, d_loss=-0.221 g_loss=-0.104 KID= 0.01142\n",
      "epoch 580, batch 2, d_loss=-0.339 g_loss=0.039 KID= 0.01142\n",
      "epoch 580, batch 3, d_loss=-0.347 g_loss=0.035 KID= 0.01142\n",
      "epoch 580, batch 4, d_loss=-0.290 g_loss=-0.000 KID= 0.01142\n",
      "epoch 580, batch 5, d_loss=-0.318 g_loss=-0.192 KID= 0.01142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 580, batch 6, d_loss=-0.402 g_loss=-0.371 KID= 0.01142\n",
      "epoch 580, batch 7, d_loss=-0.282 g_loss=-0.482 KID= 0.01142\n",
      "epoch 580, batch 8, d_loss=-0.425 g_loss=-0.466 KID= 0.01142\n",
      "epoch 580, batch 9, d_loss=-0.400 g_loss=-0.449 KID= 0.01142\n",
      "epoch 580, batch 10, d_loss=-0.362 g_loss=-0.447 KID= 0.01142\n",
      "epoch 580, batch 11, d_loss=-0.296 g_loss=-0.474 KID= 0.01142\n",
      "epoch 580, batch 12, d_loss=-0.332 g_loss=-0.565 KID= 0.01142\n",
      "epoch 580, batch 13, d_loss=-0.327 g_loss=-0.732 KID= 0.01142\n",
      "epoch 580, batch 14, d_loss=-0.277 g_loss=-0.651 KID= 0.01142\n",
      "epoch 580, batch 15, d_loss=-0.407 g_loss=-0.728 KID= 0.01142\n",
      "epoch 580, batch 16, d_loss=-0.369 g_loss=-0.802 KID= 0.01142\n",
      "epoch 580, batch 17, d_loss=-0.289 g_loss=-0.844 KID= 0.01142\n",
      "epoch 580, batch 18, d_loss=-0.345 g_loss=-0.731 KID= 0.01142\n",
      "epoch 580, batch 19, d_loss=-0.379 g_loss=-0.544 KID= 0.01142\n",
      "epoch 581, batch 0, d_loss=-0.362 g_loss=-0.297 KID= 0.01142\n",
      "epoch 581, batch 1, d_loss=-0.299 g_loss=0.042 KID= 0.01142\n",
      "epoch 581, batch 2, d_loss=-0.319 g_loss=0.303 KID= 0.01142\n",
      "epoch 581, batch 3, d_loss=-0.315 g_loss=0.343 KID= 0.01142\n",
      "epoch 581, batch 4, d_loss=-0.261 g_loss=0.367 KID= 0.01142\n",
      "epoch 581, batch 5, d_loss=-0.338 g_loss=0.342 KID= 0.01142\n",
      "epoch 581, batch 6, d_loss=-0.359 g_loss=0.202 KID= 0.01142\n",
      "epoch 581, batch 7, d_loss=-0.248 g_loss=0.025 KID= 0.01142\n",
      "epoch 581, batch 8, d_loss=-0.410 g_loss=-0.046 KID= 0.01142\n",
      "epoch 581, batch 9, d_loss=-0.394 g_loss=-0.076 KID= 0.01142\n",
      "epoch 581, batch 10, d_loss=-0.381 g_loss=-0.010 KID= 0.01142\n",
      "epoch 581, batch 11, d_loss=-0.270 g_loss=-0.007 KID= 0.01142\n",
      "epoch 581, batch 12, d_loss=-0.332 g_loss=-0.027 KID= 0.01142\n",
      "epoch 581, batch 13, d_loss=-0.337 g_loss=-0.067 KID= 0.01142\n",
      "epoch 581, batch 14, d_loss=-0.245 g_loss=-0.173 KID= 0.01142\n",
      "epoch 581, batch 15, d_loss=-0.395 g_loss=-0.424 KID= 0.01142\n",
      "epoch 581, batch 16, d_loss=-0.345 g_loss=-0.583 KID= 0.01142\n",
      "epoch 581, batch 17, d_loss=-0.282 g_loss=-0.785 KID= 0.01142\n",
      "epoch 581, batch 18, d_loss=-0.373 g_loss=-0.905 KID= 0.01142\n",
      "epoch 581, batch 19, d_loss=-0.414 g_loss=-0.880 KID= 0.01142\n",
      "epoch 582, batch 0, d_loss=-0.335 g_loss=-0.845 KID= 0.01142\n",
      "epoch 582, batch 1, d_loss=-0.290 g_loss=-0.735 KID= 0.01142\n",
      "epoch 582, batch 2, d_loss=-0.355 g_loss=-0.620 KID= 0.01142\n",
      "epoch 582, batch 3, d_loss=-0.317 g_loss=-0.553 KID= 0.01142\n",
      "epoch 582, batch 4, d_loss=-0.282 g_loss=-0.422 KID= 0.01142\n",
      "epoch 582, batch 5, d_loss=-0.354 g_loss=-0.278 KID= 0.01142\n",
      "epoch 582, batch 6, d_loss=-0.370 g_loss=-0.131 KID= 0.01142\n",
      "epoch 582, batch 7, d_loss=-0.301 g_loss=0.044 KID= 0.01142\n",
      "epoch 582, batch 8, d_loss=-0.400 g_loss=0.046 KID= 0.01142\n",
      "epoch 582, batch 9, d_loss=-0.358 g_loss=0.037 KID= 0.01142\n",
      "epoch 582, batch 10, d_loss=-0.398 g_loss=-0.038 KID= 0.01142\n",
      "epoch 582, batch 11, d_loss=-0.266 g_loss=-0.101 KID= 0.01142\n",
      "epoch 582, batch 12, d_loss=-0.387 g_loss=-0.276 KID= 0.01142\n",
      "epoch 582, batch 13, d_loss=-0.324 g_loss=-0.410 KID= 0.01142\n",
      "epoch 582, batch 14, d_loss=-0.245 g_loss=-0.384 KID= 0.01142\n",
      "epoch 582, batch 15, d_loss=-0.365 g_loss=-0.486 KID= 0.01142\n",
      "epoch 582, batch 16, d_loss=-0.407 g_loss=-0.576 KID= 0.01142\n",
      "epoch 582, batch 17, d_loss=-0.295 g_loss=-0.647 KID= 0.01142\n",
      "epoch 582, batch 18, d_loss=-0.408 g_loss=-0.716 KID= 0.01142\n",
      "epoch 582, batch 19, d_loss=-0.411 g_loss=-0.583 KID= 0.01142\n",
      "epoch 583, batch 0, d_loss=-0.332 g_loss=-0.436 KID= 0.01142\n",
      "epoch 583, batch 1, d_loss=-0.296 g_loss=-0.350 KID= 0.01142\n",
      "epoch 583, batch 2, d_loss=-0.354 g_loss=-0.391 KID= 0.01142\n",
      "epoch 583, batch 3, d_loss=-0.303 g_loss=-0.526 KID= 0.01142\n",
      "epoch 583, batch 4, d_loss=-0.216 g_loss=-0.354 KID= 0.01142\n",
      "epoch 583, batch 5, d_loss=-0.399 g_loss=-0.236 KID= 0.01142\n",
      "epoch 583, batch 6, d_loss=-0.356 g_loss=-0.164 KID= 0.01142\n",
      "epoch 583, batch 7, d_loss=-0.338 g_loss=-0.211 KID= 0.01142\n",
      "epoch 583, batch 8, d_loss=-0.396 g_loss=-0.225 KID= 0.01142\n",
      "epoch 583, batch 9, d_loss=-0.382 g_loss=-0.286 KID= 0.01142\n",
      "epoch 583, batch 10, d_loss=-0.384 g_loss=-0.238 KID= 0.01142\n",
      "epoch 583, batch 11, d_loss=-0.334 g_loss=-0.211 KID= 0.01142\n",
      "epoch 583, batch 12, d_loss=-0.293 g_loss=-0.202 KID= 0.01142\n",
      "epoch 583, batch 13, d_loss=-0.353 g_loss=-0.205 KID= 0.01142\n",
      "epoch 583, batch 14, d_loss=-0.267 g_loss=-0.024 KID= 0.01142\n",
      "epoch 583, batch 15, d_loss=-0.362 g_loss=-0.066 KID= 0.01142\n",
      "epoch 583, batch 16, d_loss=-0.337 g_loss=-0.082 KID= 0.01142\n",
      "epoch 583, batch 17, d_loss=-0.264 g_loss=-0.140 KID= 0.01142\n",
      "epoch 583, batch 18, d_loss=-0.405 g_loss=-0.101 KID= 0.01142\n",
      "epoch 583, batch 19, d_loss=-0.435 g_loss=-0.117 KID= 0.01142\n",
      "epoch 584, batch 0, d_loss=-0.374 g_loss=-0.128 KID= 0.01142\n",
      "epoch 584, batch 1, d_loss=-0.374 g_loss=-0.165 KID= 0.01142\n",
      "epoch 584, batch 2, d_loss=-0.327 g_loss=-0.333 KID= 0.01142\n",
      "epoch 584, batch 3, d_loss=-0.314 g_loss=-0.567 KID= 0.01142\n",
      "epoch 584, batch 4, d_loss=-0.161 g_loss=-0.539 KID= 0.01142\n",
      "epoch 584, batch 5, d_loss=-0.303 g_loss=-0.516 KID= 0.01142\n",
      "epoch 584, batch 6, d_loss=-0.352 g_loss=-0.474 KID= 0.01142\n",
      "epoch 584, batch 7, d_loss=-0.260 g_loss=-0.513 KID= 0.01142\n",
      "epoch 584, batch 8, d_loss=-0.408 g_loss=-0.504 KID= 0.01142\n",
      "epoch 584, batch 9, d_loss=-0.415 g_loss=-0.437 KID= 0.01142\n",
      "epoch 584, batch 10, d_loss=-0.330 g_loss=-0.317 KID= 0.01142\n",
      "epoch 584, batch 11, d_loss=-0.323 g_loss=-0.117 KID= 0.01142\n",
      "epoch 584, batch 12, d_loss=-0.389 g_loss=-0.082 KID= 0.01142\n",
      "epoch 584, batch 13, d_loss=-0.396 g_loss=-0.087 KID= 0.01142\n",
      "epoch 584, batch 14, d_loss=-0.249 g_loss=0.070 KID= 0.01142\n",
      "epoch 584, batch 15, d_loss=-0.283 g_loss=0.031 KID= 0.01142\n",
      "epoch 584, batch 16, d_loss=-0.353 g_loss=0.017 KID= 0.01142\n",
      "epoch 584, batch 17, d_loss=-0.277 g_loss=-0.021 KID= 0.01142\n",
      "epoch 584, batch 18, d_loss=-0.387 g_loss=-0.090 KID= 0.01142\n",
      "epoch 584, batch 19, d_loss=-0.339 g_loss=-0.189 KID= 0.01142\n",
      "epoch 585, batch 0, d_loss=-0.379 g_loss=-0.273 KID= 0.01142\n",
      "epoch 585, batch 1, d_loss=-0.353 g_loss=-0.292 KID= 0.01142\n",
      "epoch 585, batch 2, d_loss=-0.355 g_loss=-0.461 KID= 0.01142\n",
      "epoch 585, batch 3, d_loss=-0.282 g_loss=-0.608 KID= 0.01142\n",
      "epoch 585, batch 4, d_loss=-0.251 g_loss=-0.659 KID= 0.01142\n",
      "epoch 585, batch 5, d_loss=-0.383 g_loss=-0.640 KID= 0.01142\n",
      "epoch 585, batch 6, d_loss=-0.352 g_loss=-0.483 KID= 0.01142\n",
      "epoch 585, batch 7, d_loss=-0.275 g_loss=-0.376 KID= 0.01142\n",
      "epoch 585, batch 8, d_loss=-0.404 g_loss=-0.293 KID= 0.01142\n",
      "epoch 585, batch 9, d_loss=-0.438 g_loss=-0.268 KID= 0.01142\n",
      "epoch 585, batch 10, d_loss=-0.357 g_loss=-0.361 KID= 0.01142\n",
      "epoch 585, batch 11, d_loss=-0.305 g_loss=-0.296 KID= 0.01142\n",
      "epoch 585, batch 12, d_loss=-0.353 g_loss=-0.292 KID= 0.01142\n",
      "epoch 585, batch 13, d_loss=-0.308 g_loss=-0.297 KID= 0.01142\n",
      "epoch 585, batch 14, d_loss=-0.237 g_loss=-0.183 KID= 0.01142\n",
      "epoch 585, batch 15, d_loss=-0.323 g_loss=-0.197 KID= 0.01142\n",
      "epoch 585, batch 16, d_loss=-0.398 g_loss=-0.199 KID= 0.01142\n",
      "epoch 585, batch 17, d_loss=-0.304 g_loss=-0.190 KID= 0.01142\n",
      "epoch 585, batch 18, d_loss=-0.405 g_loss=-0.174 KID= 0.01142\n",
      "epoch 585, batch 19, d_loss=-0.410 g_loss=-0.271 KID= 0.01142\n",
      "epoch 586, batch 0, d_loss=-0.344 g_loss=-0.413 KID= 0.01142\n",
      "epoch 586, batch 1, d_loss=-0.254 g_loss=-0.459 KID= 0.01142\n",
      "epoch 586, batch 2, d_loss=-0.361 g_loss=-0.530 KID= 0.01142\n",
      "epoch 586, batch 3, d_loss=-0.329 g_loss=-0.626 KID= 0.01142\n",
      "epoch 586, batch 4, d_loss=-0.260 g_loss=-0.507 KID= 0.01142\n",
      "epoch 586, batch 5, d_loss=-0.406 g_loss=-0.401 KID= 0.01142\n",
      "epoch 586, batch 6, d_loss=-0.371 g_loss=-0.254 KID= 0.01142\n",
      "epoch 586, batch 7, d_loss=-0.319 g_loss=-0.208 KID= 0.01142\n",
      "epoch 586, batch 8, d_loss=-0.402 g_loss=-0.271 KID= 0.01142\n",
      "epoch 586, batch 9, d_loss=-0.399 g_loss=-0.374 KID= 0.01142\n",
      "epoch 586, batch 10, d_loss=-0.317 g_loss=-0.432 KID= 0.01142\n",
      "epoch 586, batch 11, d_loss=-0.327 g_loss=-0.352 KID= 0.01142\n",
      "epoch 586, batch 12, d_loss=-0.329 g_loss=-0.367 KID= 0.01142\n",
      "epoch 586, batch 13, d_loss=-0.334 g_loss=-0.439 KID= 0.01142\n",
      "epoch 586, batch 14, d_loss=-0.326 g_loss=-0.343 KID= 0.01142\n",
      "epoch 586, batch 15, d_loss=-0.382 g_loss=-0.341 KID= 0.01142\n",
      "epoch 586, batch 16, d_loss=-0.387 g_loss=-0.354 KID= 0.01142\n",
      "epoch 586, batch 17, d_loss=-0.321 g_loss=-0.393 KID= 0.01142\n",
      "epoch 586, batch 18, d_loss=-0.365 g_loss=-0.458 KID= 0.01142\n",
      "epoch 586, batch 19, d_loss=-0.405 g_loss=-0.569 KID= 0.01142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 587, batch 0, d_loss=-0.332 g_loss=-0.636 KID= 0.01142\n",
      "epoch 587, batch 1, d_loss=-0.347 g_loss=-0.667 KID= 0.01142\n",
      "epoch 587, batch 2, d_loss=-0.367 g_loss=-0.778 KID= 0.01142\n",
      "epoch 587, batch 3, d_loss=-0.322 g_loss=-0.875 KID= 0.01142\n",
      "epoch 587, batch 4, d_loss=-0.235 g_loss=-0.544 KID= 0.01142\n",
      "epoch 587, batch 5, d_loss=-0.345 g_loss=-0.364 KID= 0.01142\n",
      "epoch 587, batch 6, d_loss=-0.360 g_loss=-0.065 KID= 0.01142\n",
      "epoch 587, batch 7, d_loss=-0.322 g_loss=0.144 KID= 0.01142\n",
      "epoch 587, batch 8, d_loss=-0.366 g_loss=0.272 KID= 0.01142\n",
      "epoch 587, batch 9, d_loss=-0.427 g_loss=0.173 KID= 0.01142\n",
      "epoch 587, batch 10, d_loss=-0.344 g_loss=0.142 KID= 0.01142\n",
      "epoch 587, batch 11, d_loss=-0.286 g_loss=0.059 KID= 0.01142\n",
      "epoch 587, batch 12, d_loss=-0.308 g_loss=-0.257 KID= 0.01142\n",
      "epoch 587, batch 13, d_loss=-0.324 g_loss=-0.494 KID= 0.01142\n",
      "epoch 587, batch 14, d_loss=-0.299 g_loss=-0.524 KID= 0.01142\n",
      "epoch 587, batch 15, d_loss=-0.359 g_loss=-0.573 KID= 0.01142\n",
      "epoch 587, batch 16, d_loss=-0.404 g_loss=-0.551 KID= 0.01142\n",
      "epoch 587, batch 17, d_loss=-0.324 g_loss=-0.573 KID= 0.01142\n",
      "epoch 587, batch 18, d_loss=-0.376 g_loss=-0.594 KID= 0.01142\n",
      "epoch 587, batch 19, d_loss=-0.463 g_loss=-0.771 KID= 0.01142\n",
      "epoch 588, batch 0, d_loss=-0.244 g_loss=-0.678 KID= 0.01142\n",
      "epoch 588, batch 1, d_loss=-0.290 g_loss=-0.626 KID= 0.01142\n",
      "epoch 588, batch 2, d_loss=-0.330 g_loss=-0.709 KID= 0.01142\n",
      "epoch 588, batch 3, d_loss=-0.345 g_loss=-0.874 KID= 0.01142\n",
      "epoch 588, batch 4, d_loss=-0.192 g_loss=-0.679 KID= 0.01142\n",
      "epoch 588, batch 5, d_loss=-0.349 g_loss=-0.514 KID= 0.01142\n",
      "epoch 588, batch 6, d_loss=-0.375 g_loss=-0.222 KID= 0.01142\n",
      "epoch 588, batch 7, d_loss=-0.283 g_loss=0.008 KID= 0.01142\n",
      "epoch 588, batch 8, d_loss=-0.360 g_loss=0.146 KID= 0.01142\n",
      "epoch 588, batch 9, d_loss=-0.393 g_loss=0.114 KID= 0.01142\n",
      "epoch 588, batch 10, d_loss=-0.304 g_loss=0.073 KID= 0.01142\n",
      "epoch 588, batch 11, d_loss=-0.335 g_loss=0.035 KID= 0.01142\n",
      "epoch 588, batch 12, d_loss=-0.376 g_loss=-0.156 KID= 0.01142\n",
      "epoch 588, batch 13, d_loss=-0.301 g_loss=-0.358 KID= 0.01142\n",
      "epoch 588, batch 14, d_loss=-0.315 g_loss=-0.367 KID= 0.01142\n",
      "epoch 588, batch 15, d_loss=-0.365 g_loss=-0.306 KID= 0.01142\n",
      "epoch 588, batch 16, d_loss=-0.363 g_loss=-0.226 KID= 0.01142\n",
      "epoch 588, batch 17, d_loss=-0.366 g_loss=-0.131 KID= 0.01142\n",
      "epoch 588, batch 18, d_loss=-0.361 g_loss=-0.171 KID= 0.01142\n",
      "epoch 588, batch 19, d_loss=-0.412 g_loss=-0.308 KID= 0.01142\n",
      "epoch 589, batch 0, d_loss=-0.377 g_loss=-0.372 KID= 0.01142\n",
      "epoch 589, batch 1, d_loss=-0.360 g_loss=-0.374 KID= 0.01142\n",
      "epoch 589, batch 2, d_loss=-0.328 g_loss=-0.481 KID= 0.01142\n",
      "epoch 589, batch 3, d_loss=-0.340 g_loss=-0.690 KID= 0.01142\n",
      "epoch 589, batch 4, d_loss=-0.197 g_loss=-0.667 KID= 0.01142\n",
      "epoch 589, batch 5, d_loss=-0.329 g_loss=-0.728 KID= 0.01142\n",
      "epoch 589, batch 6, d_loss=-0.391 g_loss=-0.562 KID= 0.01142\n",
      "epoch 589, batch 7, d_loss=-0.338 g_loss=-0.318 KID= 0.01142\n",
      "epoch 589, batch 8, d_loss=-0.390 g_loss=-0.018 KID= 0.01142\n",
      "epoch 589, batch 9, d_loss=-0.448 g_loss=0.052 KID= 0.01142\n",
      "epoch 589, batch 10, d_loss=-0.300 g_loss=0.106 KID= 0.01142\n",
      "epoch 589, batch 11, d_loss=-0.366 g_loss=0.172 KID= 0.01142\n",
      "epoch 589, batch 12, d_loss=-0.316 g_loss=0.044 KID= 0.01142\n",
      "epoch 589, batch 13, d_loss=-0.272 g_loss=-0.226 KID= 0.01142\n",
      "epoch 589, batch 14, d_loss=-0.302 g_loss=-0.222 KID= 0.01142\n",
      "epoch 589, batch 15, d_loss=-0.346 g_loss=-0.182 KID= 0.01142\n",
      "epoch 589, batch 16, d_loss=-0.388 g_loss=-0.134 KID= 0.01142\n",
      "epoch 589, batch 17, d_loss=-0.350 g_loss=-0.040 KID= 0.01142\n",
      "epoch 589, batch 18, d_loss=-0.340 g_loss=0.001 KID= 0.01142\n",
      "epoch 589, batch 19, d_loss=-0.424 g_loss=-0.020 KID= 0.01142\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 590, batch 0, d_loss=-0.316 g_loss=0.035 KID= 0.00865\n",
      "epoch 590, batch 1, d_loss=-0.325 g_loss=0.002 KID= 0.00865\n",
      "epoch 590, batch 2, d_loss=-0.308 g_loss=-0.248 KID= 0.00865\n",
      "epoch 590, batch 3, d_loss=-0.340 g_loss=-0.678 KID= 0.00865\n",
      "epoch 590, batch 4, d_loss=-0.232 g_loss=-0.832 KID= 0.00865\n",
      "epoch 590, batch 5, d_loss=-0.373 g_loss=-1.027 KID= 0.00865\n",
      "epoch 590, batch 6, d_loss=-0.354 g_loss=-0.850 KID= 0.00865\n",
      "epoch 590, batch 7, d_loss=-0.322 g_loss=-0.629 KID= 0.00865\n",
      "epoch 590, batch 8, d_loss=-0.382 g_loss=-0.436 KID= 0.00865\n",
      "epoch 590, batch 9, d_loss=-0.467 g_loss=-0.330 KID= 0.00865\n",
      "epoch 590, batch 10, d_loss=-0.329 g_loss=-0.154 KID= 0.00865\n",
      "epoch 590, batch 11, d_loss=-0.370 g_loss=0.066 KID= 0.00865\n",
      "epoch 590, batch 12, d_loss=-0.236 g_loss=0.041 KID= 0.00865\n",
      "epoch 590, batch 13, d_loss=-0.244 g_loss=-0.116 KID= 0.00865\n",
      "epoch 590, batch 14, d_loss=-0.335 g_loss=-0.146 KID= 0.00865\n",
      "epoch 590, batch 15, d_loss=-0.346 g_loss=-0.178 KID= 0.00865\n",
      "epoch 590, batch 16, d_loss=-0.387 g_loss=-0.170 KID= 0.00865\n",
      "epoch 590, batch 17, d_loss=-0.335 g_loss=-0.246 KID= 0.00865\n",
      "epoch 590, batch 18, d_loss=-0.332 g_loss=-0.308 KID= 0.00865\n",
      "epoch 590, batch 19, d_loss=-0.410 g_loss=-0.349 KID= 0.00865\n",
      "epoch 591, batch 0, d_loss=-0.325 g_loss=-0.451 KID= 0.00865\n",
      "epoch 591, batch 1, d_loss=-0.321 g_loss=-0.641 KID= 0.00865\n",
      "epoch 591, batch 2, d_loss=-0.284 g_loss=-0.876 KID= 0.00865\n",
      "epoch 591, batch 3, d_loss=-0.320 g_loss=-1.167 KID= 0.00865\n",
      "epoch 591, batch 4, d_loss=-0.267 g_loss=-1.193 KID= 0.00865\n",
      "epoch 591, batch 5, d_loss=-0.376 g_loss=-1.280 KID= 0.00865\n",
      "epoch 591, batch 6, d_loss=-0.395 g_loss=-1.191 KID= 0.00865\n",
      "epoch 591, batch 7, d_loss=-0.301 g_loss=-0.967 KID= 0.00865\n",
      "epoch 591, batch 8, d_loss=-0.379 g_loss=-0.810 KID= 0.00865\n",
      "epoch 591, batch 9, d_loss=-0.457 g_loss=-0.584 KID= 0.00865\n",
      "epoch 591, batch 10, d_loss=-0.274 g_loss=-0.223 KID= 0.00865\n",
      "epoch 591, batch 11, d_loss=-0.327 g_loss=0.060 KID= 0.00865\n",
      "epoch 591, batch 12, d_loss=-0.377 g_loss=0.151 KID= 0.00865\n",
      "epoch 591, batch 13, d_loss=-0.276 g_loss=0.013 KID= 0.00865\n",
      "epoch 591, batch 14, d_loss=-0.284 g_loss=-0.051 KID= 0.00865\n",
      "epoch 591, batch 15, d_loss=-0.374 g_loss=-0.177 KID= 0.00865\n",
      "epoch 591, batch 16, d_loss=-0.402 g_loss=-0.193 KID= 0.00865\n",
      "epoch 591, batch 17, d_loss=-0.395 g_loss=-0.100 KID= 0.00865\n",
      "epoch 591, batch 18, d_loss=-0.348 g_loss=-0.024 KID= 0.00865\n",
      "epoch 591, batch 19, d_loss=-0.458 g_loss=-0.014 KID= 0.00865\n",
      "epoch 592, batch 0, d_loss=-0.319 g_loss=0.006 KID= 0.00865\n",
      "epoch 592, batch 1, d_loss=-0.385 g_loss=-0.062 KID= 0.00865\n",
      "epoch 592, batch 2, d_loss=-0.279 g_loss=-0.320 KID= 0.00865\n",
      "epoch 592, batch 3, d_loss=-0.246 g_loss=-0.683 KID= 0.00865\n",
      "epoch 592, batch 4, d_loss=-0.288 g_loss=-0.726 KID= 0.00865\n",
      "epoch 592, batch 5, d_loss=-0.338 g_loss=-0.746 KID= 0.00865\n",
      "epoch 592, batch 6, d_loss=-0.393 g_loss=-0.761 KID= 0.00865\n",
      "epoch 592, batch 7, d_loss=-0.368 g_loss=-0.710 KID= 0.00865\n",
      "epoch 592, batch 8, d_loss=-0.381 g_loss=-0.728 KID= 0.00865\n",
      "epoch 592, batch 9, d_loss=-0.474 g_loss=-0.740 KID= 0.00865\n",
      "epoch 592, batch 10, d_loss=-0.298 g_loss=-0.585 KID= 0.00865\n",
      "epoch 592, batch 11, d_loss=-0.252 g_loss=-0.484 KID= 0.00865\n",
      "epoch 592, batch 12, d_loss=-0.355 g_loss=-0.586 KID= 0.00865\n",
      "epoch 592, batch 13, d_loss=-0.260 g_loss=-0.814 KID= 0.00865\n",
      "epoch 592, batch 14, d_loss=-0.296 g_loss=-0.999 KID= 0.00865\n",
      "epoch 592, batch 15, d_loss=-0.351 g_loss=-1.122 KID= 0.00865\n",
      "epoch 592, batch 16, d_loss=-0.389 g_loss=-1.255 KID= 0.00865\n",
      "epoch 592, batch 17, d_loss=-0.308 g_loss=-1.076 KID= 0.00865\n",
      "epoch 592, batch 18, d_loss=-0.409 g_loss=-0.889 KID= 0.00865\n",
      "epoch 592, batch 19, d_loss=-0.469 g_loss=-0.848 KID= 0.00865\n",
      "epoch 593, batch 0, d_loss=-0.353 g_loss=-0.762 KID= 0.00865\n",
      "epoch 593, batch 1, d_loss=-0.339 g_loss=-0.565 KID= 0.00865\n",
      "epoch 593, batch 2, d_loss=-0.271 g_loss=-0.431 KID= 0.00865\n",
      "epoch 593, batch 3, d_loss=-0.235 g_loss=-0.435 KID= 0.00865\n",
      "epoch 593, batch 4, d_loss=-0.307 g_loss=-0.369 KID= 0.00865\n",
      "epoch 593, batch 5, d_loss=-0.357 g_loss=-0.188 KID= 0.00865\n",
      "epoch 593, batch 6, d_loss=-0.361 g_loss=-0.148 KID= 0.00865\n",
      "epoch 593, batch 7, d_loss=-0.441 g_loss=-0.137 KID= 0.00865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 593, batch 8, d_loss=-0.369 g_loss=-0.082 KID= 0.00865\n",
      "epoch 593, batch 9, d_loss=-0.438 g_loss=-0.112 KID= 0.00865\n",
      "epoch 593, batch 10, d_loss=-0.343 g_loss=-0.286 KID= 0.00865\n",
      "epoch 593, batch 11, d_loss=-0.332 g_loss=-0.355 KID= 0.00865\n",
      "epoch 593, batch 12, d_loss=-0.373 g_loss=-0.641 KID= 0.00865\n",
      "epoch 593, batch 13, d_loss=-0.262 g_loss=-0.905 KID= 0.00865\n",
      "epoch 593, batch 14, d_loss=-0.289 g_loss=-1.007 KID= 0.00865\n",
      "epoch 593, batch 15, d_loss=-0.361 g_loss=-1.098 KID= 0.00865\n",
      "epoch 593, batch 16, d_loss=-0.436 g_loss=-1.157 KID= 0.00865\n",
      "epoch 593, batch 17, d_loss=-0.367 g_loss=-0.961 KID= 0.00865\n",
      "epoch 593, batch 18, d_loss=-0.377 g_loss=-0.818 KID= 0.00865\n",
      "epoch 593, batch 19, d_loss=-0.474 g_loss=-0.798 KID= 0.00865\n",
      "epoch 594, batch 0, d_loss=-0.297 g_loss=-0.615 KID= 0.00865\n",
      "epoch 594, batch 1, d_loss=-0.317 g_loss=-0.475 KID= 0.00865\n",
      "epoch 594, batch 2, d_loss=-0.339 g_loss=-0.458 KID= 0.00865\n",
      "epoch 594, batch 3, d_loss=-0.265 g_loss=-0.561 KID= 0.00865\n",
      "epoch 594, batch 4, d_loss=-0.287 g_loss=-0.646 KID= 0.00865\n",
      "epoch 594, batch 5, d_loss=-0.396 g_loss=-0.602 KID= 0.00865\n",
      "epoch 594, batch 6, d_loss=-0.375 g_loss=-0.530 KID= 0.00865\n",
      "epoch 594, batch 7, d_loss=-0.342 g_loss=-0.401 KID= 0.00865\n",
      "epoch 594, batch 8, d_loss=-0.400 g_loss=-0.284 KID= 0.00865\n",
      "epoch 594, batch 9, d_loss=-0.441 g_loss=-0.271 KID= 0.00865\n",
      "epoch 594, batch 10, d_loss=-0.269 g_loss=-0.164 KID= 0.00865\n",
      "epoch 594, batch 11, d_loss=-0.321 g_loss=-0.076 KID= 0.00865\n",
      "epoch 594, batch 12, d_loss=-0.369 g_loss=-0.185 KID= 0.00865\n",
      "epoch 594, batch 13, d_loss=-0.298 g_loss=-0.335 KID= 0.00865\n",
      "epoch 594, batch 14, d_loss=-0.316 g_loss=-0.452 KID= 0.00865\n",
      "epoch 594, batch 15, d_loss=-0.417 g_loss=-0.449 KID= 0.00865\n",
      "epoch 594, batch 16, d_loss=-0.370 g_loss=-0.496 KID= 0.00865\n",
      "epoch 594, batch 17, d_loss=-0.379 g_loss=-0.463 KID= 0.00865\n",
      "epoch 594, batch 18, d_loss=-0.335 g_loss=-0.411 KID= 0.00865\n",
      "epoch 594, batch 19, d_loss=-0.433 g_loss=-0.379 KID= 0.00865\n",
      "epoch 595, batch 0, d_loss=-0.297 g_loss=-0.280 KID= 0.00865\n",
      "epoch 595, batch 1, d_loss=-0.370 g_loss=-0.229 KID= 0.00865\n",
      "epoch 595, batch 2, d_loss=-0.353 g_loss=-0.349 KID= 0.00865\n",
      "epoch 595, batch 3, d_loss=-0.321 g_loss=-0.637 KID= 0.00865\n",
      "epoch 595, batch 4, d_loss=-0.333 g_loss=-0.821 KID= 0.00865\n",
      "epoch 595, batch 5, d_loss=-0.352 g_loss=-1.031 KID= 0.00865\n",
      "epoch 595, batch 6, d_loss=-0.332 g_loss=-0.922 KID= 0.00865\n",
      "epoch 595, batch 7, d_loss=-0.318 g_loss=-0.773 KID= 0.00865\n",
      "epoch 595, batch 8, d_loss=-0.383 g_loss=-0.472 KID= 0.00865\n",
      "epoch 595, batch 9, d_loss=-0.424 g_loss=-0.366 KID= 0.00865\n",
      "epoch 595, batch 10, d_loss=-0.367 g_loss=-0.169 KID= 0.00865\n",
      "epoch 595, batch 11, d_loss=-0.341 g_loss=-0.065 KID= 0.00865\n",
      "epoch 595, batch 12, d_loss=-0.334 g_loss=-0.219 KID= 0.00865\n",
      "epoch 595, batch 13, d_loss=-0.272 g_loss=-0.510 KID= 0.00865\n",
      "epoch 595, batch 14, d_loss=-0.352 g_loss=-0.666 KID= 0.00865\n",
      "epoch 595, batch 15, d_loss=-0.344 g_loss=-0.797 KID= 0.00865\n",
      "epoch 595, batch 16, d_loss=-0.413 g_loss=-0.953 KID= 0.00865\n",
      "epoch 595, batch 17, d_loss=-0.397 g_loss=-0.859 KID= 0.00865\n",
      "epoch 595, batch 18, d_loss=-0.401 g_loss=-0.745 KID= 0.00865\n",
      "epoch 595, batch 19, d_loss=-0.402 g_loss=-0.712 KID= 0.00865\n",
      "epoch 596, batch 0, d_loss=-0.261 g_loss=-0.404 KID= 0.00865\n",
      "epoch 596, batch 1, d_loss=-0.352 g_loss=-0.182 KID= 0.00865\n",
      "epoch 596, batch 2, d_loss=-0.316 g_loss=-0.084 KID= 0.00865\n",
      "epoch 596, batch 3, d_loss=-0.291 g_loss=-0.201 KID= 0.00865\n",
      "epoch 596, batch 4, d_loss=-0.303 g_loss=-0.306 KID= 0.00865\n",
      "epoch 596, batch 5, d_loss=-0.392 g_loss=-0.333 KID= 0.00865\n",
      "epoch 596, batch 6, d_loss=-0.387 g_loss=-0.271 KID= 0.00865\n",
      "epoch 596, batch 7, d_loss=-0.386 g_loss=-0.227 KID= 0.00865\n",
      "epoch 596, batch 8, d_loss=-0.392 g_loss=-0.210 KID= 0.00865\n",
      "epoch 596, batch 9, d_loss=-0.446 g_loss=-0.130 KID= 0.00865\n",
      "epoch 596, batch 10, d_loss=-0.286 g_loss=-0.076 KID= 0.00865\n",
      "epoch 596, batch 11, d_loss=-0.279 g_loss=0.003 KID= 0.00865\n",
      "epoch 596, batch 12, d_loss=-0.349 g_loss=-0.055 KID= 0.00865\n",
      "epoch 596, batch 13, d_loss=-0.293 g_loss=-0.309 KID= 0.00865\n",
      "epoch 596, batch 14, d_loss=-0.302 g_loss=-0.523 KID= 0.00865\n",
      "epoch 596, batch 15, d_loss=-0.385 g_loss=-0.792 KID= 0.00865\n",
      "epoch 596, batch 16, d_loss=-0.411 g_loss=-1.015 KID= 0.00865\n",
      "epoch 596, batch 17, d_loss=-0.274 g_loss=-0.971 KID= 0.00865\n",
      "epoch 596, batch 18, d_loss=-0.409 g_loss=-1.009 KID= 0.00865\n",
      "epoch 596, batch 19, d_loss=-0.412 g_loss=-1.103 KID= 0.00865\n",
      "epoch 597, batch 0, d_loss=-0.330 g_loss=-0.945 KID= 0.00865\n",
      "epoch 597, batch 1, d_loss=-0.326 g_loss=-0.674 KID= 0.00865\n",
      "epoch 597, batch 2, d_loss=-0.334 g_loss=-0.460 KID= 0.00865\n",
      "epoch 597, batch 3, d_loss=-0.315 g_loss=-0.347 KID= 0.00865\n",
      "epoch 597, batch 4, d_loss=-0.358 g_loss=-0.245 KID= 0.00865\n",
      "epoch 597, batch 5, d_loss=-0.381 g_loss=-0.208 KID= 0.00865\n",
      "epoch 597, batch 6, d_loss=-0.393 g_loss=-0.204 KID= 0.00865\n",
      "epoch 597, batch 7, d_loss=-0.359 g_loss=-0.144 KID= 0.00865\n",
      "epoch 597, batch 8, d_loss=-0.414 g_loss=0.052 KID= 0.00865\n",
      "epoch 597, batch 9, d_loss=-0.428 g_loss=0.095 KID= 0.00865\n",
      "epoch 597, batch 10, d_loss=-0.258 g_loss=0.041 KID= 0.00865\n",
      "epoch 597, batch 11, d_loss=-0.330 g_loss=-0.056 KID= 0.00865\n",
      "epoch 597, batch 12, d_loss=-0.352 g_loss=-0.251 KID= 0.00865\n",
      "epoch 597, batch 13, d_loss=-0.314 g_loss=-0.474 KID= 0.00865\n",
      "epoch 597, batch 14, d_loss=-0.349 g_loss=-0.678 KID= 0.00865\n",
      "epoch 597, batch 15, d_loss=-0.325 g_loss=-0.823 KID= 0.00865\n",
      "epoch 597, batch 16, d_loss=-0.348 g_loss=-0.927 KID= 0.00865\n",
      "epoch 597, batch 17, d_loss=-0.316 g_loss=-0.798 KID= 0.00865\n",
      "epoch 597, batch 18, d_loss=-0.376 g_loss=-0.636 KID= 0.00865\n",
      "epoch 597, batch 19, d_loss=-0.392 g_loss=-0.564 KID= 0.00865\n",
      "epoch 598, batch 0, d_loss=-0.343 g_loss=-0.454 KID= 0.00865\n",
      "epoch 598, batch 1, d_loss=-0.327 g_loss=-0.394 KID= 0.00865\n",
      "epoch 598, batch 2, d_loss=-0.311 g_loss=-0.469 KID= 0.00865\n",
      "epoch 598, batch 3, d_loss=-0.303 g_loss=-0.684 KID= 0.00865\n",
      "epoch 598, batch 4, d_loss=-0.333 g_loss=-0.812 KID= 0.00865\n",
      "epoch 598, batch 5, d_loss=-0.331 g_loss=-0.868 KID= 0.00865\n",
      "epoch 598, batch 6, d_loss=-0.359 g_loss=-0.958 KID= 0.00865\n",
      "epoch 598, batch 7, d_loss=-0.348 g_loss=-0.811 KID= 0.00865\n",
      "epoch 598, batch 8, d_loss=-0.442 g_loss=-0.619 KID= 0.00865\n",
      "epoch 598, batch 9, d_loss=-0.410 g_loss=-0.474 KID= 0.00865\n",
      "epoch 598, batch 10, d_loss=-0.336 g_loss=-0.167 KID= 0.00865\n",
      "epoch 598, batch 11, d_loss=-0.355 g_loss=0.112 KID= 0.00865\n",
      "epoch 598, batch 12, d_loss=-0.348 g_loss=0.194 KID= 0.00865\n",
      "epoch 598, batch 13, d_loss=-0.321 g_loss=-0.012 KID= 0.00865\n",
      "epoch 598, batch 14, d_loss=-0.282 g_loss=-0.225 KID= 0.00865\n",
      "epoch 598, batch 15, d_loss=-0.356 g_loss=-0.406 KID= 0.00865\n",
      "epoch 598, batch 16, d_loss=-0.386 g_loss=-0.593 KID= 0.00865\n",
      "epoch 598, batch 17, d_loss=-0.362 g_loss=-0.569 KID= 0.00865\n",
      "epoch 598, batch 18, d_loss=-0.463 g_loss=-0.420 KID= 0.00865\n",
      "epoch 598, batch 19, d_loss=-0.423 g_loss=-0.347 KID= 0.00865\n",
      "epoch 599, batch 0, d_loss=-0.322 g_loss=-0.252 KID= 0.00865\n",
      "epoch 599, batch 1, d_loss=-0.373 g_loss=-0.194 KID= 0.00865\n",
      "epoch 599, batch 2, d_loss=-0.356 g_loss=-0.190 KID= 0.00865\n",
      "epoch 599, batch 3, d_loss=-0.241 g_loss=-0.224 KID= 0.00865\n",
      "epoch 599, batch 4, d_loss=-0.374 g_loss=-0.119 KID= 0.00865\n",
      "epoch 599, batch 5, d_loss=-0.332 g_loss=-0.038 KID= 0.00865\n",
      "epoch 599, batch 6, d_loss=-0.339 g_loss=0.000 KID= 0.00865\n",
      "epoch 599, batch 7, d_loss=-0.379 g_loss=0.035 KID= 0.00865\n",
      "epoch 599, batch 8, d_loss=-0.454 g_loss=0.172 KID= 0.00865\n",
      "epoch 599, batch 9, d_loss=-0.427 g_loss=0.322 KID= 0.00865\n",
      "epoch 599, batch 10, d_loss=-0.414 g_loss=0.442 KID= 0.00865\n",
      "epoch 599, batch 11, d_loss=-0.362 g_loss=0.446 KID= 0.00865\n",
      "epoch 599, batch 12, d_loss=-0.319 g_loss=0.233 KID= 0.00865\n",
      "epoch 599, batch 13, d_loss=-0.284 g_loss=-0.193 KID= 0.00865\n",
      "epoch 599, batch 14, d_loss=-0.295 g_loss=-0.491 KID= 0.00865\n",
      "epoch 599, batch 15, d_loss=-0.338 g_loss=-0.828 KID= 0.00865\n",
      "epoch 599, batch 16, d_loss=-0.373 g_loss=-1.057 KID= 0.00865\n",
      "epoch 599, batch 17, d_loss=-0.299 g_loss=-1.220 KID= 0.00865\n",
      "epoch 599, batch 18, d_loss=-0.461 g_loss=-1.268 KID= 0.00865\n",
      "epoch 599, batch 19, d_loss=-0.402 g_loss=-1.219 KID= 0.00865\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 600, batch 0, d_loss=-0.334 g_loss=-1.050 KID= 0.01135\n",
      "epoch 600, batch 1, d_loss=-0.343 g_loss=-0.844 KID= 0.01135\n",
      "epoch 600, batch 2, d_loss=-0.332 g_loss=-0.753 KID= 0.01135\n",
      "epoch 600, batch 3, d_loss=-0.289 g_loss=-0.511 KID= 0.01135\n",
      "epoch 600, batch 4, d_loss=-0.368 g_loss=-0.388 KID= 0.01135\n",
      "epoch 600, batch 5, d_loss=-0.352 g_loss=-0.200 KID= 0.01135\n",
      "epoch 600, batch 6, d_loss=-0.378 g_loss=-0.082 KID= 0.01135\n",
      "epoch 600, batch 7, d_loss=-0.330 g_loss=0.034 KID= 0.01135\n",
      "epoch 600, batch 8, d_loss=-0.418 g_loss=0.148 KID= 0.01135\n",
      "epoch 600, batch 9, d_loss=-0.437 g_loss=0.134 KID= 0.01135\n",
      "epoch 600, batch 10, d_loss=-0.297 g_loss=0.091 KID= 0.01135\n",
      "epoch 600, batch 11, d_loss=-0.283 g_loss=0.180 KID= 0.01135\n",
      "epoch 600, batch 12, d_loss=-0.386 g_loss=0.140 KID= 0.01135\n",
      "epoch 600, batch 13, d_loss=-0.276 g_loss=-0.028 KID= 0.01135\n",
      "epoch 600, batch 14, d_loss=-0.346 g_loss=-0.246 KID= 0.01135\n",
      "epoch 600, batch 15, d_loss=-0.385 g_loss=-0.464 KID= 0.01135\n",
      "epoch 600, batch 16, d_loss=-0.381 g_loss=-0.693 KID= 0.01135\n",
      "epoch 600, batch 17, d_loss=-0.379 g_loss=-0.836 KID= 0.01135\n",
      "epoch 600, batch 18, d_loss=-0.474 g_loss=-0.871 KID= 0.01135\n",
      "epoch 600, batch 19, d_loss=-0.428 g_loss=-0.949 KID= 0.01135\n",
      "epoch 601, batch 0, d_loss=-0.324 g_loss=-0.889 KID= 0.01135\n",
      "epoch 601, batch 1, d_loss=-0.376 g_loss=-0.760 KID= 0.01135\n",
      "epoch 601, batch 2, d_loss=-0.317 g_loss=-0.587 KID= 0.01135\n",
      "epoch 601, batch 3, d_loss=-0.249 g_loss=-0.553 KID= 0.01135\n",
      "epoch 601, batch 4, d_loss=-0.365 g_loss=-0.660 KID= 0.01135\n",
      "epoch 601, batch 5, d_loss=-0.388 g_loss=-0.666 KID= 0.01135\n",
      "epoch 601, batch 6, d_loss=-0.396 g_loss=-0.760 KID= 0.01135\n",
      "epoch 601, batch 7, d_loss=-0.356 g_loss=-0.810 KID= 0.01135\n",
      "epoch 601, batch 8, d_loss=-0.459 g_loss=-0.746 KID= 0.01135\n",
      "epoch 601, batch 9, d_loss=-0.434 g_loss=-0.715 KID= 0.01135\n",
      "epoch 601, batch 10, d_loss=-0.355 g_loss=-0.534 KID= 0.01135\n",
      "epoch 601, batch 11, d_loss=-0.334 g_loss=-0.262 KID= 0.01135\n",
      "epoch 601, batch 12, d_loss=-0.335 g_loss=-0.146 KID= 0.01135\n",
      "epoch 601, batch 13, d_loss=-0.293 g_loss=-0.091 KID= 0.01135\n",
      "epoch 601, batch 14, d_loss=-0.331 g_loss=-0.089 KID= 0.01135\n",
      "epoch 601, batch 15, d_loss=-0.380 g_loss=-0.159 KID= 0.01135\n",
      "epoch 601, batch 16, d_loss=-0.392 g_loss=-0.296 KID= 0.01135\n",
      "epoch 601, batch 17, d_loss=-0.368 g_loss=-0.410 KID= 0.01135\n",
      "epoch 601, batch 18, d_loss=-0.470 g_loss=-0.358 KID= 0.01135\n",
      "epoch 601, batch 19, d_loss=-0.449 g_loss=-0.343 KID= 0.01135\n",
      "epoch 602, batch 0, d_loss=-0.351 g_loss=-0.232 KID= 0.01135\n",
      "epoch 602, batch 1, d_loss=-0.313 g_loss=-0.151 KID= 0.01135\n",
      "epoch 602, batch 2, d_loss=-0.354 g_loss=-0.142 KID= 0.01135\n",
      "epoch 602, batch 3, d_loss=-0.245 g_loss=-0.209 KID= 0.01135\n",
      "epoch 602, batch 4, d_loss=-0.385 g_loss=-0.339 KID= 0.01135\n",
      "epoch 602, batch 5, d_loss=-0.359 g_loss=-0.450 KID= 0.01135\n",
      "epoch 602, batch 6, d_loss=-0.360 g_loss=-0.560 KID= 0.01135\n",
      "epoch 602, batch 7, d_loss=-0.350 g_loss=-0.620 KID= 0.01135\n",
      "epoch 602, batch 8, d_loss=-0.436 g_loss=-0.555 KID= 0.01135\n",
      "epoch 602, batch 9, d_loss=-0.454 g_loss=-0.604 KID= 0.01135\n",
      "epoch 602, batch 10, d_loss=-0.410 g_loss=-0.545 KID= 0.01135\n",
      "epoch 602, batch 11, d_loss=-0.324 g_loss=-0.404 KID= 0.01135\n",
      "epoch 602, batch 12, d_loss=-0.340 g_loss=-0.344 KID= 0.01135\n",
      "epoch 602, batch 13, d_loss=-0.261 g_loss=-0.323 KID= 0.01135\n",
      "epoch 602, batch 14, d_loss=-0.291 g_loss=-0.299 KID= 0.01135\n",
      "epoch 602, batch 15, d_loss=-0.398 g_loss=-0.353 KID= 0.01135\n",
      "epoch 602, batch 16, d_loss=-0.392 g_loss=-0.381 KID= 0.01135\n",
      "epoch 602, batch 17, d_loss=-0.409 g_loss=-0.455 KID= 0.01135\n",
      "epoch 602, batch 18, d_loss=-0.466 g_loss=-0.520 KID= 0.01135\n",
      "epoch 602, batch 19, d_loss=-0.485 g_loss=-0.606 KID= 0.01135\n",
      "epoch 603, batch 0, d_loss=-0.360 g_loss=-0.662 KID= 0.01135\n",
      "epoch 603, batch 1, d_loss=-0.274 g_loss=-0.577 KID= 0.01135\n",
      "epoch 603, batch 2, d_loss=-0.310 g_loss=-0.511 KID= 0.01135\n",
      "epoch 603, batch 3, d_loss=-0.302 g_loss=-0.508 KID= 0.01135\n",
      "epoch 603, batch 4, d_loss=-0.364 g_loss=-0.443 KID= 0.01135\n",
      "epoch 603, batch 5, d_loss=-0.396 g_loss=-0.506 KID= 0.01135\n",
      "epoch 603, batch 6, d_loss=-0.379 g_loss=-0.486 KID= 0.01135\n",
      "epoch 603, batch 7, d_loss=-0.410 g_loss=-0.504 KID= 0.01135\n",
      "epoch 603, batch 8, d_loss=-0.444 g_loss=-0.325 KID= 0.01135\n",
      "epoch 603, batch 9, d_loss=-0.429 g_loss=-0.197 KID= 0.01135\n",
      "epoch 603, batch 10, d_loss=-0.368 g_loss=0.002 KID= 0.01135\n",
      "epoch 603, batch 11, d_loss=-0.340 g_loss=0.105 KID= 0.01135\n",
      "epoch 603, batch 12, d_loss=-0.282 g_loss=-0.024 KID= 0.01135\n",
      "epoch 603, batch 13, d_loss=-0.240 g_loss=-0.084 KID= 0.01135\n",
      "epoch 603, batch 14, d_loss=-0.395 g_loss=-0.138 KID= 0.01135\n",
      "epoch 603, batch 15, d_loss=-0.370 g_loss=-0.113 KID= 0.01135\n",
      "epoch 603, batch 16, d_loss=-0.364 g_loss=-0.224 KID= 0.01135\n",
      "epoch 603, batch 17, d_loss=-0.380 g_loss=-0.267 KID= 0.01135\n",
      "epoch 603, batch 18, d_loss=-0.452 g_loss=-0.314 KID= 0.01135\n",
      "epoch 603, batch 19, d_loss=-0.400 g_loss=-0.355 KID= 0.01135\n",
      "epoch 604, batch 0, d_loss=-0.388 g_loss=-0.332 KID= 0.01135\n",
      "epoch 604, batch 1, d_loss=-0.341 g_loss=-0.209 KID= 0.01135\n",
      "epoch 604, batch 2, d_loss=-0.363 g_loss=-0.234 KID= 0.01135\n",
      "epoch 604, batch 3, d_loss=-0.245 g_loss=-0.268 KID= 0.01135\n",
      "epoch 604, batch 4, d_loss=-0.384 g_loss=-0.323 KID= 0.01135\n",
      "epoch 604, batch 5, d_loss=-0.377 g_loss=-0.443 KID= 0.01135\n",
      "epoch 604, batch 6, d_loss=-0.354 g_loss=-0.634 KID= 0.01135\n",
      "epoch 604, batch 7, d_loss=-0.376 g_loss=-0.758 KID= 0.01135\n",
      "epoch 604, batch 8, d_loss=-0.451 g_loss=-0.797 KID= 0.01135\n",
      "epoch 604, batch 9, d_loss=-0.452 g_loss=-0.862 KID= 0.01135\n",
      "epoch 604, batch 10, d_loss=-0.330 g_loss=-0.744 KID= 0.01135\n",
      "epoch 604, batch 11, d_loss=-0.329 g_loss=-0.620 KID= 0.01135\n",
      "epoch 604, batch 12, d_loss=-0.320 g_loss=-0.495 KID= 0.01135\n",
      "epoch 604, batch 13, d_loss=-0.278 g_loss=-0.340 KID= 0.01135\n",
      "epoch 604, batch 14, d_loss=-0.414 g_loss=-0.276 KID= 0.01135\n",
      "epoch 604, batch 15, d_loss=-0.413 g_loss=-0.306 KID= 0.01135\n",
      "epoch 604, batch 16, d_loss=-0.393 g_loss=-0.443 KID= 0.01135\n",
      "epoch 604, batch 17, d_loss=-0.391 g_loss=-0.569 KID= 0.01135\n",
      "epoch 604, batch 18, d_loss=-0.467 g_loss=-0.468 KID= 0.01135\n",
      "epoch 604, batch 19, d_loss=-0.469 g_loss=-0.483 KID= 0.01135\n",
      "epoch 605, batch 0, d_loss=-0.369 g_loss=-0.454 KID= 0.01135\n",
      "epoch 605, batch 1, d_loss=-0.375 g_loss=-0.463 KID= 0.01135\n",
      "epoch 605, batch 2, d_loss=-0.368 g_loss=-0.494 KID= 0.01135\n",
      "epoch 605, batch 3, d_loss=-0.241 g_loss=-0.526 KID= 0.01135\n",
      "epoch 605, batch 4, d_loss=-0.352 g_loss=-0.462 KID= 0.01135\n",
      "epoch 605, batch 5, d_loss=-0.380 g_loss=-0.483 KID= 0.01135\n",
      "epoch 605, batch 6, d_loss=-0.357 g_loss=-0.649 KID= 0.01135\n",
      "epoch 605, batch 7, d_loss=-0.349 g_loss=-0.611 KID= 0.01135\n",
      "epoch 605, batch 8, d_loss=-0.467 g_loss=-0.460 KID= 0.01135\n",
      "epoch 605, batch 9, d_loss=-0.439 g_loss=-0.446 KID= 0.01135\n",
      "epoch 605, batch 10, d_loss=-0.358 g_loss=-0.317 KID= 0.01135\n",
      "epoch 605, batch 11, d_loss=-0.345 g_loss=-0.157 KID= 0.01135\n",
      "epoch 605, batch 12, d_loss=-0.375 g_loss=-0.092 KID= 0.01135\n",
      "epoch 605, batch 13, d_loss=-0.239 g_loss=-0.049 KID= 0.01135\n",
      "epoch 605, batch 14, d_loss=-0.330 g_loss=-0.090 KID= 0.01135\n",
      "epoch 605, batch 15, d_loss=-0.406 g_loss=-0.231 KID= 0.01135\n",
      "epoch 605, batch 16, d_loss=-0.352 g_loss=-0.481 KID= 0.01135\n",
      "epoch 605, batch 17, d_loss=-0.409 g_loss=-0.644 KID= 0.01135\n",
      "epoch 605, batch 18, d_loss=-0.417 g_loss=-0.587 KID= 0.01135\n",
      "epoch 605, batch 19, d_loss=-0.416 g_loss=-0.510 KID= 0.01135\n",
      "epoch 606, batch 0, d_loss=-0.346 g_loss=-0.471 KID= 0.01135\n",
      "epoch 606, batch 1, d_loss=-0.356 g_loss=-0.459 KID= 0.01135\n",
      "epoch 606, batch 2, d_loss=-0.309 g_loss=-0.485 KID= 0.01135\n",
      "epoch 606, batch 3, d_loss=-0.244 g_loss=-0.440 KID= 0.01135\n",
      "epoch 606, batch 4, d_loss=-0.407 g_loss=-0.389 KID= 0.01135\n",
      "epoch 606, batch 5, d_loss=-0.327 g_loss=-0.380 KID= 0.01135\n",
      "epoch 606, batch 6, d_loss=-0.335 g_loss=-0.493 KID= 0.01135\n",
      "epoch 606, batch 7, d_loss=-0.434 g_loss=-0.560 KID= 0.01135\n",
      "epoch 606, batch 8, d_loss=-0.429 g_loss=-0.485 KID= 0.01135\n",
      "epoch 606, batch 9, d_loss=-0.383 g_loss=-0.492 KID= 0.01135\n",
      "epoch 606, batch 10, d_loss=-0.418 g_loss=-0.453 KID= 0.01135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 606, batch 11, d_loss=-0.355 g_loss=-0.397 KID= 0.01135\n",
      "epoch 606, batch 12, d_loss=-0.350 g_loss=-0.309 KID= 0.01135\n",
      "epoch 606, batch 13, d_loss=-0.259 g_loss=-0.188 KID= 0.01135\n",
      "epoch 606, batch 14, d_loss=-0.374 g_loss=-0.092 KID= 0.01135\n",
      "epoch 606, batch 15, d_loss=-0.391 g_loss=-0.047 KID= 0.01135\n",
      "epoch 606, batch 16, d_loss=-0.324 g_loss=-0.143 KID= 0.01135\n",
      "epoch 606, batch 17, d_loss=-0.335 g_loss=-0.242 KID= 0.01135\n",
      "epoch 606, batch 18, d_loss=-0.467 g_loss=-0.355 KID= 0.01135\n",
      "epoch 606, batch 19, d_loss=-0.450 g_loss=-0.414 KID= 0.01135\n",
      "epoch 607, batch 0, d_loss=-0.344 g_loss=-0.510 KID= 0.01135\n",
      "epoch 607, batch 1, d_loss=-0.363 g_loss=-0.514 KID= 0.01135\n",
      "epoch 607, batch 2, d_loss=-0.307 g_loss=-0.561 KID= 0.01135\n",
      "epoch 607, batch 3, d_loss=-0.251 g_loss=-0.597 KID= 0.01135\n",
      "epoch 607, batch 4, d_loss=-0.394 g_loss=-0.575 KID= 0.01135\n",
      "epoch 607, batch 5, d_loss=-0.354 g_loss=-0.644 KID= 0.01135\n",
      "epoch 607, batch 6, d_loss=-0.353 g_loss=-0.811 KID= 0.01135\n",
      "epoch 607, batch 7, d_loss=-0.372 g_loss=-0.861 KID= 0.01135\n",
      "epoch 607, batch 8, d_loss=-0.438 g_loss=-0.827 KID= 0.01135\n",
      "epoch 607, batch 9, d_loss=-0.444 g_loss=-0.853 KID= 0.01135\n",
      "epoch 607, batch 10, d_loss=-0.346 g_loss=-0.770 KID= 0.01135\n",
      "epoch 607, batch 11, d_loss=-0.389 g_loss=-0.728 KID= 0.01135\n",
      "epoch 607, batch 12, d_loss=-0.319 g_loss=-0.741 KID= 0.01135\n",
      "epoch 607, batch 13, d_loss=-0.202 g_loss=-0.583 KID= 0.01135\n",
      "epoch 607, batch 14, d_loss=-0.344 g_loss=-0.417 KID= 0.01135\n",
      "epoch 607, batch 15, d_loss=-0.413 g_loss=-0.262 KID= 0.01135\n",
      "epoch 607, batch 16, d_loss=-0.334 g_loss=-0.233 KID= 0.01135\n",
      "epoch 607, batch 17, d_loss=-0.441 g_loss=-0.307 KID= 0.01135\n",
      "epoch 607, batch 18, d_loss=-0.418 g_loss=-0.209 KID= 0.01135\n",
      "epoch 607, batch 19, d_loss=-0.420 g_loss=-0.292 KID= 0.01135\n",
      "epoch 608, batch 0, d_loss=-0.353 g_loss=-0.289 KID= 0.01135\n",
      "epoch 608, batch 1, d_loss=-0.404 g_loss=-0.258 KID= 0.01135\n",
      "epoch 608, batch 2, d_loss=-0.296 g_loss=-0.266 KID= 0.01135\n",
      "epoch 608, batch 3, d_loss=-0.184 g_loss=-0.292 KID= 0.01135\n",
      "epoch 608, batch 4, d_loss=-0.387 g_loss=-0.333 KID= 0.01135\n",
      "epoch 608, batch 5, d_loss=-0.352 g_loss=-0.374 KID= 0.01135\n",
      "epoch 608, batch 6, d_loss=-0.332 g_loss=-0.487 KID= 0.01135\n",
      "epoch 608, batch 7, d_loss=-0.447 g_loss=-0.591 KID= 0.01135\n",
      "epoch 608, batch 8, d_loss=-0.460 g_loss=-0.608 KID= 0.01135\n",
      "epoch 608, batch 9, d_loss=-0.425 g_loss=-0.751 KID= 0.01135\n",
      "epoch 608, batch 10, d_loss=-0.383 g_loss=-0.596 KID= 0.01135\n",
      "epoch 608, batch 11, d_loss=-0.367 g_loss=-0.462 KID= 0.01135\n",
      "epoch 608, batch 12, d_loss=-0.396 g_loss=-0.410 KID= 0.01135\n",
      "epoch 608, batch 13, d_loss=-0.251 g_loss=-0.247 KID= 0.01135\n",
      "epoch 608, batch 14, d_loss=-0.332 g_loss=-0.247 KID= 0.01135\n",
      "epoch 608, batch 15, d_loss=-0.386 g_loss=-0.262 KID= 0.01135\n",
      "epoch 608, batch 16, d_loss=-0.315 g_loss=-0.331 KID= 0.01135\n",
      "epoch 608, batch 17, d_loss=-0.437 g_loss=-0.410 KID= 0.01135\n",
      "epoch 608, batch 18, d_loss=-0.442 g_loss=-0.402 KID= 0.01135\n",
      "epoch 608, batch 19, d_loss=-0.441 g_loss=-0.494 KID= 0.01135\n",
      "epoch 609, batch 0, d_loss=-0.324 g_loss=-0.560 KID= 0.01135\n",
      "epoch 609, batch 1, d_loss=-0.389 g_loss=-0.563 KID= 0.01135\n",
      "epoch 609, batch 2, d_loss=-0.364 g_loss=-0.582 KID= 0.01135\n",
      "epoch 609, batch 3, d_loss=-0.295 g_loss=-0.418 KID= 0.01135\n",
      "epoch 609, batch 4, d_loss=-0.378 g_loss=-0.317 KID= 0.01135\n",
      "epoch 609, batch 5, d_loss=-0.339 g_loss=-0.296 KID= 0.01135\n",
      "epoch 609, batch 6, d_loss=-0.333 g_loss=-0.321 KID= 0.01135\n",
      "epoch 609, batch 7, d_loss=-0.413 g_loss=-0.427 KID= 0.01135\n",
      "epoch 609, batch 8, d_loss=-0.446 g_loss=-0.450 KID= 0.01135\n",
      "epoch 609, batch 9, d_loss=-0.468 g_loss=-0.600 KID= 0.01135\n",
      "epoch 609, batch 10, d_loss=-0.355 g_loss=-0.587 KID= 0.01135\n",
      "epoch 609, batch 11, d_loss=-0.392 g_loss=-0.596 KID= 0.01135\n",
      "epoch 609, batch 12, d_loss=-0.414 g_loss=-0.719 KID= 0.01135\n",
      "epoch 609, batch 13, d_loss=-0.223 g_loss=-0.585 KID= 0.01135\n",
      "epoch 609, batch 14, d_loss=-0.352 g_loss=-0.500 KID= 0.01135\n",
      "epoch 609, batch 15, d_loss=-0.353 g_loss=-0.478 KID= 0.01135\n",
      "epoch 609, batch 16, d_loss=-0.294 g_loss=-0.504 KID= 0.01135\n",
      "epoch 609, batch 17, d_loss=-0.440 g_loss=-0.406 KID= 0.01135\n",
      "epoch 609, batch 18, d_loss=-0.493 g_loss=-0.262 KID= 0.01135\n",
      "epoch 609, batch 19, d_loss=-0.428 g_loss=-0.262 KID= 0.01135\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 610, batch 0, d_loss=-0.321 g_loss=-0.302 KID= 0.00858\n",
      "epoch 610, batch 1, d_loss=-0.420 g_loss=-0.317 KID= 0.00858\n",
      "epoch 610, batch 2, d_loss=-0.332 g_loss=-0.344 KID= 0.00858\n",
      "epoch 610, batch 3, d_loss=-0.267 g_loss=-0.266 KID= 0.00858\n",
      "epoch 610, batch 4, d_loss=-0.410 g_loss=-0.221 KID= 0.00858\n",
      "epoch 610, batch 5, d_loss=-0.348 g_loss=-0.123 KID= 0.00858\n",
      "epoch 610, batch 6, d_loss=-0.363 g_loss=-0.121 KID= 0.00858\n",
      "epoch 610, batch 7, d_loss=-0.376 g_loss=-0.145 KID= 0.00858\n",
      "epoch 610, batch 8, d_loss=-0.458 g_loss=-0.095 KID= 0.00858\n",
      "epoch 610, batch 9, d_loss=-0.428 g_loss=-0.172 KID= 0.00858\n",
      "epoch 610, batch 10, d_loss=-0.332 g_loss=-0.320 KID= 0.00858\n",
      "epoch 610, batch 11, d_loss=-0.443 g_loss=-0.400 KID= 0.00858\n",
      "epoch 610, batch 12, d_loss=-0.381 g_loss=-0.471 KID= 0.00858\n",
      "epoch 610, batch 13, d_loss=-0.239 g_loss=-0.512 KID= 0.00858\n",
      "epoch 610, batch 14, d_loss=-0.415 g_loss=-0.546 KID= 0.00858\n",
      "epoch 610, batch 15, d_loss=-0.375 g_loss=-0.521 KID= 0.00858\n",
      "epoch 610, batch 16, d_loss=-0.332 g_loss=-0.621 KID= 0.00858\n",
      "epoch 610, batch 17, d_loss=-0.374 g_loss=-0.502 KID= 0.00858\n",
      "epoch 610, batch 18, d_loss=-0.448 g_loss=-0.416 KID= 0.00858\n",
      "epoch 610, batch 19, d_loss=-0.413 g_loss=-0.462 KID= 0.00858\n",
      "epoch 611, batch 0, d_loss=-0.396 g_loss=-0.456 KID= 0.00858\n",
      "epoch 611, batch 1, d_loss=-0.437 g_loss=-0.455 KID= 0.00858\n",
      "epoch 611, batch 2, d_loss=-0.318 g_loss=-0.429 KID= 0.00858\n",
      "epoch 611, batch 3, d_loss=-0.289 g_loss=-0.475 KID= 0.00858\n",
      "epoch 611, batch 4, d_loss=-0.314 g_loss=-0.515 KID= 0.00858\n",
      "epoch 611, batch 5, d_loss=-0.306 g_loss=-0.635 KID= 0.00858\n",
      "epoch 611, batch 6, d_loss=-0.317 g_loss=-0.716 KID= 0.00858\n",
      "epoch 611, batch 7, d_loss=-0.440 g_loss=-0.602 KID= 0.00858\n",
      "epoch 611, batch 8, d_loss=-0.540 g_loss=-0.520 KID= 0.00858\n",
      "epoch 611, batch 9, d_loss=-0.424 g_loss=-0.537 KID= 0.00858\n",
      "epoch 611, batch 10, d_loss=-0.325 g_loss=-0.471 KID= 0.00858\n",
      "epoch 611, batch 11, d_loss=-0.342 g_loss=-0.419 KID= 0.00858\n",
      "epoch 611, batch 12, d_loss=-0.385 g_loss=-0.420 KID= 0.00858\n",
      "epoch 611, batch 13, d_loss=-0.307 g_loss=-0.396 KID= 0.00858\n",
      "epoch 611, batch 14, d_loss=-0.355 g_loss=-0.389 KID= 0.00858\n",
      "epoch 611, batch 15, d_loss=-0.372 g_loss=-0.430 KID= 0.00858\n",
      "epoch 611, batch 16, d_loss=-0.342 g_loss=-0.410 KID= 0.00858\n",
      "epoch 611, batch 17, d_loss=-0.462 g_loss=-0.491 KID= 0.00858\n",
      "epoch 611, batch 18, d_loss=-0.442 g_loss=-0.481 KID= 0.00858\n",
      "epoch 611, batch 19, d_loss=-0.397 g_loss=-0.593 KID= 0.00858\n",
      "epoch 612, batch 0, d_loss=-0.309 g_loss=-0.569 KID= 0.00858\n",
      "epoch 612, batch 1, d_loss=-0.397 g_loss=-0.443 KID= 0.00858\n",
      "epoch 612, batch 2, d_loss=-0.319 g_loss=-0.387 KID= 0.00858\n",
      "epoch 612, batch 3, d_loss=-0.321 g_loss=-0.316 KID= 0.00858\n",
      "epoch 612, batch 4, d_loss=-0.396 g_loss=-0.231 KID= 0.00858\n",
      "epoch 612, batch 5, d_loss=-0.377 g_loss=-0.113 KID= 0.00858\n",
      "epoch 612, batch 6, d_loss=-0.374 g_loss=-0.032 KID= 0.00858\n",
      "epoch 612, batch 7, d_loss=-0.445 g_loss=0.179 KID= 0.00858\n",
      "epoch 612, batch 8, d_loss=-0.495 g_loss=0.256 KID= 0.00858\n",
      "epoch 612, batch 9, d_loss=-0.385 g_loss=0.185 KID= 0.00858\n",
      "epoch 612, batch 10, d_loss=-0.401 g_loss=0.057 KID= 0.00858\n",
      "epoch 612, batch 11, d_loss=-0.342 g_loss=-0.079 KID= 0.00858\n",
      "epoch 612, batch 12, d_loss=-0.364 g_loss=-0.258 KID= 0.00858\n",
      "epoch 612, batch 13, d_loss=-0.294 g_loss=-0.421 KID= 0.00858\n",
      "epoch 612, batch 14, d_loss=-0.344 g_loss=-0.553 KID= 0.00858\n",
      "epoch 612, batch 15, d_loss=-0.381 g_loss=-0.611 KID= 0.00858\n",
      "epoch 612, batch 16, d_loss=-0.327 g_loss=-0.687 KID= 0.00858\n",
      "epoch 612, batch 17, d_loss=-0.403 g_loss=-0.712 KID= 0.00858\n",
      "epoch 612, batch 18, d_loss=-0.458 g_loss=-0.642 KID= 0.00858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 612, batch 19, d_loss=-0.457 g_loss=-0.759 KID= 0.00858\n",
      "epoch 613, batch 0, d_loss=-0.402 g_loss=-0.739 KID= 0.00858\n",
      "epoch 613, batch 1, d_loss=-0.408 g_loss=-0.676 KID= 0.00858\n",
      "epoch 613, batch 2, d_loss=-0.376 g_loss=-0.640 KID= 0.00858\n",
      "epoch 613, batch 3, d_loss=-0.278 g_loss=-0.565 KID= 0.00858\n",
      "epoch 613, batch 4, d_loss=-0.371 g_loss=-0.400 KID= 0.00858\n",
      "epoch 613, batch 5, d_loss=-0.375 g_loss=-0.274 KID= 0.00858\n",
      "epoch 613, batch 6, d_loss=-0.342 g_loss=-0.062 KID= 0.00858\n",
      "epoch 613, batch 7, d_loss=-0.435 g_loss=0.091 KID= 0.00858\n",
      "epoch 613, batch 8, d_loss=-0.488 g_loss=0.146 KID= 0.00858\n",
      "epoch 613, batch 9, d_loss=-0.382 g_loss=0.034 KID= 0.00858\n",
      "epoch 613, batch 10, d_loss=-0.365 g_loss=-0.033 KID= 0.00858\n",
      "epoch 613, batch 11, d_loss=-0.375 g_loss=-0.065 KID= 0.00858\n",
      "epoch 613, batch 12, d_loss=-0.316 g_loss=-0.199 KID= 0.00858\n",
      "epoch 613, batch 13, d_loss=-0.322 g_loss=-0.295 KID= 0.00858\n",
      "epoch 613, batch 14, d_loss=-0.340 g_loss=-0.342 KID= 0.00858\n",
      "epoch 613, batch 15, d_loss=-0.341 g_loss=-0.456 KID= 0.00858\n",
      "epoch 613, batch 16, d_loss=-0.306 g_loss=-0.482 KID= 0.00858\n",
      "epoch 613, batch 17, d_loss=-0.434 g_loss=-0.449 KID= 0.00858\n",
      "epoch 613, batch 18, d_loss=-0.509 g_loss=-0.319 KID= 0.00858\n",
      "epoch 613, batch 19, d_loss=-0.359 g_loss=-0.465 KID= 0.00858\n",
      "epoch 614, batch 0, d_loss=-0.323 g_loss=-0.555 KID= 0.00858\n",
      "epoch 614, batch 1, d_loss=-0.373 g_loss=-0.676 KID= 0.00858\n",
      "epoch 614, batch 2, d_loss=-0.399 g_loss=-0.845 KID= 0.00858\n",
      "epoch 614, batch 3, d_loss=-0.256 g_loss=-0.876 KID= 0.00858\n",
      "epoch 614, batch 4, d_loss=-0.399 g_loss=-0.943 KID= 0.00858\n",
      "epoch 614, batch 5, d_loss=-0.424 g_loss=-0.928 KID= 0.00858\n",
      "epoch 614, batch 6, d_loss=-0.322 g_loss=-0.877 KID= 0.00858\n",
      "epoch 614, batch 7, d_loss=-0.445 g_loss=-0.735 KID= 0.00858\n",
      "epoch 614, batch 8, d_loss=-0.469 g_loss=-0.472 KID= 0.00858\n",
      "epoch 614, batch 9, d_loss=-0.400 g_loss=-0.347 KID= 0.00858\n",
      "epoch 614, batch 10, d_loss=-0.339 g_loss=-0.171 KID= 0.00858\n",
      "epoch 614, batch 11, d_loss=-0.374 g_loss=-0.069 KID= 0.00858\n",
      "epoch 614, batch 12, d_loss=-0.355 g_loss=-0.141 KID= 0.00858\n",
      "epoch 614, batch 13, d_loss=-0.347 g_loss=-0.308 KID= 0.00858\n",
      "epoch 614, batch 14, d_loss=-0.374 g_loss=-0.409 KID= 0.00858\n",
      "epoch 614, batch 15, d_loss=-0.386 g_loss=-0.471 KID= 0.00858\n",
      "epoch 614, batch 16, d_loss=-0.321 g_loss=-0.462 KID= 0.00858\n",
      "epoch 614, batch 17, d_loss=-0.427 g_loss=-0.375 KID= 0.00858\n",
      "epoch 614, batch 18, d_loss=-0.472 g_loss=-0.344 KID= 0.00858\n",
      "epoch 614, batch 19, d_loss=-0.389 g_loss=-0.434 KID= 0.00858\n",
      "epoch 615, batch 0, d_loss=-0.385 g_loss=-0.367 KID= 0.00858\n",
      "epoch 615, batch 1, d_loss=-0.377 g_loss=-0.431 KID= 0.00858\n",
      "epoch 615, batch 2, d_loss=-0.335 g_loss=-0.610 KID= 0.00858\n",
      "epoch 615, batch 3, d_loss=-0.325 g_loss=-0.751 KID= 0.00858\n",
      "epoch 615, batch 4, d_loss=-0.368 g_loss=-0.907 KID= 0.00858\n",
      "epoch 615, batch 5, d_loss=-0.402 g_loss=-1.004 KID= 0.00858\n",
      "epoch 615, batch 6, d_loss=-0.310 g_loss=-0.992 KID= 0.00858\n",
      "epoch 615, batch 7, d_loss=-0.388 g_loss=-0.838 KID= 0.00858\n",
      "epoch 615, batch 8, d_loss=-0.478 g_loss=-0.709 KID= 0.00858\n",
      "epoch 615, batch 9, d_loss=-0.368 g_loss=-0.595 KID= 0.00858\n",
      "epoch 615, batch 10, d_loss=-0.387 g_loss=-0.423 KID= 0.00858\n",
      "epoch 615, batch 11, d_loss=-0.420 g_loss=-0.258 KID= 0.00858\n",
      "epoch 615, batch 12, d_loss=-0.359 g_loss=-0.183 KID= 0.00858\n",
      "epoch 615, batch 13, d_loss=-0.316 g_loss=-0.237 KID= 0.00858\n",
      "epoch 615, batch 14, d_loss=-0.340 g_loss=-0.194 KID= 0.00858\n",
      "epoch 615, batch 15, d_loss=-0.409 g_loss=-0.184 KID= 0.00858\n",
      "epoch 615, batch 16, d_loss=-0.293 g_loss=-0.107 KID= 0.00858\n",
      "epoch 615, batch 17, d_loss=-0.436 g_loss=-0.080 KID= 0.00858\n",
      "epoch 615, batch 18, d_loss=-0.505 g_loss=-0.109 KID= 0.00858\n",
      "epoch 615, batch 19, d_loss=-0.409 g_loss=-0.165 KID= 0.00858\n",
      "epoch 616, batch 0, d_loss=-0.349 g_loss=-0.246 KID= 0.00858\n",
      "epoch 616, batch 1, d_loss=-0.390 g_loss=-0.308 KID= 0.00858\n",
      "epoch 616, batch 2, d_loss=-0.346 g_loss=-0.414 KID= 0.00858\n",
      "epoch 616, batch 3, d_loss=-0.359 g_loss=-0.459 KID= 0.00858\n",
      "epoch 616, batch 4, d_loss=-0.406 g_loss=-0.617 KID= 0.00858\n",
      "epoch 616, batch 5, d_loss=-0.402 g_loss=-0.634 KID= 0.00858\n",
      "epoch 616, batch 6, d_loss=-0.300 g_loss=-0.652 KID= 0.00858\n",
      "epoch 616, batch 7, d_loss=-0.426 g_loss=-0.518 KID= 0.00858\n",
      "epoch 616, batch 8, d_loss=-0.464 g_loss=-0.321 KID= 0.00858\n",
      "epoch 616, batch 9, d_loss=-0.436 g_loss=-0.140 KID= 0.00858\n",
      "epoch 616, batch 10, d_loss=-0.352 g_loss=0.004 KID= 0.00858\n",
      "epoch 616, batch 11, d_loss=-0.359 g_loss=-0.019 KID= 0.00858\n",
      "epoch 616, batch 12, d_loss=-0.339 g_loss=-0.176 KID= 0.00858\n",
      "epoch 616, batch 13, d_loss=-0.247 g_loss=-0.344 KID= 0.00858\n",
      "epoch 616, batch 14, d_loss=-0.346 g_loss=-0.331 KID= 0.00858\n",
      "epoch 616, batch 15, d_loss=-0.410 g_loss=-0.367 KID= 0.00858\n",
      "epoch 616, batch 16, d_loss=-0.300 g_loss=-0.332 KID= 0.00858\n",
      "epoch 616, batch 17, d_loss=-0.441 g_loss=-0.340 KID= 0.00858\n",
      "epoch 616, batch 18, d_loss=-0.481 g_loss=-0.392 KID= 0.00858\n",
      "epoch 616, batch 19, d_loss=-0.361 g_loss=-0.390 KID= 0.00858\n",
      "epoch 617, batch 0, d_loss=-0.371 g_loss=-0.295 KID= 0.00858\n",
      "epoch 617, batch 1, d_loss=-0.417 g_loss=-0.321 KID= 0.00858\n",
      "epoch 617, batch 2, d_loss=-0.248 g_loss=-0.370 KID= 0.00858\n",
      "epoch 617, batch 3, d_loss=-0.334 g_loss=-0.429 KID= 0.00858\n",
      "epoch 617, batch 4, d_loss=-0.375 g_loss=-0.425 KID= 0.00858\n",
      "epoch 617, batch 5, d_loss=-0.366 g_loss=-0.360 KID= 0.00858\n",
      "epoch 617, batch 6, d_loss=-0.274 g_loss=-0.217 KID= 0.00858\n",
      "epoch 617, batch 7, d_loss=-0.433 g_loss=-0.109 KID= 0.00858\n",
      "epoch 617, batch 8, d_loss=-0.490 g_loss=0.041 KID= 0.00858\n",
      "epoch 617, batch 9, d_loss=-0.387 g_loss=0.098 KID= 0.00858\n",
      "epoch 617, batch 10, d_loss=-0.306 g_loss=0.098 KID= 0.00858\n",
      "epoch 617, batch 11, d_loss=-0.354 g_loss=0.101 KID= 0.00858\n",
      "epoch 617, batch 12, d_loss=-0.337 g_loss=0.012 KID= 0.00858\n",
      "epoch 617, batch 13, d_loss=-0.329 g_loss=-0.184 KID= 0.00858\n",
      "epoch 617, batch 14, d_loss=-0.401 g_loss=-0.372 KID= 0.00858\n",
      "epoch 617, batch 15, d_loss=-0.438 g_loss=-0.624 KID= 0.00858\n",
      "epoch 617, batch 16, d_loss=-0.329 g_loss=-0.636 KID= 0.00858\n",
      "epoch 617, batch 17, d_loss=-0.466 g_loss=-0.590 KID= 0.00858\n",
      "epoch 617, batch 18, d_loss=-0.447 g_loss=-0.522 KID= 0.00858\n",
      "epoch 617, batch 19, d_loss=-0.350 g_loss=-0.487 KID= 0.00858\n",
      "epoch 618, batch 0, d_loss=-0.353 g_loss=-0.454 KID= 0.00858\n",
      "epoch 618, batch 1, d_loss=-0.430 g_loss=-0.476 KID= 0.00858\n",
      "epoch 618, batch 2, d_loss=-0.366 g_loss=-0.706 KID= 0.00858\n",
      "epoch 618, batch 3, d_loss=-0.307 g_loss=-0.840 KID= 0.00858\n",
      "epoch 618, batch 4, d_loss=-0.393 g_loss=-1.021 KID= 0.00858\n",
      "epoch 618, batch 5, d_loss=-0.394 g_loss=-1.186 KID= 0.00858\n",
      "epoch 618, batch 6, d_loss=-0.269 g_loss=-1.069 KID= 0.00858\n",
      "epoch 618, batch 7, d_loss=-0.452 g_loss=-1.055 KID= 0.00858\n",
      "epoch 618, batch 8, d_loss=-0.441 g_loss=-0.861 KID= 0.00858\n",
      "epoch 618, batch 9, d_loss=-0.428 g_loss=-0.583 KID= 0.00858\n",
      "epoch 618, batch 10, d_loss=-0.351 g_loss=-0.171 KID= 0.00858\n",
      "epoch 618, batch 11, d_loss=-0.391 g_loss=0.197 KID= 0.00858\n",
      "epoch 618, batch 12, d_loss=-0.333 g_loss=0.391 KID= 0.00858\n",
      "epoch 618, batch 13, d_loss=-0.310 g_loss=0.374 KID= 0.00858\n",
      "epoch 618, batch 14, d_loss=-0.351 g_loss=0.362 KID= 0.00858\n",
      "epoch 618, batch 15, d_loss=-0.417 g_loss=0.335 KID= 0.00858\n",
      "epoch 618, batch 16, d_loss=-0.325 g_loss=0.265 KID= 0.00858\n",
      "epoch 618, batch 17, d_loss=-0.504 g_loss=0.269 KID= 0.00858\n",
      "epoch 618, batch 18, d_loss=-0.447 g_loss=0.214 KID= 0.00858\n",
      "epoch 618, batch 19, d_loss=-0.382 g_loss=0.233 KID= 0.00858\n",
      "epoch 619, batch 0, d_loss=-0.380 g_loss=0.068 KID= 0.00858\n",
      "epoch 619, batch 1, d_loss=-0.448 g_loss=-0.073 KID= 0.00858\n",
      "epoch 619, batch 2, d_loss=-0.365 g_loss=-0.205 KID= 0.00858\n",
      "epoch 619, batch 3, d_loss=-0.289 g_loss=-0.500 KID= 0.00858\n",
      "epoch 619, batch 4, d_loss=-0.390 g_loss=-0.823 KID= 0.00858\n",
      "epoch 619, batch 5, d_loss=-0.412 g_loss=-0.961 KID= 0.00858\n",
      "epoch 619, batch 6, d_loss=-0.315 g_loss=-1.052 KID= 0.00858\n",
      "epoch 619, batch 7, d_loss=-0.376 g_loss=-1.152 KID= 0.00858\n",
      "epoch 619, batch 8, d_loss=-0.434 g_loss=-1.108 KID= 0.00858\n",
      "epoch 619, batch 9, d_loss=-0.396 g_loss=-1.029 KID= 0.00858\n",
      "epoch 619, batch 10, d_loss=-0.374 g_loss=-0.915 KID= 0.00858\n",
      "epoch 619, batch 11, d_loss=-0.416 g_loss=-0.737 KID= 0.00858\n",
      "epoch 619, batch 12, d_loss=-0.344 g_loss=-0.602 KID= 0.00858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 619, batch 13, d_loss=-0.283 g_loss=-0.542 KID= 0.00858\n",
      "epoch 619, batch 14, d_loss=-0.400 g_loss=-0.363 KID= 0.00858\n",
      "epoch 619, batch 15, d_loss=-0.419 g_loss=-0.202 KID= 0.00858\n",
      "epoch 619, batch 16, d_loss=-0.298 g_loss=-0.014 KID= 0.00858\n",
      "epoch 619, batch 17, d_loss=-0.509 g_loss=0.116 KID= 0.00858\n",
      "epoch 619, batch 18, d_loss=-0.474 g_loss=0.142 KID= 0.00858\n",
      "epoch 619, batch 19, d_loss=-0.377 g_loss=0.200 KID= 0.00858\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 620, batch 0, d_loss=-0.258 g_loss=0.061 KID= 0.00740\n",
      "epoch 620, batch 1, d_loss=-0.365 g_loss=-0.039 KID= 0.00740\n",
      "epoch 620, batch 2, d_loss=-0.371 g_loss=-0.261 KID= 0.00740\n",
      "epoch 620, batch 3, d_loss=-0.338 g_loss=-0.380 KID= 0.00740\n",
      "epoch 620, batch 4, d_loss=-0.387 g_loss=-0.489 KID= 0.00740\n",
      "epoch 620, batch 5, d_loss=-0.412 g_loss=-0.514 KID= 0.00740\n",
      "epoch 620, batch 6, d_loss=-0.371 g_loss=-0.565 KID= 0.00740\n",
      "epoch 620, batch 7, d_loss=-0.443 g_loss=-0.518 KID= 0.00740\n",
      "epoch 620, batch 8, d_loss=-0.470 g_loss=-0.435 KID= 0.00740\n",
      "epoch 620, batch 9, d_loss=-0.318 g_loss=-0.243 KID= 0.00740\n",
      "epoch 620, batch 10, d_loss=-0.328 g_loss=-0.108 KID= 0.00740\n",
      "epoch 620, batch 11, d_loss=-0.394 g_loss=0.068 KID= 0.00740\n",
      "epoch 620, batch 12, d_loss=-0.380 g_loss=-0.040 KID= 0.00740\n",
      "epoch 620, batch 13, d_loss=-0.258 g_loss=-0.192 KID= 0.00740\n",
      "epoch 620, batch 14, d_loss=-0.393 g_loss=-0.398 KID= 0.00740\n",
      "epoch 620, batch 15, d_loss=-0.441 g_loss=-0.571 KID= 0.00740\n",
      "epoch 620, batch 16, d_loss=-0.322 g_loss=-0.580 KID= 0.00740\n",
      "epoch 620, batch 17, d_loss=-0.478 g_loss=-0.570 KID= 0.00740\n",
      "epoch 620, batch 18, d_loss=-0.442 g_loss=-0.472 KID= 0.00740\n",
      "epoch 620, batch 19, d_loss=-0.418 g_loss=-0.416 KID= 0.00740\n",
      "epoch 621, batch 0, d_loss=-0.285 g_loss=-0.350 KID= 0.00740\n",
      "epoch 621, batch 1, d_loss=-0.401 g_loss=-0.335 KID= 0.00740\n",
      "epoch 621, batch 2, d_loss=-0.322 g_loss=-0.457 KID= 0.00740\n",
      "epoch 621, batch 3, d_loss=-0.310 g_loss=-0.583 KID= 0.00740\n",
      "epoch 621, batch 4, d_loss=-0.425 g_loss=-0.657 KID= 0.00740\n",
      "epoch 621, batch 5, d_loss=-0.394 g_loss=-0.793 KID= 0.00740\n",
      "epoch 621, batch 6, d_loss=-0.329 g_loss=-0.895 KID= 0.00740\n",
      "epoch 621, batch 7, d_loss=-0.432 g_loss=-0.784 KID= 0.00740\n",
      "epoch 621, batch 8, d_loss=-0.430 g_loss=-0.608 KID= 0.00740\n",
      "epoch 621, batch 9, d_loss=-0.422 g_loss=-0.375 KID= 0.00740\n",
      "epoch 621, batch 10, d_loss=-0.361 g_loss=-0.131 KID= 0.00740\n",
      "epoch 621, batch 11, d_loss=-0.445 g_loss=0.001 KID= 0.00740\n",
      "epoch 621, batch 12, d_loss=-0.355 g_loss=-0.025 KID= 0.00740\n",
      "epoch 621, batch 13, d_loss=-0.292 g_loss=-0.019 KID= 0.00740\n",
      "epoch 621, batch 14, d_loss=-0.360 g_loss=0.014 KID= 0.00740\n",
      "epoch 621, batch 15, d_loss=-0.376 g_loss=-0.082 KID= 0.00740\n",
      "epoch 621, batch 16, d_loss=-0.354 g_loss=-0.142 KID= 0.00740\n",
      "epoch 621, batch 17, d_loss=-0.477 g_loss=-0.156 KID= 0.00740\n",
      "epoch 621, batch 18, d_loss=-0.430 g_loss=-0.021 KID= 0.00740\n",
      "epoch 621, batch 19, d_loss=-0.417 g_loss=-0.010 KID= 0.00740\n",
      "epoch 622, batch 0, d_loss=-0.335 g_loss=-0.116 KID= 0.00740\n",
      "epoch 622, batch 1, d_loss=-0.367 g_loss=-0.171 KID= 0.00740\n",
      "epoch 622, batch 2, d_loss=-0.384 g_loss=-0.250 KID= 0.00740\n",
      "epoch 622, batch 3, d_loss=-0.274 g_loss=-0.359 KID= 0.00740\n",
      "epoch 622, batch 4, d_loss=-0.369 g_loss=-0.481 KID= 0.00740\n",
      "epoch 622, batch 5, d_loss=-0.468 g_loss=-0.550 KID= 0.00740\n",
      "epoch 622, batch 6, d_loss=-0.345 g_loss=-0.535 KID= 0.00740\n",
      "epoch 622, batch 7, d_loss=-0.437 g_loss=-0.502 KID= 0.00740\n",
      "epoch 622, batch 8, d_loss=-0.494 g_loss=-0.528 KID= 0.00740\n",
      "epoch 622, batch 9, d_loss=-0.395 g_loss=-0.462 KID= 0.00740\n",
      "epoch 622, batch 10, d_loss=-0.285 g_loss=-0.284 KID= 0.00740\n",
      "epoch 622, batch 11, d_loss=-0.437 g_loss=-0.195 KID= 0.00740\n",
      "epoch 622, batch 12, d_loss=-0.350 g_loss=-0.266 KID= 0.00740\n",
      "epoch 622, batch 13, d_loss=-0.301 g_loss=-0.376 KID= 0.00740\n",
      "epoch 622, batch 14, d_loss=-0.379 g_loss=-0.419 KID= 0.00740\n",
      "epoch 622, batch 15, d_loss=-0.399 g_loss=-0.452 KID= 0.00740\n",
      "epoch 622, batch 16, d_loss=-0.355 g_loss=-0.517 KID= 0.00740\n",
      "epoch 622, batch 17, d_loss=-0.493 g_loss=-0.414 KID= 0.00740\n",
      "epoch 622, batch 18, d_loss=-0.441 g_loss=-0.305 KID= 0.00740\n",
      "epoch 622, batch 19, d_loss=-0.389 g_loss=-0.168 KID= 0.00740\n",
      "epoch 623, batch 0, d_loss=-0.358 g_loss=-0.066 KID= 0.00740\n",
      "epoch 623, batch 1, d_loss=-0.420 g_loss=-0.053 KID= 0.00740\n",
      "epoch 623, batch 2, d_loss=-0.350 g_loss=-0.149 KID= 0.00740\n",
      "epoch 623, batch 3, d_loss=-0.317 g_loss=-0.246 KID= 0.00740\n",
      "epoch 623, batch 4, d_loss=-0.390 g_loss=-0.385 KID= 0.00740\n",
      "epoch 623, batch 5, d_loss=-0.443 g_loss=-0.535 KID= 0.00740\n",
      "epoch 623, batch 6, d_loss=-0.351 g_loss=-0.654 KID= 0.00740\n",
      "epoch 623, batch 7, d_loss=-0.424 g_loss=-0.673 KID= 0.00740\n",
      "epoch 623, batch 8, d_loss=-0.478 g_loss=-0.638 KID= 0.00740\n",
      "epoch 623, batch 9, d_loss=-0.484 g_loss=-0.602 KID= 0.00740\n",
      "epoch 623, batch 10, d_loss=-0.306 g_loss=-0.357 KID= 0.00740\n",
      "epoch 623, batch 11, d_loss=-0.413 g_loss=-0.296 KID= 0.00740\n",
      "epoch 623, batch 12, d_loss=-0.370 g_loss=-0.394 KID= 0.00740\n",
      "epoch 623, batch 13, d_loss=-0.317 g_loss=-0.487 KID= 0.00740\n",
      "epoch 623, batch 14, d_loss=-0.394 g_loss=-0.529 KID= 0.00740\n",
      "epoch 623, batch 15, d_loss=-0.424 g_loss=-0.614 KID= 0.00740\n",
      "epoch 623, batch 16, d_loss=-0.365 g_loss=-0.674 KID= 0.00740\n",
      "epoch 623, batch 17, d_loss=-0.438 g_loss=-0.667 KID= 0.00740\n",
      "epoch 623, batch 18, d_loss=-0.450 g_loss=-0.506 KID= 0.00740\n",
      "epoch 623, batch 19, d_loss=-0.466 g_loss=-0.444 KID= 0.00740\n",
      "epoch 624, batch 0, d_loss=-0.299 g_loss=-0.146 KID= 0.00740\n",
      "epoch 624, batch 1, d_loss=-0.391 g_loss=-0.002 KID= 0.00740\n",
      "epoch 624, batch 2, d_loss=-0.393 g_loss=-0.032 KID= 0.00740\n",
      "epoch 624, batch 3, d_loss=-0.330 g_loss=-0.094 KID= 0.00740\n",
      "epoch 624, batch 4, d_loss=-0.403 g_loss=-0.108 KID= 0.00740\n",
      "epoch 624, batch 5, d_loss=-0.418 g_loss=-0.160 KID= 0.00740\n",
      "epoch 624, batch 6, d_loss=-0.349 g_loss=-0.307 KID= 0.00740\n",
      "epoch 624, batch 7, d_loss=-0.465 g_loss=-0.335 KID= 0.00740\n",
      "epoch 624, batch 8, d_loss=-0.480 g_loss=-0.392 KID= 0.00740\n",
      "epoch 624, batch 9, d_loss=-0.413 g_loss=-0.468 KID= 0.00740\n",
      "epoch 624, batch 10, d_loss=-0.329 g_loss=-0.460 KID= 0.00740\n",
      "epoch 624, batch 11, d_loss=-0.435 g_loss=-0.396 KID= 0.00740\n",
      "epoch 624, batch 12, d_loss=-0.353 g_loss=-0.472 KID= 0.00740\n",
      "epoch 624, batch 13, d_loss=-0.295 g_loss=-0.564 KID= 0.00740\n",
      "epoch 624, batch 14, d_loss=-0.409 g_loss=-0.566 KID= 0.00740\n",
      "epoch 624, batch 15, d_loss=-0.442 g_loss=-0.578 KID= 0.00740\n",
      "epoch 624, batch 16, d_loss=-0.346 g_loss=-0.560 KID= 0.00740\n",
      "epoch 624, batch 17, d_loss=-0.517 g_loss=-0.514 KID= 0.00740\n",
      "epoch 624, batch 18, d_loss=-0.470 g_loss=-0.480 KID= 0.00740\n",
      "epoch 624, batch 19, d_loss=-0.465 g_loss=-0.429 KID= 0.00740\n",
      "epoch 625, batch 0, d_loss=-0.250 g_loss=-0.219 KID= 0.00740\n",
      "epoch 625, batch 1, d_loss=-0.391 g_loss=-0.143 KID= 0.00740\n",
      "epoch 625, batch 2, d_loss=-0.370 g_loss=-0.197 KID= 0.00740\n",
      "epoch 625, batch 3, d_loss=-0.273 g_loss=-0.219 KID= 0.00740\n",
      "epoch 625, batch 4, d_loss=-0.403 g_loss=-0.215 KID= 0.00740\n",
      "epoch 625, batch 5, d_loss=-0.446 g_loss=-0.268 KID= 0.00740\n",
      "epoch 625, batch 6, d_loss=-0.337 g_loss=-0.369 KID= 0.00740\n",
      "epoch 625, batch 7, d_loss=-0.438 g_loss=-0.379 KID= 0.00740\n",
      "epoch 625, batch 8, d_loss=-0.415 g_loss=-0.287 KID= 0.00740\n",
      "epoch 625, batch 9, d_loss=-0.468 g_loss=-0.222 KID= 0.00740\n",
      "epoch 625, batch 10, d_loss=-0.371 g_loss=-0.154 KID= 0.00740\n",
      "epoch 625, batch 11, d_loss=-0.432 g_loss=-0.145 KID= 0.00740\n",
      "epoch 625, batch 12, d_loss=-0.400 g_loss=-0.347 KID= 0.00740\n",
      "epoch 625, batch 13, d_loss=-0.284 g_loss=-0.323 KID= 0.00740\n",
      "epoch 625, batch 14, d_loss=-0.393 g_loss=-0.358 KID= 0.00740\n",
      "epoch 625, batch 15, d_loss=-0.376 g_loss=-0.544 KID= 0.00740\n",
      "epoch 625, batch 16, d_loss=-0.389 g_loss=-0.644 KID= 0.00740\n",
      "epoch 625, batch 17, d_loss=-0.490 g_loss=-0.575 KID= 0.00740\n",
      "epoch 625, batch 18, d_loss=-0.451 g_loss=-0.532 KID= 0.00740\n",
      "epoch 625, batch 19, d_loss=-0.457 g_loss=-0.480 KID= 0.00740\n",
      "epoch 626, batch 0, d_loss=-0.386 g_loss=-0.349 KID= 0.00740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 626, batch 1, d_loss=-0.391 g_loss=-0.372 KID= 0.00740\n",
      "epoch 626, batch 2, d_loss=-0.340 g_loss=-0.481 KID= 0.00740\n",
      "epoch 626, batch 3, d_loss=-0.335 g_loss=-0.658 KID= 0.00740\n",
      "epoch 626, batch 4, d_loss=-0.424 g_loss=-0.677 KID= 0.00740\n",
      "epoch 626, batch 5, d_loss=-0.428 g_loss=-0.632 KID= 0.00740\n",
      "epoch 626, batch 6, d_loss=-0.337 g_loss=-0.697 KID= 0.00740\n",
      "epoch 626, batch 7, d_loss=-0.457 g_loss=-0.633 KID= 0.00740\n",
      "epoch 626, batch 8, d_loss=-0.485 g_loss=-0.543 KID= 0.00740\n",
      "epoch 626, batch 9, d_loss=-0.354 g_loss=-0.436 KID= 0.00740\n",
      "epoch 626, batch 10, d_loss=-0.418 g_loss=-0.179 KID= 0.00740\n",
      "epoch 626, batch 11, d_loss=-0.360 g_loss=-0.069 KID= 0.00740\n",
      "epoch 626, batch 12, d_loss=-0.392 g_loss=-0.033 KID= 0.00740\n",
      "epoch 626, batch 13, d_loss=-0.289 g_loss=-0.043 KID= 0.00740\n",
      "epoch 626, batch 14, d_loss=-0.404 g_loss=-0.104 KID= 0.00740\n",
      "epoch 626, batch 15, d_loss=-0.379 g_loss=-0.129 KID= 0.00740\n",
      "epoch 626, batch 16, d_loss=-0.308 g_loss=-0.055 KID= 0.00740\n",
      "epoch 626, batch 17, d_loss=-0.430 g_loss=0.036 KID= 0.00740\n",
      "epoch 626, batch 18, d_loss=-0.523 g_loss=0.120 KID= 0.00740\n",
      "epoch 626, batch 19, d_loss=-0.381 g_loss=0.128 KID= 0.00740\n",
      "epoch 627, batch 0, d_loss=-0.299 g_loss=-0.011 KID= 0.00740\n",
      "epoch 627, batch 1, d_loss=-0.408 g_loss=-0.183 KID= 0.00740\n",
      "epoch 627, batch 2, d_loss=-0.331 g_loss=-0.364 KID= 0.00740\n",
      "epoch 627, batch 3, d_loss=-0.335 g_loss=-0.573 KID= 0.00740\n",
      "epoch 627, batch 4, d_loss=-0.448 g_loss=-0.872 KID= 0.00740\n",
      "epoch 627, batch 5, d_loss=-0.409 g_loss=-0.917 KID= 0.00740\n",
      "epoch 627, batch 6, d_loss=-0.320 g_loss=-0.985 KID= 0.00740\n",
      "epoch 627, batch 7, d_loss=-0.456 g_loss=-0.952 KID= 0.00740\n",
      "epoch 627, batch 8, d_loss=-0.494 g_loss=-0.779 KID= 0.00740\n",
      "epoch 627, batch 9, d_loss=-0.406 g_loss=-0.506 KID= 0.00740\n",
      "epoch 627, batch 10, d_loss=-0.415 g_loss=-0.166 KID= 0.00740\n",
      "epoch 627, batch 11, d_loss=-0.379 g_loss=0.005 KID= 0.00740\n",
      "epoch 627, batch 12, d_loss=-0.333 g_loss=-0.008 KID= 0.00740\n",
      "epoch 627, batch 13, d_loss=-0.302 g_loss=-0.051 KID= 0.00740\n",
      "epoch 627, batch 14, d_loss=-0.443 g_loss=-0.104 KID= 0.00740\n",
      "epoch 627, batch 15, d_loss=-0.391 g_loss=-0.059 KID= 0.00740\n",
      "epoch 627, batch 16, d_loss=-0.353 g_loss=-0.124 KID= 0.00740\n",
      "epoch 627, batch 17, d_loss=-0.453 g_loss=-0.107 KID= 0.00740\n",
      "epoch 627, batch 18, d_loss=-0.475 g_loss=-0.022 KID= 0.00740\n",
      "epoch 627, batch 19, d_loss=-0.389 g_loss=-0.004 KID= 0.00740\n",
      "epoch 628, batch 0, d_loss=-0.366 g_loss=0.074 KID= 0.00740\n",
      "epoch 628, batch 1, d_loss=-0.383 g_loss=0.031 KID= 0.00740\n",
      "epoch 628, batch 2, d_loss=-0.398 g_loss=-0.118 KID= 0.00740\n",
      "epoch 628, batch 3, d_loss=-0.299 g_loss=-0.209 KID= 0.00740\n",
      "epoch 628, batch 4, d_loss=-0.383 g_loss=-0.343 KID= 0.00740\n",
      "epoch 628, batch 5, d_loss=-0.435 g_loss=-0.525 KID= 0.00740\n",
      "epoch 628, batch 6, d_loss=-0.333 g_loss=-0.636 KID= 0.00740\n",
      "epoch 628, batch 7, d_loss=-0.430 g_loss=-0.747 KID= 0.00740\n",
      "epoch 628, batch 8, d_loss=-0.499 g_loss=-0.881 KID= 0.00740\n",
      "epoch 628, batch 9, d_loss=-0.425 g_loss=-1.065 KID= 0.00740\n",
      "epoch 628, batch 10, d_loss=-0.377 g_loss=-1.050 KID= 0.00740\n",
      "epoch 628, batch 11, d_loss=-0.369 g_loss=-0.890 KID= 0.00740\n",
      "epoch 628, batch 12, d_loss=-0.322 g_loss=-0.867 KID= 0.00740\n",
      "epoch 628, batch 13, d_loss=-0.338 g_loss=-0.754 KID= 0.00740\n",
      "epoch 628, batch 14, d_loss=-0.388 g_loss=-0.581 KID= 0.00740\n",
      "epoch 628, batch 15, d_loss=-0.431 g_loss=-0.401 KID= 0.00740\n",
      "epoch 628, batch 16, d_loss=-0.362 g_loss=-0.284 KID= 0.00740\n",
      "epoch 628, batch 17, d_loss=-0.397 g_loss=-0.118 KID= 0.00740\n",
      "epoch 628, batch 18, d_loss=-0.476 g_loss=0.070 KID= 0.00740\n",
      "epoch 628, batch 19, d_loss=-0.420 g_loss=0.336 KID= 0.00740\n",
      "epoch 629, batch 0, d_loss=-0.365 g_loss=0.493 KID= 0.00740\n",
      "epoch 629, batch 1, d_loss=-0.393 g_loss=0.464 KID= 0.00740\n",
      "epoch 629, batch 2, d_loss=-0.361 g_loss=0.316 KID= 0.00740\n",
      "epoch 629, batch 3, d_loss=-0.283 g_loss=0.072 KID= 0.00740\n",
      "epoch 629, batch 4, d_loss=-0.423 g_loss=-0.121 KID= 0.00740\n",
      "epoch 629, batch 5, d_loss=-0.408 g_loss=-0.201 KID= 0.00740\n",
      "epoch 629, batch 6, d_loss=-0.268 g_loss=-0.324 KID= 0.00740\n",
      "epoch 629, batch 7, d_loss=-0.394 g_loss=-0.427 KID= 0.00740\n",
      "epoch 629, batch 8, d_loss=-0.514 g_loss=-0.409 KID= 0.00740\n",
      "epoch 629, batch 9, d_loss=-0.405 g_loss=-0.390 KID= 0.00740\n",
      "epoch 629, batch 10, d_loss=-0.385 g_loss=-0.342 KID= 0.00740\n",
      "epoch 629, batch 11, d_loss=-0.394 g_loss=-0.399 KID= 0.00740\n",
      "epoch 629, batch 12, d_loss=-0.342 g_loss=-0.506 KID= 0.00740\n",
      "epoch 629, batch 13, d_loss=-0.343 g_loss=-0.601 KID= 0.00740\n",
      "epoch 629, batch 14, d_loss=-0.413 g_loss=-0.761 KID= 0.00740\n",
      "epoch 629, batch 15, d_loss=-0.406 g_loss=-0.842 KID= 0.00740\n",
      "epoch 629, batch 16, d_loss=-0.274 g_loss=-0.875 KID= 0.00740\n",
      "epoch 629, batch 17, d_loss=-0.390 g_loss=-0.773 KID= 0.00740\n",
      "epoch 629, batch 18, d_loss=-0.452 g_loss=-0.608 KID= 0.00740\n",
      "epoch 629, batch 19, d_loss=-0.391 g_loss=-0.213 KID= 0.00740\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 630, batch 0, d_loss=-0.364 g_loss=0.034 KID= 0.00701\n",
      "epoch 630, batch 1, d_loss=-0.385 g_loss=0.169 KID= 0.00701\n",
      "epoch 630, batch 2, d_loss=-0.356 g_loss=0.144 KID= 0.00701\n",
      "epoch 630, batch 3, d_loss=-0.328 g_loss=0.133 KID= 0.00701\n",
      "epoch 630, batch 4, d_loss=-0.416 g_loss=0.163 KID= 0.00701\n",
      "epoch 630, batch 5, d_loss=-0.448 g_loss=0.139 KID= 0.00701\n",
      "epoch 630, batch 6, d_loss=-0.317 g_loss=-0.073 KID= 0.00701\n",
      "epoch 630, batch 7, d_loss=-0.381 g_loss=-0.248 KID= 0.00701\n",
      "epoch 630, batch 8, d_loss=-0.519 g_loss=-0.340 KID= 0.00701\n",
      "epoch 630, batch 9, d_loss=-0.394 g_loss=-0.273 KID= 0.00701\n",
      "epoch 630, batch 10, d_loss=-0.345 g_loss=-0.220 KID= 0.00701\n",
      "epoch 630, batch 11, d_loss=-0.395 g_loss=-0.123 KID= 0.00701\n",
      "epoch 630, batch 12, d_loss=-0.340 g_loss=-0.090 KID= 0.00701\n",
      "epoch 630, batch 13, d_loss=-0.306 g_loss=-0.115 KID= 0.00701\n",
      "epoch 630, batch 14, d_loss=-0.421 g_loss=-0.198 KID= 0.00701\n",
      "epoch 630, batch 15, d_loss=-0.458 g_loss=-0.289 KID= 0.00701\n",
      "epoch 630, batch 16, d_loss=-0.351 g_loss=-0.464 KID= 0.00701\n",
      "epoch 630, batch 17, d_loss=-0.457 g_loss=-0.633 KID= 0.00701\n",
      "epoch 630, batch 18, d_loss=-0.524 g_loss=-0.699 KID= 0.00701\n",
      "epoch 630, batch 19, d_loss=-0.409 g_loss=-0.423 KID= 0.00701\n",
      "epoch 631, batch 0, d_loss=-0.344 g_loss=-0.116 KID= 0.00701\n",
      "epoch 631, batch 1, d_loss=-0.342 g_loss=0.092 KID= 0.00701\n",
      "epoch 631, batch 2, d_loss=-0.385 g_loss=0.165 KID= 0.00701\n",
      "epoch 631, batch 3, d_loss=-0.304 g_loss=0.294 KID= 0.00701\n",
      "epoch 631, batch 4, d_loss=-0.406 g_loss=0.375 KID= 0.00701\n",
      "epoch 631, batch 5, d_loss=-0.441 g_loss=0.393 KID= 0.00701\n",
      "epoch 631, batch 6, d_loss=-0.387 g_loss=0.234 KID= 0.00701\n",
      "epoch 631, batch 7, d_loss=-0.393 g_loss=0.087 KID= 0.00701\n",
      "epoch 631, batch 8, d_loss=-0.483 g_loss=0.034 KID= 0.00701\n",
      "epoch 631, batch 9, d_loss=-0.352 g_loss=0.004 KID= 0.00701\n",
      "epoch 631, batch 10, d_loss=-0.390 g_loss=0.019 KID= 0.00701\n",
      "epoch 631, batch 11, d_loss=-0.383 g_loss=0.077 KID= 0.00701\n",
      "epoch 631, batch 12, d_loss=-0.330 g_loss=0.040 KID= 0.00701\n",
      "epoch 631, batch 13, d_loss=-0.383 g_loss=0.008 KID= 0.00701\n",
      "epoch 631, batch 14, d_loss=-0.425 g_loss=-0.099 KID= 0.00701\n",
      "epoch 631, batch 15, d_loss=-0.444 g_loss=-0.145 KID= 0.00701\n",
      "epoch 631, batch 16, d_loss=-0.324 g_loss=-0.286 KID= 0.00701\n",
      "epoch 631, batch 17, d_loss=-0.446 g_loss=-0.128 KID= 0.00701\n",
      "epoch 631, batch 18, d_loss=-0.479 g_loss=-0.001 KID= 0.00701\n",
      "epoch 631, batch 19, d_loss=-0.394 g_loss=0.117 KID= 0.00701\n",
      "epoch 632, batch 0, d_loss=-0.394 g_loss=0.320 KID= 0.00701\n",
      "epoch 632, batch 1, d_loss=-0.330 g_loss=0.536 KID= 0.00701\n",
      "epoch 632, batch 2, d_loss=-0.330 g_loss=0.636 KID= 0.00701\n",
      "epoch 632, batch 3, d_loss=-0.347 g_loss=0.932 KID= 0.00701\n",
      "epoch 632, batch 4, d_loss=-0.431 g_loss=1.112 KID= 0.00701\n",
      "epoch 632, batch 5, d_loss=-0.396 g_loss=0.932 KID= 0.00701\n",
      "epoch 632, batch 6, d_loss=-0.296 g_loss=0.418 KID= 0.00701\n",
      "epoch 632, batch 7, d_loss=-0.383 g_loss=-0.131 KID= 0.00701\n",
      "epoch 632, batch 8, d_loss=-0.528 g_loss=-0.582 KID= 0.00701\n",
      "epoch 632, batch 9, d_loss=-0.383 g_loss=-0.905 KID= 0.00701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 632, batch 10, d_loss=-0.410 g_loss=-1.130 KID= 0.00701\n",
      "epoch 632, batch 11, d_loss=-0.360 g_loss=-1.038 KID= 0.00701\n",
      "epoch 632, batch 12, d_loss=-0.396 g_loss=-0.983 KID= 0.00701\n",
      "epoch 632, batch 13, d_loss=-0.269 g_loss=-0.688 KID= 0.00701\n",
      "epoch 632, batch 14, d_loss=-0.400 g_loss=-0.527 KID= 0.00701\n",
      "epoch 632, batch 15, d_loss=-0.406 g_loss=-0.485 KID= 0.00701\n",
      "epoch 632, batch 16, d_loss=-0.301 g_loss=-0.418 KID= 0.00701\n",
      "epoch 632, batch 17, d_loss=-0.404 g_loss=-0.472 KID= 0.00701\n",
      "epoch 632, batch 18, d_loss=-0.526 g_loss=-0.471 KID= 0.00701\n",
      "epoch 632, batch 19, d_loss=-0.363 g_loss=-0.206 KID= 0.00701\n",
      "epoch 633, batch 0, d_loss=-0.364 g_loss=0.054 KID= 0.00701\n",
      "epoch 633, batch 1, d_loss=-0.379 g_loss=0.056 KID= 0.00701\n",
      "epoch 633, batch 2, d_loss=-0.336 g_loss=0.019 KID= 0.00701\n",
      "epoch 633, batch 3, d_loss=-0.380 g_loss=0.127 KID= 0.00701\n",
      "epoch 633, batch 4, d_loss=-0.384 g_loss=0.127 KID= 0.00701\n",
      "epoch 633, batch 5, d_loss=-0.443 g_loss=0.100 KID= 0.00701\n",
      "epoch 633, batch 6, d_loss=-0.338 g_loss=0.009 KID= 0.00701\n",
      "epoch 633, batch 7, d_loss=-0.446 g_loss=-0.091 KID= 0.00701\n",
      "epoch 633, batch 8, d_loss=-0.454 g_loss=-0.120 KID= 0.00701\n",
      "epoch 633, batch 9, d_loss=-0.288 g_loss=-0.165 KID= 0.00701\n",
      "epoch 633, batch 10, d_loss=-0.400 g_loss=-0.153 KID= 0.00701\n",
      "epoch 633, batch 11, d_loss=-0.346 g_loss=-0.110 KID= 0.00701\n",
      "epoch 633, batch 12, d_loss=-0.308 g_loss=-0.117 KID= 0.00701\n",
      "epoch 633, batch 13, d_loss=-0.374 g_loss=-0.033 KID= 0.00701\n",
      "epoch 633, batch 14, d_loss=-0.439 g_loss=-0.064 KID= 0.00701\n",
      "epoch 633, batch 15, d_loss=-0.425 g_loss=-0.106 KID= 0.00701\n",
      "epoch 633, batch 16, d_loss=-0.395 g_loss=-0.258 KID= 0.00701\n",
      "epoch 633, batch 17, d_loss=-0.440 g_loss=-0.347 KID= 0.00701\n",
      "epoch 633, batch 18, d_loss=-0.463 g_loss=-0.365 KID= 0.00701\n",
      "epoch 633, batch 19, d_loss=-0.345 g_loss=-0.300 KID= 0.00701\n",
      "epoch 634, batch 0, d_loss=-0.369 g_loss=-0.141 KID= 0.00701\n",
      "epoch 634, batch 1, d_loss=-0.365 g_loss=-0.013 KID= 0.00701\n",
      "epoch 634, batch 2, d_loss=-0.334 g_loss=0.016 KID= 0.00701\n",
      "epoch 634, batch 3, d_loss=-0.313 g_loss=0.172 KID= 0.00701\n",
      "epoch 634, batch 4, d_loss=-0.447 g_loss=0.229 KID= 0.00701\n",
      "epoch 634, batch 5, d_loss=-0.393 g_loss=0.133 KID= 0.00701\n",
      "epoch 634, batch 6, d_loss=-0.345 g_loss=-0.145 KID= 0.00701\n",
      "epoch 634, batch 7, d_loss=-0.381 g_loss=-0.325 KID= 0.00701\n",
      "epoch 634, batch 8, d_loss=-0.511 g_loss=-0.526 KID= 0.00701\n",
      "epoch 634, batch 9, d_loss=-0.384 g_loss=-0.496 KID= 0.00701\n",
      "epoch 634, batch 10, d_loss=-0.398 g_loss=-0.356 KID= 0.00701\n",
      "epoch 634, batch 11, d_loss=-0.349 g_loss=-0.249 KID= 0.00701\n",
      "epoch 634, batch 12, d_loss=-0.306 g_loss=-0.241 KID= 0.00701\n",
      "epoch 634, batch 13, d_loss=-0.352 g_loss=-0.109 KID= 0.00701\n",
      "epoch 634, batch 14, d_loss=-0.404 g_loss=-0.054 KID= 0.00701\n",
      "epoch 634, batch 15, d_loss=-0.437 g_loss=-0.003 KID= 0.00701\n",
      "epoch 634, batch 16, d_loss=-0.360 g_loss=-0.210 KID= 0.00701\n",
      "epoch 634, batch 17, d_loss=-0.377 g_loss=-0.404 KID= 0.00701\n",
      "epoch 634, batch 18, d_loss=-0.507 g_loss=-0.551 KID= 0.00701\n",
      "epoch 634, batch 19, d_loss=-0.356 g_loss=-0.580 KID= 0.00701\n",
      "epoch 635, batch 0, d_loss=-0.364 g_loss=-0.564 KID= 0.00701\n",
      "epoch 635, batch 1, d_loss=-0.385 g_loss=-0.457 KID= 0.00701\n",
      "epoch 635, batch 2, d_loss=-0.312 g_loss=-0.333 KID= 0.00701\n",
      "epoch 635, batch 3, d_loss=-0.337 g_loss=-0.136 KID= 0.00701\n",
      "epoch 635, batch 4, d_loss=-0.401 g_loss=0.046 KID= 0.00701\n",
      "epoch 635, batch 5, d_loss=-0.442 g_loss=0.122 KID= 0.00701\n",
      "epoch 635, batch 6, d_loss=-0.307 g_loss=0.102 KID= 0.00701\n",
      "epoch 635, batch 7, d_loss=-0.412 g_loss=0.104 KID= 0.00701\n",
      "epoch 635, batch 8, d_loss=-0.497 g_loss=0.061 KID= 0.00701\n",
      "epoch 635, batch 9, d_loss=-0.375 g_loss=-0.098 KID= 0.00701\n",
      "epoch 635, batch 10, d_loss=-0.388 g_loss=-0.059 KID= 0.00701\n",
      "epoch 635, batch 11, d_loss=-0.404 g_loss=-0.041 KID= 0.00701\n",
      "epoch 635, batch 12, d_loss=-0.295 g_loss=-0.110 KID= 0.00701\n",
      "epoch 635, batch 13, d_loss=-0.369 g_loss=-0.071 KID= 0.00701\n",
      "epoch 635, batch 14, d_loss=-0.388 g_loss=-0.028 KID= 0.00701\n",
      "epoch 635, batch 15, d_loss=-0.410 g_loss=-0.133 KID= 0.00701\n",
      "epoch 635, batch 16, d_loss=-0.376 g_loss=-0.348 KID= 0.00701\n",
      "epoch 635, batch 17, d_loss=-0.434 g_loss=-0.489 KID= 0.00701\n",
      "epoch 635, batch 18, d_loss=-0.468 g_loss=-0.626 KID= 0.00701\n",
      "epoch 635, batch 19, d_loss=-0.303 g_loss=-0.702 KID= 0.00701\n",
      "epoch 636, batch 0, d_loss=-0.416 g_loss=-0.690 KID= 0.00701\n",
      "epoch 636, batch 1, d_loss=-0.386 g_loss=-0.664 KID= 0.00701\n",
      "epoch 636, batch 2, d_loss=-0.302 g_loss=-0.573 KID= 0.00701\n",
      "epoch 636, batch 3, d_loss=-0.327 g_loss=-0.329 KID= 0.00701\n",
      "epoch 636, batch 4, d_loss=-0.391 g_loss=0.050 KID= 0.00701\n",
      "epoch 636, batch 5, d_loss=-0.418 g_loss=0.387 KID= 0.00701\n",
      "epoch 636, batch 6, d_loss=-0.381 g_loss=0.553 KID= 0.00701\n",
      "epoch 636, batch 7, d_loss=-0.413 g_loss=0.549 KID= 0.00701\n",
      "epoch 636, batch 8, d_loss=-0.523 g_loss=0.419 KID= 0.00701\n",
      "epoch 636, batch 9, d_loss=-0.316 g_loss=0.264 KID= 0.00701\n",
      "epoch 636, batch 10, d_loss=-0.374 g_loss=0.190 KID= 0.00701\n",
      "epoch 636, batch 11, d_loss=-0.426 g_loss=-0.087 KID= 0.00701\n",
      "epoch 636, batch 12, d_loss=-0.342 g_loss=-0.198 KID= 0.00701\n",
      "epoch 636, batch 13, d_loss=-0.245 g_loss=-0.168 KID= 0.00701\n",
      "epoch 636, batch 14, d_loss=-0.399 g_loss=-0.177 KID= 0.00701\n",
      "epoch 636, batch 15, d_loss=-0.397 g_loss=-0.088 KID= 0.00701\n",
      "epoch 636, batch 16, d_loss=-0.364 g_loss=-0.087 KID= 0.00701\n",
      "epoch 636, batch 17, d_loss=-0.458 g_loss=-0.199 KID= 0.00701\n",
      "epoch 636, batch 18, d_loss=-0.505 g_loss=-0.260 KID= 0.00701\n",
      "epoch 636, batch 19, d_loss=-0.398 g_loss=-0.282 KID= 0.00701\n",
      "epoch 637, batch 0, d_loss=-0.391 g_loss=-0.203 KID= 0.00701\n",
      "epoch 637, batch 1, d_loss=-0.404 g_loss=-0.214 KID= 0.00701\n",
      "epoch 637, batch 2, d_loss=-0.318 g_loss=-0.166 KID= 0.00701\n",
      "epoch 637, batch 3, d_loss=-0.360 g_loss=-0.033 KID= 0.00701\n",
      "epoch 637, batch 4, d_loss=-0.438 g_loss=0.109 KID= 0.00701\n",
      "epoch 637, batch 5, d_loss=-0.400 g_loss=0.166 KID= 0.00701\n",
      "epoch 637, batch 6, d_loss=-0.385 g_loss=0.167 KID= 0.00701\n",
      "epoch 637, batch 7, d_loss=-0.416 g_loss=0.071 KID= 0.00701\n",
      "epoch 637, batch 8, d_loss=-0.485 g_loss=-0.035 KID= 0.00701\n",
      "epoch 637, batch 9, d_loss=-0.363 g_loss=-0.085 KID= 0.00701\n",
      "epoch 637, batch 10, d_loss=-0.409 g_loss=-0.130 KID= 0.00701\n",
      "epoch 637, batch 11, d_loss=-0.393 g_loss=-0.215 KID= 0.00701\n",
      "epoch 637, batch 12, d_loss=-0.324 g_loss=-0.403 KID= 0.00701\n",
      "epoch 637, batch 13, d_loss=-0.372 g_loss=-0.363 KID= 0.00701\n",
      "epoch 637, batch 14, d_loss=-0.377 g_loss=-0.359 KID= 0.00701\n",
      "epoch 637, batch 15, d_loss=-0.408 g_loss=-0.448 KID= 0.00701\n",
      "epoch 637, batch 16, d_loss=-0.352 g_loss=-0.554 KID= 0.00701\n",
      "epoch 637, batch 17, d_loss=-0.430 g_loss=-0.689 KID= 0.00701\n",
      "epoch 637, batch 18, d_loss=-0.500 g_loss=-0.804 KID= 0.00701\n",
      "epoch 637, batch 19, d_loss=-0.356 g_loss=-0.843 KID= 0.00701\n",
      "epoch 638, batch 0, d_loss=-0.424 g_loss=-0.805 KID= 0.00701\n",
      "epoch 638, batch 1, d_loss=-0.405 g_loss=-0.721 KID= 0.00701\n",
      "epoch 638, batch 2, d_loss=-0.350 g_loss=-0.538 KID= 0.00701\n",
      "epoch 638, batch 3, d_loss=-0.335 g_loss=-0.207 KID= 0.00701\n",
      "epoch 638, batch 4, d_loss=-0.416 g_loss=0.073 KID= 0.00701\n",
      "epoch 638, batch 5, d_loss=-0.412 g_loss=0.404 KID= 0.00701\n",
      "epoch 638, batch 6, d_loss=-0.364 g_loss=0.644 KID= 0.00701\n",
      "epoch 638, batch 7, d_loss=-0.426 g_loss=0.770 KID= 0.00701\n",
      "epoch 638, batch 8, d_loss=-0.493 g_loss=0.767 KID= 0.00701\n",
      "epoch 638, batch 9, d_loss=-0.392 g_loss=0.592 KID= 0.00701\n",
      "epoch 638, batch 10, d_loss=-0.389 g_loss=0.475 KID= 0.00701\n",
      "epoch 638, batch 11, d_loss=-0.337 g_loss=0.151 KID= 0.00701\n",
      "epoch 638, batch 12, d_loss=-0.378 g_loss=-0.105 KID= 0.00701\n",
      "epoch 638, batch 13, d_loss=-0.354 g_loss=-0.159 KID= 0.00701\n",
      "epoch 638, batch 14, d_loss=-0.414 g_loss=-0.241 KID= 0.00701\n",
      "epoch 638, batch 15, d_loss=-0.436 g_loss=-0.301 KID= 0.00701\n",
      "epoch 638, batch 16, d_loss=-0.405 g_loss=-0.392 KID= 0.00701\n",
      "epoch 638, batch 17, d_loss=-0.500 g_loss=-0.507 KID= 0.00701\n",
      "epoch 638, batch 18, d_loss=-0.541 g_loss=-0.674 KID= 0.00701\n",
      "epoch 638, batch 19, d_loss=-0.302 g_loss=-0.657 KID= 0.00701\n",
      "epoch 639, batch 0, d_loss=-0.394 g_loss=-0.577 KID= 0.00701\n",
      "epoch 639, batch 1, d_loss=-0.428 g_loss=-0.541 KID= 0.00701\n",
      "epoch 639, batch 2, d_loss=-0.369 g_loss=-0.549 KID= 0.00701\n",
      "epoch 639, batch 3, d_loss=-0.402 g_loss=-0.484 KID= 0.00701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 639, batch 4, d_loss=-0.347 g_loss=-0.442 KID= 0.00701\n",
      "epoch 639, batch 5, d_loss=-0.459 g_loss=-0.381 KID= 0.00701\n",
      "epoch 639, batch 6, d_loss=-0.324 g_loss=-0.272 KID= 0.00701\n",
      "epoch 639, batch 7, d_loss=-0.447 g_loss=-0.189 KID= 0.00701\n",
      "epoch 639, batch 8, d_loss=-0.526 g_loss=-0.075 KID= 0.00701\n",
      "epoch 639, batch 9, d_loss=-0.332 g_loss=-0.085 KID= 0.00701\n",
      "epoch 639, batch 10, d_loss=-0.379 g_loss=-0.073 KID= 0.00701\n",
      "epoch 639, batch 11, d_loss=-0.389 g_loss=-0.091 KID= 0.00701\n",
      "epoch 639, batch 12, d_loss=-0.323 g_loss=-0.104 KID= 0.00701\n",
      "epoch 639, batch 13, d_loss=-0.306 g_loss=-0.017 KID= 0.00701\n",
      "epoch 639, batch 14, d_loss=-0.400 g_loss=0.023 KID= 0.00701\n",
      "epoch 639, batch 15, d_loss=-0.449 g_loss=0.005 KID= 0.00701\n",
      "epoch 639, batch 16, d_loss=-0.331 g_loss=-0.021 KID= 0.00701\n",
      "epoch 639, batch 17, d_loss=-0.465 g_loss=-0.164 KID= 0.00701\n",
      "epoch 639, batch 18, d_loss=-0.519 g_loss=-0.317 KID= 0.00701\n",
      "epoch 639, batch 19, d_loss=-0.380 g_loss=-0.465 KID= 0.00701\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 640, batch 0, d_loss=-0.408 g_loss=-0.600 KID= 0.00964\n",
      "epoch 640, batch 1, d_loss=-0.379 g_loss=-0.765 KID= 0.00964\n",
      "epoch 640, batch 2, d_loss=-0.359 g_loss=-0.863 KID= 0.00964\n",
      "epoch 640, batch 3, d_loss=-0.365 g_loss=-0.712 KID= 0.00964\n",
      "epoch 640, batch 4, d_loss=-0.375 g_loss=-0.519 KID= 0.00964\n",
      "epoch 640, batch 5, d_loss=-0.477 g_loss=-0.474 KID= 0.00964\n",
      "epoch 640, batch 6, d_loss=-0.350 g_loss=-0.296 KID= 0.00964\n",
      "epoch 640, batch 7, d_loss=-0.476 g_loss=-0.188 KID= 0.00964\n",
      "epoch 640, batch 8, d_loss=-0.486 g_loss=-0.140 KID= 0.00964\n",
      "epoch 640, batch 9, d_loss=-0.303 g_loss=-0.127 KID= 0.00964\n",
      "epoch 640, batch 10, d_loss=-0.407 g_loss=-0.073 KID= 0.00964\n",
      "epoch 640, batch 11, d_loss=-0.405 g_loss=-0.070 KID= 0.00964\n",
      "epoch 640, batch 12, d_loss=-0.334 g_loss=-0.160 KID= 0.00964\n",
      "epoch 640, batch 13, d_loss=-0.357 g_loss=-0.163 KID= 0.00964\n",
      "epoch 640, batch 14, d_loss=-0.384 g_loss=-0.158 KID= 0.00964\n",
      "epoch 640, batch 15, d_loss=-0.426 g_loss=-0.057 KID= 0.00964\n",
      "epoch 640, batch 16, d_loss=-0.345 g_loss=0.086 KID= 0.00964\n",
      "epoch 640, batch 17, d_loss=-0.475 g_loss=0.205 KID= 0.00964\n",
      "epoch 640, batch 18, d_loss=-0.528 g_loss=0.158 KID= 0.00964\n",
      "epoch 640, batch 19, d_loss=-0.398 g_loss=0.076 KID= 0.00964\n",
      "epoch 641, batch 0, d_loss=-0.386 g_loss=0.029 KID= 0.00964\n",
      "epoch 641, batch 1, d_loss=-0.344 g_loss=-0.229 KID= 0.00964\n",
      "epoch 641, batch 2, d_loss=-0.353 g_loss=-0.473 KID= 0.00964\n",
      "epoch 641, batch 3, d_loss=-0.355 g_loss=-0.544 KID= 0.00964\n",
      "epoch 641, batch 4, d_loss=-0.414 g_loss=-0.502 KID= 0.00964\n",
      "epoch 641, batch 5, d_loss=-0.454 g_loss=-0.531 KID= 0.00964\n",
      "epoch 641, batch 6, d_loss=-0.320 g_loss=-0.485 KID= 0.00964\n",
      "epoch 641, batch 7, d_loss=-0.547 g_loss=-0.479 KID= 0.00964\n",
      "epoch 641, batch 8, d_loss=-0.398 g_loss=-0.516 KID= 0.00964\n",
      "epoch 641, batch 9, d_loss=-0.375 g_loss=-0.580 KID= 0.00964\n",
      "epoch 641, batch 10, d_loss=-0.418 g_loss=-0.571 KID= 0.00964\n",
      "epoch 641, batch 11, d_loss=-0.335 g_loss=-0.544 KID= 0.00964\n",
      "epoch 641, batch 12, d_loss=-0.312 g_loss=-0.530 KID= 0.00964\n",
      "epoch 641, batch 13, d_loss=-0.363 g_loss=-0.345 KID= 0.00964\n",
      "epoch 641, batch 14, d_loss=-0.425 g_loss=-0.076 KID= 0.00964\n",
      "epoch 641, batch 15, d_loss=-0.417 g_loss=0.052 KID= 0.00964\n",
      "epoch 641, batch 16, d_loss=-0.392 g_loss=0.216 KID= 0.00964\n",
      "epoch 641, batch 17, d_loss=-0.469 g_loss=0.161 KID= 0.00964\n",
      "epoch 641, batch 18, d_loss=-0.492 g_loss=-0.118 KID= 0.00964\n",
      "epoch 641, batch 19, d_loss=-0.378 g_loss=-0.246 KID= 0.00964\n",
      "epoch 642, batch 0, d_loss=-0.397 g_loss=-0.336 KID= 0.00964\n",
      "epoch 642, batch 1, d_loss=-0.386 g_loss=-0.477 KID= 0.00964\n",
      "epoch 642, batch 2, d_loss=-0.334 g_loss=-0.556 KID= 0.00964\n",
      "epoch 642, batch 3, d_loss=-0.372 g_loss=-0.571 KID= 0.00964\n",
      "epoch 642, batch 4, d_loss=-0.389 g_loss=-0.500 KID= 0.00964\n",
      "epoch 642, batch 5, d_loss=-0.499 g_loss=-0.333 KID= 0.00964\n",
      "epoch 642, batch 6, d_loss=-0.322 g_loss=-0.168 KID= 0.00964\n",
      "epoch 642, batch 7, d_loss=-0.491 g_loss=-0.118 KID= 0.00964\n",
      "epoch 642, batch 8, d_loss=-0.513 g_loss=-0.194 KID= 0.00964\n",
      "epoch 642, batch 9, d_loss=-0.353 g_loss=-0.124 KID= 0.00964\n",
      "epoch 642, batch 10, d_loss=-0.358 g_loss=-0.015 KID= 0.00964\n",
      "epoch 642, batch 11, d_loss=-0.386 g_loss=-0.197 KID= 0.00964\n",
      "epoch 642, batch 12, d_loss=-0.299 g_loss=-0.319 KID= 0.00964\n",
      "epoch 642, batch 13, d_loss=-0.391 g_loss=-0.257 KID= 0.00964\n",
      "epoch 642, batch 14, d_loss=-0.418 g_loss=-0.260 KID= 0.00964\n",
      "epoch 642, batch 15, d_loss=-0.418 g_loss=-0.232 KID= 0.00964\n",
      "epoch 642, batch 16, d_loss=-0.392 g_loss=-0.265 KID= 0.00964\n",
      "epoch 642, batch 17, d_loss=-0.474 g_loss=-0.197 KID= 0.00964\n",
      "epoch 642, batch 18, d_loss=-0.443 g_loss=-0.307 KID= 0.00964\n",
      "epoch 642, batch 19, d_loss=-0.402 g_loss=-0.211 KID= 0.00964\n",
      "epoch 643, batch 0, d_loss=-0.365 g_loss=-0.118 KID= 0.00964\n",
      "epoch 643, batch 1, d_loss=-0.399 g_loss=-0.199 KID= 0.00964\n",
      "epoch 643, batch 2, d_loss=-0.286 g_loss=-0.274 KID= 0.00964\n",
      "epoch 643, batch 3, d_loss=-0.413 g_loss=-0.394 KID= 0.00964\n",
      "epoch 643, batch 4, d_loss=-0.389 g_loss=-0.411 KID= 0.00964\n",
      "epoch 643, batch 5, d_loss=-0.449 g_loss=-0.413 KID= 0.00964\n",
      "epoch 643, batch 6, d_loss=-0.377 g_loss=-0.447 KID= 0.00964\n",
      "epoch 643, batch 7, d_loss=-0.508 g_loss=-0.484 KID= 0.00964\n",
      "epoch 643, batch 8, d_loss=-0.488 g_loss=-0.697 KID= 0.00964\n",
      "epoch 643, batch 9, d_loss=-0.387 g_loss=-0.609 KID= 0.00964\n",
      "epoch 643, batch 10, d_loss=-0.378 g_loss=-0.480 KID= 0.00964\n",
      "epoch 643, batch 11, d_loss=-0.352 g_loss=-0.367 KID= 0.00964\n",
      "epoch 643, batch 12, d_loss=-0.318 g_loss=-0.353 KID= 0.00964\n",
      "epoch 643, batch 13, d_loss=-0.349 g_loss=-0.300 KID= 0.00964\n",
      "epoch 643, batch 14, d_loss=-0.434 g_loss=-0.233 KID= 0.00964\n",
      "epoch 643, batch 15, d_loss=-0.425 g_loss=-0.123 KID= 0.00964\n",
      "epoch 643, batch 16, d_loss=-0.375 g_loss=0.014 KID= 0.00964\n",
      "epoch 643, batch 17, d_loss=-0.548 g_loss=0.107 KID= 0.00964\n",
      "epoch 643, batch 18, d_loss=-0.507 g_loss=-0.016 KID= 0.00964\n",
      "epoch 643, batch 19, d_loss=-0.462 g_loss=-0.078 KID= 0.00964\n",
      "epoch 644, batch 0, d_loss=-0.426 g_loss=-0.067 KID= 0.00964\n",
      "epoch 644, batch 1, d_loss=-0.405 g_loss=-0.175 KID= 0.00964\n",
      "epoch 644, batch 2, d_loss=-0.290 g_loss=-0.244 KID= 0.00964\n",
      "epoch 644, batch 3, d_loss=-0.412 g_loss=-0.291 KID= 0.00964\n",
      "epoch 644, batch 4, d_loss=-0.427 g_loss=-0.288 KID= 0.00964\n",
      "epoch 644, batch 5, d_loss=-0.460 g_loss=-0.197 KID= 0.00964\n",
      "epoch 644, batch 6, d_loss=-0.353 g_loss=-0.084 KID= 0.00964\n",
      "epoch 644, batch 7, d_loss=-0.525 g_loss=-0.020 KID= 0.00964\n",
      "epoch 644, batch 8, d_loss=-0.452 g_loss=-0.135 KID= 0.00964\n",
      "epoch 644, batch 9, d_loss=-0.468 g_loss=-0.017 KID= 0.00964\n",
      "epoch 644, batch 10, d_loss=-0.353 g_loss=0.127 KID= 0.00964\n",
      "epoch 644, batch 11, d_loss=-0.417 g_loss=0.154 KID= 0.00964\n",
      "epoch 644, batch 12, d_loss=-0.327 g_loss=0.117 KID= 0.00964\n",
      "epoch 644, batch 13, d_loss=-0.387 g_loss=0.219 KID= 0.00964\n",
      "epoch 644, batch 14, d_loss=-0.378 g_loss=0.230 KID= 0.00964\n",
      "epoch 644, batch 15, d_loss=-0.421 g_loss=0.189 KID= 0.00964\n",
      "epoch 644, batch 16, d_loss=-0.365 g_loss=0.002 KID= 0.00964\n",
      "epoch 644, batch 17, d_loss=-0.540 g_loss=-0.063 KID= 0.00964\n",
      "epoch 644, batch 18, d_loss=-0.524 g_loss=-0.206 KID= 0.00964\n",
      "epoch 644, batch 19, d_loss=-0.404 g_loss=-0.293 KID= 0.00964\n",
      "epoch 645, batch 0, d_loss=-0.336 g_loss=-0.520 KID= 0.00964\n",
      "epoch 645, batch 1, d_loss=-0.415 g_loss=-0.609 KID= 0.00964\n",
      "epoch 645, batch 2, d_loss=-0.306 g_loss=-0.585 KID= 0.00964\n",
      "epoch 645, batch 3, d_loss=-0.350 g_loss=-0.584 KID= 0.00964\n",
      "epoch 645, batch 4, d_loss=-0.413 g_loss=-0.604 KID= 0.00964\n",
      "epoch 645, batch 5, d_loss=-0.450 g_loss=-0.593 KID= 0.00964\n",
      "epoch 645, batch 6, d_loss=-0.412 g_loss=-0.529 KID= 0.00964\n",
      "epoch 645, batch 7, d_loss=-0.539 g_loss=-0.506 KID= 0.00964\n",
      "epoch 645, batch 8, d_loss=-0.521 g_loss=-0.657 KID= 0.00964\n",
      "epoch 645, batch 9, d_loss=-0.407 g_loss=-0.596 KID= 0.00964\n",
      "epoch 645, batch 10, d_loss=-0.327 g_loss=-0.516 KID= 0.00964\n",
      "epoch 645, batch 11, d_loss=-0.378 g_loss=-0.400 KID= 0.00964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 645, batch 12, d_loss=-0.309 g_loss=-0.298 KID= 0.00964\n",
      "epoch 645, batch 13, d_loss=-0.412 g_loss=-0.172 KID= 0.00964\n",
      "epoch 645, batch 14, d_loss=-0.459 g_loss=0.070 KID= 0.00964\n",
      "epoch 645, batch 15, d_loss=-0.441 g_loss=0.228 KID= 0.00964\n",
      "epoch 645, batch 16, d_loss=-0.400 g_loss=0.255 KID= 0.00964\n",
      "epoch 645, batch 17, d_loss=-0.524 g_loss=0.402 KID= 0.00964\n",
      "epoch 645, batch 18, d_loss=-0.481 g_loss=0.431 KID= 0.00964\n",
      "epoch 645, batch 19, d_loss=-0.353 g_loss=0.432 KID= 0.00964\n",
      "epoch 646, batch 0, d_loss=-0.368 g_loss=0.288 KID= 0.00964\n",
      "epoch 646, batch 1, d_loss=-0.419 g_loss=-0.012 KID= 0.00964\n",
      "epoch 646, batch 2, d_loss=-0.305 g_loss=-0.318 KID= 0.00964\n",
      "epoch 646, batch 3, d_loss=-0.404 g_loss=-0.515 KID= 0.00964\n",
      "epoch 646, batch 4, d_loss=-0.423 g_loss=-0.592 KID= 0.00964\n",
      "epoch 646, batch 5, d_loss=-0.412 g_loss=-0.730 KID= 0.00964\n",
      "epoch 646, batch 6, d_loss=-0.403 g_loss=-0.719 KID= 0.00964\n",
      "epoch 646, batch 7, d_loss=-0.498 g_loss=-0.617 KID= 0.00964\n",
      "epoch 646, batch 8, d_loss=-0.489 g_loss=-0.754 KID= 0.00964\n",
      "epoch 646, batch 9, d_loss=-0.463 g_loss=-0.619 KID= 0.00964\n",
      "epoch 646, batch 10, d_loss=-0.371 g_loss=-0.601 KID= 0.00964\n",
      "epoch 646, batch 11, d_loss=-0.380 g_loss=-0.630 KID= 0.00964\n",
      "epoch 646, batch 12, d_loss=-0.297 g_loss=-0.532 KID= 0.00964\n",
      "epoch 646, batch 13, d_loss=-0.391 g_loss=-0.491 KID= 0.00964\n",
      "epoch 646, batch 14, d_loss=-0.396 g_loss=-0.368 KID= 0.00964\n",
      "epoch 646, batch 15, d_loss=-0.443 g_loss=-0.220 KID= 0.00964\n",
      "epoch 646, batch 16, d_loss=-0.413 g_loss=0.030 KID= 0.00964\n",
      "epoch 646, batch 17, d_loss=-0.510 g_loss=0.263 KID= 0.00964\n",
      "epoch 646, batch 18, d_loss=-0.484 g_loss=0.368 KID= 0.00964\n",
      "epoch 646, batch 19, d_loss=-0.333 g_loss=0.479 KID= 0.00964\n",
      "epoch 647, batch 0, d_loss=-0.378 g_loss=0.461 KID= 0.00964\n",
      "epoch 647, batch 1, d_loss=-0.335 g_loss=0.103 KID= 0.00964\n",
      "epoch 647, batch 2, d_loss=-0.313 g_loss=-0.281 KID= 0.00964\n",
      "epoch 647, batch 3, d_loss=-0.409 g_loss=-0.638 KID= 0.00964\n",
      "epoch 647, batch 4, d_loss=-0.415 g_loss=-0.756 KID= 0.00964\n",
      "epoch 647, batch 5, d_loss=-0.458 g_loss=-0.778 KID= 0.00964\n",
      "epoch 647, batch 6, d_loss=-0.428 g_loss=-0.715 KID= 0.00964\n",
      "epoch 647, batch 7, d_loss=-0.500 g_loss=-0.631 KID= 0.00964\n",
      "epoch 647, batch 8, d_loss=-0.486 g_loss=-0.729 KID= 0.00964\n",
      "epoch 647, batch 9, d_loss=-0.399 g_loss=-0.605 KID= 0.00964\n",
      "epoch 647, batch 10, d_loss=-0.367 g_loss=-0.579 KID= 0.00964\n",
      "epoch 647, batch 11, d_loss=-0.393 g_loss=-0.625 KID= 0.00964\n",
      "epoch 647, batch 12, d_loss=-0.293 g_loss=-0.590 KID= 0.00964\n",
      "epoch 647, batch 13, d_loss=-0.429 g_loss=-0.492 KID= 0.00964\n",
      "epoch 647, batch 14, d_loss=-0.406 g_loss=-0.307 KID= 0.00964\n",
      "epoch 647, batch 15, d_loss=-0.456 g_loss=-0.225 KID= 0.00964\n",
      "epoch 647, batch 16, d_loss=-0.406 g_loss=-0.087 KID= 0.00964\n",
      "epoch 647, batch 17, d_loss=-0.497 g_loss=-0.071 KID= 0.00964\n",
      "epoch 647, batch 18, d_loss=-0.508 g_loss=-0.087 KID= 0.00964\n",
      "epoch 647, batch 19, d_loss=-0.379 g_loss=0.094 KID= 0.00964\n",
      "epoch 648, batch 0, d_loss=-0.392 g_loss=0.093 KID= 0.00964\n",
      "epoch 648, batch 1, d_loss=-0.408 g_loss=-0.048 KID= 0.00964\n",
      "epoch 648, batch 2, d_loss=-0.275 g_loss=-0.198 KID= 0.00964\n",
      "epoch 648, batch 3, d_loss=-0.394 g_loss=-0.331 KID= 0.00964\n",
      "epoch 648, batch 4, d_loss=-0.434 g_loss=-0.335 KID= 0.00964\n",
      "epoch 648, batch 5, d_loss=-0.449 g_loss=-0.419 KID= 0.00964\n",
      "epoch 648, batch 6, d_loss=-0.402 g_loss=-0.479 KID= 0.00964\n",
      "epoch 648, batch 7, d_loss=-0.504 g_loss=-0.491 KID= 0.00964\n",
      "epoch 648, batch 8, d_loss=-0.512 g_loss=-0.584 KID= 0.00964\n",
      "epoch 648, batch 9, d_loss=-0.374 g_loss=-0.456 KID= 0.00964\n",
      "epoch 648, batch 10, d_loss=-0.407 g_loss=-0.274 KID= 0.00964\n",
      "epoch 648, batch 11, d_loss=-0.425 g_loss=-0.236 KID= 0.00964\n",
      "epoch 648, batch 12, d_loss=-0.306 g_loss=-0.145 KID= 0.00964\n",
      "epoch 648, batch 13, d_loss=-0.396 g_loss=-0.119 KID= 0.00964\n",
      "epoch 648, batch 14, d_loss=-0.428 g_loss=-0.060 KID= 0.00964\n",
      "epoch 648, batch 15, d_loss=-0.398 g_loss=-0.038 KID= 0.00964\n",
      "epoch 648, batch 16, d_loss=-0.453 g_loss=-0.073 KID= 0.00964\n",
      "epoch 648, batch 17, d_loss=-0.493 g_loss=-0.156 KID= 0.00964\n",
      "epoch 648, batch 18, d_loss=-0.459 g_loss=-0.326 KID= 0.00964\n",
      "epoch 648, batch 19, d_loss=-0.402 g_loss=-0.304 KID= 0.00964\n",
      "epoch 649, batch 0, d_loss=-0.431 g_loss=-0.395 KID= 0.00964\n",
      "epoch 649, batch 1, d_loss=-0.384 g_loss=-0.455 KID= 0.00964\n",
      "epoch 649, batch 2, d_loss=-0.329 g_loss=-0.407 KID= 0.00964\n",
      "epoch 649, batch 3, d_loss=-0.384 g_loss=-0.422 KID= 0.00964\n",
      "epoch 649, batch 4, d_loss=-0.399 g_loss=-0.377 KID= 0.00964\n",
      "epoch 649, batch 5, d_loss=-0.410 g_loss=-0.378 KID= 0.00964\n",
      "epoch 649, batch 6, d_loss=-0.436 g_loss=-0.295 KID= 0.00964\n",
      "epoch 649, batch 7, d_loss=-0.488 g_loss=-0.207 KID= 0.00964\n",
      "epoch 649, batch 8, d_loss=-0.491 g_loss=-0.227 KID= 0.00964\n",
      "epoch 649, batch 9, d_loss=-0.346 g_loss=-0.144 KID= 0.00964\n",
      "epoch 649, batch 10, d_loss=-0.439 g_loss=-0.129 KID= 0.00964\n",
      "epoch 649, batch 11, d_loss=-0.370 g_loss=-0.311 KID= 0.00964\n",
      "epoch 649, batch 12, d_loss=-0.307 g_loss=-0.381 KID= 0.00964\n",
      "epoch 649, batch 13, d_loss=-0.427 g_loss=-0.421 KID= 0.00964\n",
      "epoch 649, batch 14, d_loss=-0.400 g_loss=-0.376 KID= 0.00964\n",
      "epoch 649, batch 15, d_loss=-0.449 g_loss=-0.312 KID= 0.00964\n",
      "epoch 649, batch 16, d_loss=-0.465 g_loss=-0.286 KID= 0.00964\n",
      "epoch 649, batch 17, d_loss=-0.489 g_loss=-0.164 KID= 0.00964\n",
      "epoch 649, batch 18, d_loss=-0.456 g_loss=-0.141 KID= 0.00964\n",
      "epoch 649, batch 19, d_loss=-0.347 g_loss=-0.055 KID= 0.00964\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 650, batch 0, d_loss=-0.382 g_loss=-0.123 KID= 0.00579\n",
      "epoch 650, batch 1, d_loss=-0.406 g_loss=-0.088 KID= 0.00579\n",
      "epoch 650, batch 2, d_loss=-0.277 g_loss=-0.081 KID= 0.00579\n",
      "epoch 650, batch 3, d_loss=-0.452 g_loss=-0.214 KID= 0.00579\n",
      "epoch 650, batch 4, d_loss=-0.392 g_loss=-0.234 KID= 0.00579\n",
      "epoch 650, batch 5, d_loss=-0.406 g_loss=-0.279 KID= 0.00579\n",
      "epoch 650, batch 6, d_loss=-0.452 g_loss=-0.299 KID= 0.00579\n",
      "epoch 650, batch 7, d_loss=-0.465 g_loss=-0.224 KID= 0.00579\n",
      "epoch 650, batch 8, d_loss=-0.482 g_loss=-0.313 KID= 0.00579\n",
      "epoch 650, batch 9, d_loss=-0.405 g_loss=-0.340 KID= 0.00579\n",
      "epoch 650, batch 10, d_loss=-0.416 g_loss=-0.438 KID= 0.00579\n",
      "epoch 650, batch 11, d_loss=-0.420 g_loss=-0.491 KID= 0.00579\n",
      "epoch 650, batch 12, d_loss=-0.354 g_loss=-0.399 KID= 0.00579\n",
      "epoch 650, batch 13, d_loss=-0.473 g_loss=-0.407 KID= 0.00579\n",
      "epoch 650, batch 14, d_loss=-0.413 g_loss=-0.339 KID= 0.00579\n",
      "epoch 650, batch 15, d_loss=-0.415 g_loss=-0.374 KID= 0.00579\n",
      "epoch 650, batch 16, d_loss=-0.459 g_loss=-0.303 KID= 0.00579\n",
      "epoch 650, batch 17, d_loss=-0.541 g_loss=-0.220 KID= 0.00579\n",
      "epoch 650, batch 18, d_loss=-0.486 g_loss=-0.293 KID= 0.00579\n",
      "epoch 650, batch 19, d_loss=-0.394 g_loss=-0.238 KID= 0.00579\n",
      "epoch 651, batch 0, d_loss=-0.382 g_loss=-0.185 KID= 0.00579\n",
      "epoch 651, batch 1, d_loss=-0.443 g_loss=-0.314 KID= 0.00579\n",
      "epoch 651, batch 2, d_loss=-0.308 g_loss=-0.290 KID= 0.00579\n",
      "epoch 651, batch 3, d_loss=-0.409 g_loss=-0.232 KID= 0.00579\n",
      "epoch 651, batch 4, d_loss=-0.437 g_loss=-0.142 KID= 0.00579\n",
      "epoch 651, batch 5, d_loss=-0.428 g_loss=0.024 KID= 0.00579\n",
      "epoch 651, batch 6, d_loss=-0.448 g_loss=0.056 KID= 0.00579\n",
      "epoch 651, batch 7, d_loss=-0.520 g_loss=0.182 KID= 0.00579\n",
      "epoch 651, batch 8, d_loss=-0.492 g_loss=0.103 KID= 0.00579\n",
      "epoch 651, batch 9, d_loss=-0.367 g_loss=0.041 KID= 0.00579\n",
      "epoch 651, batch 10, d_loss=-0.445 g_loss=-0.045 KID= 0.00579\n",
      "epoch 651, batch 11, d_loss=-0.410 g_loss=-0.246 KID= 0.00579\n",
      "epoch 651, batch 12, d_loss=-0.256 g_loss=-0.361 KID= 0.00579\n",
      "epoch 651, batch 13, d_loss=-0.477 g_loss=-0.475 KID= 0.00579\n",
      "epoch 651, batch 14, d_loss=-0.411 g_loss=-0.571 KID= 0.00579\n",
      "epoch 651, batch 15, d_loss=-0.345 g_loss=-0.549 KID= 0.00579\n",
      "epoch 651, batch 16, d_loss=-0.483 g_loss=-0.469 KID= 0.00579\n",
      "epoch 651, batch 17, d_loss=-0.529 g_loss=-0.147 KID= 0.00579\n",
      "epoch 651, batch 18, d_loss=-0.499 g_loss=-0.034 KID= 0.00579\n",
      "epoch 651, batch 19, d_loss=-0.404 g_loss=0.154 KID= 0.00579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 652, batch 0, d_loss=-0.413 g_loss=0.141 KID= 0.00579\n",
      "epoch 652, batch 1, d_loss=-0.391 g_loss=-0.034 KID= 0.00579\n",
      "epoch 652, batch 2, d_loss=-0.301 g_loss=-0.166 KID= 0.00579\n",
      "epoch 652, batch 3, d_loss=-0.411 g_loss=-0.164 KID= 0.00579\n",
      "epoch 652, batch 4, d_loss=-0.408 g_loss=-0.203 KID= 0.00579\n",
      "epoch 652, batch 5, d_loss=-0.425 g_loss=-0.264 KID= 0.00579\n",
      "epoch 652, batch 6, d_loss=-0.452 g_loss=-0.320 KID= 0.00579\n",
      "epoch 652, batch 7, d_loss=-0.554 g_loss=-0.390 KID= 0.00579\n",
      "epoch 652, batch 8, d_loss=-0.469 g_loss=-0.575 KID= 0.00579\n",
      "epoch 652, batch 9, d_loss=-0.398 g_loss=-0.583 KID= 0.00579\n",
      "epoch 652, batch 10, d_loss=-0.419 g_loss=-0.607 KID= 0.00579\n",
      "epoch 652, batch 11, d_loss=-0.395 g_loss=-0.676 KID= 0.00579\n",
      "epoch 652, batch 12, d_loss=-0.361 g_loss=-0.633 KID= 0.00579\n",
      "epoch 652, batch 13, d_loss=-0.464 g_loss=-0.625 KID= 0.00579\n",
      "epoch 652, batch 14, d_loss=-0.450 g_loss=-0.657 KID= 0.00579\n",
      "epoch 652, batch 15, d_loss=-0.413 g_loss=-0.591 KID= 0.00579\n",
      "epoch 652, batch 16, d_loss=-0.443 g_loss=-0.288 KID= 0.00579\n",
      "epoch 652, batch 17, d_loss=-0.500 g_loss=0.039 KID= 0.00579\n",
      "epoch 652, batch 18, d_loss=-0.435 g_loss=0.160 KID= 0.00579\n",
      "epoch 652, batch 19, d_loss=-0.431 g_loss=0.317 KID= 0.00579\n",
      "epoch 653, batch 0, d_loss=-0.465 g_loss=0.515 KID= 0.00579\n",
      "epoch 653, batch 1, d_loss=-0.372 g_loss=0.397 KID= 0.00579\n",
      "epoch 653, batch 2, d_loss=-0.347 g_loss=0.199 KID= 0.00579\n",
      "epoch 653, batch 3, d_loss=-0.390 g_loss=0.065 KID= 0.00579\n",
      "epoch 653, batch 4, d_loss=-0.409 g_loss=0.074 KID= 0.00579\n",
      "epoch 653, batch 5, d_loss=-0.392 g_loss=-0.117 KID= 0.00579\n",
      "epoch 653, batch 6, d_loss=-0.420 g_loss=-0.252 KID= 0.00579\n",
      "epoch 653, batch 7, d_loss=-0.534 g_loss=-0.372 KID= 0.00579\n",
      "epoch 653, batch 8, d_loss=-0.461 g_loss=-0.663 KID= 0.00579\n",
      "epoch 653, batch 9, d_loss=-0.385 g_loss=-0.812 KID= 0.00579\n",
      "epoch 653, batch 10, d_loss=-0.469 g_loss=-0.895 KID= 0.00579\n",
      "epoch 653, batch 11, d_loss=-0.369 g_loss=-0.894 KID= 0.00579\n",
      "epoch 653, batch 12, d_loss=-0.376 g_loss=-0.675 KID= 0.00579\n",
      "epoch 653, batch 13, d_loss=-0.433 g_loss=-0.465 KID= 0.00579\n",
      "epoch 653, batch 14, d_loss=-0.404 g_loss=-0.211 KID= 0.00579\n",
      "epoch 653, batch 15, d_loss=-0.383 g_loss=-0.252 KID= 0.00579\n",
      "epoch 653, batch 16, d_loss=-0.484 g_loss=-0.255 KID= 0.00579\n",
      "epoch 653, batch 17, d_loss=-0.552 g_loss=-0.117 KID= 0.00579\n",
      "epoch 653, batch 18, d_loss=-0.474 g_loss=-0.060 KID= 0.00579\n",
      "epoch 653, batch 19, d_loss=-0.408 g_loss=0.004 KID= 0.00579\n",
      "epoch 654, batch 0, d_loss=-0.422 g_loss=-0.001 KID= 0.00579\n",
      "epoch 654, batch 1, d_loss=-0.393 g_loss=-0.080 KID= 0.00579\n",
      "epoch 654, batch 2, d_loss=-0.339 g_loss=-0.161 KID= 0.00579\n",
      "epoch 654, batch 3, d_loss=-0.445 g_loss=-0.325 KID= 0.00579\n",
      "epoch 654, batch 4, d_loss=-0.449 g_loss=-0.395 KID= 0.00579\n",
      "epoch 654, batch 5, d_loss=-0.400 g_loss=-0.580 KID= 0.00579\n",
      "epoch 654, batch 6, d_loss=-0.458 g_loss=-0.617 KID= 0.00579\n",
      "epoch 654, batch 7, d_loss=-0.543 g_loss=-0.581 KID= 0.00579\n",
      "epoch 654, batch 8, d_loss=-0.425 g_loss=-0.597 KID= 0.00579\n",
      "epoch 654, batch 9, d_loss=-0.406 g_loss=-0.579 KID= 0.00579\n",
      "epoch 654, batch 10, d_loss=-0.419 g_loss=-0.640 KID= 0.00579\n",
      "epoch 654, batch 11, d_loss=-0.414 g_loss=-0.634 KID= 0.00579\n",
      "epoch 654, batch 12, d_loss=-0.334 g_loss=-0.589 KID= 0.00579\n",
      "epoch 654, batch 13, d_loss=-0.425 g_loss=-0.523 KID= 0.00579\n",
      "epoch 654, batch 14, d_loss=-0.428 g_loss=-0.390 KID= 0.00579\n",
      "epoch 654, batch 15, d_loss=-0.379 g_loss=-0.314 KID= 0.00579\n",
      "epoch 654, batch 16, d_loss=-0.509 g_loss=-0.075 KID= 0.00579\n",
      "epoch 654, batch 17, d_loss=-0.536 g_loss=0.113 KID= 0.00579\n",
      "epoch 654, batch 18, d_loss=-0.454 g_loss=0.128 KID= 0.00579\n",
      "epoch 654, batch 19, d_loss=-0.415 g_loss=0.157 KID= 0.00579\n",
      "epoch 655, batch 0, d_loss=-0.367 g_loss=0.254 KID= 0.00579\n",
      "epoch 655, batch 1, d_loss=-0.366 g_loss=0.113 KID= 0.00579\n",
      "epoch 655, batch 2, d_loss=-0.357 g_loss=-0.048 KID= 0.00579\n",
      "epoch 655, batch 3, d_loss=-0.476 g_loss=-0.256 KID= 0.00579\n",
      "epoch 655, batch 4, d_loss=-0.407 g_loss=-0.356 KID= 0.00579\n",
      "epoch 655, batch 5, d_loss=-0.410 g_loss=-0.519 KID= 0.00579\n",
      "epoch 655, batch 6, d_loss=-0.490 g_loss=-0.447 KID= 0.00579\n",
      "epoch 655, batch 7, d_loss=-0.548 g_loss=-0.415 KID= 0.00579\n",
      "epoch 655, batch 8, d_loss=-0.467 g_loss=-0.493 KID= 0.00579\n",
      "epoch 655, batch 9, d_loss=-0.422 g_loss=-0.499 KID= 0.00579\n",
      "epoch 655, batch 10, d_loss=-0.367 g_loss=-0.382 KID= 0.00579\n",
      "epoch 655, batch 11, d_loss=-0.472 g_loss=-0.431 KID= 0.00579\n",
      "epoch 655, batch 12, d_loss=-0.235 g_loss=-0.327 KID= 0.00579\n",
      "epoch 655, batch 13, d_loss=-0.441 g_loss=-0.295 KID= 0.00579\n",
      "epoch 655, batch 14, d_loss=-0.419 g_loss=-0.169 KID= 0.00579\n",
      "epoch 655, batch 15, d_loss=-0.385 g_loss=-0.204 KID= 0.00579\n",
      "epoch 655, batch 16, d_loss=-0.443 g_loss=-0.215 KID= 0.00579\n",
      "epoch 655, batch 17, d_loss=-0.562 g_loss=-0.147 KID= 0.00579\n",
      "epoch 655, batch 18, d_loss=-0.470 g_loss=-0.204 KID= 0.00579\n",
      "epoch 655, batch 19, d_loss=-0.363 g_loss=-0.212 KID= 0.00579\n",
      "epoch 656, batch 0, d_loss=-0.423 g_loss=-0.232 KID= 0.00579\n",
      "epoch 656, batch 1, d_loss=-0.416 g_loss=-0.215 KID= 0.00579\n",
      "epoch 656, batch 2, d_loss=-0.410 g_loss=-0.190 KID= 0.00579\n",
      "epoch 656, batch 3, d_loss=-0.423 g_loss=-0.163 KID= 0.00579\n",
      "epoch 656, batch 4, d_loss=-0.421 g_loss=-0.112 KID= 0.00579\n",
      "epoch 656, batch 5, d_loss=-0.396 g_loss=-0.125 KID= 0.00579\n",
      "epoch 656, batch 6, d_loss=-0.512 g_loss=-0.006 KID= 0.00579\n",
      "epoch 656, batch 7, d_loss=-0.528 g_loss=0.083 KID= 0.00579\n",
      "epoch 656, batch 8, d_loss=-0.406 g_loss=0.077 KID= 0.00579\n",
      "epoch 656, batch 9, d_loss=-0.382 g_loss=-0.001 KID= 0.00579\n",
      "epoch 656, batch 10, d_loss=-0.420 g_loss=-0.032 KID= 0.00579\n",
      "epoch 656, batch 11, d_loss=-0.439 g_loss=-0.205 KID= 0.00579\n",
      "epoch 656, batch 12, d_loss=-0.363 g_loss=-0.296 KID= 0.00579\n",
      "epoch 656, batch 13, d_loss=-0.463 g_loss=-0.189 KID= 0.00579\n",
      "epoch 656, batch 14, d_loss=-0.437 g_loss=-0.110 KID= 0.00579\n",
      "epoch 656, batch 15, d_loss=-0.369 g_loss=-0.202 KID= 0.00579\n",
      "epoch 656, batch 16, d_loss=-0.502 g_loss=-0.181 KID= 0.00579\n",
      "epoch 656, batch 17, d_loss=-0.581 g_loss=-0.134 KID= 0.00579\n",
      "epoch 656, batch 18, d_loss=-0.458 g_loss=-0.192 KID= 0.00579\n",
      "epoch 656, batch 19, d_loss=-0.404 g_loss=-0.137 KID= 0.00579\n",
      "epoch 657, batch 0, d_loss=-0.396 g_loss=-0.162 KID= 0.00579\n",
      "epoch 657, batch 1, d_loss=-0.421 g_loss=-0.268 KID= 0.00579\n",
      "epoch 657, batch 2, d_loss=-0.349 g_loss=-0.277 KID= 0.00579\n",
      "epoch 657, batch 3, d_loss=-0.462 g_loss=-0.354 KID= 0.00579\n",
      "epoch 657, batch 4, d_loss=-0.410 g_loss=-0.333 KID= 0.00579\n",
      "epoch 657, batch 5, d_loss=-0.383 g_loss=-0.461 KID= 0.00579\n",
      "epoch 657, batch 6, d_loss=-0.479 g_loss=-0.453 KID= 0.00579\n",
      "epoch 657, batch 7, d_loss=-0.528 g_loss=-0.352 KID= 0.00579\n",
      "epoch 657, batch 8, d_loss=-0.466 g_loss=-0.399 KID= 0.00579\n",
      "epoch 657, batch 9, d_loss=-0.412 g_loss=-0.361 KID= 0.00579\n",
      "epoch 657, batch 10, d_loss=-0.443 g_loss=-0.367 KID= 0.00579\n",
      "epoch 657, batch 11, d_loss=-0.402 g_loss=-0.507 KID= 0.00579\n",
      "epoch 657, batch 12, d_loss=-0.383 g_loss=-0.645 KID= 0.00579\n",
      "epoch 657, batch 13, d_loss=-0.477 g_loss=-0.662 KID= 0.00579\n",
      "epoch 657, batch 14, d_loss=-0.424 g_loss=-0.642 KID= 0.00579\n",
      "epoch 657, batch 15, d_loss=-0.409 g_loss=-0.705 KID= 0.00579\n",
      "epoch 657, batch 16, d_loss=-0.483 g_loss=-0.684 KID= 0.00579\n",
      "epoch 657, batch 17, d_loss=-0.498 g_loss=-0.572 KID= 0.00579\n",
      "epoch 657, batch 18, d_loss=-0.384 g_loss=-0.574 KID= 0.00579\n",
      "epoch 657, batch 19, d_loss=-0.459 g_loss=-0.471 KID= 0.00579\n",
      "epoch 658, batch 0, d_loss=-0.423 g_loss=-0.322 KID= 0.00579\n",
      "epoch 658, batch 1, d_loss=-0.414 g_loss=-0.309 KID= 0.00579\n",
      "epoch 658, batch 2, d_loss=-0.335 g_loss=-0.205 KID= 0.00579\n",
      "epoch 658, batch 3, d_loss=-0.428 g_loss=-0.087 KID= 0.00579\n",
      "epoch 658, batch 4, d_loss=-0.465 g_loss=-0.006 KID= 0.00579\n",
      "epoch 658, batch 5, d_loss=-0.393 g_loss=0.098 KID= 0.00579\n",
      "epoch 658, batch 6, d_loss=-0.460 g_loss=0.267 KID= 0.00579\n",
      "epoch 658, batch 7, d_loss=-0.540 g_loss=0.309 KID= 0.00579\n",
      "epoch 658, batch 8, d_loss=-0.423 g_loss=0.326 KID= 0.00579\n",
      "epoch 658, batch 9, d_loss=-0.362 g_loss=0.193 KID= 0.00579\n",
      "epoch 658, batch 10, d_loss=-0.424 g_loss=0.074 KID= 0.00579\n",
      "epoch 658, batch 11, d_loss=-0.391 g_loss=-0.109 KID= 0.00579\n",
      "epoch 658, batch 12, d_loss=-0.402 g_loss=-0.267 KID= 0.00579\n",
      "epoch 658, batch 13, d_loss=-0.419 g_loss=-0.482 KID= 0.00579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 658, batch 14, d_loss=-0.415 g_loss=-0.554 KID= 0.00579\n",
      "epoch 658, batch 15, d_loss=-0.375 g_loss=-0.637 KID= 0.00579\n",
      "epoch 658, batch 16, d_loss=-0.531 g_loss=-0.563 KID= 0.00579\n",
      "epoch 658, batch 17, d_loss=-0.576 g_loss=-0.542 KID= 0.00579\n",
      "epoch 658, batch 18, d_loss=-0.378 g_loss=-0.534 KID= 0.00579\n",
      "epoch 658, batch 19, d_loss=-0.351 g_loss=-0.342 KID= 0.00579\n",
      "epoch 659, batch 0, d_loss=-0.426 g_loss=-0.081 KID= 0.00579\n",
      "epoch 659, batch 1, d_loss=-0.368 g_loss=-0.038 KID= 0.00579\n",
      "epoch 659, batch 2, d_loss=-0.395 g_loss=0.080 KID= 0.00579\n",
      "epoch 659, batch 3, d_loss=-0.457 g_loss=0.035 KID= 0.00579\n",
      "epoch 659, batch 4, d_loss=-0.441 g_loss=-0.037 KID= 0.00579\n",
      "epoch 659, batch 5, d_loss=-0.292 g_loss=-0.065 KID= 0.00579\n",
      "epoch 659, batch 6, d_loss=-0.497 g_loss=-0.103 KID= 0.00579\n",
      "epoch 659, batch 7, d_loss=-0.542 g_loss=-0.173 KID= 0.00579\n",
      "epoch 659, batch 8, d_loss=-0.419 g_loss=-0.189 KID= 0.00579\n",
      "epoch 659, batch 9, d_loss=-0.351 g_loss=-0.256 KID= 0.00579\n",
      "epoch 659, batch 10, d_loss=-0.453 g_loss=-0.395 KID= 0.00579\n",
      "epoch 659, batch 11, d_loss=-0.327 g_loss=-0.565 KID= 0.00579\n",
      "epoch 659, batch 12, d_loss=-0.330 g_loss=-0.628 KID= 0.00579\n",
      "epoch 659, batch 13, d_loss=-0.375 g_loss=-0.618 KID= 0.00579\n",
      "epoch 659, batch 14, d_loss=-0.472 g_loss=-0.621 KID= 0.00579\n",
      "epoch 659, batch 15, d_loss=-0.407 g_loss=-0.666 KID= 0.00579\n",
      "epoch 659, batch 16, d_loss=-0.481 g_loss=-0.551 KID= 0.00579\n",
      "epoch 659, batch 17, d_loss=-0.493 g_loss=-0.359 KID= 0.00579\n",
      "epoch 659, batch 18, d_loss=-0.409 g_loss=-0.254 KID= 0.00579\n",
      "epoch 659, batch 19, d_loss=-0.379 g_loss=-0.093 KID= 0.00579\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 660, batch 0, d_loss=-0.418 g_loss=0.071 KID= 0.00499\n",
      "epoch 660, batch 1, d_loss=-0.352 g_loss=0.092 KID= 0.00499\n",
      "epoch 660, batch 2, d_loss=-0.378 g_loss=0.109 KID= 0.00499\n",
      "epoch 660, batch 3, d_loss=-0.452 g_loss=-0.011 KID= 0.00499\n",
      "epoch 660, batch 4, d_loss=-0.478 g_loss=-0.104 KID= 0.00499\n",
      "epoch 660, batch 5, d_loss=-0.347 g_loss=-0.212 KID= 0.00499\n",
      "epoch 660, batch 6, d_loss=-0.497 g_loss=-0.247 KID= 0.00499\n",
      "epoch 660, batch 7, d_loss=-0.530 g_loss=-0.203 KID= 0.00499\n",
      "epoch 660, batch 8, d_loss=-0.432 g_loss=-0.128 KID= 0.00499\n",
      "epoch 660, batch 9, d_loss=-0.370 g_loss=-0.119 KID= 0.00499\n",
      "epoch 660, batch 10, d_loss=-0.419 g_loss=-0.078 KID= 0.00499\n",
      "epoch 660, batch 11, d_loss=-0.455 g_loss=-0.092 KID= 0.00499\n",
      "epoch 660, batch 12, d_loss=-0.368 g_loss=-0.011 KID= 0.00499\n",
      "epoch 660, batch 13, d_loss=-0.455 g_loss=-0.173 KID= 0.00499\n",
      "epoch 660, batch 14, d_loss=-0.460 g_loss=-0.358 KID= 0.00499\n",
      "epoch 660, batch 15, d_loss=-0.371 g_loss=-0.467 KID= 0.00499\n",
      "epoch 660, batch 16, d_loss=-0.566 g_loss=-0.495 KID= 0.00499\n",
      "epoch 660, batch 17, d_loss=-0.481 g_loss=-0.528 KID= 0.00499\n",
      "epoch 660, batch 18, d_loss=-0.468 g_loss=-0.572 KID= 0.00499\n",
      "epoch 660, batch 19, d_loss=-0.382 g_loss=-0.517 KID= 0.00499\n",
      "epoch 661, batch 0, d_loss=-0.407 g_loss=-0.498 KID= 0.00499\n",
      "epoch 661, batch 1, d_loss=-0.429 g_loss=-0.389 KID= 0.00499\n",
      "epoch 661, batch 2, d_loss=-0.349 g_loss=-0.224 KID= 0.00499\n",
      "epoch 661, batch 3, d_loss=-0.442 g_loss=-0.165 KID= 0.00499\n",
      "epoch 661, batch 4, d_loss=-0.462 g_loss=-0.168 KID= 0.00499\n",
      "epoch 661, batch 5, d_loss=-0.327 g_loss=-0.185 KID= 0.00499\n",
      "epoch 661, batch 6, d_loss=-0.456 g_loss=-0.168 KID= 0.00499\n",
      "epoch 661, batch 7, d_loss=-0.547 g_loss=-0.118 KID= 0.00499\n",
      "epoch 661, batch 8, d_loss=-0.383 g_loss=-0.043 KID= 0.00499\n",
      "epoch 661, batch 9, d_loss=-0.385 g_loss=0.073 KID= 0.00499\n",
      "epoch 661, batch 10, d_loss=-0.477 g_loss=0.086 KID= 0.00499\n",
      "epoch 661, batch 11, d_loss=-0.417 g_loss=0.094 KID= 0.00499\n",
      "epoch 661, batch 12, d_loss=-0.358 g_loss=0.102 KID= 0.00499\n",
      "epoch 661, batch 13, d_loss=-0.452 g_loss=0.026 KID= 0.00499\n",
      "epoch 661, batch 14, d_loss=-0.416 g_loss=-0.177 KID= 0.00499\n",
      "epoch 661, batch 15, d_loss=-0.331 g_loss=-0.264 KID= 0.00499\n",
      "epoch 661, batch 16, d_loss=-0.544 g_loss=-0.294 KID= 0.00499\n",
      "epoch 661, batch 17, d_loss=-0.546 g_loss=-0.370 KID= 0.00499\n",
      "epoch 661, batch 18, d_loss=-0.468 g_loss=-0.385 KID= 0.00499\n",
      "epoch 661, batch 19, d_loss=-0.425 g_loss=-0.509 KID= 0.00499\n",
      "epoch 662, batch 0, d_loss=-0.456 g_loss=-0.607 KID= 0.00499\n",
      "epoch 662, batch 1, d_loss=-0.392 g_loss=-0.566 KID= 0.00499\n",
      "epoch 662, batch 2, d_loss=-0.356 g_loss=-0.444 KID= 0.00499\n",
      "epoch 662, batch 3, d_loss=-0.399 g_loss=-0.289 KID= 0.00499\n",
      "epoch 662, batch 4, d_loss=-0.460 g_loss=-0.231 KID= 0.00499\n",
      "epoch 662, batch 5, d_loss=-0.391 g_loss=-0.217 KID= 0.00499\n",
      "epoch 662, batch 6, d_loss=-0.455 g_loss=-0.179 KID= 0.00499\n",
      "epoch 662, batch 7, d_loss=-0.560 g_loss=-0.077 KID= 0.00499\n",
      "epoch 662, batch 8, d_loss=-0.442 g_loss=0.044 KID= 0.00499\n",
      "epoch 662, batch 9, d_loss=-0.366 g_loss=0.081 KID= 0.00499\n",
      "epoch 662, batch 10, d_loss=-0.458 g_loss=0.150 KID= 0.00499\n",
      "epoch 662, batch 11, d_loss=-0.447 g_loss=0.161 KID= 0.00499\n",
      "epoch 662, batch 12, d_loss=-0.408 g_loss=0.169 KID= 0.00499\n",
      "epoch 662, batch 13, d_loss=-0.451 g_loss=0.179 KID= 0.00499\n",
      "epoch 662, batch 14, d_loss=-0.453 g_loss=0.058 KID= 0.00499\n",
      "epoch 662, batch 15, d_loss=-0.371 g_loss=-0.077 KID= 0.00499\n",
      "epoch 662, batch 16, d_loss=-0.559 g_loss=-0.239 KID= 0.00499\n",
      "epoch 662, batch 17, d_loss=-0.464 g_loss=-0.275 KID= 0.00499\n",
      "epoch 662, batch 18, d_loss=-0.401 g_loss=-0.395 KID= 0.00499\n",
      "epoch 662, batch 19, d_loss=-0.394 g_loss=-0.499 KID= 0.00499\n",
      "epoch 663, batch 0, d_loss=-0.420 g_loss=-0.567 KID= 0.00499\n",
      "epoch 663, batch 1, d_loss=-0.390 g_loss=-0.598 KID= 0.00499\n",
      "epoch 663, batch 2, d_loss=-0.358 g_loss=-0.680 KID= 0.00499\n",
      "epoch 663, batch 3, d_loss=-0.442 g_loss=-0.642 KID= 0.00499\n",
      "epoch 663, batch 4, d_loss=-0.480 g_loss=-0.583 KID= 0.00499\n",
      "epoch 663, batch 5, d_loss=-0.371 g_loss=-0.513 KID= 0.00499\n",
      "epoch 663, batch 6, d_loss=-0.449 g_loss=-0.459 KID= 0.00499\n",
      "epoch 663, batch 7, d_loss=-0.563 g_loss=-0.287 KID= 0.00499\n",
      "epoch 663, batch 8, d_loss=-0.493 g_loss=-0.196 KID= 0.00499\n",
      "epoch 663, batch 9, d_loss=-0.345 g_loss=-0.056 KID= 0.00499\n",
      "epoch 663, batch 10, d_loss=-0.425 g_loss=-0.026 KID= 0.00499\n",
      "epoch 663, batch 11, d_loss=-0.404 g_loss=-0.040 KID= 0.00499\n",
      "epoch 663, batch 12, d_loss=-0.350 g_loss=0.109 KID= 0.00499\n",
      "epoch 663, batch 13, d_loss=-0.426 g_loss=0.136 KID= 0.00499\n",
      "epoch 663, batch 14, d_loss=-0.449 g_loss=0.146 KID= 0.00499\n",
      "epoch 663, batch 15, d_loss=-0.367 g_loss=0.108 KID= 0.00499\n",
      "epoch 663, batch 16, d_loss=-0.510 g_loss=0.040 KID= 0.00499\n",
      "epoch 663, batch 17, d_loss=-0.501 g_loss=-0.055 KID= 0.00499\n",
      "epoch 663, batch 18, d_loss=-0.470 g_loss=-0.221 KID= 0.00499\n",
      "epoch 663, batch 19, d_loss=-0.401 g_loss=-0.301 KID= 0.00499\n",
      "epoch 664, batch 0, d_loss=-0.409 g_loss=-0.367 KID= 0.00499\n",
      "epoch 664, batch 1, d_loss=-0.407 g_loss=-0.422 KID= 0.00499\n",
      "epoch 664, batch 2, d_loss=-0.357 g_loss=-0.400 KID= 0.00499\n",
      "epoch 664, batch 3, d_loss=-0.447 g_loss=-0.390 KID= 0.00499\n",
      "epoch 664, batch 4, d_loss=-0.413 g_loss=-0.417 KID= 0.00499\n",
      "epoch 664, batch 5, d_loss=-0.348 g_loss=-0.543 KID= 0.00499\n",
      "epoch 664, batch 6, d_loss=-0.528 g_loss=-0.704 KID= 0.00499\n",
      "epoch 664, batch 7, d_loss=-0.538 g_loss=-0.743 KID= 0.00499\n",
      "epoch 664, batch 8, d_loss=-0.493 g_loss=-0.767 KID= 0.00499\n",
      "epoch 664, batch 9, d_loss=-0.376 g_loss=-0.695 KID= 0.00499\n",
      "epoch 664, batch 10, d_loss=-0.429 g_loss=-0.684 KID= 0.00499\n",
      "epoch 664, batch 11, d_loss=-0.363 g_loss=-0.612 KID= 0.00499\n",
      "epoch 664, batch 12, d_loss=-0.316 g_loss=-0.586 KID= 0.00499\n",
      "epoch 664, batch 13, d_loss=-0.412 g_loss=-0.441 KID= 0.00499\n",
      "epoch 664, batch 14, d_loss=-0.427 g_loss=-0.334 KID= 0.00499\n",
      "epoch 664, batch 15, d_loss=-0.364 g_loss=-0.344 KID= 0.00499\n",
      "epoch 664, batch 16, d_loss=-0.475 g_loss=-0.411 KID= 0.00499\n",
      "epoch 664, batch 17, d_loss=-0.573 g_loss=-0.400 KID= 0.00499\n",
      "epoch 664, batch 18, d_loss=-0.498 g_loss=-0.393 KID= 0.00499\n",
      "epoch 664, batch 19, d_loss=-0.394 g_loss=-0.341 KID= 0.00499\n",
      "epoch 665, batch 0, d_loss=-0.359 g_loss=-0.220 KID= 0.00499\n",
      "epoch 665, batch 1, d_loss=-0.387 g_loss=-0.135 KID= 0.00499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 665, batch 2, d_loss=-0.334 g_loss=0.048 KID= 0.00499\n",
      "epoch 665, batch 3, d_loss=-0.469 g_loss=0.227 KID= 0.00499\n",
      "epoch 665, batch 4, d_loss=-0.427 g_loss=0.193 KID= 0.00499\n",
      "epoch 665, batch 5, d_loss=-0.384 g_loss=0.092 KID= 0.00499\n",
      "epoch 665, batch 6, d_loss=-0.480 g_loss=-0.149 KID= 0.00499\n",
      "epoch 665, batch 7, d_loss=-0.541 g_loss=-0.254 KID= 0.00499\n",
      "epoch 665, batch 8, d_loss=-0.472 g_loss=-0.370 KID= 0.00499\n",
      "epoch 665, batch 9, d_loss=-0.391 g_loss=-0.403 KID= 0.00499\n",
      "epoch 665, batch 10, d_loss=-0.404 g_loss=-0.445 KID= 0.00499\n",
      "epoch 665, batch 11, d_loss=-0.376 g_loss=-0.556 KID= 0.00499\n",
      "epoch 665, batch 12, d_loss=-0.332 g_loss=-0.509 KID= 0.00499\n",
      "epoch 665, batch 13, d_loss=-0.478 g_loss=-0.521 KID= 0.00499\n",
      "epoch 665, batch 14, d_loss=-0.390 g_loss=-0.526 KID= 0.00499\n",
      "epoch 665, batch 15, d_loss=-0.385 g_loss=-0.510 KID= 0.00499\n",
      "epoch 665, batch 16, d_loss=-0.524 g_loss=-0.588 KID= 0.00499\n",
      "epoch 665, batch 17, d_loss=-0.512 g_loss=-0.514 KID= 0.00499\n",
      "epoch 665, batch 18, d_loss=-0.526 g_loss=-0.543 KID= 0.00499\n",
      "epoch 665, batch 19, d_loss=-0.370 g_loss=-0.435 KID= 0.00499\n",
      "epoch 666, batch 0, d_loss=-0.468 g_loss=-0.234 KID= 0.00499\n",
      "epoch 666, batch 1, d_loss=-0.436 g_loss=-0.174 KID= 0.00499\n",
      "epoch 666, batch 2, d_loss=-0.342 g_loss=-0.008 KID= 0.00499\n",
      "epoch 666, batch 3, d_loss=-0.510 g_loss=0.111 KID= 0.00499\n",
      "epoch 666, batch 4, d_loss=-0.499 g_loss=0.026 KID= 0.00499\n",
      "epoch 666, batch 5, d_loss=-0.370 g_loss=-0.066 KID= 0.00499\n",
      "epoch 666, batch 6, d_loss=-0.448 g_loss=-0.155 KID= 0.00499\n",
      "epoch 666, batch 7, d_loss=-0.502 g_loss=-0.205 KID= 0.00499\n",
      "epoch 666, batch 8, d_loss=-0.483 g_loss=-0.279 KID= 0.00499\n",
      "epoch 666, batch 9, d_loss=-0.316 g_loss=-0.417 KID= 0.00499\n",
      "epoch 666, batch 10, d_loss=-0.412 g_loss=-0.450 KID= 0.00499\n",
      "epoch 666, batch 11, d_loss=-0.385 g_loss=-0.614 KID= 0.00499\n",
      "epoch 666, batch 12, d_loss=-0.332 g_loss=-0.527 KID= 0.00499\n",
      "epoch 666, batch 13, d_loss=-0.474 g_loss=-0.346 KID= 0.00499\n",
      "epoch 666, batch 14, d_loss=-0.478 g_loss=-0.308 KID= 0.00499\n",
      "epoch 666, batch 15, d_loss=-0.384 g_loss=-0.310 KID= 0.00499\n",
      "epoch 666, batch 16, d_loss=-0.498 g_loss=-0.311 KID= 0.00499\n",
      "epoch 666, batch 17, d_loss=-0.487 g_loss=-0.313 KID= 0.00499\n",
      "epoch 666, batch 18, d_loss=-0.446 g_loss=-0.188 KID= 0.00499\n",
      "epoch 666, batch 19, d_loss=-0.391 g_loss=-0.160 KID= 0.00499\n",
      "epoch 667, batch 0, d_loss=-0.491 g_loss=-0.142 KID= 0.00499\n",
      "epoch 667, batch 1, d_loss=-0.447 g_loss=-0.190 KID= 0.00499\n",
      "epoch 667, batch 2, d_loss=-0.325 g_loss=-0.059 KID= 0.00499\n",
      "epoch 667, batch 3, d_loss=-0.491 g_loss=0.058 KID= 0.00499\n",
      "epoch 667, batch 4, d_loss=-0.435 g_loss=0.002 KID= 0.00499\n",
      "epoch 667, batch 5, d_loss=-0.380 g_loss=-0.097 KID= 0.00499\n",
      "epoch 667, batch 6, d_loss=-0.482 g_loss=-0.192 KID= 0.00499\n",
      "epoch 667, batch 7, d_loss=-0.510 g_loss=-0.319 KID= 0.00499\n",
      "epoch 667, batch 8, d_loss=-0.429 g_loss=-0.521 KID= 0.00499\n",
      "epoch 667, batch 9, d_loss=-0.413 g_loss=-0.565 KID= 0.00499\n",
      "epoch 667, batch 10, d_loss=-0.471 g_loss=-0.667 KID= 0.00499\n",
      "epoch 667, batch 11, d_loss=-0.399 g_loss=-0.674 KID= 0.00499\n",
      "epoch 667, batch 12, d_loss=-0.345 g_loss=-0.482 KID= 0.00499\n",
      "epoch 667, batch 13, d_loss=-0.458 g_loss=-0.333 KID= 0.00499\n",
      "epoch 667, batch 14, d_loss=-0.490 g_loss=-0.237 KID= 0.00499\n",
      "epoch 667, batch 15, d_loss=-0.293 g_loss=-0.126 KID= 0.00499\n",
      "epoch 667, batch 16, d_loss=-0.491 g_loss=-0.075 KID= 0.00499\n",
      "epoch 667, batch 17, d_loss=-0.538 g_loss=0.084 KID= 0.00499\n",
      "epoch 667, batch 18, d_loss=-0.512 g_loss=0.205 KID= 0.00499\n",
      "epoch 667, batch 19, d_loss=-0.419 g_loss=0.194 KID= 0.00499\n",
      "epoch 668, batch 0, d_loss=-0.472 g_loss=0.144 KID= 0.00499\n",
      "epoch 668, batch 1, d_loss=-0.362 g_loss=0.084 KID= 0.00499\n",
      "epoch 668, batch 2, d_loss=-0.359 g_loss=0.173 KID= 0.00499\n",
      "epoch 668, batch 3, d_loss=-0.489 g_loss=0.217 KID= 0.00499\n",
      "epoch 668, batch 4, d_loss=-0.507 g_loss=0.132 KID= 0.00499\n",
      "epoch 668, batch 5, d_loss=-0.416 g_loss=0.008 KID= 0.00499\n",
      "epoch 668, batch 6, d_loss=-0.465 g_loss=-0.070 KID= 0.00499\n",
      "epoch 668, batch 7, d_loss=-0.504 g_loss=-0.185 KID= 0.00499\n",
      "epoch 668, batch 8, d_loss=-0.421 g_loss=-0.281 KID= 0.00499\n",
      "epoch 668, batch 9, d_loss=-0.443 g_loss=-0.434 KID= 0.00499\n",
      "epoch 668, batch 10, d_loss=-0.450 g_loss=-0.549 KID= 0.00499\n",
      "epoch 668, batch 11, d_loss=-0.482 g_loss=-0.665 KID= 0.00499\n",
      "epoch 668, batch 12, d_loss=-0.281 g_loss=-0.600 KID= 0.00499\n",
      "epoch 668, batch 13, d_loss=-0.464 g_loss=-0.451 KID= 0.00499\n",
      "epoch 668, batch 14, d_loss=-0.454 g_loss=-0.381 KID= 0.00499\n",
      "epoch 668, batch 15, d_loss=-0.395 g_loss=-0.262 KID= 0.00499\n",
      "epoch 668, batch 16, d_loss=-0.515 g_loss=-0.150 KID= 0.00499\n",
      "epoch 668, batch 17, d_loss=-0.554 g_loss=-0.204 KID= 0.00499\n",
      "epoch 668, batch 18, d_loss=-0.428 g_loss=-0.392 KID= 0.00499\n",
      "epoch 668, batch 19, d_loss=-0.399 g_loss=-0.510 KID= 0.00499\n",
      "epoch 669, batch 0, d_loss=-0.391 g_loss=-0.692 KID= 0.00499\n",
      "epoch 669, batch 1, d_loss=-0.376 g_loss=-0.732 KID= 0.00499\n",
      "epoch 669, batch 2, d_loss=-0.304 g_loss=-0.500 KID= 0.00499\n",
      "epoch 669, batch 3, d_loss=-0.437 g_loss=-0.340 KID= 0.00499\n",
      "epoch 669, batch 4, d_loss=-0.456 g_loss=-0.215 KID= 0.00499\n",
      "epoch 669, batch 5, d_loss=-0.384 g_loss=-0.017 KID= 0.00499\n",
      "epoch 669, batch 6, d_loss=-0.497 g_loss=0.077 KID= 0.00499\n",
      "epoch 669, batch 7, d_loss=-0.531 g_loss=0.140 KID= 0.00499\n",
      "epoch 669, batch 8, d_loss=-0.433 g_loss=0.187 KID= 0.00499\n",
      "epoch 669, batch 9, d_loss=-0.379 g_loss=0.245 KID= 0.00499\n",
      "epoch 669, batch 10, d_loss=-0.374 g_loss=0.171 KID= 0.00499\n",
      "epoch 669, batch 11, d_loss=-0.353 g_loss=0.003 KID= 0.00499\n",
      "epoch 669, batch 12, d_loss=-0.338 g_loss=0.026 KID= 0.00499\n",
      "epoch 669, batch 13, d_loss=-0.419 g_loss=0.065 KID= 0.00499\n",
      "epoch 669, batch 14, d_loss=-0.456 g_loss=0.163 KID= 0.00499\n",
      "epoch 669, batch 15, d_loss=-0.389 g_loss=0.120 KID= 0.00499\n",
      "epoch 669, batch 16, d_loss=-0.506 g_loss=0.149 KID= 0.00499\n",
      "epoch 669, batch 17, d_loss=-0.509 g_loss=-0.026 KID= 0.00499\n",
      "epoch 669, batch 18, d_loss=-0.428 g_loss=-0.269 KID= 0.00499\n",
      "epoch 669, batch 19, d_loss=-0.393 g_loss=-0.516 KID= 0.00499\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 670, batch 0, d_loss=-0.460 g_loss=-0.826 KID= 0.00740\n",
      "epoch 670, batch 1, d_loss=-0.398 g_loss=-0.945 KID= 0.00740\n",
      "epoch 670, batch 2, d_loss=-0.301 g_loss=-0.711 KID= 0.00740\n",
      "epoch 670, batch 3, d_loss=-0.484 g_loss=-0.599 KID= 0.00740\n",
      "epoch 670, batch 4, d_loss=-0.503 g_loss=-0.468 KID= 0.00740\n",
      "epoch 670, batch 5, d_loss=-0.338 g_loss=-0.249 KID= 0.00740\n",
      "epoch 670, batch 6, d_loss=-0.486 g_loss=-0.023 KID= 0.00740\n",
      "epoch 670, batch 7, d_loss=-0.496 g_loss=0.106 KID= 0.00740\n",
      "epoch 670, batch 8, d_loss=-0.465 g_loss=0.212 KID= 0.00740\n",
      "epoch 670, batch 9, d_loss=-0.425 g_loss=0.165 KID= 0.00740\n",
      "epoch 670, batch 10, d_loss=-0.430 g_loss=0.068 KID= 0.00740\n",
      "epoch 670, batch 11, d_loss=-0.394 g_loss=-0.160 KID= 0.00740\n",
      "epoch 670, batch 12, d_loss=-0.366 g_loss=-0.307 KID= 0.00740\n",
      "epoch 670, batch 13, d_loss=-0.499 g_loss=-0.373 KID= 0.00740\n",
      "epoch 670, batch 14, d_loss=-0.432 g_loss=-0.376 KID= 0.00740\n",
      "epoch 670, batch 15, d_loss=-0.400 g_loss=-0.311 KID= 0.00740\n",
      "epoch 670, batch 16, d_loss=-0.469 g_loss=-0.273 KID= 0.00740\n",
      "epoch 670, batch 17, d_loss=-0.582 g_loss=-0.294 KID= 0.00740\n",
      "epoch 670, batch 18, d_loss=-0.439 g_loss=-0.321 KID= 0.00740\n",
      "epoch 670, batch 19, d_loss=-0.377 g_loss=-0.291 KID= 0.00740\n",
      "epoch 671, batch 0, d_loss=-0.436 g_loss=-0.464 KID= 0.00740\n",
      "epoch 671, batch 1, d_loss=-0.420 g_loss=-0.696 KID= 0.00740\n",
      "epoch 671, batch 2, d_loss=-0.306 g_loss=-0.640 KID= 0.00740\n",
      "epoch 671, batch 3, d_loss=-0.412 g_loss=-0.721 KID= 0.00740\n",
      "epoch 671, batch 4, d_loss=-0.480 g_loss=-0.778 KID= 0.00740\n",
      "epoch 671, batch 5, d_loss=-0.365 g_loss=-0.659 KID= 0.00740\n",
      "epoch 671, batch 6, d_loss=-0.480 g_loss=-0.512 KID= 0.00740\n",
      "epoch 671, batch 7, d_loss=-0.543 g_loss=-0.347 KID= 0.00740\n",
      "epoch 671, batch 8, d_loss=-0.458 g_loss=-0.247 KID= 0.00740\n",
      "epoch 671, batch 9, d_loss=-0.487 g_loss=-0.073 KID= 0.00740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 671, batch 10, d_loss=-0.452 g_loss=-0.138 KID= 0.00740\n",
      "epoch 671, batch 11, d_loss=-0.320 g_loss=-0.195 KID= 0.00740\n",
      "epoch 671, batch 12, d_loss=-0.316 g_loss=-0.100 KID= 0.00740\n",
      "epoch 671, batch 13, d_loss=-0.415 g_loss=-0.017 KID= 0.00740\n",
      "epoch 671, batch 14, d_loss=-0.446 g_loss=0.048 KID= 0.00740\n",
      "epoch 671, batch 15, d_loss=-0.388 g_loss=0.067 KID= 0.00740\n",
      "epoch 671, batch 16, d_loss=-0.512 g_loss=0.051 KID= 0.00740\n",
      "epoch 671, batch 17, d_loss=-0.513 g_loss=0.003 KID= 0.00740\n",
      "epoch 671, batch 18, d_loss=-0.430 g_loss=-0.091 KID= 0.00740\n",
      "epoch 671, batch 19, d_loss=-0.384 g_loss=-0.173 KID= 0.00740\n",
      "epoch 672, batch 0, d_loss=-0.405 g_loss=-0.400 KID= 0.00740\n",
      "epoch 672, batch 1, d_loss=-0.404 g_loss=-0.684 KID= 0.00740\n",
      "epoch 672, batch 2, d_loss=-0.319 g_loss=-0.775 KID= 0.00740\n",
      "epoch 672, batch 3, d_loss=-0.464 g_loss=-0.854 KID= 0.00740\n",
      "epoch 672, batch 4, d_loss=-0.537 g_loss=-0.854 KID= 0.00740\n",
      "epoch 672, batch 5, d_loss=-0.390 g_loss=-0.663 KID= 0.00740\n",
      "epoch 672, batch 6, d_loss=-0.453 g_loss=-0.536 KID= 0.00740\n",
      "epoch 672, batch 7, d_loss=-0.511 g_loss=-0.458 KID= 0.00740\n",
      "epoch 672, batch 8, d_loss=-0.406 g_loss=-0.374 KID= 0.00740\n",
      "epoch 672, batch 9, d_loss=-0.446 g_loss=-0.359 KID= 0.00740\n",
      "epoch 672, batch 10, d_loss=-0.463 g_loss=-0.444 KID= 0.00740\n",
      "epoch 672, batch 11, d_loss=-0.376 g_loss=-0.532 KID= 0.00740\n",
      "epoch 672, batch 12, d_loss=-0.355 g_loss=-0.558 KID= 0.00740\n",
      "epoch 672, batch 13, d_loss=-0.448 g_loss=-0.502 KID= 0.00740\n",
      "epoch 672, batch 14, d_loss=-0.471 g_loss=-0.368 KID= 0.00740\n",
      "epoch 672, batch 15, d_loss=-0.459 g_loss=-0.322 KID= 0.00740\n",
      "epoch 672, batch 16, d_loss=-0.436 g_loss=-0.239 KID= 0.00740\n",
      "epoch 672, batch 17, d_loss=-0.551 g_loss=-0.365 KID= 0.00740\n",
      "epoch 672, batch 18, d_loss=-0.425 g_loss=-0.397 KID= 0.00740\n",
      "epoch 672, batch 19, d_loss=-0.434 g_loss=-0.372 KID= 0.00740\n",
      "epoch 673, batch 0, d_loss=-0.414 g_loss=-0.502 KID= 0.00740\n",
      "epoch 673, batch 1, d_loss=-0.432 g_loss=-0.707 KID= 0.00740\n",
      "epoch 673, batch 2, d_loss=-0.293 g_loss=-0.713 KID= 0.00740\n",
      "epoch 673, batch 3, d_loss=-0.417 g_loss=-0.767 KID= 0.00740\n",
      "epoch 673, batch 4, d_loss=-0.509 g_loss=-0.651 KID= 0.00740\n",
      "epoch 673, batch 5, d_loss=-0.466 g_loss=-0.431 KID= 0.00740\n",
      "epoch 673, batch 6, d_loss=-0.477 g_loss=-0.152 KID= 0.00740\n",
      "epoch 673, batch 7, d_loss=-0.603 g_loss=-0.090 KID= 0.00740\n",
      "epoch 673, batch 8, d_loss=-0.393 g_loss=0.125 KID= 0.00740\n",
      "epoch 673, batch 9, d_loss=-0.464 g_loss=0.227 KID= 0.00740\n",
      "epoch 673, batch 10, d_loss=-0.411 g_loss=0.175 KID= 0.00740\n",
      "epoch 673, batch 11, d_loss=-0.354 g_loss=-0.023 KID= 0.00740\n",
      "epoch 673, batch 12, d_loss=-0.307 g_loss=-0.028 KID= 0.00740\n",
      "epoch 673, batch 13, d_loss=-0.414 g_loss=-0.109 KID= 0.00740\n",
      "epoch 673, batch 14, d_loss=-0.428 g_loss=-0.094 KID= 0.00740\n",
      "epoch 673, batch 15, d_loss=-0.454 g_loss=-0.129 KID= 0.00740\n",
      "epoch 673, batch 16, d_loss=-0.445 g_loss=-0.111 KID= 0.00740\n",
      "epoch 673, batch 17, d_loss=-0.549 g_loss=-0.145 KID= 0.00740\n",
      "epoch 673, batch 18, d_loss=-0.370 g_loss=-0.145 KID= 0.00740\n",
      "epoch 673, batch 19, d_loss=-0.422 g_loss=-0.210 KID= 0.00740\n",
      "epoch 674, batch 0, d_loss=-0.445 g_loss=-0.349 KID= 0.00740\n",
      "epoch 674, batch 1, d_loss=-0.353 g_loss=-0.565 KID= 0.00740\n",
      "epoch 674, batch 2, d_loss=-0.318 g_loss=-0.742 KID= 0.00740\n",
      "epoch 674, batch 3, d_loss=-0.449 g_loss=-0.872 KID= 0.00740\n",
      "epoch 674, batch 4, d_loss=-0.499 g_loss=-0.827 KID= 0.00740\n",
      "epoch 674, batch 5, d_loss=-0.420 g_loss=-0.867 KID= 0.00740\n",
      "epoch 674, batch 6, d_loss=-0.483 g_loss=-0.866 KID= 0.00740\n",
      "epoch 674, batch 7, d_loss=-0.536 g_loss=-0.849 KID= 0.00740\n",
      "epoch 674, batch 8, d_loss=-0.370 g_loss=-0.687 KID= 0.00740\n",
      "epoch 674, batch 9, d_loss=-0.414 g_loss=-0.563 KID= 0.00740\n",
      "epoch 674, batch 10, d_loss=-0.443 g_loss=-0.446 KID= 0.00740\n",
      "epoch 674, batch 11, d_loss=-0.424 g_loss=-0.479 KID= 0.00740\n",
      "epoch 674, batch 12, d_loss=-0.371 g_loss=-0.236 KID= 0.00740\n",
      "epoch 674, batch 13, d_loss=-0.484 g_loss=-0.179 KID= 0.00740\n",
      "epoch 674, batch 14, d_loss=-0.478 g_loss=-0.061 KID= 0.00740\n",
      "epoch 674, batch 15, d_loss=-0.441 g_loss=-0.062 KID= 0.00740\n",
      "epoch 674, batch 16, d_loss=-0.453 g_loss=0.030 KID= 0.00740\n",
      "epoch 674, batch 17, d_loss=-0.577 g_loss=0.085 KID= 0.00740\n",
      "epoch 674, batch 18, d_loss=-0.389 g_loss=0.169 KID= 0.00740\n",
      "epoch 674, batch 19, d_loss=-0.446 g_loss=0.045 KID= 0.00740\n",
      "epoch 675, batch 0, d_loss=-0.425 g_loss=-0.150 KID= 0.00740\n",
      "epoch 675, batch 1, d_loss=-0.335 g_loss=-0.365 KID= 0.00740\n",
      "epoch 675, batch 2, d_loss=-0.304 g_loss=-0.405 KID= 0.00740\n",
      "epoch 675, batch 3, d_loss=-0.423 g_loss=-0.398 KID= 0.00740\n",
      "epoch 675, batch 4, d_loss=-0.543 g_loss=-0.336 KID= 0.00740\n",
      "epoch 675, batch 5, d_loss=-0.370 g_loss=-0.262 KID= 0.00740\n",
      "epoch 675, batch 6, d_loss=-0.486 g_loss=-0.238 KID= 0.00740\n",
      "epoch 675, batch 7, d_loss=-0.540 g_loss=-0.296 KID= 0.00740\n",
      "epoch 675, batch 8, d_loss=-0.348 g_loss=-0.205 KID= 0.00740\n",
      "epoch 675, batch 9, d_loss=-0.403 g_loss=-0.125 KID= 0.00740\n",
      "epoch 675, batch 10, d_loss=-0.436 g_loss=-0.184 KID= 0.00740\n",
      "epoch 675, batch 11, d_loss=-0.421 g_loss=-0.307 KID= 0.00740\n",
      "epoch 675, batch 12, d_loss=-0.353 g_loss=-0.408 KID= 0.00740\n",
      "epoch 675, batch 13, d_loss=-0.394 g_loss=-0.481 KID= 0.00740\n",
      "epoch 675, batch 14, d_loss=-0.517 g_loss=-0.455 KID= 0.00740\n",
      "epoch 675, batch 15, d_loss=-0.431 g_loss=-0.379 KID= 0.00740\n",
      "epoch 675, batch 16, d_loss=-0.470 g_loss=-0.384 KID= 0.00740\n",
      "epoch 675, batch 17, d_loss=-0.548 g_loss=-0.469 KID= 0.00740\n",
      "epoch 675, batch 18, d_loss=-0.350 g_loss=-0.401 KID= 0.00740\n",
      "epoch 675, batch 19, d_loss=-0.393 g_loss=-0.438 KID= 0.00740\n",
      "epoch 676, batch 0, d_loss=-0.427 g_loss=-0.536 KID= 0.00740\n",
      "epoch 676, batch 1, d_loss=-0.401 g_loss=-0.707 KID= 0.00740\n",
      "epoch 676, batch 2, d_loss=-0.380 g_loss=-0.653 KID= 0.00740\n",
      "epoch 676, batch 3, d_loss=-0.430 g_loss=-0.595 KID= 0.00740\n",
      "epoch 676, batch 4, d_loss=-0.511 g_loss=-0.589 KID= 0.00740\n",
      "epoch 676, batch 5, d_loss=-0.392 g_loss=-0.429 KID= 0.00740\n",
      "epoch 676, batch 6, d_loss=-0.458 g_loss=-0.398 KID= 0.00740\n",
      "epoch 676, batch 7, d_loss=-0.569 g_loss=-0.410 KID= 0.00740\n",
      "epoch 676, batch 8, d_loss=-0.451 g_loss=-0.330 KID= 0.00740\n",
      "epoch 676, batch 9, d_loss=-0.421 g_loss=-0.363 KID= 0.00740\n",
      "epoch 676, batch 10, d_loss=-0.449 g_loss=-0.503 KID= 0.00740\n",
      "epoch 676, batch 11, d_loss=-0.387 g_loss=-0.677 KID= 0.00740\n",
      "epoch 676, batch 12, d_loss=-0.344 g_loss=-0.699 KID= 0.00740\n",
      "epoch 676, batch 13, d_loss=-0.400 g_loss=-0.683 KID= 0.00740\n",
      "epoch 676, batch 14, d_loss=-0.442 g_loss=-0.639 KID= 0.00740\n",
      "epoch 676, batch 15, d_loss=-0.474 g_loss=-0.519 KID= 0.00740\n",
      "epoch 676, batch 16, d_loss=-0.455 g_loss=-0.323 KID= 0.00740\n",
      "epoch 676, batch 17, d_loss=-0.562 g_loss=-0.286 KID= 0.00740\n",
      "epoch 676, batch 18, d_loss=-0.419 g_loss=-0.121 KID= 0.00740\n",
      "epoch 676, batch 19, d_loss=-0.413 g_loss=-0.079 KID= 0.00740\n",
      "epoch 677, batch 0, d_loss=-0.434 g_loss=-0.171 KID= 0.00740\n",
      "epoch 677, batch 1, d_loss=-0.322 g_loss=-0.301 KID= 0.00740\n",
      "epoch 677, batch 2, d_loss=-0.320 g_loss=-0.340 KID= 0.00740\n",
      "epoch 677, batch 3, d_loss=-0.399 g_loss=-0.424 KID= 0.00740\n",
      "epoch 677, batch 4, d_loss=-0.496 g_loss=-0.380 KID= 0.00740\n",
      "epoch 677, batch 5, d_loss=-0.458 g_loss=-0.426 KID= 0.00740\n",
      "epoch 677, batch 6, d_loss=-0.524 g_loss=-0.376 KID= 0.00740\n",
      "epoch 677, batch 7, d_loss=-0.544 g_loss=-0.385 KID= 0.00740\n",
      "epoch 677, batch 8, d_loss=-0.281 g_loss=-0.285 KID= 0.00740\n",
      "epoch 677, batch 9, d_loss=-0.386 g_loss=-0.263 KID= 0.00740\n",
      "epoch 677, batch 10, d_loss=-0.455 g_loss=-0.386 KID= 0.00740\n",
      "epoch 677, batch 11, d_loss=-0.421 g_loss=-0.609 KID= 0.00740\n",
      "epoch 677, batch 12, d_loss=-0.373 g_loss=-0.744 KID= 0.00740\n",
      "epoch 677, batch 13, d_loss=-0.448 g_loss=-0.866 KID= 0.00740\n",
      "epoch 677, batch 14, d_loss=-0.480 g_loss=-0.949 KID= 0.00740\n",
      "epoch 677, batch 15, d_loss=-0.427 g_loss=-0.955 KID= 0.00740\n",
      "epoch 677, batch 16, d_loss=-0.485 g_loss=-0.855 KID= 0.00740\n",
      "epoch 677, batch 17, d_loss=-0.584 g_loss=-0.830 KID= 0.00740\n",
      "epoch 677, batch 18, d_loss=-0.386 g_loss=-0.635 KID= 0.00740\n",
      "epoch 677, batch 19, d_loss=-0.393 g_loss=-0.351 KID= 0.00740\n",
      "epoch 678, batch 0, d_loss=-0.408 g_loss=-0.262 KID= 0.00740\n",
      "epoch 678, batch 1, d_loss=-0.349 g_loss=-0.267 KID= 0.00740\n",
      "epoch 678, batch 2, d_loss=-0.432 g_loss=-0.078 KID= 0.00740\n",
      "epoch 678, batch 3, d_loss=-0.442 g_loss=0.124 KID= 0.00740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 678, batch 4, d_loss=-0.472 g_loss=0.251 KID= 0.00740\n",
      "epoch 678, batch 5, d_loss=-0.392 g_loss=0.249 KID= 0.00740\n",
      "epoch 678, batch 6, d_loss=-0.471 g_loss=0.405 KID= 0.00740\n",
      "epoch 678, batch 7, d_loss=-0.539 g_loss=0.407 KID= 0.00740\n",
      "epoch 678, batch 8, d_loss=-0.371 g_loss=0.488 KID= 0.00740\n",
      "epoch 678, batch 9, d_loss=-0.402 g_loss=0.329 KID= 0.00740\n",
      "epoch 678, batch 10, d_loss=-0.425 g_loss=-0.019 KID= 0.00740\n",
      "epoch 678, batch 11, d_loss=-0.368 g_loss=-0.431 KID= 0.00740\n",
      "epoch 678, batch 12, d_loss=-0.374 g_loss=-0.733 KID= 0.00740\n",
      "epoch 678, batch 13, d_loss=-0.416 g_loss=-0.945 KID= 0.00740\n",
      "epoch 678, batch 14, d_loss=-0.458 g_loss=-1.008 KID= 0.00740\n",
      "epoch 678, batch 15, d_loss=-0.445 g_loss=-0.932 KID= 0.00740\n",
      "epoch 678, batch 16, d_loss=-0.480 g_loss=-0.898 KID= 0.00740\n",
      "epoch 678, batch 17, d_loss=-0.539 g_loss=-0.926 KID= 0.00740\n",
      "epoch 678, batch 18, d_loss=-0.378 g_loss=-0.637 KID= 0.00740\n",
      "epoch 678, batch 19, d_loss=-0.414 g_loss=-0.344 KID= 0.00740\n",
      "epoch 679, batch 0, d_loss=-0.410 g_loss=-0.298 KID= 0.00740\n",
      "epoch 679, batch 1, d_loss=-0.372 g_loss=-0.342 KID= 0.00740\n",
      "epoch 679, batch 2, d_loss=-0.400 g_loss=-0.468 KID= 0.00740\n",
      "epoch 679, batch 3, d_loss=-0.418 g_loss=-0.550 KID= 0.00740\n",
      "epoch 679, batch 4, d_loss=-0.435 g_loss=-0.493 KID= 0.00740\n",
      "epoch 679, batch 5, d_loss=-0.466 g_loss=-0.421 KID= 0.00740\n",
      "epoch 679, batch 6, d_loss=-0.536 g_loss=-0.402 KID= 0.00740\n",
      "epoch 679, batch 7, d_loss=-0.573 g_loss=-0.325 KID= 0.00740\n",
      "epoch 679, batch 8, d_loss=-0.401 g_loss=-0.283 KID= 0.00740\n",
      "epoch 679, batch 9, d_loss=-0.388 g_loss=-0.241 KID= 0.00740\n",
      "epoch 679, batch 10, d_loss=-0.429 g_loss=-0.277 KID= 0.00740\n",
      "epoch 679, batch 11, d_loss=-0.380 g_loss=-0.339 KID= 0.00740\n",
      "epoch 679, batch 12, d_loss=-0.411 g_loss=-0.299 KID= 0.00740\n",
      "epoch 679, batch 13, d_loss=-0.437 g_loss=-0.225 KID= 0.00740\n",
      "epoch 679, batch 14, d_loss=-0.500 g_loss=-0.114 KID= 0.00740\n",
      "epoch 679, batch 15, d_loss=-0.421 g_loss=0.036 KID= 0.00740\n",
      "epoch 679, batch 16, d_loss=-0.520 g_loss=0.293 KID= 0.00740\n",
      "epoch 679, batch 17, d_loss=-0.542 g_loss=0.561 KID= 0.00740\n",
      "epoch 679, batch 18, d_loss=-0.386 g_loss=0.660 KID= 0.00740\n",
      "epoch 679, batch 19, d_loss=-0.431 g_loss=0.635 KID= 0.00740\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 680, batch 0, d_loss=-0.433 g_loss=0.331 KID= 0.00611\n",
      "epoch 680, batch 1, d_loss=-0.369 g_loss=-0.161 KID= 0.00611\n",
      "epoch 680, batch 2, d_loss=-0.357 g_loss=-0.597 KID= 0.00611\n",
      "epoch 680, batch 3, d_loss=-0.416 g_loss=-0.863 KID= 0.00611\n",
      "epoch 680, batch 4, d_loss=-0.448 g_loss=-1.044 KID= 0.00611\n",
      "epoch 680, batch 5, d_loss=-0.424 g_loss=-1.002 KID= 0.00611\n",
      "epoch 680, batch 6, d_loss=-0.474 g_loss=-0.904 KID= 0.00611\n",
      "epoch 680, batch 7, d_loss=-0.532 g_loss=-0.871 KID= 0.00611\n",
      "epoch 680, batch 8, d_loss=-0.332 g_loss=-0.606 KID= 0.00611\n",
      "epoch 680, batch 9, d_loss=-0.410 g_loss=-0.344 KID= 0.00611\n",
      "epoch 680, batch 10, d_loss=-0.414 g_loss=-0.138 KID= 0.00611\n",
      "epoch 680, batch 11, d_loss=-0.392 g_loss=-0.141 KID= 0.00611\n",
      "epoch 680, batch 12, d_loss=-0.428 g_loss=-0.137 KID= 0.00611\n",
      "epoch 680, batch 13, d_loss=-0.477 g_loss=-0.227 KID= 0.00611\n",
      "epoch 680, batch 14, d_loss=-0.443 g_loss=-0.246 KID= 0.00611\n",
      "epoch 680, batch 15, d_loss=-0.429 g_loss=-0.270 KID= 0.00611\n",
      "epoch 680, batch 16, d_loss=-0.479 g_loss=-0.202 KID= 0.00611\n",
      "epoch 680, batch 17, d_loss=-0.550 g_loss=-0.147 KID= 0.00611\n",
      "epoch 680, batch 18, d_loss=-0.436 g_loss=-0.030 KID= 0.00611\n",
      "epoch 680, batch 19, d_loss=-0.425 g_loss=0.084 KID= 0.00611\n",
      "epoch 681, batch 0, d_loss=-0.371 g_loss=0.011 KID= 0.00611\n",
      "epoch 681, batch 1, d_loss=-0.337 g_loss=-0.184 KID= 0.00611\n",
      "epoch 681, batch 2, d_loss=-0.445 g_loss=-0.323 KID= 0.00611\n",
      "epoch 681, batch 3, d_loss=-0.440 g_loss=-0.475 KID= 0.00611\n",
      "epoch 681, batch 4, d_loss=-0.462 g_loss=-0.492 KID= 0.00611\n",
      "epoch 681, batch 5, d_loss=-0.381 g_loss=-0.458 KID= 0.00611\n",
      "epoch 681, batch 6, d_loss=-0.505 g_loss=-0.417 KID= 0.00611\n",
      "epoch 681, batch 7, d_loss=-0.566 g_loss=-0.486 KID= 0.00611\n",
      "epoch 681, batch 8, d_loss=-0.368 g_loss=-0.422 KID= 0.00611\n",
      "epoch 681, batch 9, d_loss=-0.423 g_loss=-0.483 KID= 0.00611\n",
      "epoch 681, batch 10, d_loss=-0.436 g_loss=-0.602 KID= 0.00611\n",
      "epoch 681, batch 11, d_loss=-0.394 g_loss=-0.640 KID= 0.00611\n",
      "epoch 681, batch 12, d_loss=-0.471 g_loss=-0.703 KID= 0.00611\n",
      "epoch 681, batch 13, d_loss=-0.420 g_loss=-0.810 KID= 0.00611\n",
      "epoch 681, batch 14, d_loss=-0.471 g_loss=-0.827 KID= 0.00611\n",
      "epoch 681, batch 15, d_loss=-0.375 g_loss=-0.602 KID= 0.00611\n",
      "epoch 681, batch 16, d_loss=-0.452 g_loss=-0.410 KID= 0.00611\n",
      "epoch 681, batch 17, d_loss=-0.483 g_loss=-0.231 KID= 0.00611\n",
      "epoch 681, batch 18, d_loss=-0.424 g_loss=0.022 KID= 0.00611\n",
      "epoch 681, batch 19, d_loss=-0.436 g_loss=0.231 KID= 0.00611\n",
      "epoch 682, batch 0, d_loss=-0.438 g_loss=0.242 KID= 0.00611\n",
      "epoch 682, batch 1, d_loss=-0.387 g_loss=0.041 KID= 0.00611\n",
      "epoch 682, batch 2, d_loss=-0.395 g_loss=0.004 KID= 0.00611\n",
      "epoch 682, batch 3, d_loss=-0.483 g_loss=-0.159 KID= 0.00611\n",
      "epoch 682, batch 4, d_loss=-0.487 g_loss=-0.089 KID= 0.00611\n",
      "epoch 682, batch 5, d_loss=-0.402 g_loss=-0.219 KID= 0.00611\n",
      "epoch 682, batch 6, d_loss=-0.508 g_loss=-0.265 KID= 0.00611\n",
      "epoch 682, batch 7, d_loss=-0.505 g_loss=-0.319 KID= 0.00611\n",
      "epoch 682, batch 8, d_loss=-0.397 g_loss=-0.196 KID= 0.00611\n",
      "epoch 682, batch 9, d_loss=-0.423 g_loss=-0.087 KID= 0.00611\n",
      "epoch 682, batch 10, d_loss=-0.379 g_loss=-0.141 KID= 0.00611\n",
      "epoch 682, batch 11, d_loss=-0.437 g_loss=-0.297 KID= 0.00611\n",
      "epoch 682, batch 12, d_loss=-0.457 g_loss=-0.405 KID= 0.00611\n",
      "epoch 682, batch 13, d_loss=-0.390 g_loss=-0.608 KID= 0.00611\n",
      "epoch 682, batch 14, d_loss=-0.518 g_loss=-0.727 KID= 0.00611\n",
      "epoch 682, batch 15, d_loss=-0.425 g_loss=-0.814 KID= 0.00611\n",
      "epoch 682, batch 16, d_loss=-0.516 g_loss=-0.716 KID= 0.00611\n",
      "epoch 682, batch 17, d_loss=-0.549 g_loss=-0.662 KID= 0.00611\n",
      "epoch 682, batch 18, d_loss=-0.355 g_loss=-0.318 KID= 0.00611\n",
      "epoch 682, batch 19, d_loss=-0.410 g_loss=-0.044 KID= 0.00611\n",
      "epoch 683, batch 0, d_loss=-0.415 g_loss=0.056 KID= 0.00611\n",
      "epoch 683, batch 1, d_loss=-0.385 g_loss=0.013 KID= 0.00611\n",
      "epoch 683, batch 2, d_loss=-0.454 g_loss=-0.018 KID= 0.00611\n",
      "epoch 683, batch 3, d_loss=-0.479 g_loss=-0.151 KID= 0.00611\n",
      "epoch 683, batch 4, d_loss=-0.532 g_loss=-0.199 KID= 0.00611\n",
      "epoch 683, batch 5, d_loss=-0.426 g_loss=-0.359 KID= 0.00611\n",
      "epoch 683, batch 6, d_loss=-0.534 g_loss=-0.475 KID= 0.00611\n",
      "epoch 683, batch 7, d_loss=-0.521 g_loss=-0.422 KID= 0.00611\n",
      "epoch 683, batch 8, d_loss=-0.424 g_loss=-0.420 KID= 0.00611\n",
      "epoch 683, batch 9, d_loss=-0.424 g_loss=-0.417 KID= 0.00611\n",
      "epoch 683, batch 10, d_loss=-0.452 g_loss=-0.513 KID= 0.00611\n",
      "epoch 683, batch 11, d_loss=-0.379 g_loss=-0.657 KID= 0.00611\n",
      "epoch 683, batch 12, d_loss=-0.423 g_loss=-0.739 KID= 0.00611\n",
      "epoch 683, batch 13, d_loss=-0.483 g_loss=-0.873 KID= 0.00611\n",
      "epoch 683, batch 14, d_loss=-0.540 g_loss=-1.018 KID= 0.00611\n",
      "epoch 683, batch 15, d_loss=-0.470 g_loss=-0.975 KID= 0.00611\n",
      "epoch 683, batch 16, d_loss=-0.536 g_loss=-0.827 KID= 0.00611\n",
      "epoch 683, batch 17, d_loss=-0.521 g_loss=-0.689 KID= 0.00611\n",
      "epoch 683, batch 18, d_loss=-0.405 g_loss=-0.434 KID= 0.00611\n",
      "epoch 683, batch 19, d_loss=-0.403 g_loss=-0.212 KID= 0.00611\n",
      "epoch 684, batch 0, d_loss=-0.406 g_loss=-0.248 KID= 0.00611\n",
      "epoch 684, batch 1, d_loss=-0.363 g_loss=-0.317 KID= 0.00611\n",
      "epoch 684, batch 2, d_loss=-0.462 g_loss=-0.392 KID= 0.00611\n",
      "epoch 684, batch 3, d_loss=-0.454 g_loss=-0.414 KID= 0.00611\n",
      "epoch 684, batch 4, d_loss=-0.499 g_loss=-0.413 KID= 0.00611\n",
      "epoch 684, batch 5, d_loss=-0.416 g_loss=-0.525 KID= 0.00611\n",
      "epoch 684, batch 6, d_loss=-0.571 g_loss=-0.450 KID= 0.00611\n",
      "epoch 684, batch 7, d_loss=-0.500 g_loss=-0.402 KID= 0.00611\n",
      "epoch 684, batch 8, d_loss=-0.463 g_loss=-0.352 KID= 0.00611\n",
      "epoch 684, batch 9, d_loss=-0.447 g_loss=-0.364 KID= 0.00611\n",
      "epoch 684, batch 10, d_loss=-0.411 g_loss=-0.517 KID= 0.00611\n",
      "epoch 684, batch 11, d_loss=-0.354 g_loss=-0.765 KID= 0.00611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 684, batch 12, d_loss=-0.418 g_loss=-0.815 KID= 0.00611\n",
      "epoch 684, batch 13, d_loss=-0.462 g_loss=-0.946 KID= 0.00611\n",
      "epoch 684, batch 14, d_loss=-0.520 g_loss=-1.090 KID= 0.00611\n",
      "epoch 684, batch 15, d_loss=-0.454 g_loss=-1.151 KID= 0.00611\n",
      "epoch 684, batch 16, d_loss=-0.538 g_loss=-0.973 KID= 0.00611\n",
      "epoch 684, batch 17, d_loss=-0.499 g_loss=-0.829 KID= 0.00611\n",
      "epoch 684, batch 18, d_loss=-0.426 g_loss=-0.407 KID= 0.00611\n",
      "epoch 684, batch 19, d_loss=-0.450 g_loss=-0.117 KID= 0.00611\n",
      "epoch 685, batch 0, d_loss=-0.460 g_loss=-0.080 KID= 0.00611\n",
      "epoch 685, batch 1, d_loss=-0.353 g_loss=-0.155 KID= 0.00611\n",
      "epoch 685, batch 2, d_loss=-0.476 g_loss=-0.195 KID= 0.00611\n",
      "epoch 685, batch 3, d_loss=-0.408 g_loss=-0.200 KID= 0.00611\n",
      "epoch 685, batch 4, d_loss=-0.454 g_loss=-0.088 KID= 0.00611\n",
      "epoch 685, batch 5, d_loss=-0.430 g_loss=-0.129 KID= 0.00611\n",
      "epoch 685, batch 6, d_loss=-0.534 g_loss=-0.100 KID= 0.00611\n",
      "epoch 685, batch 7, d_loss=-0.515 g_loss=-0.005 KID= 0.00611\n",
      "epoch 685, batch 8, d_loss=-0.443 g_loss=-0.139 KID= 0.00611\n",
      "epoch 685, batch 9, d_loss=-0.433 g_loss=-0.188 KID= 0.00611\n",
      "epoch 685, batch 10, d_loss=-0.393 g_loss=-0.373 KID= 0.00611\n",
      "epoch 685, batch 11, d_loss=-0.383 g_loss=-0.563 KID= 0.00611\n",
      "epoch 685, batch 12, d_loss=-0.414 g_loss=-0.744 KID= 0.00611\n",
      "epoch 685, batch 13, d_loss=-0.469 g_loss=-0.972 KID= 0.00611\n",
      "epoch 685, batch 14, d_loss=-0.500 g_loss=-1.026 KID= 0.00611\n",
      "epoch 685, batch 15, d_loss=-0.372 g_loss=-0.813 KID= 0.00611\n",
      "epoch 685, batch 16, d_loss=-0.540 g_loss=-0.708 KID= 0.00611\n",
      "epoch 685, batch 17, d_loss=-0.545 g_loss=-0.530 KID= 0.00611\n",
      "epoch 685, batch 18, d_loss=-0.418 g_loss=-0.238 KID= 0.00611\n",
      "epoch 685, batch 19, d_loss=-0.424 g_loss=-0.007 KID= 0.00611\n",
      "epoch 686, batch 0, d_loss=-0.387 g_loss=0.049 KID= 0.00611\n",
      "epoch 686, batch 1, d_loss=-0.378 g_loss=0.022 KID= 0.00611\n",
      "epoch 686, batch 2, d_loss=-0.491 g_loss=-0.084 KID= 0.00611\n",
      "epoch 686, batch 3, d_loss=-0.456 g_loss=-0.200 KID= 0.00611\n",
      "epoch 686, batch 4, d_loss=-0.502 g_loss=-0.318 KID= 0.00611\n",
      "epoch 686, batch 5, d_loss=-0.413 g_loss=-0.395 KID= 0.00611\n",
      "epoch 686, batch 6, d_loss=-0.557 g_loss=-0.387 KID= 0.00611\n",
      "epoch 686, batch 7, d_loss=-0.521 g_loss=-0.228 KID= 0.00611\n",
      "epoch 686, batch 8, d_loss=-0.412 g_loss=-0.015 KID= 0.00611\n",
      "epoch 686, batch 9, d_loss=-0.430 g_loss=0.158 KID= 0.00611\n",
      "epoch 686, batch 10, d_loss=-0.450 g_loss=0.044 KID= 0.00611\n",
      "epoch 686, batch 11, d_loss=-0.344 g_loss=-0.080 KID= 0.00611\n",
      "epoch 686, batch 12, d_loss=-0.412 g_loss=-0.433 KID= 0.00611\n",
      "epoch 686, batch 13, d_loss=-0.434 g_loss=-0.584 KID= 0.00611\n",
      "epoch 686, batch 14, d_loss=-0.483 g_loss=-0.707 KID= 0.00611\n",
      "epoch 686, batch 15, d_loss=-0.463 g_loss=-0.780 KID= 0.00611\n",
      "epoch 686, batch 16, d_loss=-0.592 g_loss=-0.713 KID= 0.00611\n",
      "epoch 686, batch 17, d_loss=-0.507 g_loss=-0.788 KID= 0.00611\n",
      "epoch 686, batch 18, d_loss=-0.442 g_loss=-0.588 KID= 0.00611\n",
      "epoch 686, batch 19, d_loss=-0.438 g_loss=-0.377 KID= 0.00611\n",
      "epoch 687, batch 0, d_loss=-0.434 g_loss=-0.335 KID= 0.00611\n",
      "epoch 687, batch 1, d_loss=-0.406 g_loss=-0.332 KID= 0.00611\n",
      "epoch 687, batch 2, d_loss=-0.482 g_loss=-0.446 KID= 0.00611\n",
      "epoch 687, batch 3, d_loss=-0.463 g_loss=-0.373 KID= 0.00611\n",
      "epoch 687, batch 4, d_loss=-0.496 g_loss=-0.306 KID= 0.00611\n",
      "epoch 687, batch 5, d_loss=-0.445 g_loss=-0.260 KID= 0.00611\n",
      "epoch 687, batch 6, d_loss=-0.591 g_loss=-0.252 KID= 0.00611\n",
      "epoch 687, batch 7, d_loss=-0.536 g_loss=-0.292 KID= 0.00611\n",
      "epoch 687, batch 8, d_loss=-0.432 g_loss=-0.186 KID= 0.00611\n",
      "epoch 687, batch 9, d_loss=-0.345 g_loss=-0.003 KID= 0.00611\n",
      "epoch 687, batch 10, d_loss=-0.413 g_loss=0.014 KID= 0.00611\n",
      "epoch 687, batch 11, d_loss=-0.324 g_loss=-0.057 KID= 0.00611\n",
      "epoch 687, batch 12, d_loss=-0.469 g_loss=-0.123 KID= 0.00611\n",
      "epoch 687, batch 13, d_loss=-0.468 g_loss=-0.168 KID= 0.00611\n",
      "epoch 687, batch 14, d_loss=-0.502 g_loss=-0.321 KID= 0.00611\n",
      "epoch 687, batch 15, d_loss=-0.489 g_loss=-0.442 KID= 0.00611\n",
      "epoch 687, batch 16, d_loss=-0.566 g_loss=-0.446 KID= 0.00611\n",
      "epoch 687, batch 17, d_loss=-0.519 g_loss=-0.516 KID= 0.00611\n",
      "epoch 687, batch 18, d_loss=-0.386 g_loss=-0.314 KID= 0.00611\n",
      "epoch 687, batch 19, d_loss=-0.403 g_loss=-0.188 KID= 0.00611\n",
      "epoch 688, batch 0, d_loss=-0.493 g_loss=-0.184 KID= 0.00611\n",
      "epoch 688, batch 1, d_loss=-0.399 g_loss=-0.163 KID= 0.00611\n",
      "epoch 688, batch 2, d_loss=-0.423 g_loss=-0.195 KID= 0.00611\n",
      "epoch 688, batch 3, d_loss=-0.506 g_loss=-0.058 KID= 0.00611\n",
      "epoch 688, batch 4, d_loss=-0.429 g_loss=0.034 KID= 0.00611\n",
      "epoch 688, batch 5, d_loss=-0.506 g_loss=0.003 KID= 0.00611\n",
      "epoch 688, batch 6, d_loss=-0.567 g_loss=0.050 KID= 0.00611\n",
      "epoch 688, batch 7, d_loss=-0.596 g_loss=0.021 KID= 0.00611\n",
      "epoch 688, batch 8, d_loss=-0.420 g_loss=0.070 KID= 0.00611\n",
      "epoch 688, batch 9, d_loss=-0.412 g_loss=0.113 KID= 0.00611\n",
      "epoch 688, batch 10, d_loss=-0.424 g_loss=-0.019 KID= 0.00611\n",
      "epoch 688, batch 11, d_loss=-0.400 g_loss=-0.181 KID= 0.00611\n",
      "epoch 688, batch 12, d_loss=-0.476 g_loss=-0.408 KID= 0.00611\n",
      "epoch 688, batch 13, d_loss=-0.436 g_loss=-0.469 KID= 0.00611\n",
      "epoch 688, batch 14, d_loss=-0.497 g_loss=-0.597 KID= 0.00611\n",
      "epoch 688, batch 15, d_loss=-0.483 g_loss=-0.583 KID= 0.00611\n",
      "epoch 688, batch 16, d_loss=-0.544 g_loss=-0.419 KID= 0.00611\n",
      "epoch 688, batch 17, d_loss=-0.548 g_loss=-0.358 KID= 0.00611\n",
      "epoch 688, batch 18, d_loss=-0.407 g_loss=-0.120 KID= 0.00611\n",
      "epoch 688, batch 19, d_loss=-0.422 g_loss=0.034 KID= 0.00611\n",
      "epoch 689, batch 0, d_loss=-0.439 g_loss=-0.059 KID= 0.00611\n",
      "epoch 689, batch 1, d_loss=-0.345 g_loss=-0.157 KID= 0.00611\n",
      "epoch 689, batch 2, d_loss=-0.463 g_loss=-0.322 KID= 0.00611\n",
      "epoch 689, batch 3, d_loss=-0.492 g_loss=-0.472 KID= 0.00611\n",
      "epoch 689, batch 4, d_loss=-0.515 g_loss=-0.562 KID= 0.00611\n",
      "epoch 689, batch 5, d_loss=-0.457 g_loss=-0.728 KID= 0.00611\n",
      "epoch 689, batch 6, d_loss=-0.543 g_loss=-0.663 KID= 0.00611\n",
      "epoch 689, batch 7, d_loss=-0.526 g_loss=-0.494 KID= 0.00611\n",
      "epoch 689, batch 8, d_loss=-0.461 g_loss=-0.310 KID= 0.00611\n",
      "epoch 689, batch 9, d_loss=-0.444 g_loss=-0.045 KID= 0.00611\n",
      "epoch 689, batch 10, d_loss=-0.425 g_loss=0.072 KID= 0.00611\n",
      "epoch 689, batch 11, d_loss=-0.321 g_loss=0.048 KID= 0.00611\n",
      "epoch 689, batch 12, d_loss=-0.509 g_loss=-0.015 KID= 0.00611\n",
      "epoch 689, batch 13, d_loss=-0.487 g_loss=-0.160 KID= 0.00611\n",
      "epoch 689, batch 14, d_loss=-0.474 g_loss=-0.225 KID= 0.00611\n",
      "epoch 689, batch 15, d_loss=-0.527 g_loss=-0.375 KID= 0.00611\n",
      "epoch 689, batch 16, d_loss=-0.555 g_loss=-0.343 KID= 0.00611\n",
      "epoch 689, batch 17, d_loss=-0.531 g_loss=-0.382 KID= 0.00611\n",
      "epoch 689, batch 18, d_loss=-0.457 g_loss=-0.233 KID= 0.00611\n",
      "epoch 689, batch 19, d_loss=-0.441 g_loss=-0.139 KID= 0.00611\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 690, batch 0, d_loss=-0.413 g_loss=-0.209 KID= 0.00835\n",
      "epoch 690, batch 1, d_loss=-0.352 g_loss=-0.272 KID= 0.00835\n",
      "epoch 690, batch 2, d_loss=-0.480 g_loss=-0.270 KID= 0.00835\n",
      "epoch 690, batch 3, d_loss=-0.476 g_loss=-0.365 KID= 0.00835\n",
      "epoch 690, batch 4, d_loss=-0.478 g_loss=-0.440 KID= 0.00835\n",
      "epoch 690, batch 5, d_loss=-0.431 g_loss=-0.639 KID= 0.00835\n",
      "epoch 690, batch 6, d_loss=-0.578 g_loss=-0.710 KID= 0.00835\n",
      "epoch 690, batch 7, d_loss=-0.540 g_loss=-0.662 KID= 0.00835\n",
      "epoch 690, batch 8, d_loss=-0.485 g_loss=-0.587 KID= 0.00835\n",
      "epoch 690, batch 9, d_loss=-0.427 g_loss=-0.587 KID= 0.00835\n",
      "epoch 690, batch 10, d_loss=-0.400 g_loss=-0.522 KID= 0.00835\n",
      "epoch 690, batch 11, d_loss=-0.394 g_loss=-0.422 KID= 0.00835\n",
      "epoch 690, batch 12, d_loss=-0.425 g_loss=-0.306 KID= 0.00835\n",
      "epoch 690, batch 13, d_loss=-0.520 g_loss=-0.298 KID= 0.00835\n",
      "epoch 690, batch 14, d_loss=-0.441 g_loss=-0.368 KID= 0.00835\n",
      "epoch 690, batch 15, d_loss=-0.517 g_loss=-0.423 KID= 0.00835\n",
      "epoch 690, batch 16, d_loss=-0.553 g_loss=-0.388 KID= 0.00835\n",
      "epoch 690, batch 17, d_loss=-0.530 g_loss=-0.307 KID= 0.00835\n",
      "epoch 690, batch 18, d_loss=-0.455 g_loss=-0.049 KID= 0.00835\n",
      "epoch 690, batch 19, d_loss=-0.459 g_loss=0.221 KID= 0.00835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 691, batch 0, d_loss=-0.488 g_loss=0.115 KID= 0.00835\n",
      "epoch 691, batch 1, d_loss=-0.413 g_loss=-0.023 KID= 0.00835\n",
      "epoch 691, batch 2, d_loss=-0.465 g_loss=-0.135 KID= 0.00835\n",
      "epoch 691, batch 3, d_loss=-0.478 g_loss=-0.318 KID= 0.00835\n",
      "epoch 691, batch 4, d_loss=-0.480 g_loss=-0.474 KID= 0.00835\n",
      "epoch 691, batch 5, d_loss=-0.496 g_loss=-0.550 KID= 0.00835\n",
      "epoch 691, batch 6, d_loss=-0.600 g_loss=-0.552 KID= 0.00835\n",
      "epoch 691, batch 7, d_loss=-0.534 g_loss=-0.461 KID= 0.00835\n",
      "epoch 691, batch 8, d_loss=-0.462 g_loss=-0.142 KID= 0.00835\n",
      "epoch 691, batch 9, d_loss=-0.506 g_loss=0.031 KID= 0.00835\n",
      "epoch 691, batch 10, d_loss=-0.517 g_loss=-0.006 KID= 0.00835\n",
      "epoch 691, batch 11, d_loss=-0.377 g_loss=0.047 KID= 0.00835\n",
      "epoch 691, batch 12, d_loss=-0.488 g_loss=0.078 KID= 0.00835\n",
      "epoch 691, batch 13, d_loss=-0.500 g_loss=0.071 KID= 0.00835\n",
      "epoch 691, batch 14, d_loss=-0.393 g_loss=0.073 KID= 0.00835\n",
      "epoch 691, batch 15, d_loss=-0.518 g_loss=-0.078 KID= 0.00835\n",
      "epoch 691, batch 16, d_loss=-0.603 g_loss=0.003 KID= 0.00835\n",
      "epoch 691, batch 17, d_loss=-0.554 g_loss=0.081 KID= 0.00835\n",
      "epoch 691, batch 18, d_loss=-0.421 g_loss=0.149 KID= 0.00835\n",
      "epoch 691, batch 19, d_loss=-0.434 g_loss=0.089 KID= 0.00835\n",
      "epoch 692, batch 0, d_loss=-0.394 g_loss=-0.038 KID= 0.00835\n",
      "epoch 692, batch 1, d_loss=-0.354 g_loss=-0.144 KID= 0.00835\n",
      "epoch 692, batch 2, d_loss=-0.515 g_loss=-0.259 KID= 0.00835\n",
      "epoch 692, batch 3, d_loss=-0.514 g_loss=-0.355 KID= 0.00835\n",
      "epoch 692, batch 4, d_loss=-0.463 g_loss=-0.443 KID= 0.00835\n",
      "epoch 692, batch 5, d_loss=-0.495 g_loss=-0.510 KID= 0.00835\n",
      "epoch 692, batch 6, d_loss=-0.547 g_loss=-0.604 KID= 0.00835\n",
      "epoch 692, batch 7, d_loss=-0.562 g_loss=-0.581 KID= 0.00835\n",
      "epoch 692, batch 8, d_loss=-0.431 g_loss=-0.343 KID= 0.00835\n",
      "epoch 692, batch 9, d_loss=-0.429 g_loss=-0.251 KID= 0.00835\n",
      "epoch 692, batch 10, d_loss=-0.501 g_loss=-0.381 KID= 0.00835\n",
      "epoch 692, batch 11, d_loss=-0.375 g_loss=-0.322 KID= 0.00835\n",
      "epoch 692, batch 12, d_loss=-0.432 g_loss=-0.352 KID= 0.00835\n",
      "epoch 692, batch 13, d_loss=-0.545 g_loss=-0.412 KID= 0.00835\n",
      "epoch 692, batch 14, d_loss=-0.450 g_loss=-0.395 KID= 0.00835\n",
      "epoch 692, batch 15, d_loss=-0.527 g_loss=-0.446 KID= 0.00835\n",
      "epoch 692, batch 16, d_loss=-0.598 g_loss=-0.519 KID= 0.00835\n",
      "epoch 692, batch 17, d_loss=-0.548 g_loss=-0.538 KID= 0.00835\n",
      "epoch 692, batch 18, d_loss=-0.398 g_loss=-0.463 KID= 0.00835\n",
      "epoch 692, batch 19, d_loss=-0.420 g_loss=-0.399 KID= 0.00835\n",
      "epoch 693, batch 0, d_loss=-0.500 g_loss=-0.373 KID= 0.00835\n",
      "epoch 693, batch 1, d_loss=-0.424 g_loss=-0.264 KID= 0.00835\n",
      "epoch 693, batch 2, d_loss=-0.468 g_loss=-0.213 KID= 0.00835\n",
      "epoch 693, batch 3, d_loss=-0.520 g_loss=-0.226 KID= 0.00835\n",
      "epoch 693, batch 4, d_loss=-0.453 g_loss=-0.310 KID= 0.00835\n",
      "epoch 693, batch 5, d_loss=-0.514 g_loss=-0.363 KID= 0.00835\n",
      "epoch 693, batch 6, d_loss=-0.556 g_loss=-0.229 KID= 0.00835\n",
      "epoch 693, batch 7, d_loss=-0.534 g_loss=-0.169 KID= 0.00835\n",
      "epoch 693, batch 8, d_loss=-0.375 g_loss=-0.038 KID= 0.00835\n",
      "epoch 693, batch 9, d_loss=-0.465 g_loss=0.148 KID= 0.00835\n",
      "epoch 693, batch 10, d_loss=-0.452 g_loss=0.062 KID= 0.00835\n",
      "epoch 693, batch 11, d_loss=-0.421 g_loss=-0.013 KID= 0.00835\n",
      "epoch 693, batch 12, d_loss=-0.544 g_loss=-0.145 KID= 0.00835\n",
      "epoch 693, batch 13, d_loss=-0.456 g_loss=-0.303 KID= 0.00835\n",
      "epoch 693, batch 14, d_loss=-0.452 g_loss=-0.504 KID= 0.00835\n",
      "epoch 693, batch 15, d_loss=-0.500 g_loss=-0.708 KID= 0.00835\n",
      "epoch 693, batch 16, d_loss=-0.557 g_loss=-0.768 KID= 0.00835\n",
      "epoch 693, batch 17, d_loss=-0.556 g_loss=-0.807 KID= 0.00835\n",
      "epoch 693, batch 18, d_loss=-0.396 g_loss=-0.572 KID= 0.00835\n",
      "epoch 693, batch 19, d_loss=-0.412 g_loss=-0.334 KID= 0.00835\n",
      "epoch 694, batch 0, d_loss=-0.485 g_loss=-0.267 KID= 0.00835\n",
      "epoch 694, batch 1, d_loss=-0.340 g_loss=-0.239 KID= 0.00835\n",
      "epoch 694, batch 2, d_loss=-0.491 g_loss=-0.150 KID= 0.00835\n",
      "epoch 694, batch 3, d_loss=-0.453 g_loss=-0.109 KID= 0.00835\n",
      "epoch 694, batch 4, d_loss=-0.489 g_loss=-0.093 KID= 0.00835\n",
      "epoch 694, batch 5, d_loss=-0.509 g_loss=-0.082 KID= 0.00835\n",
      "epoch 694, batch 6, d_loss=-0.565 g_loss=-0.117 KID= 0.00835\n",
      "epoch 694, batch 7, d_loss=-0.505 g_loss=-0.141 KID= 0.00835\n",
      "epoch 694, batch 8, d_loss=-0.444 g_loss=-0.072 KID= 0.00835\n",
      "epoch 694, batch 9, d_loss=-0.455 g_loss=-0.124 KID= 0.00835\n",
      "epoch 694, batch 10, d_loss=-0.436 g_loss=-0.266 KID= 0.00835\n",
      "epoch 694, batch 11, d_loss=-0.376 g_loss=-0.500 KID= 0.00835\n",
      "epoch 694, batch 12, d_loss=-0.521 g_loss=-0.639 KID= 0.00835\n",
      "epoch 694, batch 13, d_loss=-0.531 g_loss=-0.740 KID= 0.00835\n",
      "epoch 694, batch 14, d_loss=-0.414 g_loss=-0.832 KID= 0.00835\n",
      "epoch 694, batch 15, d_loss=-0.522 g_loss=-0.894 KID= 0.00835\n",
      "epoch 694, batch 16, d_loss=-0.603 g_loss=-0.893 KID= 0.00835\n",
      "epoch 694, batch 17, d_loss=-0.545 g_loss=-0.868 KID= 0.00835\n",
      "epoch 694, batch 18, d_loss=-0.452 g_loss=-0.700 KID= 0.00835\n",
      "epoch 694, batch 19, d_loss=-0.507 g_loss=-0.511 KID= 0.00835\n",
      "epoch 695, batch 0, d_loss=-0.426 g_loss=-0.499 KID= 0.00835\n",
      "epoch 695, batch 1, d_loss=-0.367 g_loss=-0.328 KID= 0.00835\n",
      "epoch 695, batch 2, d_loss=-0.495 g_loss=-0.251 KID= 0.00835\n",
      "epoch 695, batch 3, d_loss=-0.455 g_loss=-0.161 KID= 0.00835\n",
      "epoch 695, batch 4, d_loss=-0.484 g_loss=-0.144 KID= 0.00835\n",
      "epoch 695, batch 5, d_loss=-0.499 g_loss=-0.209 KID= 0.00835\n",
      "epoch 695, batch 6, d_loss=-0.624 g_loss=-0.172 KID= 0.00835\n",
      "epoch 695, batch 7, d_loss=-0.570 g_loss=0.034 KID= 0.00835\n",
      "epoch 695, batch 8, d_loss=-0.439 g_loss=0.247 KID= 0.00835\n",
      "epoch 695, batch 9, d_loss=-0.419 g_loss=0.375 KID= 0.00835\n",
      "epoch 695, batch 10, d_loss=-0.480 g_loss=0.302 KID= 0.00835\n",
      "epoch 695, batch 11, d_loss=-0.415 g_loss=0.187 KID= 0.00835\n",
      "epoch 695, batch 12, d_loss=-0.488 g_loss=0.029 KID= 0.00835\n",
      "epoch 695, batch 13, d_loss=-0.507 g_loss=-0.110 KID= 0.00835\n",
      "epoch 695, batch 14, d_loss=-0.382 g_loss=-0.218 KID= 0.00835\n",
      "epoch 695, batch 15, d_loss=-0.569 g_loss=-0.304 KID= 0.00835\n",
      "epoch 695, batch 16, d_loss=-0.595 g_loss=-0.357 KID= 0.00835\n",
      "epoch 695, batch 17, d_loss=-0.537 g_loss=-0.371 KID= 0.00835\n",
      "epoch 695, batch 18, d_loss=-0.425 g_loss=-0.251 KID= 0.00835\n",
      "epoch 695, batch 19, d_loss=-0.458 g_loss=-0.133 KID= 0.00835\n",
      "epoch 696, batch 0, d_loss=-0.439 g_loss=-0.151 KID= 0.00835\n",
      "epoch 696, batch 1, d_loss=-0.446 g_loss=-0.271 KID= 0.00835\n",
      "epoch 696, batch 2, d_loss=-0.503 g_loss=-0.396 KID= 0.00835\n",
      "epoch 696, batch 3, d_loss=-0.510 g_loss=-0.468 KID= 0.00835\n",
      "epoch 696, batch 4, d_loss=-0.493 g_loss=-0.664 KID= 0.00835\n",
      "epoch 696, batch 5, d_loss=-0.496 g_loss=-0.697 KID= 0.00835\n",
      "epoch 696, batch 6, d_loss=-0.598 g_loss=-0.632 KID= 0.00835\n",
      "epoch 696, batch 7, d_loss=-0.523 g_loss=-0.629 KID= 0.00835\n",
      "epoch 696, batch 8, d_loss=-0.472 g_loss=-0.367 KID= 0.00835\n",
      "epoch 696, batch 9, d_loss=-0.437 g_loss=-0.180 KID= 0.00835\n",
      "epoch 696, batch 10, d_loss=-0.401 g_loss=-0.237 KID= 0.00835\n",
      "epoch 696, batch 11, d_loss=-0.381 g_loss=-0.276 KID= 0.00835\n",
      "epoch 696, batch 12, d_loss=-0.521 g_loss=-0.350 KID= 0.00835\n",
      "epoch 696, batch 13, d_loss=-0.472 g_loss=-0.372 KID= 0.00835\n",
      "epoch 696, batch 14, d_loss=-0.398 g_loss=-0.517 KID= 0.00835\n",
      "epoch 696, batch 15, d_loss=-0.555 g_loss=-0.607 KID= 0.00835\n",
      "epoch 696, batch 16, d_loss=-0.608 g_loss=-0.555 KID= 0.00835\n",
      "epoch 696, batch 17, d_loss=-0.502 g_loss=-0.421 KID= 0.00835\n",
      "epoch 696, batch 18, d_loss=-0.441 g_loss=-0.315 KID= 0.00835\n",
      "epoch 696, batch 19, d_loss=-0.463 g_loss=-0.187 KID= 0.00835\n",
      "epoch 697, batch 0, d_loss=-0.441 g_loss=-0.122 KID= 0.00835\n",
      "epoch 697, batch 1, d_loss=-0.362 g_loss=-0.023 KID= 0.00835\n",
      "epoch 697, batch 2, d_loss=-0.502 g_loss=0.137 KID= 0.00835\n",
      "epoch 697, batch 3, d_loss=-0.500 g_loss=0.260 KID= 0.00835\n",
      "epoch 697, batch 4, d_loss=-0.470 g_loss=0.201 KID= 0.00835\n",
      "epoch 697, batch 5, d_loss=-0.555 g_loss=-0.040 KID= 0.00835\n",
      "epoch 697, batch 6, d_loss=-0.613 g_loss=-0.183 KID= 0.00835\n",
      "epoch 697, batch 7, d_loss=-0.519 g_loss=-0.287 KID= 0.00835\n",
      "epoch 697, batch 8, d_loss=-0.457 g_loss=-0.433 KID= 0.00835\n",
      "epoch 697, batch 9, d_loss=-0.414 g_loss=-0.530 KID= 0.00835\n",
      "epoch 697, batch 10, d_loss=-0.466 g_loss=-0.649 KID= 0.00835\n",
      "epoch 697, batch 11, d_loss=-0.426 g_loss=-0.662 KID= 0.00835\n",
      "epoch 697, batch 12, d_loss=-0.545 g_loss=-0.689 KID= 0.00835\n",
      "epoch 697, batch 13, d_loss=-0.488 g_loss=-0.758 KID= 0.00835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 697, batch 14, d_loss=-0.397 g_loss=-0.752 KID= 0.00835\n",
      "epoch 697, batch 15, d_loss=-0.560 g_loss=-0.783 KID= 0.00835\n",
      "epoch 697, batch 16, d_loss=-0.567 g_loss=-0.606 KID= 0.00835\n",
      "epoch 697, batch 17, d_loss=-0.514 g_loss=-0.436 KID= 0.00835\n",
      "epoch 697, batch 18, d_loss=-0.438 g_loss=-0.031 KID= 0.00835\n",
      "epoch 697, batch 19, d_loss=-0.462 g_loss=0.325 KID= 0.00835\n",
      "epoch 698, batch 0, d_loss=-0.482 g_loss=0.390 KID= 0.00835\n",
      "epoch 698, batch 1, d_loss=-0.425 g_loss=0.349 KID= 0.00835\n",
      "epoch 698, batch 2, d_loss=-0.501 g_loss=0.248 KID= 0.00835\n",
      "epoch 698, batch 3, d_loss=-0.488 g_loss=0.145 KID= 0.00835\n",
      "epoch 698, batch 4, d_loss=-0.388 g_loss=-0.005 KID= 0.00835\n",
      "epoch 698, batch 5, d_loss=-0.522 g_loss=-0.248 KID= 0.00835\n",
      "epoch 698, batch 6, d_loss=-0.625 g_loss=-0.412 KID= 0.00835\n",
      "epoch 698, batch 7, d_loss=-0.560 g_loss=-0.526 KID= 0.00835\n",
      "epoch 698, batch 8, d_loss=-0.432 g_loss=-0.458 KID= 0.00835\n",
      "epoch 698, batch 9, d_loss=-0.456 g_loss=-0.414 KID= 0.00835\n",
      "epoch 698, batch 10, d_loss=-0.464 g_loss=-0.411 KID= 0.00835\n",
      "epoch 698, batch 11, d_loss=-0.408 g_loss=-0.296 KID= 0.00835\n",
      "epoch 698, batch 12, d_loss=-0.526 g_loss=-0.350 KID= 0.00835\n",
      "epoch 698, batch 13, d_loss=-0.475 g_loss=-0.521 KID= 0.00835\n",
      "epoch 698, batch 14, d_loss=-0.396 g_loss=-0.671 KID= 0.00835\n",
      "epoch 698, batch 15, d_loss=-0.544 g_loss=-0.775 KID= 0.00835\n",
      "epoch 698, batch 16, d_loss=-0.591 g_loss=-0.785 KID= 0.00835\n",
      "epoch 698, batch 17, d_loss=-0.533 g_loss=-0.828 KID= 0.00835\n",
      "epoch 698, batch 18, d_loss=-0.427 g_loss=-0.714 KID= 0.00835\n",
      "epoch 698, batch 19, d_loss=-0.452 g_loss=-0.589 KID= 0.00835\n",
      "epoch 699, batch 0, d_loss=-0.447 g_loss=-0.537 KID= 0.00835\n",
      "epoch 699, batch 1, d_loss=-0.451 g_loss=-0.426 KID= 0.00835\n",
      "epoch 699, batch 2, d_loss=-0.471 g_loss=-0.273 KID= 0.00835\n",
      "epoch 699, batch 3, d_loss=-0.514 g_loss=-0.132 KID= 0.00835\n",
      "epoch 699, batch 4, d_loss=-0.375 g_loss=-0.177 KID= 0.00835\n",
      "epoch 699, batch 5, d_loss=-0.505 g_loss=-0.255 KID= 0.00835\n",
      "epoch 699, batch 6, d_loss=-0.670 g_loss=-0.345 KID= 0.00835\n",
      "epoch 699, batch 7, d_loss=-0.504 g_loss=-0.486 KID= 0.00835\n",
      "epoch 699, batch 8, d_loss=-0.433 g_loss=-0.465 KID= 0.00835\n",
      "epoch 699, batch 9, d_loss=-0.496 g_loss=-0.436 KID= 0.00835\n",
      "epoch 699, batch 10, d_loss=-0.467 g_loss=-0.439 KID= 0.00835\n",
      "epoch 699, batch 11, d_loss=-0.363 g_loss=-0.280 KID= 0.00835\n",
      "epoch 699, batch 12, d_loss=-0.509 g_loss=-0.227 KID= 0.00835\n",
      "epoch 699, batch 13, d_loss=-0.514 g_loss=-0.241 KID= 0.00835\n",
      "epoch 699, batch 14, d_loss=-0.423 g_loss=-0.388 KID= 0.00835\n",
      "epoch 699, batch 15, d_loss=-0.591 g_loss=-0.622 KID= 0.00835\n",
      "epoch 699, batch 16, d_loss=-0.626 g_loss=-0.746 KID= 0.00835\n",
      "epoch 699, batch 17, d_loss=-0.554 g_loss=-0.840 KID= 0.00835\n",
      "epoch 699, batch 18, d_loss=-0.428 g_loss=-0.627 KID= 0.00835\n",
      "epoch 699, batch 19, d_loss=-0.486 g_loss=-0.570 KID= 0.00835\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 700, batch 0, d_loss=-0.415 g_loss=-0.499 KID= 0.00715\n",
      "epoch 700, batch 1, d_loss=-0.438 g_loss=-0.341 KID= 0.00715\n",
      "epoch 700, batch 2, d_loss=-0.499 g_loss=-0.179 KID= 0.00715\n",
      "epoch 700, batch 3, d_loss=-0.530 g_loss=-0.051 KID= 0.00715\n",
      "epoch 700, batch 4, d_loss=-0.425 g_loss=-0.097 KID= 0.00715\n",
      "epoch 700, batch 5, d_loss=-0.525 g_loss=-0.176 KID= 0.00715\n",
      "epoch 700, batch 6, d_loss=-0.615 g_loss=-0.268 KID= 0.00715\n",
      "epoch 700, batch 7, d_loss=-0.489 g_loss=-0.378 KID= 0.00715\n",
      "epoch 700, batch 8, d_loss=-0.453 g_loss=-0.376 KID= 0.00715\n",
      "epoch 700, batch 9, d_loss=-0.450 g_loss=-0.345 KID= 0.00715\n",
      "epoch 700, batch 10, d_loss=-0.438 g_loss=-0.344 KID= 0.00715\n",
      "epoch 700, batch 11, d_loss=-0.395 g_loss=-0.272 KID= 0.00715\n",
      "epoch 700, batch 12, d_loss=-0.514 g_loss=-0.199 KID= 0.00715\n",
      "epoch 700, batch 13, d_loss=-0.518 g_loss=-0.162 KID= 0.00715\n",
      "epoch 700, batch 14, d_loss=-0.360 g_loss=-0.362 KID= 0.00715\n",
      "epoch 700, batch 15, d_loss=-0.507 g_loss=-0.593 KID= 0.00715\n",
      "epoch 700, batch 16, d_loss=-0.600 g_loss=-0.565 KID= 0.00715\n",
      "epoch 700, batch 17, d_loss=-0.504 g_loss=-0.659 KID= 0.00715\n",
      "epoch 700, batch 18, d_loss=-0.478 g_loss=-0.762 KID= 0.00715\n",
      "epoch 700, batch 19, d_loss=-0.501 g_loss=-0.799 KID= 0.00715\n",
      "epoch 701, batch 0, d_loss=-0.387 g_loss=-0.604 KID= 0.00715\n",
      "epoch 701, batch 1, d_loss=-0.398 g_loss=-0.365 KID= 0.00715\n",
      "epoch 701, batch 2, d_loss=-0.511 g_loss=-0.062 KID= 0.00715\n",
      "epoch 701, batch 3, d_loss=-0.473 g_loss=0.175 KID= 0.00715\n",
      "epoch 701, batch 4, d_loss=-0.360 g_loss=0.155 KID= 0.00715\n",
      "epoch 701, batch 5, d_loss=-0.555 g_loss=0.063 KID= 0.00715\n",
      "epoch 701, batch 6, d_loss=-0.626 g_loss=0.059 KID= 0.00715\n",
      "epoch 701, batch 7, d_loss=-0.586 g_loss=0.038 KID= 0.00715\n",
      "epoch 701, batch 8, d_loss=-0.395 g_loss=-0.066 KID= 0.00715\n",
      "epoch 701, batch 9, d_loss=-0.449 g_loss=-0.232 KID= 0.00715\n",
      "epoch 701, batch 10, d_loss=-0.480 g_loss=-0.332 KID= 0.00715\n",
      "epoch 701, batch 11, d_loss=-0.405 g_loss=-0.388 KID= 0.00715\n",
      "epoch 701, batch 12, d_loss=-0.526 g_loss=-0.453 KID= 0.00715\n",
      "epoch 701, batch 13, d_loss=-0.539 g_loss=-0.428 KID= 0.00715\n",
      "epoch 701, batch 14, d_loss=-0.326 g_loss=-0.482 KID= 0.00715\n",
      "epoch 701, batch 15, d_loss=-0.620 g_loss=-0.602 KID= 0.00715\n",
      "epoch 701, batch 16, d_loss=-0.629 g_loss=-0.647 KID= 0.00715\n",
      "epoch 701, batch 17, d_loss=-0.537 g_loss=-0.649 KID= 0.00715\n",
      "epoch 701, batch 18, d_loss=-0.506 g_loss=-0.652 KID= 0.00715\n",
      "epoch 701, batch 19, d_loss=-0.493 g_loss=-0.612 KID= 0.00715\n",
      "epoch 702, batch 0, d_loss=-0.383 g_loss=-0.435 KID= 0.00715\n",
      "epoch 702, batch 1, d_loss=-0.412 g_loss=-0.341 KID= 0.00715\n",
      "epoch 702, batch 2, d_loss=-0.506 g_loss=-0.218 KID= 0.00715\n",
      "epoch 702, batch 3, d_loss=-0.516 g_loss=-0.105 KID= 0.00715\n",
      "epoch 702, batch 4, d_loss=-0.371 g_loss=-0.173 KID= 0.00715\n",
      "epoch 702, batch 5, d_loss=-0.585 g_loss=-0.255 KID= 0.00715\n",
      "epoch 702, batch 6, d_loss=-0.609 g_loss=-0.305 KID= 0.00715\n",
      "epoch 702, batch 7, d_loss=-0.515 g_loss=-0.386 KID= 0.00715\n",
      "epoch 702, batch 8, d_loss=-0.441 g_loss=-0.393 KID= 0.00715\n",
      "epoch 702, batch 9, d_loss=-0.478 g_loss=-0.269 KID= 0.00715\n",
      "epoch 702, batch 10, d_loss=-0.403 g_loss=-0.272 KID= 0.00715\n",
      "epoch 702, batch 11, d_loss=-0.426 g_loss=-0.240 KID= 0.00715\n",
      "epoch 702, batch 12, d_loss=-0.521 g_loss=-0.299 KID= 0.00715\n",
      "epoch 702, batch 13, d_loss=-0.558 g_loss=-0.385 KID= 0.00715\n",
      "epoch 702, batch 14, d_loss=-0.382 g_loss=-0.535 KID= 0.00715\n",
      "epoch 702, batch 15, d_loss=-0.600 g_loss=-0.690 KID= 0.00715\n",
      "epoch 702, batch 16, d_loss=-0.580 g_loss=-0.915 KID= 0.00715\n",
      "epoch 702, batch 17, d_loss=-0.489 g_loss=-0.903 KID= 0.00715\n",
      "epoch 702, batch 18, d_loss=-0.475 g_loss=-0.771 KID= 0.00715\n",
      "epoch 702, batch 19, d_loss=-0.489 g_loss=-0.683 KID= 0.00715\n",
      "epoch 703, batch 0, d_loss=-0.385 g_loss=-0.586 KID= 0.00715\n",
      "epoch 703, batch 1, d_loss=-0.380 g_loss=-0.495 KID= 0.00715\n",
      "epoch 703, batch 2, d_loss=-0.507 g_loss=-0.378 KID= 0.00715\n",
      "epoch 703, batch 3, d_loss=-0.514 g_loss=-0.330 KID= 0.00715\n",
      "epoch 703, batch 4, d_loss=-0.342 g_loss=-0.389 KID= 0.00715\n",
      "epoch 703, batch 5, d_loss=-0.601 g_loss=-0.605 KID= 0.00715\n",
      "epoch 703, batch 6, d_loss=-0.589 g_loss=-0.574 KID= 0.00715\n",
      "epoch 703, batch 7, d_loss=-0.541 g_loss=-0.545 KID= 0.00715\n",
      "epoch 703, batch 8, d_loss=-0.499 g_loss=-0.342 KID= 0.00715\n",
      "epoch 703, batch 9, d_loss=-0.502 g_loss=-0.272 KID= 0.00715\n",
      "epoch 703, batch 10, d_loss=-0.408 g_loss=-0.124 KID= 0.00715\n",
      "epoch 703, batch 11, d_loss=-0.318 g_loss=0.080 KID= 0.00715\n",
      "epoch 703, batch 12, d_loss=-0.501 g_loss=0.230 KID= 0.00715\n",
      "epoch 703, batch 13, d_loss=-0.534 g_loss=0.278 KID= 0.00715\n",
      "epoch 703, batch 14, d_loss=-0.340 g_loss=0.145 KID= 0.00715\n",
      "epoch 703, batch 15, d_loss=-0.587 g_loss=-0.070 KID= 0.00715\n",
      "epoch 703, batch 16, d_loss=-0.594 g_loss=-0.366 KID= 0.00715\n",
      "epoch 703, batch 17, d_loss=-0.519 g_loss=-0.549 KID= 0.00715\n",
      "epoch 703, batch 18, d_loss=-0.501 g_loss=-0.663 KID= 0.00715\n",
      "epoch 703, batch 19, d_loss=-0.545 g_loss=-0.636 KID= 0.00715\n",
      "epoch 704, batch 0, d_loss=-0.435 g_loss=-0.588 KID= 0.00715\n",
      "epoch 704, batch 1, d_loss=-0.374 g_loss=-0.400 KID= 0.00715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 704, batch 2, d_loss=-0.508 g_loss=-0.284 KID= 0.00715\n",
      "epoch 704, batch 3, d_loss=-0.519 g_loss=-0.339 KID= 0.00715\n",
      "epoch 704, batch 4, d_loss=-0.358 g_loss=-0.398 KID= 0.00715\n",
      "epoch 704, batch 5, d_loss=-0.617 g_loss=-0.419 KID= 0.00715\n",
      "epoch 704, batch 6, d_loss=-0.566 g_loss=-0.428 KID= 0.00715\n",
      "epoch 704, batch 7, d_loss=-0.488 g_loss=-0.447 KID= 0.00715\n",
      "epoch 704, batch 8, d_loss=-0.461 g_loss=-0.511 KID= 0.00715\n",
      "epoch 704, batch 9, d_loss=-0.488 g_loss=-0.511 KID= 0.00715\n",
      "epoch 704, batch 10, d_loss=-0.456 g_loss=-0.521 KID= 0.00715\n",
      "epoch 704, batch 11, d_loss=-0.350 g_loss=-0.443 KID= 0.00715\n",
      "epoch 704, batch 12, d_loss=-0.548 g_loss=-0.388 KID= 0.00715\n",
      "epoch 704, batch 13, d_loss=-0.554 g_loss=-0.261 KID= 0.00715\n",
      "epoch 704, batch 14, d_loss=-0.333 g_loss=-0.266 KID= 0.00715\n",
      "epoch 704, batch 15, d_loss=-0.558 g_loss=-0.317 KID= 0.00715\n",
      "epoch 704, batch 16, d_loss=-0.608 g_loss=-0.416 KID= 0.00715\n",
      "epoch 704, batch 17, d_loss=-0.487 g_loss=-0.549 KID= 0.00715\n",
      "epoch 704, batch 18, d_loss=-0.424 g_loss=-0.525 KID= 0.00715\n",
      "epoch 704, batch 19, d_loss=-0.491 g_loss=-0.481 KID= 0.00715\n",
      "epoch 705, batch 0, d_loss=-0.451 g_loss=-0.381 KID= 0.00715\n",
      "epoch 705, batch 1, d_loss=-0.353 g_loss=-0.257 KID= 0.00715\n",
      "epoch 705, batch 2, d_loss=-0.493 g_loss=-0.159 KID= 0.00715\n",
      "epoch 705, batch 3, d_loss=-0.544 g_loss=-0.202 KID= 0.00715\n",
      "epoch 705, batch 4, d_loss=-0.365 g_loss=-0.323 KID= 0.00715\n",
      "epoch 705, batch 5, d_loss=-0.510 g_loss=-0.563 KID= 0.00715\n",
      "epoch 705, batch 6, d_loss=-0.555 g_loss=-0.697 KID= 0.00715\n",
      "epoch 705, batch 7, d_loss=-0.500 g_loss=-0.834 KID= 0.00715\n",
      "epoch 705, batch 8, d_loss=-0.468 g_loss=-0.895 KID= 0.00715\n",
      "epoch 705, batch 9, d_loss=-0.559 g_loss=-0.897 KID= 0.00715\n",
      "epoch 705, batch 10, d_loss=-0.422 g_loss=-0.775 KID= 0.00715\n",
      "epoch 705, batch 11, d_loss=-0.400 g_loss=-0.505 KID= 0.00715\n",
      "epoch 705, batch 12, d_loss=-0.472 g_loss=-0.288 KID= 0.00715\n",
      "epoch 705, batch 13, d_loss=-0.552 g_loss=-0.227 KID= 0.00715\n",
      "epoch 705, batch 14, d_loss=-0.366 g_loss=-0.236 KID= 0.00715\n",
      "epoch 705, batch 15, d_loss=-0.531 g_loss=-0.335 KID= 0.00715\n",
      "epoch 705, batch 16, d_loss=-0.578 g_loss=-0.504 KID= 0.00715\n",
      "epoch 705, batch 17, d_loss=-0.499 g_loss=-0.614 KID= 0.00715\n",
      "epoch 705, batch 18, d_loss=-0.476 g_loss=-0.459 KID= 0.00715\n",
      "epoch 705, batch 19, d_loss=-0.529 g_loss=-0.383 KID= 0.00715\n",
      "epoch 706, batch 0, d_loss=-0.453 g_loss=-0.328 KID= 0.00715\n",
      "epoch 706, batch 1, d_loss=-0.332 g_loss=-0.232 KID= 0.00715\n",
      "epoch 706, batch 2, d_loss=-0.504 g_loss=-0.148 KID= 0.00715\n",
      "epoch 706, batch 3, d_loss=-0.517 g_loss=-0.210 KID= 0.00715\n",
      "epoch 706, batch 4, d_loss=-0.405 g_loss=-0.362 KID= 0.00715\n",
      "epoch 706, batch 5, d_loss=-0.607 g_loss=-0.624 KID= 0.00715\n",
      "epoch 706, batch 6, d_loss=-0.544 g_loss=-0.681 KID= 0.00715\n",
      "epoch 706, batch 7, d_loss=-0.535 g_loss=-0.730 KID= 0.00715\n",
      "epoch 706, batch 8, d_loss=-0.438 g_loss=-0.689 KID= 0.00715\n",
      "epoch 706, batch 9, d_loss=-0.489 g_loss=-0.578 KID= 0.00715\n",
      "epoch 706, batch 10, d_loss=-0.446 g_loss=-0.589 KID= 0.00715\n",
      "epoch 706, batch 11, d_loss=-0.360 g_loss=-0.367 KID= 0.00715\n",
      "epoch 706, batch 12, d_loss=-0.483 g_loss=-0.173 KID= 0.00715\n",
      "epoch 706, batch 13, d_loss=-0.543 g_loss=-0.130 KID= 0.00715\n",
      "epoch 706, batch 14, d_loss=-0.378 g_loss=-0.090 KID= 0.00715\n",
      "epoch 706, batch 15, d_loss=-0.543 g_loss=-0.205 KID= 0.00715\n",
      "epoch 706, batch 16, d_loss=-0.598 g_loss=-0.277 KID= 0.00715\n",
      "epoch 706, batch 17, d_loss=-0.530 g_loss=-0.556 KID= 0.00715\n",
      "epoch 706, batch 18, d_loss=-0.464 g_loss=-0.630 KID= 0.00715\n",
      "epoch 706, batch 19, d_loss=-0.522 g_loss=-0.595 KID= 0.00715\n",
      "epoch 707, batch 0, d_loss=-0.405 g_loss=-0.550 KID= 0.00715\n",
      "epoch 707, batch 1, d_loss=-0.387 g_loss=-0.353 KID= 0.00715\n",
      "epoch 707, batch 2, d_loss=-0.503 g_loss=-0.177 KID= 0.00715\n",
      "epoch 707, batch 3, d_loss=-0.505 g_loss=-0.074 KID= 0.00715\n",
      "epoch 707, batch 4, d_loss=-0.427 g_loss=-0.028 KID= 0.00715\n",
      "epoch 707, batch 5, d_loss=-0.570 g_loss=-0.075 KID= 0.00715\n",
      "epoch 707, batch 6, d_loss=-0.566 g_loss=-0.218 KID= 0.00715\n",
      "epoch 707, batch 7, d_loss=-0.468 g_loss=-0.392 KID= 0.00715\n",
      "epoch 707, batch 8, d_loss=-0.455 g_loss=-0.505 KID= 0.00715\n",
      "epoch 707, batch 9, d_loss=-0.537 g_loss=-0.518 KID= 0.00715\n",
      "epoch 707, batch 10, d_loss=-0.469 g_loss=-0.549 KID= 0.00715\n",
      "epoch 707, batch 11, d_loss=-0.338 g_loss=-0.449 KID= 0.00715\n",
      "epoch 707, batch 12, d_loss=-0.485 g_loss=-0.355 KID= 0.00715\n",
      "epoch 707, batch 13, d_loss=-0.473 g_loss=-0.259 KID= 0.00715\n",
      "epoch 707, batch 14, d_loss=-0.420 g_loss=-0.239 KID= 0.00715\n",
      "epoch 707, batch 15, d_loss=-0.541 g_loss=-0.324 KID= 0.00715\n",
      "epoch 707, batch 16, d_loss=-0.582 g_loss=-0.404 KID= 0.00715\n",
      "epoch 707, batch 17, d_loss=-0.509 g_loss=-0.566 KID= 0.00715\n",
      "epoch 707, batch 18, d_loss=-0.468 g_loss=-0.643 KID= 0.00715\n",
      "epoch 707, batch 19, d_loss=-0.494 g_loss=-0.634 KID= 0.00715\n",
      "epoch 708, batch 0, d_loss=-0.470 g_loss=-0.707 KID= 0.00715\n",
      "epoch 708, batch 1, d_loss=-0.334 g_loss=-0.504 KID= 0.00715\n",
      "epoch 708, batch 2, d_loss=-0.471 g_loss=-0.326 KID= 0.00715\n",
      "epoch 708, batch 3, d_loss=-0.517 g_loss=-0.260 KID= 0.00715\n",
      "epoch 708, batch 4, d_loss=-0.391 g_loss=-0.291 KID= 0.00715\n",
      "epoch 708, batch 5, d_loss=-0.566 g_loss=-0.318 KID= 0.00715\n",
      "epoch 708, batch 6, d_loss=-0.560 g_loss=-0.387 KID= 0.00715\n",
      "epoch 708, batch 7, d_loss=-0.544 g_loss=-0.547 KID= 0.00715\n",
      "epoch 708, batch 8, d_loss=-0.371 g_loss=-0.570 KID= 0.00715\n",
      "epoch 708, batch 9, d_loss=-0.510 g_loss=-0.620 KID= 0.00715\n",
      "epoch 708, batch 10, d_loss=-0.495 g_loss=-0.481 KID= 0.00715\n",
      "epoch 708, batch 11, d_loss=-0.366 g_loss=-0.200 KID= 0.00715\n",
      "epoch 708, batch 12, d_loss=-0.548 g_loss=-0.002 KID= 0.00715\n",
      "epoch 708, batch 13, d_loss=-0.561 g_loss=0.074 KID= 0.00715\n",
      "epoch 708, batch 14, d_loss=-0.389 g_loss=0.011 KID= 0.00715\n",
      "epoch 708, batch 15, d_loss=-0.561 g_loss=-0.124 KID= 0.00715\n",
      "epoch 708, batch 16, d_loss=-0.596 g_loss=-0.220 KID= 0.00715\n",
      "epoch 708, batch 17, d_loss=-0.531 g_loss=-0.481 KID= 0.00715\n",
      "epoch 708, batch 18, d_loss=-0.446 g_loss=-0.665 KID= 0.00715\n",
      "epoch 708, batch 19, d_loss=-0.505 g_loss=-0.746 KID= 0.00715\n",
      "epoch 709, batch 0, d_loss=-0.494 g_loss=-0.851 KID= 0.00715\n",
      "epoch 709, batch 1, d_loss=-0.333 g_loss=-0.661 KID= 0.00715\n",
      "epoch 709, batch 2, d_loss=-0.492 g_loss=-0.525 KID= 0.00715\n",
      "epoch 709, batch 3, d_loss=-0.511 g_loss=-0.468 KID= 0.00715\n",
      "epoch 709, batch 4, d_loss=-0.410 g_loss=-0.458 KID= 0.00715\n",
      "epoch 709, batch 5, d_loss=-0.530 g_loss=-0.408 KID= 0.00715\n",
      "epoch 709, batch 6, d_loss=-0.520 g_loss=-0.460 KID= 0.00715\n",
      "epoch 709, batch 7, d_loss=-0.551 g_loss=-0.583 KID= 0.00715\n",
      "epoch 709, batch 8, d_loss=-0.450 g_loss=-0.506 KID= 0.00715\n",
      "epoch 709, batch 9, d_loss=-0.567 g_loss=-0.488 KID= 0.00715\n",
      "epoch 709, batch 10, d_loss=-0.472 g_loss=-0.469 KID= 0.00715\n",
      "epoch 709, batch 11, d_loss=-0.347 g_loss=-0.351 KID= 0.00715\n",
      "epoch 709, batch 12, d_loss=-0.479 g_loss=-0.280 KID= 0.00715\n",
      "epoch 709, batch 13, d_loss=-0.485 g_loss=-0.105 KID= 0.00715\n",
      "epoch 709, batch 14, d_loss=-0.446 g_loss=-0.117 KID= 0.00715\n",
      "epoch 709, batch 15, d_loss=-0.573 g_loss=-0.111 KID= 0.00715\n",
      "epoch 709, batch 16, d_loss=-0.557 g_loss=-0.261 KID= 0.00715\n",
      "epoch 709, batch 17, d_loss=-0.564 g_loss=-0.427 KID= 0.00715\n",
      "epoch 709, batch 18, d_loss=-0.410 g_loss=-0.604 KID= 0.00715\n",
      "epoch 709, batch 19, d_loss=-0.511 g_loss=-0.805 KID= 0.00715\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 710, batch 0, d_loss=-0.472 g_loss=-0.891 KID= 0.00561\n",
      "epoch 710, batch 1, d_loss=-0.364 g_loss=-0.804 KID= 0.00561\n",
      "epoch 710, batch 2, d_loss=-0.480 g_loss=-0.671 KID= 0.00561\n",
      "epoch 710, batch 3, d_loss=-0.502 g_loss=-0.515 KID= 0.00561\n",
      "epoch 710, batch 4, d_loss=-0.413 g_loss=-0.303 KID= 0.00561\n",
      "epoch 710, batch 5, d_loss=-0.605 g_loss=-0.168 KID= 0.00561\n",
      "epoch 710, batch 6, d_loss=-0.585 g_loss=-0.090 KID= 0.00561\n",
      "epoch 710, batch 7, d_loss=-0.476 g_loss=-0.192 KID= 0.00561\n",
      "epoch 710, batch 8, d_loss=-0.475 g_loss=-0.152 KID= 0.00561\n",
      "epoch 710, batch 9, d_loss=-0.530 g_loss=-0.086 KID= 0.00561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 710, batch 10, d_loss=-0.474 g_loss=-0.174 KID= 0.00561\n",
      "epoch 710, batch 11, d_loss=-0.406 g_loss=-0.198 KID= 0.00561\n",
      "epoch 710, batch 12, d_loss=-0.502 g_loss=-0.082 KID= 0.00561\n",
      "epoch 710, batch 13, d_loss=-0.519 g_loss=-0.129 KID= 0.00561\n",
      "epoch 710, batch 14, d_loss=-0.476 g_loss=-0.105 KID= 0.00561\n",
      "epoch 710, batch 15, d_loss=-0.515 g_loss=-0.158 KID= 0.00561\n",
      "epoch 710, batch 16, d_loss=-0.560 g_loss=-0.258 KID= 0.00561\n",
      "epoch 710, batch 17, d_loss=-0.503 g_loss=-0.430 KID= 0.00561\n",
      "epoch 710, batch 18, d_loss=-0.418 g_loss=-0.485 KID= 0.00561\n",
      "epoch 710, batch 19, d_loss=-0.566 g_loss=-0.531 KID= 0.00561\n",
      "epoch 711, batch 0, d_loss=-0.435 g_loss=-0.609 KID= 0.00561\n",
      "epoch 711, batch 1, d_loss=-0.330 g_loss=-0.459 KID= 0.00561\n",
      "epoch 711, batch 2, d_loss=-0.485 g_loss=-0.419 KID= 0.00561\n",
      "epoch 711, batch 3, d_loss=-0.517 g_loss=-0.452 KID= 0.00561\n",
      "epoch 711, batch 4, d_loss=-0.457 g_loss=-0.354 KID= 0.00561\n",
      "epoch 711, batch 5, d_loss=-0.562 g_loss=-0.192 KID= 0.00561\n",
      "epoch 711, batch 6, d_loss=-0.613 g_loss=-0.083 KID= 0.00561\n",
      "epoch 711, batch 7, d_loss=-0.490 g_loss=-0.175 KID= 0.00561\n",
      "epoch 711, batch 8, d_loss=-0.455 g_loss=-0.337 KID= 0.00561\n",
      "epoch 711, batch 9, d_loss=-0.556 g_loss=-0.500 KID= 0.00561\n",
      "epoch 711, batch 10, d_loss=-0.458 g_loss=-0.590 KID= 0.00561\n",
      "epoch 711, batch 11, d_loss=-0.396 g_loss=-0.464 KID= 0.00561\n",
      "epoch 711, batch 12, d_loss=-0.497 g_loss=-0.373 KID= 0.00561\n",
      "epoch 711, batch 13, d_loss=-0.523 g_loss=-0.285 KID= 0.00561\n",
      "epoch 711, batch 14, d_loss=-0.476 g_loss=-0.167 KID= 0.00561\n",
      "epoch 711, batch 15, d_loss=-0.584 g_loss=-0.158 KID= 0.00561\n",
      "epoch 711, batch 16, d_loss=-0.630 g_loss=-0.261 KID= 0.00561\n",
      "epoch 711, batch 17, d_loss=-0.467 g_loss=-0.251 KID= 0.00561\n",
      "epoch 711, batch 18, d_loss=-0.446 g_loss=-0.214 KID= 0.00561\n",
      "epoch 711, batch 19, d_loss=-0.553 g_loss=-0.335 KID= 0.00561\n",
      "epoch 712, batch 0, d_loss=-0.437 g_loss=-0.404 KID= 0.00561\n",
      "epoch 712, batch 1, d_loss=-0.389 g_loss=-0.371 KID= 0.00561\n",
      "epoch 712, batch 2, d_loss=-0.505 g_loss=-0.415 KID= 0.00561\n",
      "epoch 712, batch 3, d_loss=-0.508 g_loss=-0.383 KID= 0.00561\n",
      "epoch 712, batch 4, d_loss=-0.460 g_loss=-0.400 KID= 0.00561\n",
      "epoch 712, batch 5, d_loss=-0.561 g_loss=-0.445 KID= 0.00561\n",
      "epoch 712, batch 6, d_loss=-0.609 g_loss=-0.563 KID= 0.00561\n",
      "epoch 712, batch 7, d_loss=-0.449 g_loss=-0.768 KID= 0.00561\n",
      "epoch 712, batch 8, d_loss=-0.406 g_loss=-0.883 KID= 0.00561\n",
      "epoch 712, batch 9, d_loss=-0.489 g_loss=-0.896 KID= 0.00561\n",
      "epoch 712, batch 10, d_loss=-0.453 g_loss=-0.770 KID= 0.00561\n",
      "epoch 712, batch 11, d_loss=-0.394 g_loss=-0.519 KID= 0.00561\n",
      "epoch 712, batch 12, d_loss=-0.504 g_loss=-0.127 KID= 0.00561\n",
      "epoch 712, batch 13, d_loss=-0.487 g_loss=0.194 KID= 0.00561\n",
      "epoch 712, batch 14, d_loss=-0.460 g_loss=0.400 KID= 0.00561\n",
      "epoch 712, batch 15, d_loss=-0.532 g_loss=0.542 KID= 0.00561\n",
      "epoch 712, batch 16, d_loss=-0.576 g_loss=0.473 KID= 0.00561\n",
      "epoch 712, batch 17, d_loss=-0.532 g_loss=0.466 KID= 0.00561\n",
      "epoch 712, batch 18, d_loss=-0.465 g_loss=0.463 KID= 0.00561\n",
      "epoch 712, batch 19, d_loss=-0.504 g_loss=0.076 KID= 0.00561\n",
      "epoch 713, batch 0, d_loss=-0.466 g_loss=-0.432 KID= 0.00561\n",
      "epoch 713, batch 1, d_loss=-0.375 g_loss=-0.616 KID= 0.00561\n",
      "epoch 713, batch 2, d_loss=-0.490 g_loss=-0.812 KID= 0.00561\n",
      "epoch 713, batch 3, d_loss=-0.514 g_loss=-0.851 KID= 0.00561\n",
      "epoch 713, batch 4, d_loss=-0.444 g_loss=-0.780 KID= 0.00561\n",
      "epoch 713, batch 5, d_loss=-0.529 g_loss=-0.677 KID= 0.00561\n",
      "epoch 713, batch 6, d_loss=-0.605 g_loss=-0.765 KID= 0.00561\n",
      "epoch 713, batch 7, d_loss=-0.422 g_loss=-0.672 KID= 0.00561\n",
      "epoch 713, batch 8, d_loss=-0.436 g_loss=-0.440 KID= 0.00561\n",
      "epoch 713, batch 9, d_loss=-0.525 g_loss=-0.464 KID= 0.00561\n",
      "epoch 713, batch 10, d_loss=-0.398 g_loss=-0.590 KID= 0.00561\n",
      "epoch 713, batch 11, d_loss=-0.357 g_loss=-0.617 KID= 0.00561\n",
      "epoch 713, batch 12, d_loss=-0.523 g_loss=-0.662 KID= 0.00561\n",
      "epoch 713, batch 13, d_loss=-0.504 g_loss=-0.522 KID= 0.00561\n",
      "epoch 713, batch 14, d_loss=-0.444 g_loss=-0.348 KID= 0.00561\n",
      "epoch 713, batch 15, d_loss=-0.544 g_loss=-0.097 KID= 0.00561\n",
      "epoch 713, batch 16, d_loss=-0.577 g_loss=-0.017 KID= 0.00561\n",
      "epoch 713, batch 17, d_loss=-0.485 g_loss=0.020 KID= 0.00561\n",
      "epoch 713, batch 18, d_loss=-0.434 g_loss=0.050 KID= 0.00561\n",
      "epoch 713, batch 19, d_loss=-0.467 g_loss=-0.162 KID= 0.00561\n",
      "epoch 714, batch 0, d_loss=-0.431 g_loss=-0.416 KID= 0.00561\n",
      "epoch 714, batch 1, d_loss=-0.421 g_loss=-0.464 KID= 0.00561\n",
      "epoch 714, batch 2, d_loss=-0.568 g_loss=-0.559 KID= 0.00561\n",
      "epoch 714, batch 3, d_loss=-0.570 g_loss=-0.572 KID= 0.00561\n",
      "epoch 714, batch 4, d_loss=-0.428 g_loss=-0.517 KID= 0.00561\n",
      "epoch 714, batch 5, d_loss=-0.506 g_loss=-0.246 KID= 0.00561\n",
      "epoch 714, batch 6, d_loss=-0.581 g_loss=-0.047 KID= 0.00561\n",
      "epoch 714, batch 7, d_loss=-0.503 g_loss=0.045 KID= 0.00561\n",
      "epoch 714, batch 8, d_loss=-0.514 g_loss=0.156 KID= 0.00561\n",
      "epoch 714, batch 9, d_loss=-0.478 g_loss=-0.127 KID= 0.00561\n",
      "epoch 714, batch 10, d_loss=-0.385 g_loss=-0.443 KID= 0.00561\n",
      "epoch 714, batch 11, d_loss=-0.409 g_loss=-0.589 KID= 0.00561\n",
      "epoch 714, batch 12, d_loss=-0.503 g_loss=-0.674 KID= 0.00561\n",
      "epoch 714, batch 13, d_loss=-0.528 g_loss=-0.765 KID= 0.00561\n",
      "epoch 714, batch 14, d_loss=-0.458 g_loss=-0.826 KID= 0.00561\n",
      "epoch 714, batch 15, d_loss=-0.430 g_loss=-0.638 KID= 0.00561\n",
      "epoch 714, batch 16, d_loss=-0.569 g_loss=-0.615 KID= 0.00561\n",
      "epoch 714, batch 17, d_loss=-0.459 g_loss=-0.529 KID= 0.00561\n",
      "epoch 714, batch 18, d_loss=-0.422 g_loss=-0.329 KID= 0.00561\n",
      "epoch 714, batch 19, d_loss=-0.522 g_loss=-0.360 KID= 0.00561\n",
      "epoch 715, batch 0, d_loss=-0.468 g_loss=-0.548 KID= 0.00561\n",
      "epoch 715, batch 1, d_loss=-0.380 g_loss=-0.417 KID= 0.00561\n",
      "epoch 715, batch 2, d_loss=-0.500 g_loss=-0.459 KID= 0.00561\n",
      "epoch 715, batch 3, d_loss=-0.510 g_loss=-0.364 KID= 0.00561\n",
      "epoch 715, batch 4, d_loss=-0.474 g_loss=-0.233 KID= 0.00561\n",
      "epoch 715, batch 5, d_loss=-0.504 g_loss=-0.145 KID= 0.00561\n",
      "epoch 715, batch 6, d_loss=-0.625 g_loss=-0.183 KID= 0.00561\n",
      "epoch 715, batch 7, d_loss=-0.484 g_loss=-0.184 KID= 0.00561\n",
      "epoch 715, batch 8, d_loss=-0.418 g_loss=-0.173 KID= 0.00561\n",
      "epoch 715, batch 9, d_loss=-0.484 g_loss=-0.272 KID= 0.00561\n",
      "epoch 715, batch 10, d_loss=-0.446 g_loss=-0.485 KID= 0.00561\n",
      "epoch 715, batch 11, d_loss=-0.378 g_loss=-0.530 KID= 0.00561\n",
      "epoch 715, batch 12, d_loss=-0.513 g_loss=-0.622 KID= 0.00561\n",
      "epoch 715, batch 13, d_loss=-0.550 g_loss=-0.585 KID= 0.00561\n",
      "epoch 715, batch 14, d_loss=-0.447 g_loss=-0.629 KID= 0.00561\n",
      "epoch 715, batch 15, d_loss=-0.498 g_loss=-0.495 KID= 0.00561\n",
      "epoch 715, batch 16, d_loss=-0.590 g_loss=-0.471 KID= 0.00561\n",
      "epoch 715, batch 17, d_loss=-0.483 g_loss=-0.392 KID= 0.00561\n",
      "epoch 715, batch 18, d_loss=-0.472 g_loss=-0.230 KID= 0.00561\n",
      "epoch 715, batch 19, d_loss=-0.469 g_loss=-0.369 KID= 0.00561\n",
      "epoch 716, batch 0, d_loss=-0.468 g_loss=-0.641 KID= 0.00561\n",
      "epoch 716, batch 1, d_loss=-0.371 g_loss=-0.782 KID= 0.00561\n",
      "epoch 716, batch 2, d_loss=-0.473 g_loss=-0.846 KID= 0.00561\n",
      "epoch 716, batch 3, d_loss=-0.539 g_loss=-0.736 KID= 0.00561\n",
      "epoch 716, batch 4, d_loss=-0.510 g_loss=-0.670 KID= 0.00561\n",
      "epoch 716, batch 5, d_loss=-0.495 g_loss=-0.530 KID= 0.00561\n",
      "epoch 716, batch 6, d_loss=-0.645 g_loss=-0.480 KID= 0.00561\n",
      "epoch 716, batch 7, d_loss=-0.434 g_loss=-0.254 KID= 0.00561\n",
      "epoch 716, batch 8, d_loss=-0.427 g_loss=-0.044 KID= 0.00561\n",
      "epoch 716, batch 9, d_loss=-0.450 g_loss=-0.046 KID= 0.00561\n",
      "epoch 716, batch 10, d_loss=-0.425 g_loss=-0.182 KID= 0.00561\n",
      "epoch 716, batch 11, d_loss=-0.411 g_loss=-0.262 KID= 0.00561\n",
      "epoch 716, batch 12, d_loss=-0.500 g_loss=-0.291 KID= 0.00561\n",
      "epoch 716, batch 13, d_loss=-0.594 g_loss=-0.340 KID= 0.00561\n",
      "epoch 716, batch 14, d_loss=-0.499 g_loss=-0.306 KID= 0.00561\n",
      "epoch 716, batch 15, d_loss=-0.508 g_loss=-0.245 KID= 0.00561\n",
      "epoch 716, batch 16, d_loss=-0.630 g_loss=-0.274 KID= 0.00561\n",
      "epoch 716, batch 17, d_loss=-0.413 g_loss=-0.342 KID= 0.00561\n",
      "epoch 716, batch 18, d_loss=-0.437 g_loss=-0.286 KID= 0.00561\n",
      "epoch 716, batch 19, d_loss=-0.507 g_loss=-0.289 KID= 0.00561\n",
      "epoch 717, batch 0, d_loss=-0.425 g_loss=-0.377 KID= 0.00561\n",
      "epoch 717, batch 1, d_loss=-0.367 g_loss=-0.398 KID= 0.00561\n",
      "epoch 717, batch 2, d_loss=-0.509 g_loss=-0.441 KID= 0.00561\n",
      "epoch 717, batch 3, d_loss=-0.538 g_loss=-0.378 KID= 0.00561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 717, batch 4, d_loss=-0.451 g_loss=-0.344 KID= 0.00561\n",
      "epoch 717, batch 5, d_loss=-0.518 g_loss=-0.306 KID= 0.00561\n",
      "epoch 717, batch 6, d_loss=-0.629 g_loss=-0.252 KID= 0.00561\n",
      "epoch 717, batch 7, d_loss=-0.444 g_loss=-0.259 KID= 0.00561\n",
      "epoch 717, batch 8, d_loss=-0.459 g_loss=-0.257 KID= 0.00561\n",
      "epoch 717, batch 9, d_loss=-0.479 g_loss=-0.460 KID= 0.00561\n",
      "epoch 717, batch 10, d_loss=-0.425 g_loss=-0.650 KID= 0.00561\n",
      "epoch 717, batch 11, d_loss=-0.445 g_loss=-0.756 KID= 0.00561\n",
      "epoch 717, batch 12, d_loss=-0.498 g_loss=-0.819 KID= 0.00561\n",
      "epoch 717, batch 13, d_loss=-0.550 g_loss=-0.711 KID= 0.00561\n",
      "epoch 717, batch 14, d_loss=-0.533 g_loss=-0.718 KID= 0.00561\n",
      "epoch 717, batch 15, d_loss=-0.493 g_loss=-0.552 KID= 0.00561\n",
      "epoch 717, batch 16, d_loss=-0.634 g_loss=-0.418 KID= 0.00561\n",
      "epoch 717, batch 17, d_loss=-0.401 g_loss=-0.124 KID= 0.00561\n",
      "epoch 717, batch 18, d_loss=-0.465 g_loss=0.135 KID= 0.00561\n",
      "epoch 717, batch 19, d_loss=-0.442 g_loss=0.020 KID= 0.00561\n",
      "epoch 718, batch 0, d_loss=-0.484 g_loss=-0.192 KID= 0.00561\n",
      "epoch 718, batch 1, d_loss=-0.392 g_loss=-0.272 KID= 0.00561\n",
      "epoch 718, batch 2, d_loss=-0.498 g_loss=-0.416 KID= 0.00561\n",
      "epoch 718, batch 3, d_loss=-0.552 g_loss=-0.448 KID= 0.00561\n",
      "epoch 718, batch 4, d_loss=-0.449 g_loss=-0.487 KID= 0.00561\n",
      "epoch 718, batch 5, d_loss=-0.486 g_loss=-0.510 KID= 0.00561\n",
      "epoch 718, batch 6, d_loss=-0.629 g_loss=-0.599 KID= 0.00561\n",
      "epoch 718, batch 7, d_loss=-0.472 g_loss=-0.548 KID= 0.00561\n",
      "epoch 718, batch 8, d_loss=-0.473 g_loss=-0.435 KID= 0.00561\n",
      "epoch 718, batch 9, d_loss=-0.494 g_loss=-0.431 KID= 0.00561\n",
      "epoch 718, batch 10, d_loss=-0.392 g_loss=-0.550 KID= 0.00561\n",
      "epoch 718, batch 11, d_loss=-0.439 g_loss=-0.605 KID= 0.00561\n",
      "epoch 718, batch 12, d_loss=-0.466 g_loss=-0.704 KID= 0.00561\n",
      "epoch 718, batch 13, d_loss=-0.527 g_loss=-0.809 KID= 0.00561\n",
      "epoch 718, batch 14, d_loss=-0.513 g_loss=-0.800 KID= 0.00561\n",
      "epoch 718, batch 15, d_loss=-0.515 g_loss=-0.743 KID= 0.00561\n",
      "epoch 718, batch 16, d_loss=-0.638 g_loss=-0.780 KID= 0.00561\n",
      "epoch 718, batch 17, d_loss=-0.458 g_loss=-0.597 KID= 0.00561\n",
      "epoch 718, batch 18, d_loss=-0.462 g_loss=-0.309 KID= 0.00561\n",
      "epoch 718, batch 19, d_loss=-0.465 g_loss=-0.317 KID= 0.00561\n",
      "epoch 719, batch 0, d_loss=-0.412 g_loss=-0.333 KID= 0.00561\n",
      "epoch 719, batch 1, d_loss=-0.431 g_loss=-0.312 KID= 0.00561\n",
      "epoch 719, batch 2, d_loss=-0.533 g_loss=-0.355 KID= 0.00561\n",
      "epoch 719, batch 3, d_loss=-0.557 g_loss=-0.262 KID= 0.00561\n",
      "epoch 719, batch 4, d_loss=-0.512 g_loss=-0.378 KID= 0.00561\n",
      "epoch 719, batch 5, d_loss=-0.524 g_loss=-0.256 KID= 0.00561\n",
      "epoch 719, batch 6, d_loss=-0.631 g_loss=-0.057 KID= 0.00561\n",
      "epoch 719, batch 7, d_loss=-0.429 g_loss=0.100 KID= 0.00561\n",
      "epoch 719, batch 8, d_loss=-0.406 g_loss=0.245 KID= 0.00561\n",
      "epoch 719, batch 9, d_loss=-0.436 g_loss=0.106 KID= 0.00561\n",
      "epoch 719, batch 10, d_loss=-0.419 g_loss=-0.161 KID= 0.00561\n",
      "epoch 719, batch 11, d_loss=-0.443 g_loss=-0.244 KID= 0.00561\n",
      "epoch 719, batch 12, d_loss=-0.533 g_loss=-0.534 KID= 0.00561\n",
      "epoch 719, batch 13, d_loss=-0.514 g_loss=-0.528 KID= 0.00561\n",
      "epoch 719, batch 14, d_loss=-0.497 g_loss=-0.622 KID= 0.00561\n",
      "epoch 719, batch 15, d_loss=-0.493 g_loss=-0.513 KID= 0.00561\n",
      "epoch 719, batch 16, d_loss=-0.603 g_loss=-0.453 KID= 0.00561\n",
      "epoch 719, batch 17, d_loss=-0.422 g_loss=-0.349 KID= 0.00561\n",
      "epoch 719, batch 18, d_loss=-0.499 g_loss=-0.084 KID= 0.00561\n",
      "epoch 719, batch 19, d_loss=-0.501 g_loss=-0.135 KID= 0.00561\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 720, batch 0, d_loss=-0.415 g_loss=-0.288 KID= 0.01162\n",
      "epoch 720, batch 1, d_loss=-0.448 g_loss=-0.236 KID= 0.01162\n",
      "epoch 720, batch 2, d_loss=-0.514 g_loss=-0.290 KID= 0.01162\n",
      "epoch 720, batch 3, d_loss=-0.499 g_loss=-0.415 KID= 0.01162\n",
      "epoch 720, batch 4, d_loss=-0.522 g_loss=-0.593 KID= 0.01162\n",
      "epoch 720, batch 5, d_loss=-0.479 g_loss=-0.468 KID= 0.01162\n",
      "epoch 720, batch 6, d_loss=-0.586 g_loss=-0.259 KID= 0.01162\n",
      "epoch 720, batch 7, d_loss=-0.435 g_loss=-0.143 KID= 0.01162\n",
      "epoch 720, batch 8, d_loss=-0.468 g_loss=0.001 KID= 0.01162\n",
      "epoch 720, batch 9, d_loss=-0.464 g_loss=-0.022 KID= 0.01162\n",
      "epoch 720, batch 10, d_loss=-0.490 g_loss=-0.127 KID= 0.01162\n",
      "epoch 720, batch 11, d_loss=-0.477 g_loss=-0.083 KID= 0.01162\n",
      "epoch 720, batch 12, d_loss=-0.449 g_loss=-0.073 KID= 0.01162\n",
      "epoch 720, batch 13, d_loss=-0.545 g_loss=-0.038 KID= 0.01162\n",
      "epoch 720, batch 14, d_loss=-0.459 g_loss=-0.218 KID= 0.01162\n",
      "epoch 720, batch 15, d_loss=-0.519 g_loss=-0.281 KID= 0.01162\n",
      "epoch 720, batch 16, d_loss=-0.597 g_loss=-0.300 KID= 0.01162\n",
      "epoch 720, batch 17, d_loss=-0.486 g_loss=-0.400 KID= 0.01162\n",
      "epoch 720, batch 18, d_loss=-0.450 g_loss=-0.419 KID= 0.01162\n",
      "epoch 720, batch 19, d_loss=-0.489 g_loss=-0.563 KID= 0.01162\n",
      "epoch 721, batch 0, d_loss=-0.416 g_loss=-0.719 KID= 0.01162\n",
      "epoch 721, batch 1, d_loss=-0.480 g_loss=-0.781 KID= 0.01162\n",
      "epoch 721, batch 2, d_loss=-0.524 g_loss=-0.890 KID= 0.01162\n",
      "epoch 721, batch 3, d_loss=-0.483 g_loss=-0.836 KID= 0.01162\n",
      "epoch 721, batch 4, d_loss=-0.479 g_loss=-0.745 KID= 0.01162\n",
      "epoch 721, batch 5, d_loss=-0.503 g_loss=-0.583 KID= 0.01162\n",
      "epoch 721, batch 6, d_loss=-0.585 g_loss=-0.408 KID= 0.01162\n",
      "epoch 721, batch 7, d_loss=-0.432 g_loss=-0.157 KID= 0.01162\n",
      "epoch 721, batch 8, d_loss=-0.469 g_loss=0.219 KID= 0.01162\n",
      "epoch 721, batch 9, d_loss=-0.498 g_loss=0.252 KID= 0.01162\n",
      "epoch 721, batch 10, d_loss=-0.401 g_loss=0.046 KID= 0.01162\n",
      "epoch 721, batch 11, d_loss=-0.455 g_loss=-0.056 KID= 0.01162\n",
      "epoch 721, batch 12, d_loss=-0.532 g_loss=-0.149 KID= 0.01162\n",
      "epoch 721, batch 13, d_loss=-0.488 g_loss=-0.278 KID= 0.01162\n",
      "epoch 721, batch 14, d_loss=-0.505 g_loss=-0.527 KID= 0.01162\n",
      "epoch 721, batch 15, d_loss=-0.525 g_loss=-0.660 KID= 0.01162\n",
      "epoch 721, batch 16, d_loss=-0.595 g_loss=-0.702 KID= 0.01162\n",
      "epoch 721, batch 17, d_loss=-0.472 g_loss=-0.730 KID= 0.01162\n",
      "epoch 721, batch 18, d_loss=-0.462 g_loss=-0.606 KID= 0.01162\n",
      "epoch 721, batch 19, d_loss=-0.474 g_loss=-0.477 KID= 0.01162\n",
      "epoch 722, batch 0, d_loss=-0.432 g_loss=-0.365 KID= 0.01162\n",
      "epoch 722, batch 1, d_loss=-0.436 g_loss=-0.252 KID= 0.01162\n",
      "epoch 722, batch 2, d_loss=-0.491 g_loss=-0.227 KID= 0.01162\n",
      "epoch 722, batch 3, d_loss=-0.524 g_loss=-0.218 KID= 0.01162\n",
      "epoch 722, batch 4, d_loss=-0.481 g_loss=-0.339 KID= 0.01162\n",
      "epoch 722, batch 5, d_loss=-0.517 g_loss=-0.287 KID= 0.01162\n",
      "epoch 722, batch 6, d_loss=-0.601 g_loss=-0.129 KID= 0.01162\n",
      "epoch 722, batch 7, d_loss=-0.433 g_loss=0.092 KID= 0.01162\n",
      "epoch 722, batch 8, d_loss=-0.509 g_loss=0.331 KID= 0.01162\n",
      "epoch 722, batch 9, d_loss=-0.452 g_loss=0.260 KID= 0.01162\n",
      "epoch 722, batch 10, d_loss=-0.372 g_loss=0.054 KID= 0.01162\n",
      "epoch 722, batch 11, d_loss=-0.445 g_loss=-0.135 KID= 0.01162\n",
      "epoch 722, batch 12, d_loss=-0.525 g_loss=-0.395 KID= 0.01162\n",
      "epoch 722, batch 13, d_loss=-0.542 g_loss=-0.573 KID= 0.01162\n",
      "epoch 722, batch 14, d_loss=-0.458 g_loss=-0.802 KID= 0.01162\n",
      "epoch 722, batch 15, d_loss=-0.519 g_loss=-0.949 KID= 0.01162\n",
      "epoch 722, batch 16, d_loss=-0.638 g_loss=-0.996 KID= 0.01162\n",
      "epoch 722, batch 17, d_loss=-0.484 g_loss=-0.963 KID= 0.01162\n",
      "epoch 722, batch 18, d_loss=-0.433 g_loss=-0.776 KID= 0.01162\n",
      "epoch 722, batch 19, d_loss=-0.458 g_loss=-0.755 KID= 0.01162\n",
      "epoch 723, batch 0, d_loss=-0.423 g_loss=-0.781 KID= 0.01162\n",
      "epoch 723, batch 1, d_loss=-0.367 g_loss=-0.554 KID= 0.01162\n",
      "epoch 723, batch 2, d_loss=-0.490 g_loss=-0.511 KID= 0.01162\n",
      "epoch 723, batch 3, d_loss=-0.499 g_loss=-0.393 KID= 0.01162\n",
      "epoch 723, batch 4, d_loss=-0.544 g_loss=-0.315 KID= 0.01162\n",
      "epoch 723, batch 5, d_loss=-0.530 g_loss=-0.263 KID= 0.01162\n",
      "epoch 723, batch 6, d_loss=-0.614 g_loss=-0.157 KID= 0.01162\n",
      "epoch 723, batch 7, d_loss=-0.471 g_loss=0.086 KID= 0.01162\n",
      "epoch 723, batch 8, d_loss=-0.444 g_loss=0.322 KID= 0.01162\n",
      "epoch 723, batch 9, d_loss=-0.474 g_loss=0.227 KID= 0.01162\n",
      "epoch 723, batch 10, d_loss=-0.420 g_loss=0.017 KID= 0.01162\n",
      "epoch 723, batch 11, d_loss=-0.464 g_loss=-0.184 KID= 0.01162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 723, batch 12, d_loss=-0.532 g_loss=-0.433 KID= 0.01162\n",
      "epoch 723, batch 13, d_loss=-0.503 g_loss=-0.537 KID= 0.01162\n",
      "epoch 723, batch 14, d_loss=-0.446 g_loss=-0.736 KID= 0.01162\n",
      "epoch 723, batch 15, d_loss=-0.520 g_loss=-0.816 KID= 0.01162\n",
      "epoch 723, batch 16, d_loss=-0.588 g_loss=-0.610 KID= 0.01162\n",
      "epoch 723, batch 17, d_loss=-0.439 g_loss=-0.541 KID= 0.01162\n",
      "epoch 723, batch 18, d_loss=-0.488 g_loss=-0.296 KID= 0.01162\n",
      "epoch 723, batch 19, d_loss=-0.443 g_loss=-0.132 KID= 0.01162\n",
      "epoch 724, batch 0, d_loss=-0.405 g_loss=-0.036 KID= 0.01162\n",
      "epoch 724, batch 1, d_loss=-0.402 g_loss=0.073 KID= 0.01162\n",
      "epoch 724, batch 2, d_loss=-0.530 g_loss=0.069 KID= 0.01162\n",
      "epoch 724, batch 3, d_loss=-0.554 g_loss=0.039 KID= 0.01162\n",
      "epoch 724, batch 4, d_loss=-0.446 g_loss=-0.224 KID= 0.01162\n",
      "epoch 724, batch 5, d_loss=-0.595 g_loss=-0.330 KID= 0.01162\n",
      "epoch 724, batch 6, d_loss=-0.599 g_loss=-0.212 KID= 0.01162\n",
      "epoch 724, batch 7, d_loss=-0.474 g_loss=-0.152 KID= 0.01162\n",
      "epoch 724, batch 8, d_loss=-0.481 g_loss=-0.021 KID= 0.01162\n",
      "epoch 724, batch 9, d_loss=-0.450 g_loss=-0.160 KID= 0.01162\n",
      "epoch 724, batch 10, d_loss=-0.397 g_loss=-0.271 KID= 0.01162\n",
      "epoch 724, batch 11, d_loss=-0.393 g_loss=-0.332 KID= 0.01162\n",
      "epoch 724, batch 12, d_loss=-0.522 g_loss=-0.407 KID= 0.01162\n",
      "epoch 724, batch 13, d_loss=-0.514 g_loss=-0.408 KID= 0.01162\n",
      "epoch 724, batch 14, d_loss=-0.466 g_loss=-0.495 KID= 0.01162\n",
      "epoch 724, batch 15, d_loss=-0.554 g_loss=-0.516 KID= 0.01162\n",
      "epoch 724, batch 16, d_loss=-0.617 g_loss=-0.434 KID= 0.01162\n",
      "epoch 724, batch 17, d_loss=-0.447 g_loss=-0.177 KID= 0.01162\n",
      "epoch 724, batch 18, d_loss=-0.526 g_loss=0.073 KID= 0.01162\n",
      "epoch 724, batch 19, d_loss=-0.390 g_loss=0.075 KID= 0.01162\n",
      "epoch 725, batch 0, d_loss=-0.445 g_loss=-0.037 KID= 0.01162\n",
      "epoch 725, batch 1, d_loss=-0.414 g_loss=-0.030 KID= 0.01162\n",
      "epoch 725, batch 2, d_loss=-0.496 g_loss=-0.082 KID= 0.01162\n",
      "epoch 725, batch 3, d_loss=-0.533 g_loss=-0.237 KID= 0.01162\n",
      "epoch 725, batch 4, d_loss=-0.419 g_loss=-0.477 KID= 0.01162\n",
      "epoch 725, batch 5, d_loss=-0.538 g_loss=-0.659 KID= 0.01162\n",
      "epoch 725, batch 6, d_loss=-0.600 g_loss=-0.690 KID= 0.01162\n",
      "epoch 725, batch 7, d_loss=-0.485 g_loss=-0.694 KID= 0.01162\n",
      "epoch 725, batch 8, d_loss=-0.484 g_loss=-0.647 KID= 0.01162\n",
      "epoch 725, batch 9, d_loss=-0.432 g_loss=-0.689 KID= 0.01162\n",
      "epoch 725, batch 10, d_loss=-0.383 g_loss=-0.599 KID= 0.01162\n",
      "epoch 725, batch 11, d_loss=-0.423 g_loss=-0.442 KID= 0.01162\n",
      "epoch 725, batch 12, d_loss=-0.475 g_loss=-0.362 KID= 0.01162\n",
      "epoch 725, batch 13, d_loss=-0.502 g_loss=-0.335 KID= 0.01162\n",
      "epoch 725, batch 14, d_loss=-0.434 g_loss=-0.345 KID= 0.01162\n",
      "epoch 725, batch 15, d_loss=-0.573 g_loss=-0.405 KID= 0.01162\n",
      "epoch 725, batch 16, d_loss=-0.559 g_loss=-0.379 KID= 0.01162\n",
      "epoch 725, batch 17, d_loss=-0.477 g_loss=-0.382 KID= 0.01162\n",
      "epoch 725, batch 18, d_loss=-0.497 g_loss=-0.239 KID= 0.01162\n",
      "epoch 725, batch 19, d_loss=-0.490 g_loss=-0.296 KID= 0.01162\n",
      "epoch 726, batch 0, d_loss=-0.360 g_loss=-0.362 KID= 0.01162\n",
      "epoch 726, batch 1, d_loss=-0.436 g_loss=-0.263 KID= 0.01162\n",
      "epoch 726, batch 2, d_loss=-0.470 g_loss=-0.155 KID= 0.01162\n",
      "epoch 726, batch 3, d_loss=-0.532 g_loss=-0.189 KID= 0.01162\n",
      "epoch 726, batch 4, d_loss=-0.449 g_loss=-0.474 KID= 0.01162\n",
      "epoch 726, batch 5, d_loss=-0.579 g_loss=-0.495 KID= 0.01162\n",
      "epoch 726, batch 6, d_loss=-0.603 g_loss=-0.509 KID= 0.01162\n",
      "epoch 726, batch 7, d_loss=-0.464 g_loss=-0.441 KID= 0.01162\n",
      "epoch 726, batch 8, d_loss=-0.494 g_loss=-0.535 KID= 0.01162\n",
      "epoch 726, batch 9, d_loss=-0.463 g_loss=-0.724 KID= 0.01162\n",
      "epoch 726, batch 10, d_loss=-0.419 g_loss=-0.836 KID= 0.01162\n",
      "epoch 726, batch 11, d_loss=-0.450 g_loss=-0.652 KID= 0.01162\n",
      "epoch 726, batch 12, d_loss=-0.485 g_loss=-0.615 KID= 0.01162\n",
      "epoch 726, batch 13, d_loss=-0.528 g_loss=-0.610 KID= 0.01162\n",
      "epoch 726, batch 14, d_loss=-0.471 g_loss=-0.557 KID= 0.01162\n",
      "epoch 726, batch 15, d_loss=-0.588 g_loss=-0.511 KID= 0.01162\n",
      "epoch 726, batch 16, d_loss=-0.585 g_loss=-0.386 KID= 0.01162\n",
      "epoch 726, batch 17, d_loss=-0.465 g_loss=-0.194 KID= 0.01162\n",
      "epoch 726, batch 18, d_loss=-0.485 g_loss=-0.047 KID= 0.01162\n",
      "epoch 726, batch 19, d_loss=-0.456 g_loss=-0.104 KID= 0.01162\n",
      "epoch 727, batch 0, d_loss=-0.377 g_loss=-0.223 KID= 0.01162\n",
      "epoch 727, batch 1, d_loss=-0.481 g_loss=-0.278 KID= 0.01162\n",
      "epoch 727, batch 2, d_loss=-0.486 g_loss=-0.243 KID= 0.01162\n",
      "epoch 727, batch 3, d_loss=-0.570 g_loss=-0.361 KID= 0.01162\n",
      "epoch 727, batch 4, d_loss=-0.433 g_loss=-0.442 KID= 0.01162\n",
      "epoch 727, batch 5, d_loss=-0.530 g_loss=-0.431 KID= 0.01162\n",
      "epoch 727, batch 6, d_loss=-0.556 g_loss=-0.462 KID= 0.01162\n",
      "epoch 727, batch 7, d_loss=-0.500 g_loss=-0.405 KID= 0.01162\n",
      "epoch 727, batch 8, d_loss=-0.504 g_loss=-0.172 KID= 0.01162\n",
      "epoch 727, batch 9, d_loss=-0.424 g_loss=-0.146 KID= 0.01162\n",
      "epoch 727, batch 10, d_loss=-0.333 g_loss=-0.129 KID= 0.01162\n",
      "epoch 727, batch 11, d_loss=-0.460 g_loss=-0.152 KID= 0.01162\n",
      "epoch 727, batch 12, d_loss=-0.488 g_loss=-0.141 KID= 0.01162\n",
      "epoch 727, batch 13, d_loss=-0.587 g_loss=-0.270 KID= 0.01162\n",
      "epoch 727, batch 14, d_loss=-0.438 g_loss=-0.435 KID= 0.01162\n",
      "epoch 727, batch 15, d_loss=-0.622 g_loss=-0.543 KID= 0.01162\n",
      "epoch 727, batch 16, d_loss=-0.593 g_loss=-0.581 KID= 0.01162\n",
      "epoch 727, batch 17, d_loss=-0.558 g_loss=-0.531 KID= 0.01162\n",
      "epoch 727, batch 18, d_loss=-0.533 g_loss=-0.384 KID= 0.01162\n",
      "epoch 727, batch 19, d_loss=-0.467 g_loss=-0.420 KID= 0.01162\n",
      "epoch 728, batch 0, d_loss=-0.331 g_loss=-0.397 KID= 0.01162\n",
      "epoch 728, batch 1, d_loss=-0.464 g_loss=-0.336 KID= 0.01162\n",
      "epoch 728, batch 2, d_loss=-0.500 g_loss=-0.233 KID= 0.01162\n",
      "epoch 728, batch 3, d_loss=-0.511 g_loss=-0.199 KID= 0.01162\n",
      "epoch 728, batch 4, d_loss=-0.427 g_loss=-0.389 KID= 0.01162\n",
      "epoch 728, batch 5, d_loss=-0.630 g_loss=-0.577 KID= 0.01162\n",
      "epoch 728, batch 6, d_loss=-0.578 g_loss=-0.717 KID= 0.01162\n",
      "epoch 728, batch 7, d_loss=-0.493 g_loss=-0.770 KID= 0.01162\n",
      "epoch 728, batch 8, d_loss=-0.456 g_loss=-0.645 KID= 0.01162\n",
      "epoch 728, batch 9, d_loss=-0.468 g_loss=-0.678 KID= 0.01162\n",
      "epoch 728, batch 10, d_loss=-0.312 g_loss=-0.553 KID= 0.01162\n",
      "epoch 728, batch 11, d_loss=-0.481 g_loss=-0.439 KID= 0.01162\n",
      "epoch 728, batch 12, d_loss=-0.499 g_loss=-0.377 KID= 0.01162\n",
      "epoch 728, batch 13, d_loss=-0.508 g_loss=-0.331 KID= 0.01162\n",
      "epoch 728, batch 14, d_loss=-0.443 g_loss=-0.464 KID= 0.01162\n",
      "epoch 728, batch 15, d_loss=-0.631 g_loss=-0.406 KID= 0.01162\n",
      "epoch 728, batch 16, d_loss=-0.576 g_loss=-0.454 KID= 0.01162\n",
      "epoch 728, batch 17, d_loss=-0.472 g_loss=-0.433 KID= 0.01162\n",
      "epoch 728, batch 18, d_loss=-0.445 g_loss=-0.260 KID= 0.01162\n",
      "epoch 728, batch 19, d_loss=-0.450 g_loss=-0.169 KID= 0.01162\n",
      "epoch 729, batch 0, d_loss=-0.388 g_loss=-0.064 KID= 0.01162\n",
      "epoch 729, batch 1, d_loss=-0.409 g_loss=-0.052 KID= 0.01162\n",
      "epoch 729, batch 2, d_loss=-0.490 g_loss=0.054 KID= 0.01162\n",
      "epoch 729, batch 3, d_loss=-0.579 g_loss=0.074 KID= 0.01162\n",
      "epoch 729, batch 4, d_loss=-0.413 g_loss=-0.083 KID= 0.01162\n",
      "epoch 729, batch 5, d_loss=-0.630 g_loss=-0.237 KID= 0.01162\n",
      "epoch 729, batch 6, d_loss=-0.583 g_loss=-0.322 KID= 0.01162\n",
      "epoch 729, batch 7, d_loss=-0.377 g_loss=-0.327 KID= 0.01162\n",
      "epoch 729, batch 8, d_loss=-0.454 g_loss=-0.307 KID= 0.01162\n",
      "epoch 729, batch 9, d_loss=-0.510 g_loss=-0.334 KID= 0.01162\n",
      "epoch 729, batch 10, d_loss=-0.344 g_loss=-0.261 KID= 0.01162\n",
      "epoch 729, batch 11, d_loss=-0.491 g_loss=-0.144 KID= 0.01162\n",
      "epoch 729, batch 12, d_loss=-0.434 g_loss=-0.109 KID= 0.01162\n",
      "epoch 729, batch 13, d_loss=-0.539 g_loss=-0.188 KID= 0.01162\n",
      "epoch 729, batch 14, d_loss=-0.493 g_loss=-0.317 KID= 0.01162\n",
      "epoch 729, batch 15, d_loss=-0.572 g_loss=-0.325 KID= 0.01162\n",
      "epoch 729, batch 16, d_loss=-0.554 g_loss=-0.312 KID= 0.01162\n",
      "epoch 729, batch 17, d_loss=-0.503 g_loss=-0.305 KID= 0.01162\n",
      "epoch 729, batch 18, d_loss=-0.447 g_loss=-0.094 KID= 0.01162\n",
      "epoch 729, batch 19, d_loss=-0.482 g_loss=-0.089 KID= 0.01162\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 730, batch 0, d_loss=-0.322 g_loss=-0.132 KID= 0.00573\n",
      "epoch 730, batch 1, d_loss=-0.456 g_loss=-0.060 KID= 0.00573\n",
      "epoch 730, batch 2, d_loss=-0.476 g_loss=-0.005 KID= 0.00573\n",
      "epoch 730, batch 3, d_loss=-0.524 g_loss=0.076 KID= 0.00573\n",
      "epoch 730, batch 4, d_loss=-0.491 g_loss=-0.082 KID= 0.00573\n",
      "epoch 730, batch 5, d_loss=-0.630 g_loss=-0.128 KID= 0.00573\n",
      "epoch 730, batch 6, d_loss=-0.631 g_loss=-0.246 KID= 0.00573\n",
      "epoch 730, batch 7, d_loss=-0.448 g_loss=-0.437 KID= 0.00573\n",
      "epoch 730, batch 8, d_loss=-0.444 g_loss=-0.499 KID= 0.00573\n",
      "epoch 730, batch 9, d_loss=-0.507 g_loss=-0.555 KID= 0.00573\n",
      "epoch 730, batch 10, d_loss=-0.339 g_loss=-0.589 KID= 0.00573\n",
      "epoch 730, batch 11, d_loss=-0.471 g_loss=-0.625 KID= 0.00573\n",
      "epoch 730, batch 12, d_loss=-0.506 g_loss=-0.648 KID= 0.00573\n",
      "epoch 730, batch 13, d_loss=-0.524 g_loss=-0.804 KID= 0.00573\n",
      "epoch 730, batch 14, d_loss=-0.521 g_loss=-0.778 KID= 0.00573\n",
      "epoch 730, batch 15, d_loss=-0.634 g_loss=-0.752 KID= 0.00573\n",
      "epoch 730, batch 16, d_loss=-0.629 g_loss=-0.770 KID= 0.00573\n",
      "epoch 730, batch 17, d_loss=-0.481 g_loss=-0.562 KID= 0.00573\n",
      "epoch 730, batch 18, d_loss=-0.453 g_loss=-0.237 KID= 0.00573\n",
      "epoch 730, batch 19, d_loss=-0.466 g_loss=-0.172 KID= 0.00573\n",
      "epoch 731, batch 0, d_loss=-0.392 g_loss=-0.134 KID= 0.00573\n",
      "epoch 731, batch 1, d_loss=-0.516 g_loss=-0.167 KID= 0.00573\n",
      "epoch 731, batch 2, d_loss=-0.498 g_loss=-0.174 KID= 0.00573\n",
      "epoch 731, batch 3, d_loss=-0.487 g_loss=-0.244 KID= 0.00573\n",
      "epoch 731, batch 4, d_loss=-0.507 g_loss=-0.408 KID= 0.00573\n",
      "epoch 731, batch 5, d_loss=-0.585 g_loss=-0.437 KID= 0.00573\n",
      "epoch 731, batch 6, d_loss=-0.594 g_loss=-0.349 KID= 0.00573\n",
      "epoch 731, batch 7, d_loss=-0.413 g_loss=-0.241 KID= 0.00573\n",
      "epoch 731, batch 8, d_loss=-0.458 g_loss=-0.141 KID= 0.00573\n",
      "epoch 731, batch 9, d_loss=-0.492 g_loss=-0.204 KID= 0.00573\n",
      "epoch 731, batch 10, d_loss=-0.334 g_loss=-0.196 KID= 0.00573\n",
      "epoch 731, batch 11, d_loss=-0.468 g_loss=-0.160 KID= 0.00573\n",
      "epoch 731, batch 12, d_loss=-0.563 g_loss=-0.188 KID= 0.00573\n",
      "epoch 731, batch 13, d_loss=-0.522 g_loss=-0.271 KID= 0.00573\n",
      "epoch 731, batch 14, d_loss=-0.507 g_loss=-0.442 KID= 0.00573\n",
      "epoch 731, batch 15, d_loss=-0.625 g_loss=-0.578 KID= 0.00573\n",
      "epoch 731, batch 16, d_loss=-0.600 g_loss=-0.773 KID= 0.00573\n",
      "epoch 731, batch 17, d_loss=-0.459 g_loss=-0.898 KID= 0.00573\n",
      "epoch 731, batch 18, d_loss=-0.473 g_loss=-0.883 KID= 0.00573\n",
      "epoch 731, batch 19, d_loss=-0.498 g_loss=-0.854 KID= 0.00573\n",
      "epoch 732, batch 0, d_loss=-0.370 g_loss=-0.722 KID= 0.00573\n",
      "epoch 732, batch 1, d_loss=-0.484 g_loss=-0.747 KID= 0.00573\n",
      "epoch 732, batch 2, d_loss=-0.454 g_loss=-0.680 KID= 0.00573\n",
      "epoch 732, batch 3, d_loss=-0.477 g_loss=-0.645 KID= 0.00573\n",
      "epoch 732, batch 4, d_loss=-0.525 g_loss=-0.640 KID= 0.00573\n",
      "epoch 732, batch 5, d_loss=-0.630 g_loss=-0.734 KID= 0.00573\n",
      "epoch 732, batch 6, d_loss=-0.591 g_loss=-0.666 KID= 0.00573\n",
      "epoch 732, batch 7, d_loss=-0.494 g_loss=-0.589 KID= 0.00573\n",
      "epoch 732, batch 8, d_loss=-0.448 g_loss=-0.365 KID= 0.00573\n",
      "epoch 732, batch 9, d_loss=-0.451 g_loss=-0.213 KID= 0.00573\n",
      "epoch 732, batch 10, d_loss=-0.336 g_loss=-0.080 KID= 0.00573\n",
      "epoch 732, batch 11, d_loss=-0.483 g_loss=0.004 KID= 0.00573\n",
      "epoch 732, batch 12, d_loss=-0.490 g_loss=0.055 KID= 0.00573\n",
      "epoch 732, batch 13, d_loss=-0.476 g_loss=-0.035 KID= 0.00573\n",
      "epoch 732, batch 14, d_loss=-0.464 g_loss=-0.131 KID= 0.00573\n",
      "epoch 732, batch 15, d_loss=-0.681 g_loss=-0.214 KID= 0.00573\n",
      "epoch 732, batch 16, d_loss=-0.640 g_loss=-0.358 KID= 0.00573\n",
      "epoch 732, batch 17, d_loss=-0.502 g_loss=-0.560 KID= 0.00573\n",
      "epoch 732, batch 18, d_loss=-0.457 g_loss=-0.654 KID= 0.00573\n",
      "epoch 732, batch 19, d_loss=-0.513 g_loss=-0.755 KID= 0.00573\n",
      "epoch 733, batch 0, d_loss=-0.350 g_loss=-0.659 KID= 0.00573\n",
      "epoch 733, batch 1, d_loss=-0.470 g_loss=-0.690 KID= 0.00573\n",
      "epoch 733, batch 2, d_loss=-0.442 g_loss=-0.642 KID= 0.00573\n",
      "epoch 733, batch 3, d_loss=-0.452 g_loss=-0.554 KID= 0.00573\n",
      "epoch 733, batch 4, d_loss=-0.556 g_loss=-0.527 KID= 0.00573\n",
      "epoch 733, batch 5, d_loss=-0.630 g_loss=-0.477 KID= 0.00573\n",
      "epoch 733, batch 6, d_loss=-0.629 g_loss=-0.571 KID= 0.00573\n",
      "epoch 733, batch 7, d_loss=-0.455 g_loss=-0.639 KID= 0.00573\n",
      "epoch 733, batch 8, d_loss=-0.512 g_loss=-0.560 KID= 0.00573\n",
      "epoch 733, batch 9, d_loss=-0.472 g_loss=-0.625 KID= 0.00573\n",
      "epoch 733, batch 10, d_loss=-0.377 g_loss=-0.537 KID= 0.00573\n",
      "epoch 733, batch 11, d_loss=-0.427 g_loss=-0.446 KID= 0.00573\n",
      "epoch 733, batch 12, d_loss=-0.479 g_loss=-0.336 KID= 0.00573\n",
      "epoch 733, batch 13, d_loss=-0.484 g_loss=-0.320 KID= 0.00573\n",
      "epoch 733, batch 14, d_loss=-0.519 g_loss=-0.344 KID= 0.00573\n",
      "epoch 733, batch 15, d_loss=-0.642 g_loss=-0.492 KID= 0.00573\n",
      "epoch 733, batch 16, d_loss=-0.557 g_loss=-0.647 KID= 0.00573\n",
      "epoch 733, batch 17, d_loss=-0.509 g_loss=-0.689 KID= 0.00573\n",
      "epoch 733, batch 18, d_loss=-0.460 g_loss=-0.569 KID= 0.00573\n",
      "epoch 733, batch 19, d_loss=-0.493 g_loss=-0.539 KID= 0.00573\n",
      "epoch 734, batch 0, d_loss=-0.421 g_loss=-0.432 KID= 0.00573\n",
      "epoch 734, batch 1, d_loss=-0.480 g_loss=-0.323 KID= 0.00573\n",
      "epoch 734, batch 2, d_loss=-0.528 g_loss=-0.237 KID= 0.00573\n",
      "epoch 734, batch 3, d_loss=-0.474 g_loss=-0.178 KID= 0.00573\n",
      "epoch 734, batch 4, d_loss=-0.541 g_loss=-0.136 KID= 0.00573\n",
      "epoch 734, batch 5, d_loss=-0.563 g_loss=-0.130 KID= 0.00573\n",
      "epoch 734, batch 6, d_loss=-0.613 g_loss=-0.256 KID= 0.00573\n",
      "epoch 734, batch 7, d_loss=-0.460 g_loss=-0.450 KID= 0.00573\n",
      "epoch 734, batch 8, d_loss=-0.479 g_loss=-0.570 KID= 0.00573\n",
      "epoch 734, batch 9, d_loss=-0.495 g_loss=-0.714 KID= 0.00573\n",
      "epoch 734, batch 10, d_loss=-0.412 g_loss=-0.768 KID= 0.00573\n",
      "epoch 734, batch 11, d_loss=-0.497 g_loss=-0.706 KID= 0.00573\n",
      "epoch 734, batch 12, d_loss=-0.446 g_loss=-0.745 KID= 0.00573\n",
      "epoch 734, batch 13, d_loss=-0.440 g_loss=-0.791 KID= 0.00573\n",
      "epoch 734, batch 14, d_loss=-0.511 g_loss=-0.691 KID= 0.00573\n",
      "epoch 734, batch 15, d_loss=-0.660 g_loss=-0.624 KID= 0.00573\n",
      "epoch 734, batch 16, d_loss=-0.517 g_loss=-0.716 KID= 0.00573\n",
      "epoch 734, batch 17, d_loss=-0.482 g_loss=-0.770 KID= 0.00573\n",
      "epoch 734, batch 18, d_loss=-0.512 g_loss=-0.755 KID= 0.00573\n",
      "epoch 734, batch 19, d_loss=-0.501 g_loss=-0.757 KID= 0.00573\n",
      "epoch 735, batch 0, d_loss=-0.340 g_loss=-0.595 KID= 0.00573\n",
      "epoch 735, batch 1, d_loss=-0.487 g_loss=-0.447 KID= 0.00573\n",
      "epoch 735, batch 2, d_loss=-0.463 g_loss=-0.338 KID= 0.00573\n",
      "epoch 735, batch 3, d_loss=-0.440 g_loss=-0.254 KID= 0.00573\n",
      "epoch 735, batch 4, d_loss=-0.523 g_loss=-0.131 KID= 0.00573\n",
      "epoch 735, batch 5, d_loss=-0.657 g_loss=-0.048 KID= 0.00573\n",
      "epoch 735, batch 6, d_loss=-0.579 g_loss=-0.180 KID= 0.00573\n",
      "epoch 735, batch 7, d_loss=-0.492 g_loss=-0.218 KID= 0.00573\n",
      "epoch 735, batch 8, d_loss=-0.475 g_loss=-0.252 KID= 0.00573\n",
      "epoch 735, batch 9, d_loss=-0.428 g_loss=-0.292 KID= 0.00573\n",
      "epoch 735, batch 10, d_loss=-0.377 g_loss=-0.123 KID= 0.00573\n",
      "epoch 735, batch 11, d_loss=-0.511 g_loss=-0.149 KID= 0.00573\n",
      "epoch 735, batch 12, d_loss=-0.476 g_loss=-0.054 KID= 0.00573\n",
      "epoch 735, batch 13, d_loss=-0.471 g_loss=-0.022 KID= 0.00573\n",
      "epoch 735, batch 14, d_loss=-0.550 g_loss=0.021 KID= 0.00573\n",
      "epoch 735, batch 15, d_loss=-0.590 g_loss=0.109 KID= 0.00573\n",
      "epoch 735, batch 16, d_loss=-0.582 g_loss=-0.062 KID= 0.00573\n",
      "epoch 735, batch 17, d_loss=-0.474 g_loss=-0.267 KID= 0.00573\n",
      "epoch 735, batch 18, d_loss=-0.445 g_loss=-0.423 KID= 0.00573\n",
      "epoch 735, batch 19, d_loss=-0.472 g_loss=-0.696 KID= 0.00573\n",
      "epoch 736, batch 0, d_loss=-0.390 g_loss=-0.753 KID= 0.00573\n",
      "epoch 736, batch 1, d_loss=-0.488 g_loss=-0.829 KID= 0.00573\n",
      "epoch 736, batch 2, d_loss=-0.471 g_loss=-0.921 KID= 0.00573\n",
      "epoch 736, batch 3, d_loss=-0.439 g_loss=-0.951 KID= 0.00573\n",
      "epoch 736, batch 4, d_loss=-0.515 g_loss=-0.880 KID= 0.00573\n",
      "epoch 736, batch 5, d_loss=-0.602 g_loss=-0.640 KID= 0.00573\n",
      "epoch 736, batch 6, d_loss=-0.605 g_loss=-0.594 KID= 0.00573\n",
      "epoch 736, batch 7, d_loss=-0.464 g_loss=-0.323 KID= 0.00573\n",
      "epoch 736, batch 8, d_loss=-0.456 g_loss=-0.132 KID= 0.00573\n",
      "epoch 736, batch 9, d_loss=-0.396 g_loss=-0.144 KID= 0.00573\n",
      "epoch 736, batch 10, d_loss=-0.382 g_loss=-0.075 KID= 0.00573\n",
      "epoch 736, batch 11, d_loss=-0.534 g_loss=-0.098 KID= 0.00573\n",
      "epoch 736, batch 12, d_loss=-0.470 g_loss=-0.173 KID= 0.00573\n",
      "epoch 736, batch 13, d_loss=-0.435 g_loss=-0.168 KID= 0.00573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 736, batch 14, d_loss=-0.551 g_loss=-0.178 KID= 0.00573\n",
      "epoch 736, batch 15, d_loss=-0.589 g_loss=-0.222 KID= 0.00573\n",
      "epoch 736, batch 16, d_loss=-0.558 g_loss=-0.386 KID= 0.00573\n",
      "epoch 736, batch 17, d_loss=-0.542 g_loss=-0.455 KID= 0.00573\n",
      "epoch 736, batch 18, d_loss=-0.426 g_loss=-0.567 KID= 0.00573\n",
      "epoch 736, batch 19, d_loss=-0.515 g_loss=-0.764 KID= 0.00573\n",
      "epoch 737, batch 0, d_loss=-0.390 g_loss=-0.789 KID= 0.00573\n",
      "epoch 737, batch 1, d_loss=-0.494 g_loss=-0.682 KID= 0.00573\n",
      "epoch 737, batch 2, d_loss=-0.475 g_loss=-0.624 KID= 0.00573\n",
      "epoch 737, batch 3, d_loss=-0.458 g_loss=-0.573 KID= 0.00573\n",
      "epoch 737, batch 4, d_loss=-0.504 g_loss=-0.511 KID= 0.00573\n",
      "epoch 737, batch 5, d_loss=-0.665 g_loss=-0.399 KID= 0.00573\n",
      "epoch 737, batch 6, d_loss=-0.554 g_loss=-0.329 KID= 0.00573\n",
      "epoch 737, batch 7, d_loss=-0.469 g_loss=-0.284 KID= 0.00573\n",
      "epoch 737, batch 8, d_loss=-0.527 g_loss=-0.259 KID= 0.00573\n",
      "epoch 737, batch 9, d_loss=-0.462 g_loss=-0.268 KID= 0.00573\n",
      "epoch 737, batch 10, d_loss=-0.402 g_loss=-0.123 KID= 0.00573\n",
      "epoch 737, batch 11, d_loss=-0.530 g_loss=-0.073 KID= 0.00573\n",
      "epoch 737, batch 12, d_loss=-0.522 g_loss=-0.135 KID= 0.00573\n",
      "epoch 737, batch 13, d_loss=-0.420 g_loss=-0.153 KID= 0.00573\n",
      "epoch 737, batch 14, d_loss=-0.574 g_loss=-0.188 KID= 0.00573\n",
      "epoch 737, batch 15, d_loss=-0.670 g_loss=-0.165 KID= 0.00573\n",
      "epoch 737, batch 16, d_loss=-0.554 g_loss=-0.263 KID= 0.00573\n",
      "epoch 737, batch 17, d_loss=-0.454 g_loss=-0.399 KID= 0.00573\n",
      "epoch 737, batch 18, d_loss=-0.458 g_loss=-0.571 KID= 0.00573\n",
      "epoch 737, batch 19, d_loss=-0.476 g_loss=-0.767 KID= 0.00573\n",
      "epoch 738, batch 0, d_loss=-0.409 g_loss=-0.706 KID= 0.00573\n",
      "epoch 738, batch 1, d_loss=-0.545 g_loss=-0.602 KID= 0.00573\n",
      "epoch 738, batch 2, d_loss=-0.483 g_loss=-0.539 KID= 0.00573\n",
      "epoch 738, batch 3, d_loss=-0.438 g_loss=-0.507 KID= 0.00573\n",
      "epoch 738, batch 4, d_loss=-0.484 g_loss=-0.499 KID= 0.00573\n",
      "epoch 738, batch 5, d_loss=-0.675 g_loss=-0.384 KID= 0.00573\n",
      "epoch 738, batch 6, d_loss=-0.507 g_loss=-0.375 KID= 0.00573\n",
      "epoch 738, batch 7, d_loss=-0.525 g_loss=-0.313 KID= 0.00573\n",
      "epoch 738, batch 8, d_loss=-0.508 g_loss=-0.440 KID= 0.00573\n",
      "epoch 738, batch 9, d_loss=-0.441 g_loss=-0.556 KID= 0.00573\n",
      "epoch 738, batch 10, d_loss=-0.399 g_loss=-0.431 KID= 0.00573\n",
      "epoch 738, batch 11, d_loss=-0.490 g_loss=-0.552 KID= 0.00573\n",
      "epoch 738, batch 12, d_loss=-0.455 g_loss=-0.475 KID= 0.00573\n",
      "epoch 738, batch 13, d_loss=-0.425 g_loss=-0.490 KID= 0.00573\n",
      "epoch 738, batch 14, d_loss=-0.558 g_loss=-0.505 KID= 0.00573\n",
      "epoch 738, batch 15, d_loss=-0.646 g_loss=-0.428 KID= 0.00573\n",
      "epoch 738, batch 16, d_loss=-0.564 g_loss=-0.484 KID= 0.00573\n",
      "epoch 738, batch 17, d_loss=-0.504 g_loss=-0.396 KID= 0.00573\n",
      "epoch 738, batch 18, d_loss=-0.518 g_loss=-0.400 KID= 0.00573\n",
      "epoch 738, batch 19, d_loss=-0.463 g_loss=-0.621 KID= 0.00573\n",
      "epoch 739, batch 0, d_loss=-0.434 g_loss=-0.743 KID= 0.00573\n",
      "epoch 739, batch 1, d_loss=-0.487 g_loss=-0.875 KID= 0.00573\n",
      "epoch 739, batch 2, d_loss=-0.502 g_loss=-0.854 KID= 0.00573\n",
      "epoch 739, batch 3, d_loss=-0.433 g_loss=-0.845 KID= 0.00573\n",
      "epoch 739, batch 4, d_loss=-0.487 g_loss=-0.657 KID= 0.00573\n",
      "epoch 739, batch 5, d_loss=-0.635 g_loss=-0.401 KID= 0.00573\n",
      "epoch 739, batch 6, d_loss=-0.578 g_loss=-0.376 KID= 0.00573\n",
      "epoch 739, batch 7, d_loss=-0.569 g_loss=-0.374 KID= 0.00573\n",
      "epoch 739, batch 8, d_loss=-0.499 g_loss=-0.365 KID= 0.00573\n",
      "epoch 739, batch 9, d_loss=-0.441 g_loss=-0.460 KID= 0.00573\n",
      "epoch 739, batch 10, d_loss=-0.322 g_loss=-0.263 KID= 0.00573\n",
      "epoch 739, batch 11, d_loss=-0.500 g_loss=-0.107 KID= 0.00573\n",
      "epoch 739, batch 12, d_loss=-0.551 g_loss=-0.014 KID= 0.00573\n",
      "epoch 739, batch 13, d_loss=-0.419 g_loss=-0.018 KID= 0.00573\n",
      "epoch 739, batch 14, d_loss=-0.593 g_loss=-0.050 KID= 0.00573\n",
      "epoch 739, batch 15, d_loss=-0.644 g_loss=-0.073 KID= 0.00573\n",
      "epoch 739, batch 16, d_loss=-0.577 g_loss=-0.145 KID= 0.00573\n",
      "epoch 739, batch 17, d_loss=-0.512 g_loss=-0.205 KID= 0.00573\n",
      "epoch 739, batch 18, d_loss=-0.534 g_loss=-0.287 KID= 0.00573\n",
      "epoch 739, batch 19, d_loss=-0.442 g_loss=-0.518 KID= 0.00573\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 740, batch 0, d_loss=-0.403 g_loss=-0.636 KID= 0.00478\n",
      "epoch 740, batch 1, d_loss=-0.483 g_loss=-0.743 KID= 0.00478\n",
      "epoch 740, batch 2, d_loss=-0.495 g_loss=-0.739 KID= 0.00478\n",
      "epoch 740, batch 3, d_loss=-0.435 g_loss=-0.832 KID= 0.00478\n",
      "epoch 740, batch 4, d_loss=-0.532 g_loss=-0.760 KID= 0.00478\n",
      "epoch 740, batch 5, d_loss=-0.616 g_loss=-0.693 KID= 0.00478\n",
      "epoch 740, batch 6, d_loss=-0.580 g_loss=-0.779 KID= 0.00478\n",
      "epoch 740, batch 7, d_loss=-0.565 g_loss=-0.792 KID= 0.00478\n",
      "epoch 740, batch 8, d_loss=-0.524 g_loss=-0.585 KID= 0.00478\n",
      "epoch 740, batch 9, d_loss=-0.478 g_loss=-0.585 KID= 0.00478\n",
      "epoch 740, batch 10, d_loss=-0.382 g_loss=-0.419 KID= 0.00478\n",
      "epoch 740, batch 11, d_loss=-0.471 g_loss=-0.296 KID= 0.00478\n",
      "epoch 740, batch 12, d_loss=-0.490 g_loss=-0.184 KID= 0.00478\n",
      "epoch 740, batch 13, d_loss=-0.419 g_loss=-0.061 KID= 0.00478\n",
      "epoch 740, batch 14, d_loss=-0.571 g_loss=-0.044 KID= 0.00478\n",
      "epoch 740, batch 15, d_loss=-0.682 g_loss=0.054 KID= 0.00478\n",
      "epoch 740, batch 16, d_loss=-0.558 g_loss=0.074 KID= 0.00478\n",
      "epoch 740, batch 17, d_loss=-0.485 g_loss=0.024 KID= 0.00478\n",
      "epoch 740, batch 18, d_loss=-0.511 g_loss=-0.078 KID= 0.00478\n",
      "epoch 740, batch 19, d_loss=-0.425 g_loss=-0.365 KID= 0.00478\n",
      "epoch 741, batch 0, d_loss=-0.458 g_loss=-0.500 KID= 0.00478\n",
      "epoch 741, batch 1, d_loss=-0.522 g_loss=-0.677 KID= 0.00478\n",
      "epoch 741, batch 2, d_loss=-0.551 g_loss=-0.767 KID= 0.00478\n",
      "epoch 741, batch 3, d_loss=-0.428 g_loss=-0.759 KID= 0.00478\n",
      "epoch 741, batch 4, d_loss=-0.576 g_loss=-0.698 KID= 0.00478\n",
      "epoch 741, batch 5, d_loss=-0.651 g_loss=-0.473 KID= 0.00478\n",
      "epoch 741, batch 6, d_loss=-0.484 g_loss=-0.410 KID= 0.00478\n",
      "epoch 741, batch 7, d_loss=-0.467 g_loss=-0.336 KID= 0.00478\n",
      "epoch 741, batch 8, d_loss=-0.454 g_loss=-0.369 KID= 0.00478\n",
      "epoch 741, batch 9, d_loss=-0.465 g_loss=-0.631 KID= 0.00478\n",
      "epoch 741, batch 10, d_loss=-0.423 g_loss=-0.550 KID= 0.00478\n",
      "epoch 741, batch 11, d_loss=-0.513 g_loss=-0.515 KID= 0.00478\n",
      "epoch 741, batch 12, d_loss=-0.537 g_loss=-0.400 KID= 0.00478\n",
      "epoch 741, batch 13, d_loss=-0.430 g_loss=-0.350 KID= 0.00478\n",
      "epoch 741, batch 14, d_loss=-0.555 g_loss=-0.256 KID= 0.00478\n",
      "epoch 741, batch 15, d_loss=-0.662 g_loss=-0.154 KID= 0.00478\n",
      "epoch 741, batch 16, d_loss=-0.541 g_loss=-0.214 KID= 0.00478\n",
      "epoch 741, batch 17, d_loss=-0.522 g_loss=-0.214 KID= 0.00478\n",
      "epoch 741, batch 18, d_loss=-0.506 g_loss=-0.207 KID= 0.00478\n",
      "epoch 741, batch 19, d_loss=-0.438 g_loss=-0.408 KID= 0.00478\n",
      "epoch 742, batch 0, d_loss=-0.403 g_loss=-0.447 KID= 0.00478\n",
      "epoch 742, batch 1, d_loss=-0.503 g_loss=-0.390 KID= 0.00478\n",
      "epoch 742, batch 2, d_loss=-0.572 g_loss=-0.392 KID= 0.00478\n",
      "epoch 742, batch 3, d_loss=-0.431 g_loss=-0.340 KID= 0.00478\n",
      "epoch 742, batch 4, d_loss=-0.585 g_loss=-0.297 KID= 0.00478\n",
      "epoch 742, batch 5, d_loss=-0.668 g_loss=-0.163 KID= 0.00478\n",
      "epoch 742, batch 6, d_loss=-0.475 g_loss=-0.187 KID= 0.00478\n",
      "epoch 742, batch 7, d_loss=-0.474 g_loss=-0.241 KID= 0.00478\n",
      "epoch 742, batch 8, d_loss=-0.540 g_loss=-0.390 KID= 0.00478\n",
      "epoch 742, batch 9, d_loss=-0.489 g_loss=-0.633 KID= 0.00478\n",
      "epoch 742, batch 10, d_loss=-0.406 g_loss=-0.632 KID= 0.00478\n",
      "epoch 742, batch 11, d_loss=-0.514 g_loss=-0.646 KID= 0.00478\n",
      "epoch 742, batch 12, d_loss=-0.549 g_loss=-0.573 KID= 0.00478\n",
      "epoch 742, batch 13, d_loss=-0.420 g_loss=-0.522 KID= 0.00478\n",
      "epoch 742, batch 14, d_loss=-0.553 g_loss=-0.460 KID= 0.00478\n",
      "epoch 742, batch 15, d_loss=-0.633 g_loss=-0.374 KID= 0.00478\n",
      "epoch 742, batch 16, d_loss=-0.528 g_loss=-0.321 KID= 0.00478\n",
      "epoch 742, batch 17, d_loss=-0.496 g_loss=-0.228 KID= 0.00478\n",
      "epoch 742, batch 18, d_loss=-0.527 g_loss=-0.236 KID= 0.00478\n",
      "epoch 742, batch 19, d_loss=-0.466 g_loss=-0.455 KID= 0.00478\n",
      "epoch 743, batch 0, d_loss=-0.421 g_loss=-0.555 KID= 0.00478\n",
      "epoch 743, batch 1, d_loss=-0.510 g_loss=-0.658 KID= 0.00478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 743, batch 2, d_loss=-0.505 g_loss=-0.725 KID= 0.00478\n",
      "epoch 743, batch 3, d_loss=-0.435 g_loss=-0.726 KID= 0.00478\n",
      "epoch 743, batch 4, d_loss=-0.576 g_loss=-0.656 KID= 0.00478\n",
      "epoch 743, batch 5, d_loss=-0.672 g_loss=-0.507 KID= 0.00478\n",
      "epoch 743, batch 6, d_loss=-0.528 g_loss=-0.420 KID= 0.00478\n",
      "epoch 743, batch 7, d_loss=-0.489 g_loss=-0.218 KID= 0.00478\n",
      "epoch 743, batch 8, d_loss=-0.580 g_loss=-0.050 KID= 0.00478\n",
      "epoch 743, batch 9, d_loss=-0.419 g_loss=-0.218 KID= 0.00478\n",
      "epoch 743, batch 10, d_loss=-0.438 g_loss=-0.245 KID= 0.00478\n",
      "epoch 743, batch 11, d_loss=-0.463 g_loss=-0.197 KID= 0.00478\n",
      "epoch 743, batch 12, d_loss=-0.504 g_loss=-0.263 KID= 0.00478\n",
      "epoch 743, batch 13, d_loss=-0.385 g_loss=-0.228 KID= 0.00478\n",
      "epoch 743, batch 14, d_loss=-0.574 g_loss=-0.202 KID= 0.00478\n",
      "epoch 743, batch 15, d_loss=-0.646 g_loss=-0.253 KID= 0.00478\n",
      "epoch 743, batch 16, d_loss=-0.503 g_loss=-0.366 KID= 0.00478\n",
      "epoch 743, batch 17, d_loss=-0.510 g_loss=-0.398 KID= 0.00478\n",
      "epoch 743, batch 18, d_loss=-0.543 g_loss=-0.420 KID= 0.00478\n",
      "epoch 743, batch 19, d_loss=-0.412 g_loss=-0.509 KID= 0.00478\n",
      "epoch 744, batch 0, d_loss=-0.382 g_loss=-0.535 KID= 0.00478\n",
      "epoch 744, batch 1, d_loss=-0.450 g_loss=-0.543 KID= 0.00478\n",
      "epoch 744, batch 2, d_loss=-0.553 g_loss=-0.615 KID= 0.00478\n",
      "epoch 744, batch 3, d_loss=-0.443 g_loss=-0.553 KID= 0.00478\n",
      "epoch 744, batch 4, d_loss=-0.631 g_loss=-0.609 KID= 0.00478\n",
      "epoch 744, batch 5, d_loss=-0.621 g_loss=-0.549 KID= 0.00478\n",
      "epoch 744, batch 6, d_loss=-0.552 g_loss=-0.556 KID= 0.00478\n",
      "epoch 744, batch 7, d_loss=-0.494 g_loss=-0.365 KID= 0.00478\n",
      "epoch 744, batch 8, d_loss=-0.558 g_loss=-0.340 KID= 0.00478\n",
      "epoch 744, batch 9, d_loss=-0.473 g_loss=-0.396 KID= 0.00478\n",
      "epoch 744, batch 10, d_loss=-0.413 g_loss=-0.406 KID= 0.00478\n",
      "epoch 744, batch 11, d_loss=-0.505 g_loss=-0.321 KID= 0.00478\n",
      "epoch 744, batch 12, d_loss=-0.567 g_loss=-0.300 KID= 0.00478\n",
      "epoch 744, batch 13, d_loss=-0.478 g_loss=-0.321 KID= 0.00478\n",
      "epoch 744, batch 14, d_loss=-0.581 g_loss=-0.346 KID= 0.00478\n",
      "epoch 744, batch 15, d_loss=-0.615 g_loss=-0.328 KID= 0.00478\n",
      "epoch 744, batch 16, d_loss=-0.509 g_loss=-0.361 KID= 0.00478\n",
      "epoch 744, batch 17, d_loss=-0.500 g_loss=-0.395 KID= 0.00478\n",
      "epoch 744, batch 18, d_loss=-0.541 g_loss=-0.467 KID= 0.00478\n",
      "epoch 744, batch 19, d_loss=-0.482 g_loss=-0.532 KID= 0.00478\n",
      "epoch 745, batch 0, d_loss=-0.415 g_loss=-0.558 KID= 0.00478\n",
      "epoch 745, batch 1, d_loss=-0.548 g_loss=-0.594 KID= 0.00478\n",
      "epoch 745, batch 2, d_loss=-0.553 g_loss=-0.559 KID= 0.00478\n",
      "epoch 745, batch 3, d_loss=-0.443 g_loss=-0.467 KID= 0.00478\n",
      "epoch 745, batch 4, d_loss=-0.617 g_loss=-0.472 KID= 0.00478\n",
      "epoch 745, batch 5, d_loss=-0.656 g_loss=-0.392 KID= 0.00478\n",
      "epoch 745, batch 6, d_loss=-0.532 g_loss=-0.373 KID= 0.00478\n",
      "epoch 745, batch 7, d_loss=-0.484 g_loss=-0.320 KID= 0.00478\n",
      "epoch 745, batch 8, d_loss=-0.498 g_loss=-0.406 KID= 0.00478\n",
      "epoch 745, batch 9, d_loss=-0.513 g_loss=-0.624 KID= 0.00478\n",
      "epoch 745, batch 10, d_loss=-0.390 g_loss=-0.664 KID= 0.00478\n",
      "epoch 745, batch 11, d_loss=-0.569 g_loss=-0.771 KID= 0.00478\n",
      "epoch 745, batch 12, d_loss=-0.592 g_loss=-0.841 KID= 0.00478\n",
      "epoch 745, batch 13, d_loss=-0.349 g_loss=-0.742 KID= 0.00478\n",
      "epoch 745, batch 14, d_loss=-0.650 g_loss=-0.731 KID= 0.00478\n",
      "epoch 745, batch 15, d_loss=-0.627 g_loss=-0.603 KID= 0.00478\n",
      "epoch 745, batch 16, d_loss=-0.521 g_loss=-0.422 KID= 0.00478\n",
      "epoch 745, batch 17, d_loss=-0.515 g_loss=-0.242 KID= 0.00478\n",
      "epoch 745, batch 18, d_loss=-0.572 g_loss=-0.115 KID= 0.00478\n",
      "epoch 745, batch 19, d_loss=-0.431 g_loss=-0.189 KID= 0.00478\n",
      "epoch 746, batch 0, d_loss=-0.421 g_loss=-0.206 KID= 0.00478\n",
      "epoch 746, batch 1, d_loss=-0.482 g_loss=-0.220 KID= 0.00478\n",
      "epoch 746, batch 2, d_loss=-0.602 g_loss=-0.249 KID= 0.00478\n",
      "epoch 746, batch 3, d_loss=-0.409 g_loss=-0.192 KID= 0.00478\n",
      "epoch 746, batch 4, d_loss=-0.611 g_loss=-0.144 KID= 0.00478\n",
      "epoch 746, batch 5, d_loss=-0.581 g_loss=-0.161 KID= 0.00478\n",
      "epoch 746, batch 6, d_loss=-0.517 g_loss=-0.077 KID= 0.00478\n",
      "epoch 746, batch 7, d_loss=-0.451 g_loss=-0.066 KID= 0.00478\n",
      "epoch 746, batch 8, d_loss=-0.560 g_loss=-0.099 KID= 0.00478\n",
      "epoch 746, batch 9, d_loss=-0.449 g_loss=-0.141 KID= 0.00478\n",
      "epoch 746, batch 10, d_loss=-0.434 g_loss=-0.218 KID= 0.00478\n",
      "epoch 746, batch 11, d_loss=-0.534 g_loss=-0.550 KID= 0.00478\n",
      "epoch 746, batch 12, d_loss=-0.540 g_loss=-0.756 KID= 0.00478\n",
      "epoch 746, batch 13, d_loss=-0.447 g_loss=-0.779 KID= 0.00478\n",
      "epoch 746, batch 14, d_loss=-0.619 g_loss=-0.719 KID= 0.00478\n",
      "epoch 746, batch 15, d_loss=-0.660 g_loss=-0.717 KID= 0.00478\n",
      "epoch 746, batch 16, d_loss=-0.538 g_loss=-0.750 KID= 0.00478\n",
      "epoch 746, batch 17, d_loss=-0.515 g_loss=-0.615 KID= 0.00478\n",
      "epoch 746, batch 18, d_loss=-0.585 g_loss=-0.485 KID= 0.00478\n",
      "epoch 746, batch 19, d_loss=-0.460 g_loss=-0.422 KID= 0.00478\n",
      "epoch 747, batch 0, d_loss=-0.422 g_loss=-0.311 KID= 0.00478\n",
      "epoch 747, batch 1, d_loss=-0.555 g_loss=-0.295 KID= 0.00478\n",
      "epoch 747, batch 2, d_loss=-0.578 g_loss=-0.265 KID= 0.00478\n",
      "epoch 747, batch 3, d_loss=-0.377 g_loss=-0.285 KID= 0.00478\n",
      "epoch 747, batch 4, d_loss=-0.614 g_loss=-0.305 KID= 0.00478\n",
      "epoch 747, batch 5, d_loss=-0.625 g_loss=-0.181 KID= 0.00478\n",
      "epoch 747, batch 6, d_loss=-0.558 g_loss=-0.137 KID= 0.00478\n",
      "epoch 747, batch 7, d_loss=-0.507 g_loss=-0.158 KID= 0.00478\n",
      "epoch 747, batch 8, d_loss=-0.537 g_loss=-0.114 KID= 0.00478\n",
      "epoch 747, batch 9, d_loss=-0.481 g_loss=-0.201 KID= 0.00478\n",
      "epoch 747, batch 10, d_loss=-0.397 g_loss=-0.344 KID= 0.00478\n",
      "epoch 747, batch 11, d_loss=-0.535 g_loss=-0.480 KID= 0.00478\n",
      "epoch 747, batch 12, d_loss=-0.499 g_loss=-0.573 KID= 0.00478\n",
      "epoch 747, batch 13, d_loss=-0.409 g_loss=-0.620 KID= 0.00478\n",
      "epoch 747, batch 14, d_loss=-0.598 g_loss=-0.652 KID= 0.00478\n",
      "epoch 747, batch 15, d_loss=-0.672 g_loss=-0.647 KID= 0.00478\n",
      "epoch 747, batch 16, d_loss=-0.544 g_loss=-0.635 KID= 0.00478\n",
      "epoch 747, batch 17, d_loss=-0.529 g_loss=-0.638 KID= 0.00478\n",
      "epoch 747, batch 18, d_loss=-0.491 g_loss=-0.456 KID= 0.00478\n",
      "epoch 747, batch 19, d_loss=-0.500 g_loss=-0.438 KID= 0.00478\n",
      "epoch 748, batch 0, d_loss=-0.434 g_loss=-0.347 KID= 0.00478\n",
      "epoch 748, batch 1, d_loss=-0.569 g_loss=-0.316 KID= 0.00478\n",
      "epoch 748, batch 2, d_loss=-0.553 g_loss=-0.384 KID= 0.00478\n",
      "epoch 748, batch 3, d_loss=-0.438 g_loss=-0.344 KID= 0.00478\n",
      "epoch 748, batch 4, d_loss=-0.636 g_loss=-0.314 KID= 0.00478\n",
      "epoch 748, batch 5, d_loss=-0.664 g_loss=-0.286 KID= 0.00478\n",
      "epoch 748, batch 6, d_loss=-0.503 g_loss=-0.366 KID= 0.00478\n",
      "epoch 748, batch 7, d_loss=-0.512 g_loss=-0.345 KID= 0.00478\n",
      "epoch 748, batch 8, d_loss=-0.534 g_loss=-0.301 KID= 0.00478\n",
      "epoch 748, batch 9, d_loss=-0.497 g_loss=-0.352 KID= 0.00478\n",
      "epoch 748, batch 10, d_loss=-0.413 g_loss=-0.359 KID= 0.00478\n",
      "epoch 748, batch 11, d_loss=-0.498 g_loss=-0.504 KID= 0.00478\n",
      "epoch 748, batch 12, d_loss=-0.548 g_loss=-0.717 KID= 0.00478\n",
      "epoch 748, batch 13, d_loss=-0.450 g_loss=-0.729 KID= 0.00478\n",
      "epoch 748, batch 14, d_loss=-0.617 g_loss=-0.609 KID= 0.00478\n",
      "epoch 748, batch 15, d_loss=-0.649 g_loss=-0.459 KID= 0.00478\n",
      "epoch 748, batch 16, d_loss=-0.589 g_loss=-0.316 KID= 0.00478\n",
      "epoch 748, batch 17, d_loss=-0.458 g_loss=-0.174 KID= 0.00478\n",
      "epoch 748, batch 18, d_loss=-0.561 g_loss=-0.157 KID= 0.00478\n",
      "epoch 748, batch 19, d_loss=-0.507 g_loss=-0.285 KID= 0.00478\n",
      "epoch 749, batch 0, d_loss=-0.414 g_loss=-0.199 KID= 0.00478\n",
      "epoch 749, batch 1, d_loss=-0.540 g_loss=-0.186 KID= 0.00478\n",
      "epoch 749, batch 2, d_loss=-0.567 g_loss=-0.303 KID= 0.00478\n",
      "epoch 749, batch 3, d_loss=-0.448 g_loss=-0.291 KID= 0.00478\n",
      "epoch 749, batch 4, d_loss=-0.653 g_loss=-0.339 KID= 0.00478\n",
      "epoch 749, batch 5, d_loss=-0.651 g_loss=-0.413 KID= 0.00478\n",
      "epoch 749, batch 6, d_loss=-0.530 g_loss=-0.446 KID= 0.00478\n",
      "epoch 749, batch 7, d_loss=-0.500 g_loss=-0.368 KID= 0.00478\n",
      "epoch 749, batch 8, d_loss=-0.555 g_loss=-0.351 KID= 0.00478\n",
      "epoch 749, batch 9, d_loss=-0.463 g_loss=-0.405 KID= 0.00478\n",
      "epoch 749, batch 10, d_loss=-0.393 g_loss=-0.406 KID= 0.00478\n",
      "epoch 749, batch 11, d_loss=-0.540 g_loss=-0.367 KID= 0.00478\n",
      "epoch 749, batch 12, d_loss=-0.582 g_loss=-0.327 KID= 0.00478\n",
      "epoch 749, batch 13, d_loss=-0.446 g_loss=-0.363 KID= 0.00478\n",
      "epoch 749, batch 14, d_loss=-0.589 g_loss=-0.424 KID= 0.00478\n",
      "epoch 749, batch 15, d_loss=-0.628 g_loss=-0.344 KID= 0.00478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 749, batch 16, d_loss=-0.540 g_loss=-0.434 KID= 0.00478\n",
      "epoch 749, batch 17, d_loss=-0.486 g_loss=-0.385 KID= 0.00478\n",
      "epoch 749, batch 18, d_loss=-0.569 g_loss=-0.351 KID= 0.00478\n",
      "epoch 749, batch 19, d_loss=-0.468 g_loss=-0.502 KID= 0.00478\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 750, batch 0, d_loss=-0.429 g_loss=-0.440 KID= 0.00582\n",
      "epoch 750, batch 1, d_loss=-0.492 g_loss=-0.397 KID= 0.00582\n",
      "epoch 750, batch 2, d_loss=-0.579 g_loss=-0.430 KID= 0.00582\n",
      "epoch 750, batch 3, d_loss=-0.445 g_loss=-0.413 KID= 0.00582\n",
      "epoch 750, batch 4, d_loss=-0.592 g_loss=-0.441 KID= 0.00582\n",
      "epoch 750, batch 5, d_loss=-0.631 g_loss=-0.417 KID= 0.00582\n",
      "epoch 750, batch 6, d_loss=-0.564 g_loss=-0.486 KID= 0.00582\n",
      "epoch 750, batch 7, d_loss=-0.436 g_loss=-0.422 KID= 0.00582\n",
      "epoch 750, batch 8, d_loss=-0.528 g_loss=-0.443 KID= 0.00582\n",
      "epoch 750, batch 9, d_loss=-0.518 g_loss=-0.550 KID= 0.00582\n",
      "epoch 750, batch 10, d_loss=-0.386 g_loss=-0.431 KID= 0.00582\n",
      "epoch 750, batch 11, d_loss=-0.516 g_loss=-0.448 KID= 0.00582\n",
      "epoch 750, batch 12, d_loss=-0.555 g_loss=-0.579 KID= 0.00582\n",
      "epoch 750, batch 13, d_loss=-0.477 g_loss=-0.674 KID= 0.00582\n",
      "epoch 750, batch 14, d_loss=-0.615 g_loss=-0.687 KID= 0.00582\n",
      "epoch 750, batch 15, d_loss=-0.704 g_loss=-0.540 KID= 0.00582\n",
      "epoch 750, batch 16, d_loss=-0.525 g_loss=-0.449 KID= 0.00582\n",
      "epoch 750, batch 17, d_loss=-0.438 g_loss=-0.415 KID= 0.00582\n",
      "epoch 750, batch 18, d_loss=-0.558 g_loss=-0.353 KID= 0.00582\n",
      "epoch 750, batch 19, d_loss=-0.528 g_loss=-0.475 KID= 0.00582\n",
      "epoch 751, batch 0, d_loss=-0.441 g_loss=-0.469 KID= 0.00582\n",
      "epoch 751, batch 1, d_loss=-0.507 g_loss=-0.403 KID= 0.00582\n",
      "epoch 751, batch 2, d_loss=-0.551 g_loss=-0.467 KID= 0.00582\n",
      "epoch 751, batch 3, d_loss=-0.485 g_loss=-0.591 KID= 0.00582\n",
      "epoch 751, batch 4, d_loss=-0.635 g_loss=-0.639 KID= 0.00582\n",
      "epoch 751, batch 5, d_loss=-0.589 g_loss=-0.628 KID= 0.00582\n",
      "epoch 751, batch 6, d_loss=-0.594 g_loss=-0.547 KID= 0.00582\n",
      "epoch 751, batch 7, d_loss=-0.457 g_loss=-0.330 KID= 0.00582\n",
      "epoch 751, batch 8, d_loss=-0.591 g_loss=-0.252 KID= 0.00582\n",
      "epoch 751, batch 9, d_loss=-0.459 g_loss=-0.284 KID= 0.00582\n",
      "epoch 751, batch 10, d_loss=-0.367 g_loss=-0.145 KID= 0.00582\n",
      "epoch 751, batch 11, d_loss=-0.546 g_loss=-0.069 KID= 0.00582\n",
      "epoch 751, batch 12, d_loss=-0.564 g_loss=0.000 KID= 0.00582\n",
      "epoch 751, batch 13, d_loss=-0.450 g_loss=-0.021 KID= 0.00582\n",
      "epoch 751, batch 14, d_loss=-0.630 g_loss=0.091 KID= 0.00582\n",
      "epoch 751, batch 15, d_loss=-0.626 g_loss=0.138 KID= 0.00582\n",
      "epoch 751, batch 16, d_loss=-0.544 g_loss=0.012 KID= 0.00582\n",
      "epoch 751, batch 17, d_loss=-0.443 g_loss=0.034 KID= 0.00582\n",
      "epoch 751, batch 18, d_loss=-0.534 g_loss=0.023 KID= 0.00582\n",
      "epoch 751, batch 19, d_loss=-0.526 g_loss=-0.076 KID= 0.00582\n",
      "epoch 752, batch 0, d_loss=-0.366 g_loss=-0.078 KID= 0.00582\n",
      "epoch 752, batch 1, d_loss=-0.504 g_loss=-0.169 KID= 0.00582\n",
      "epoch 752, batch 2, d_loss=-0.563 g_loss=-0.329 KID= 0.00582\n",
      "epoch 752, batch 3, d_loss=-0.423 g_loss=-0.503 KID= 0.00582\n",
      "epoch 752, batch 4, d_loss=-0.629 g_loss=-0.573 KID= 0.00582\n",
      "epoch 752, batch 5, d_loss=-0.628 g_loss=-0.677 KID= 0.00582\n",
      "epoch 752, batch 6, d_loss=-0.563 g_loss=-0.782 KID= 0.00582\n",
      "epoch 752, batch 7, d_loss=-0.474 g_loss=-0.700 KID= 0.00582\n",
      "epoch 752, batch 8, d_loss=-0.572 g_loss=-0.558 KID= 0.00582\n",
      "epoch 752, batch 9, d_loss=-0.500 g_loss=-0.350 KID= 0.00582\n",
      "epoch 752, batch 10, d_loss=-0.449 g_loss=-0.087 KID= 0.00582\n",
      "epoch 752, batch 11, d_loss=-0.568 g_loss=0.010 KID= 0.00582\n",
      "epoch 752, batch 12, d_loss=-0.558 g_loss=-0.035 KID= 0.00582\n",
      "epoch 752, batch 13, d_loss=-0.511 g_loss=-0.146 KID= 0.00582\n",
      "epoch 752, batch 14, d_loss=-0.621 g_loss=-0.191 KID= 0.00582\n",
      "epoch 752, batch 15, d_loss=-0.626 g_loss=-0.137 KID= 0.00582\n",
      "epoch 752, batch 16, d_loss=-0.613 g_loss=-0.184 KID= 0.00582\n",
      "epoch 752, batch 17, d_loss=-0.459 g_loss=-0.234 KID= 0.00582\n",
      "epoch 752, batch 18, d_loss=-0.550 g_loss=-0.325 KID= 0.00582\n",
      "epoch 752, batch 19, d_loss=-0.492 g_loss=-0.476 KID= 0.00582\n",
      "epoch 753, batch 0, d_loss=-0.377 g_loss=-0.353 KID= 0.00582\n",
      "epoch 753, batch 1, d_loss=-0.503 g_loss=-0.407 KID= 0.00582\n",
      "epoch 753, batch 2, d_loss=-0.558 g_loss=-0.480 KID= 0.00582\n",
      "epoch 753, batch 3, d_loss=-0.458 g_loss=-0.654 KID= 0.00582\n",
      "epoch 753, batch 4, d_loss=-0.600 g_loss=-0.658 KID= 0.00582\n",
      "epoch 753, batch 5, d_loss=-0.582 g_loss=-0.563 KID= 0.00582\n",
      "epoch 753, batch 6, d_loss=-0.535 g_loss=-0.547 KID= 0.00582\n",
      "epoch 753, batch 7, d_loss=-0.470 g_loss=-0.408 KID= 0.00582\n",
      "epoch 753, batch 8, d_loss=-0.538 g_loss=-0.310 KID= 0.00582\n",
      "epoch 753, batch 9, d_loss=-0.492 g_loss=-0.542 KID= 0.00582\n",
      "epoch 753, batch 10, d_loss=-0.455 g_loss=-0.470 KID= 0.00582\n",
      "epoch 753, batch 11, d_loss=-0.510 g_loss=-0.321 KID= 0.00582\n",
      "epoch 753, batch 12, d_loss=-0.500 g_loss=-0.402 KID= 0.00582\n",
      "epoch 753, batch 13, d_loss=-0.525 g_loss=-0.451 KID= 0.00582\n",
      "epoch 753, batch 14, d_loss=-0.606 g_loss=-0.469 KID= 0.00582\n",
      "epoch 753, batch 15, d_loss=-0.615 g_loss=-0.489 KID= 0.00582\n",
      "epoch 753, batch 16, d_loss=-0.564 g_loss=-0.394 KID= 0.00582\n",
      "epoch 753, batch 17, d_loss=-0.482 g_loss=-0.289 KID= 0.00582\n",
      "epoch 753, batch 18, d_loss=-0.568 g_loss=-0.240 KID= 0.00582\n",
      "epoch 753, batch 19, d_loss=-0.490 g_loss=-0.183 KID= 0.00582\n",
      "epoch 754, batch 0, d_loss=-0.424 g_loss=-0.097 KID= 0.00582\n",
      "epoch 754, batch 1, d_loss=-0.589 g_loss=-0.116 KID= 0.00582\n",
      "epoch 754, batch 2, d_loss=-0.536 g_loss=-0.098 KID= 0.00582\n",
      "epoch 754, batch 3, d_loss=-0.438 g_loss=-0.161 KID= 0.00582\n",
      "epoch 754, batch 4, d_loss=-0.614 g_loss=-0.254 KID= 0.00582\n",
      "epoch 754, batch 5, d_loss=-0.639 g_loss=-0.330 KID= 0.00582\n",
      "epoch 754, batch 6, d_loss=-0.567 g_loss=-0.270 KID= 0.00582\n",
      "epoch 754, batch 7, d_loss=-0.491 g_loss=-0.215 KID= 0.00582\n",
      "epoch 754, batch 8, d_loss=-0.562 g_loss=-0.231 KID= 0.00582\n",
      "epoch 754, batch 9, d_loss=-0.506 g_loss=-0.224 KID= 0.00582\n",
      "epoch 754, batch 10, d_loss=-0.447 g_loss=-0.081 KID= 0.00582\n",
      "epoch 754, batch 11, d_loss=-0.543 g_loss=-0.010 KID= 0.00582\n",
      "epoch 754, batch 12, d_loss=-0.531 g_loss=-0.112 KID= 0.00582\n",
      "epoch 754, batch 13, d_loss=-0.504 g_loss=-0.246 KID= 0.00582\n",
      "epoch 754, batch 14, d_loss=-0.625 g_loss=-0.421 KID= 0.00582\n",
      "epoch 754, batch 15, d_loss=-0.652 g_loss=-0.482 KID= 0.00582\n",
      "epoch 754, batch 16, d_loss=-0.554 g_loss=-0.450 KID= 0.00582\n",
      "epoch 754, batch 17, d_loss=-0.474 g_loss=-0.319 KID= 0.00582\n",
      "epoch 754, batch 18, d_loss=-0.566 g_loss=-0.238 KID= 0.00582\n",
      "epoch 754, batch 19, d_loss=-0.509 g_loss=-0.329 KID= 0.00582\n",
      "epoch 755, batch 0, d_loss=-0.421 g_loss=-0.316 KID= 0.00582\n",
      "epoch 755, batch 1, d_loss=-0.557 g_loss=-0.280 KID= 0.00582\n",
      "epoch 755, batch 2, d_loss=-0.567 g_loss=-0.323 KID= 0.00582\n",
      "epoch 755, batch 3, d_loss=-0.491 g_loss=-0.430 KID= 0.00582\n",
      "epoch 755, batch 4, d_loss=-0.619 g_loss=-0.447 KID= 0.00582\n",
      "epoch 755, batch 5, d_loss=-0.588 g_loss=-0.480 KID= 0.00582\n",
      "epoch 755, batch 6, d_loss=-0.502 g_loss=-0.445 KID= 0.00582\n",
      "epoch 755, batch 7, d_loss=-0.509 g_loss=-0.344 KID= 0.00582\n",
      "epoch 755, batch 8, d_loss=-0.507 g_loss=-0.195 KID= 0.00582\n",
      "epoch 755, batch 9, d_loss=-0.524 g_loss=-0.209 KID= 0.00582\n",
      "epoch 755, batch 10, d_loss=-0.412 g_loss=-0.150 KID= 0.00582\n",
      "epoch 755, batch 11, d_loss=-0.501 g_loss=-0.052 KID= 0.00582\n",
      "epoch 755, batch 12, d_loss=-0.496 g_loss=-0.054 KID= 0.00582\n",
      "epoch 755, batch 13, d_loss=-0.544 g_loss=-0.177 KID= 0.00582\n",
      "epoch 755, batch 14, d_loss=-0.588 g_loss=-0.290 KID= 0.00582\n",
      "epoch 755, batch 15, d_loss=-0.658 g_loss=-0.563 KID= 0.00582\n",
      "epoch 755, batch 16, d_loss=-0.560 g_loss=-0.586 KID= 0.00582\n",
      "epoch 755, batch 17, d_loss=-0.482 g_loss=-0.607 KID= 0.00582\n",
      "epoch 755, batch 18, d_loss=-0.582 g_loss=-0.588 KID= 0.00582\n",
      "epoch 755, batch 19, d_loss=-0.513 g_loss=-0.569 KID= 0.00582\n",
      "epoch 756, batch 0, d_loss=-0.391 g_loss=-0.407 KID= 0.00582\n",
      "epoch 756, batch 1, d_loss=-0.522 g_loss=-0.288 KID= 0.00582\n",
      "epoch 756, batch 2, d_loss=-0.584 g_loss=-0.060 KID= 0.00582\n",
      "epoch 756, batch 3, d_loss=-0.530 g_loss=0.065 KID= 0.00582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 756, batch 4, d_loss=-0.614 g_loss=0.019 KID= 0.00582\n",
      "epoch 756, batch 5, d_loss=-0.614 g_loss=-0.151 KID= 0.00582\n",
      "epoch 756, batch 6, d_loss=-0.555 g_loss=-0.276 KID= 0.00582\n",
      "epoch 756, batch 7, d_loss=-0.474 g_loss=-0.532 KID= 0.00582\n",
      "epoch 756, batch 8, d_loss=-0.480 g_loss=-0.590 KID= 0.00582\n",
      "epoch 756, batch 9, d_loss=-0.535 g_loss=-0.693 KID= 0.00582\n",
      "epoch 756, batch 10, d_loss=-0.439 g_loss=-0.564 KID= 0.00582\n",
      "epoch 756, batch 11, d_loss=-0.536 g_loss=-0.595 KID= 0.00582\n",
      "epoch 756, batch 12, d_loss=-0.563 g_loss=-0.578 KID= 0.00582\n",
      "epoch 756, batch 13, d_loss=-0.455 g_loss=-0.575 KID= 0.00582\n",
      "epoch 756, batch 14, d_loss=-0.612 g_loss=-0.535 KID= 0.00582\n",
      "epoch 756, batch 15, d_loss=-0.683 g_loss=-0.559 KID= 0.00582\n",
      "epoch 756, batch 16, d_loss=-0.544 g_loss=-0.551 KID= 0.00582\n",
      "epoch 756, batch 17, d_loss=-0.481 g_loss=-0.412 KID= 0.00582\n",
      "epoch 756, batch 18, d_loss=-0.480 g_loss=-0.286 KID= 0.00582\n",
      "epoch 756, batch 19, d_loss=-0.540 g_loss=-0.265 KID= 0.00582\n",
      "epoch 757, batch 0, d_loss=-0.407 g_loss=-0.220 KID= 0.00582\n",
      "epoch 757, batch 1, d_loss=-0.518 g_loss=-0.090 KID= 0.00582\n",
      "epoch 757, batch 2, d_loss=-0.572 g_loss=-0.006 KID= 0.00582\n",
      "epoch 757, batch 3, d_loss=-0.493 g_loss=0.032 KID= 0.00582\n",
      "epoch 757, batch 4, d_loss=-0.585 g_loss=0.036 KID= 0.00582\n",
      "epoch 757, batch 5, d_loss=-0.580 g_loss=-0.108 KID= 0.00582\n",
      "epoch 757, batch 6, d_loss=-0.539 g_loss=-0.221 KID= 0.00582\n",
      "epoch 757, batch 7, d_loss=-0.480 g_loss=-0.251 KID= 0.00582\n",
      "epoch 757, batch 8, d_loss=-0.539 g_loss=-0.403 KID= 0.00582\n",
      "epoch 757, batch 9, d_loss=-0.530 g_loss=-0.589 KID= 0.00582\n",
      "epoch 757, batch 10, d_loss=-0.413 g_loss=-0.597 KID= 0.00582\n",
      "epoch 757, batch 11, d_loss=-0.567 g_loss=-0.523 KID= 0.00582\n",
      "epoch 757, batch 12, d_loss=-0.571 g_loss=-0.441 KID= 0.00582\n",
      "epoch 757, batch 13, d_loss=-0.511 g_loss=-0.328 KID= 0.00582\n",
      "epoch 757, batch 14, d_loss=-0.574 g_loss=-0.354 KID= 0.00582\n",
      "epoch 757, batch 15, d_loss=-0.651 g_loss=-0.440 KID= 0.00582\n",
      "epoch 757, batch 16, d_loss=-0.539 g_loss=-0.531 KID= 0.00582\n",
      "epoch 757, batch 17, d_loss=-0.478 g_loss=-0.561 KID= 0.00582\n",
      "epoch 757, batch 18, d_loss=-0.548 g_loss=-0.541 KID= 0.00582\n",
      "epoch 757, batch 19, d_loss=-0.583 g_loss=-0.569 KID= 0.00582\n",
      "epoch 758, batch 0, d_loss=-0.388 g_loss=-0.499 KID= 0.00582\n",
      "epoch 758, batch 1, d_loss=-0.504 g_loss=-0.631 KID= 0.00582\n",
      "epoch 758, batch 2, d_loss=-0.602 g_loss=-0.597 KID= 0.00582\n",
      "epoch 758, batch 3, d_loss=-0.446 g_loss=-0.405 KID= 0.00582\n",
      "epoch 758, batch 4, d_loss=-0.573 g_loss=-0.397 KID= 0.00582\n",
      "epoch 758, batch 5, d_loss=-0.692 g_loss=-0.535 KID= 0.00582\n",
      "epoch 758, batch 6, d_loss=-0.474 g_loss=-0.519 KID= 0.00582\n",
      "epoch 758, batch 7, d_loss=-0.516 g_loss=-0.491 KID= 0.00582\n",
      "epoch 758, batch 8, d_loss=-0.449 g_loss=-0.390 KID= 0.00582\n",
      "epoch 758, batch 9, d_loss=-0.562 g_loss=-0.401 KID= 0.00582\n",
      "epoch 758, batch 10, d_loss=-0.473 g_loss=-0.306 KID= 0.00582\n",
      "epoch 758, batch 11, d_loss=-0.522 g_loss=-0.290 KID= 0.00582\n",
      "epoch 758, batch 12, d_loss=-0.598 g_loss=-0.123 KID= 0.00582\n",
      "epoch 758, batch 13, d_loss=-0.475 g_loss=-0.026 KID= 0.00582\n",
      "epoch 758, batch 14, d_loss=-0.606 g_loss=0.036 KID= 0.00582\n",
      "epoch 758, batch 15, d_loss=-0.655 g_loss=-0.075 KID= 0.00582\n",
      "epoch 758, batch 16, d_loss=-0.440 g_loss=-0.323 KID= 0.00582\n",
      "epoch 758, batch 17, d_loss=-0.453 g_loss=-0.523 KID= 0.00582\n",
      "epoch 758, batch 18, d_loss=-0.524 g_loss=-0.660 KID= 0.00582\n",
      "epoch 758, batch 19, d_loss=-0.507 g_loss=-0.785 KID= 0.00582\n",
      "epoch 759, batch 0, d_loss=-0.469 g_loss=-0.803 KID= 0.00582\n",
      "epoch 759, batch 1, d_loss=-0.526 g_loss=-0.765 KID= 0.00582\n",
      "epoch 759, batch 2, d_loss=-0.602 g_loss=-0.655 KID= 0.00582\n",
      "epoch 759, batch 3, d_loss=-0.474 g_loss=-0.444 KID= 0.00582\n",
      "epoch 759, batch 4, d_loss=-0.551 g_loss=-0.315 KID= 0.00582\n",
      "epoch 759, batch 5, d_loss=-0.658 g_loss=-0.295 KID= 0.00582\n",
      "epoch 759, batch 6, d_loss=-0.444 g_loss=-0.286 KID= 0.00582\n",
      "epoch 759, batch 7, d_loss=-0.512 g_loss=-0.284 KID= 0.00582\n",
      "epoch 759, batch 8, d_loss=-0.547 g_loss=-0.167 KID= 0.00582\n",
      "epoch 759, batch 9, d_loss=-0.486 g_loss=-0.180 KID= 0.00582\n",
      "epoch 759, batch 10, d_loss=-0.514 g_loss=-0.143 KID= 0.00582\n",
      "epoch 759, batch 11, d_loss=-0.518 g_loss=-0.026 KID= 0.00582\n",
      "epoch 759, batch 12, d_loss=-0.501 g_loss=-0.035 KID= 0.00582\n",
      "epoch 759, batch 13, d_loss=-0.414 g_loss=0.178 KID= 0.00582\n",
      "epoch 759, batch 14, d_loss=-0.570 g_loss=0.252 KID= 0.00582\n",
      "epoch 759, batch 15, d_loss=-0.648 g_loss=0.119 KID= 0.00582\n",
      "epoch 759, batch 16, d_loss=-0.585 g_loss=0.169 KID= 0.00582\n",
      "epoch 759, batch 17, d_loss=-0.558 g_loss=0.121 KID= 0.00582\n",
      "epoch 759, batch 18, d_loss=-0.532 g_loss=-0.097 KID= 0.00582\n",
      "epoch 759, batch 19, d_loss=-0.500 g_loss=-0.414 KID= 0.00582\n",
      "Processing Figure 0\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "epoch 760, batch 0, d_loss=-0.426 g_loss=-0.674 KID= 0.00693\n",
      "epoch 760, batch 1, d_loss=-0.525 g_loss=-0.739 KID= 0.00693\n",
      "epoch 760, batch 2, d_loss=-0.501 g_loss=-0.553 KID= 0.00693\n",
      "epoch 760, batch 3, d_loss=-0.475 g_loss=-0.333 KID= 0.00693\n",
      "epoch 760, batch 4, d_loss=-0.537 g_loss=-0.317 KID= 0.00693\n",
      "epoch 760, batch 5, d_loss=-0.656 g_loss=-0.371 KID= 0.00693\n",
      "epoch 760, batch 6, d_loss=-0.514 g_loss=-0.335 KID= 0.00693\n",
      "epoch 760, batch 7, d_loss=-0.466 g_loss=-0.282 KID= 0.00693\n",
      "epoch 760, batch 8, d_loss=-0.468 g_loss=-0.208 KID= 0.00693\n",
      "epoch 760, batch 9, d_loss=-0.447 g_loss=-0.090 KID= 0.00693\n",
      "epoch 760, batch 10, d_loss=-0.511 g_loss=0.100 KID= 0.00693\n",
      "epoch 760, batch 11, d_loss=-0.479 g_loss=0.131 KID= 0.00693\n",
      "epoch 760, batch 12, d_loss=-0.597 g_loss=0.107 KID= 0.00693\n",
      "epoch 760, batch 13, d_loss=-0.441 g_loss=0.094 KID= 0.00693\n",
      "epoch 760, batch 14, d_loss=-0.535 g_loss=-0.035 KID= 0.00693\n",
      "epoch 760, batch 15, d_loss=-0.666 g_loss=-0.126 KID= 0.00693\n",
      "epoch 760, batch 16, d_loss=-0.509 g_loss=-0.297 KID= 0.00693\n",
      "epoch 760, batch 17, d_loss=-0.528 g_loss=-0.466 KID= 0.00693\n",
      "epoch 760, batch 18, d_loss=-0.495 g_loss=-0.770 KID= 0.00693\n",
      "epoch 760, batch 19, d_loss=-0.458 g_loss=-1.088 KID= 0.00693\n",
      "epoch 761, batch 0, d_loss=-0.429 g_loss=-1.190 KID= 0.00693\n",
      "epoch 761, batch 1, d_loss=-0.552 g_loss=-1.301 KID= 0.00693\n",
      "epoch 761, batch 2, d_loss=-0.575 g_loss=-1.214 KID= 0.00693\n",
      "epoch 761, batch 3, d_loss=-0.419 g_loss=-0.878 KID= 0.00693\n",
      "epoch 761, batch 4, d_loss=-0.551 g_loss=-0.504 KID= 0.00693\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [12], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m GENERATOR\u001b[38;5;241m=\u001b[39mG_Create_CNN(latent_dim_G)\n\u001b[0;32m     17\u001b[0m GENERATOR\u001b[38;5;241m.\u001b[39m_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerator\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 19\u001b[0m _\u001b[38;5;241m=\u001b[39m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGENERATOR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDISCRIMINATOR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim_G\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTrainData\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNumEpochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mImageShape\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [11], line 51\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(GENERATOR, DISCRIMINATOR, latent_dim_G, TrainData, batch_size, NumEpochs, ImageShape)\u001b[0m\n\u001b[0;32m     48\u001b[0m     d_loss \u001b[38;5;241m=\u001b[39m d_cost \u001b[38;5;241m+\u001b[39m gp \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10.0\u001b[39m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Get the gradients w.r.t the discriminator loss\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m d_gradient \u001b[38;5;241m=\u001b[39m \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDISCRIMINATOR\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Update the weights of the discriminator using the discriminator optimizer\u001b[39;00m\n\u001b[0;32m     53\u001b[0m discriminator_optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(d_gradient, DISCRIMINATOR\u001b[38;5;241m.\u001b[39mtrainable_variables))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TF_V0\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1084\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_gradients \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1081\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m   1082\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mflatten(output_gradients)]\n\u001b[1;32m-> 1084\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m \u001b[43mimperative_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimperative_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1088\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1089\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflat_sources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1090\u001b[0m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n\u001b[0;32m   1093\u001b[0m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_watched_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TF_V0\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:71\u001b[0m, in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m     68\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     69\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m unconnected_gradients)\n\u001b[1;32m---> 71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_TapeGradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TF_V0\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:159\u001b[0m, in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    157\u001b[0m     gradient_name_scope \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m forward_pass_name_scope \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    158\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[1;32m--> 159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmock_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m grad_fn(mock_op, \u001b[38;5;241m*\u001b[39mout_grads)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TF_V0\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:264\u001b[0m, in \u001b[0;36m_MeanGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    262\u001b[0m   output_size \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mprod(output_shape)\n\u001b[0;32m    263\u001b[0m   factor \u001b[38;5;241m=\u001b[39m input_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mmax\u001b[39m(output_size, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 264\u001b[0m   factor \u001b[38;5;241m=\u001b[39m \u001b[43mconstant_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfactor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msum_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    266\u001b[0m   input_shape \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39mshape(op\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TF_V0\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:271\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    176\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 271\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TF_V0\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:283\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    282\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 283\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[0;32m    286\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TF_V0\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:308\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[0;32m    307\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 308\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    309\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "latent_dim_G=100 #40\n",
    "batch_size=256#64/2\n",
    "NumEpochs=10000\n",
    "\n",
    "#GaussianData_Interpolated=np.load(\"GaussianData_Interpolated.npz\")\n",
    "#GaussianSample=GaussianData_Interpolated[\"GaussianSample\"]\n",
    "\n",
    "ImageShape=EnergyPu.shape[1:]\n",
    "TrainData=EnergyPu#EnergyPu # GaussianSample\n",
    "\n",
    "DISCRIMINATOR=D_Create_CNN(in_shape=ImageShape)\n",
    "DISCRIMINATOR._name=\"Discriminator\"\n",
    "\n",
    "GENERATOR=G_Create_CNN(latent_dim_G)\n",
    "GENERATOR._name=\"Generator\"\n",
    "\n",
    "_=train(GENERATOR, DISCRIMINATOR, latent_dim_G, TrainData, batch_size, NumEpochs,ImageShape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299faec6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "fb077fb1c95689db1cf48f7ced55ef86eeb4a299ea5885bf4f26b586756a7374"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
